---
title: Geopolitical and governance implications of AI
videoId: wvBzGK72rgU
---

From: [[josephnoelwalker]] <br/> 

Larry Summers, a prominent American Economic Policy maker and current board member at OpenAI, shared his insights on the profound [[impact_of_ai_on_economic_growth | economic implications of AI]], as well as its governance and geopolitical dimensions <a class="yt-timestamp" data-t="00:00:05">[00:00:05]</a>. He views technology as the primary driver of major historical inflection points <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>, noting that two-thirds of all GDP ever produced by human beings occurred during his lifetime <a class="yt-timestamp" data-t="00:02:02">[00:02:02]</a>. He projects that three times as much GDP could be produced in the next 50 years as in all of human history to date <a class="yt-timestamp" data-t="00:02:18">[00:02:18]</a>.

## Understanding AI Technology
Summers approaches learning about new technologies by studying historical technological revolutions, understanding the science at a layperson's level, and engaging with people involved in practical applications <a class="yt-timestamp" data-t="00:03:08">[00:03:08]</a>. He emphasizes the need to grasp what models with hundreds of billions of parameters are doing, a new world for someone accustomed to simpler econometric models <a class="yt-timestamp" data-t="00:03:38">[00:03:38]</a>. His learning process involves watching tutorials, listening to YouTubes, and speaking with OpenAI staff <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>. He also recommends writings by economists like Susan Athey and Sendhil Mullainathan for their accessibility to those with initial training in econometrics <a class="yt-timestamp" data-t="00:08:38">[00:08:38]</a>. He estimates spending roughly a day a week on OpenAI-related matters, including understanding the technology and addressing governance [[challenges_and_opportunities_in_ai_technology | challenges]] <a class="yt-timestamp" data-t="00:09:27">[00:09:27]</a>.

## Bottlenecks in AI Development
When considering the bottlenecks to scaling AI, Summers points to three main areas:
*   **Ideas and Insights** He believes that new insights to strengthen reasoning, use compute more efficiently, and generate training information are crucial and underrated <a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>.
*   **Compute and Chips** For the near term, the primary constraint is likely to be compute and access to sophisticated chips for both training and inference <a class="yt-timestamp" data-t="00:11:38">[00:11:38]</a>.
*   **Energy** In the longer run, energy is anticipated to be the larger constraint <a class="yt-timestamp" data-t="00:12:00">[00:12:00]</a>.

Summers also speculates that a significant portion of AI researchers' tasks (potentially 25% to 75%) could be automated by AI itself within five years <a class="yt-timestamp" data-t="00:12:50">[00:12:50]</a>. This automation would include routine administrative tasks, but also more complex ones like programming and software creation <a class="yt-timestamp" data-t="00:13:30">[00:13:30]</a>.

## AI and Economic Growth
Summers notes that US GDP per capita growth has been relatively stable at around 2% per year for the past 150 years <a class="yt-timestamp" data-t="00:15:10">[00:15:10]</a>, although he cautions against overstating this stability, as underlying factors like workforce and productivity growth have fluctuated <a class="yt-timestamp" data-t="00:15:36">[00:15:36]</a>. He believes that [[impact_of_ai_on_economic_growth | AI]] has the potential to initiate a new growth regime with substantial acceleration, though he finds a "10x faster" growth rate hard to imagine due to inherent limits on certain activities like construction <a class="yt-timestamp" data-t="00:20:44">[00:20:44]</a>.

He challenges the idea of an "economic singularity" with ever-increasing growth rates, drawing an analogy to sectors like agriculture or manufacturing <a class="yt-timestamp" data-t="00:22:25">[00:22:25]</a>. When a sector experiences very rapid growth and falling prices, it tends to become a smaller share of the total economy unless demand is highly elastic <a class="yt-timestamp" data-t="00:22:41">[00:22:41]</a>. He suggests that activities inherently involving the passage of time and human interaction, such as personal intimacy, will inevitably become a larger share of the economy by value <a class="yt-timestamp" data-t="00:24:43">[00:24:43]</a>, thus tempering overall productivity growth.

## [[ai_in_developing_economies_and_economic_policy | AI in Economic Policy]]
Summers believes that [[Artificial General Intelligence and its feasibility | AGI]] could significantly aid policymakers in [[ai_in_developing_economies_and_economic_policy | developing countries]] by enabling the pervasive import and application of knowledge and expertise <a class="yt-timestamp" data-t="00:26:29">[00:26:29]</a>. This rapid transmission of knowledge is likely to be the most important positive factor in accelerating development <a class="yt-timestamp" data-t="00:27:19">[00:27:19]</a>. By distilling past human experience and extrapolating to new cases, AI can contribute to wiser economic policies <a class="yt-timestamp" data-t="00:27:57">[00:27:57]</a>.

For developed economies like the US, Summers is optimistic that AI could improve economic forecasting and stabilization efforts <a class="yt-timestamp" data-t="00:29:58">[00:29:58]</a>. While acknowledging the chaotic nature of some economic phenomena (like weather), he suggests that AI will allow for more accurate forecasting, leading to better monetary policies <a class="yt-timestamp" data-t="00:29:05">[00:29:05]</a>. He also speculates that AI might aid in predicting financial crashes and evaluating bubbles, contributing to stabilization policy <a class="yt-timestamp" data-t="00:30:41">[00:30:41]</a>.

During crises like the Great Recession, Summers believes that better economic science and shared understandings of causal mechanisms, promoted by AI tools, would likely lead to better solutions <a class="yt-timestamp" data-t="00:33:55">[00:33:55]</a>. He uses the analogy of medical knowledge: where definitive scientific knowledge exists (e.g., for broken arms), people rally behind it, but where it's lacking (e.g., for common cold), more debate and "flaky solutions" arise <a class="yt-timestamp" data-t="00:35:12">[00:35:12]</a>. AI is expected to drive greater understanding, leading to better outcomes <a class="yt-timestamp" data-t="00:36:01">[00:36:01]</a>.

## Geopolitical and Governance Implications
Summers draws an analogy between AI and [[nuclear_proliferation_and_its_implications | nuclear technology]] <a class="yt-timestamp" data-t="00:06:12">[00:06:12]</a>, acknowledging that AI's implications could be even greater because, unlike fire or electricity, AI has the capacity to be self-improving <a class="yt-timestamp" data-t="00:07:14">[00:07:14]</a>.

### Security and IP Theft
He emphasizes the critical importance of security and American leadership in AI <a class="yt-timestamp" data-t="00:37:07">[00:37:07]</a>. While recognizing the tension between the open flow of information (which drives progress) and the preservation of secrecy, he notes the difficulty in judging what can truly be learned through spying <a class="yt-timestamp" data-t="00:37:42">[00:37:42]</a>. He references the US's struggle to emulate British textile technology in the 1800s, where blueprints alone were insufficient <a class="yt-timestamp" data-t="00:38:06">[00:38:06]</a>. Summers cautions that restricting information flow too much could chill a nation's own capacity for progress <a class="yt-timestamp" data-t="00:39:14">[00:39:14]</a>.

### Nationalization of AI
Summers does not necessarily agree with the premise that AI should be nationalized <a class="yt-timestamp" data-t="00:39:51">[00:39:51]</a>. He points to the history of computing, which transformed virtually everything (including military and automotive sectors) without being nationalized <a class="yt-timestamp" data-t="00:40:11">[00:40:11]</a>. He also cites the Apollo program, where the government exerted significant control without nationalizing the project <a class="yt-timestamp" data-t="00:41:10">[00:41:10]</a>. While open to the idea that specific aspects might require nationalization, he does not see it as the principal policy response for governments nurturing national security technology <a class="yt-timestamp" data-t="00:41:40">[00:41:40]</a>.

### Government Approach to AI Governance
Based on his experience working with Presidents Bill Clinton and Barack Obama, Summers suggests that governments should adopt an "evolutionary rather than revolutionary" approach to complex problems like AI governance <a class="yt-timestamp" data-t="00:43:19">[00:43:19]</a>. This involves:
*   Approaching issues through multiple channels <a class="yt-timestamp" data-t="00:43:31">[00:43:31]</a>.
*   Planting "seeds" for solutions and observing the best path forward <a class="yt-timestamp" data-t="00:43:38">[00:43:38]</a>.
*   Being very familiar with ongoing developments and maintaining close relationships with major actors <a class="yt-timestamp" data-t="00:43:54">[00:43:54]</a>.
*   Exercising caution in establishing rigid structures that might channel things in the wrong direction <a class="yt-timestamp" data-t="00:44:11">[00:44:11]</a>.
*   Adopting a "portfolio approach" <a class="yt-timestamp" data-t="00:44:22">[00:44:22]</a>.

Regarding OpenAI's potential shift from a non-profit/capped for-profit partnership to a public benefit corporation, Summers states that a public benefit corporation can maintain incentives for responsible stewardship similar to a non-profit <a class="yt-timestamp" data-t="00:44:50">[00:44:50]</a>. He views this potential change not as a move away from public interest considerations, but as a reflection of existing non-profit law limitations and the need for credible capital-raising vehicles to pursue a public interest mission <a class="yt-timestamp" data-t="00:45:54">[00:45:54]</a>.

### Discrepancy in AI Potential
Summers notes a discrepancy between technologists' views on AI's extraordinary economic potential and the more conservative outlook of some academic economists <a class="yt-timestamp" data-t="00:46:25">[00:46:25]</a>. He criticizes analyses, such as one by Daron Acemoglu predicting only 0.6% productivity increases over 10 years <a class="yt-timestamp" data-t="00:46:38">[00:46:38]</a>, for entirely omitting the possibility of more rapid scientific progress or better decision-making due to AI <a class="yt-timestamp" data-t="00:47:02">[00:47:02]</a>. He likens such analyses to historical underestimations of market size for computers or cell phones <a class="yt-timestamp" data-t="00:47:26">[00:47:26]</a>.