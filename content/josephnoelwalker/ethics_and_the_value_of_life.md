---
title: Ethics and the value of life
videoId: 2MLZxJuzT5E
---

From: [[josephnoelwalker]] <br/> 

## The Intrinsic Value of Life
Life is considered to possess a positive value, and any argument for action presupposes an underlying set of values and agency, for which some form of life is a prerequisite <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>. While there might be specific individuals for whom suicide could be an answer, the obliteration of all life is considered "as close to self-evidently wrong as we can find a proposition in ethics" <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>.

## Caring for the Distant Future
The distant future will be inhabited by a very large number of people <a class="yt-timestamp" data-t="00:00:51">[00:00:51]</a>. Their pleasures and sufferings will be no less real, despite their temporal distance <a class="yt-timestamp" data-t="00:00:58">[00:00:58]</a>. The distance in time is comparable to distance in space; for example, a person in Australia is distant in space from Northern Virginia, but this does not make them worthless <a class="yt-timestamp" data-t="00:01:05">[00:01:05]</a>. This concept relates to [[the_importance_of_caring_for_the_distant_future]].

### Discount Rates and Well-being
When discounting cash flows for the near or distant future, a positive return is appropriate due to opportunity cost <a class="yt-timestamp" data-t="00:01:51">[00:01:51]</a>. However, when discounting concepts like happiness, utility, or well-being, there should be no discount rate across either short or long time horizons, maintaining consistency in choices <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.

### Challenges in Promoting Future-Oriented Thinking
Caring about the distant future is not natural for most people <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>. The main issue is a fixation on the very soon, rather than a distinction between 100 years and 500 years out <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>. Many highly successful people and countries with high savings rates demonstrate that it is possible to overcome the obsession with the immediate present <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>.

## Utilitarianism and Moral Decision-Making
Utilitarianism, whether rule or act-based, fundamentally asks individuals to maximize utility subject to a constraint <a class="yt-timestamp" data-t="00:05:09">[00:05:09]</a>. The difference lies in how these constraints are specified <a class="yt-timestamp" data-t="00:05:20">[00:05:20]</a>. Societies that adopt a "rule consequentialist frame of mind" tend to perform significantly better <a class="yt-timestamp" data-t="00:05:33">[00:05:33]</a>. Key philosophical texts on this topic include *Ideal Code, Real World* by Brad Hooker, and works by Butler, Mill, Sidgwick, Barthes, and Donald Reagan <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>. These fundamental questions are best understood by going back to classic philosophical sources rather than solely focusing on the latest journal articles <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a>.

## Philosophy, Uncertainty, and Action
Philosophical questions, unlike empirical ones (e.g., medicare advantage program effectiveness), often yield better understanding from classics, suggesting that philosophy has become over-specialized and less relevant <a class="yt-timestamp" data-t="00:07:04">[00:07:04]</a>. This relates to the [[role_of_philosophy_in_understanding_modern_issues]].

Uncertainty should not lead to moral paralysis <a class="yt-timestamp" data-t="00:08:31">[00:08:31]</a>. Decisions are made regardless, and "doing nothing" is also a decision <a class="yt-timestamp" data-t="00:08:10">[00:08:10]</a>. The approach should be to "do your best," "pursue maximum expected value," and avoid "moral nervousness" <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>. It's about being a "builder" rather than indulging in "neuroticism" <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>.

The epistemic critique of consequentialism, which questions our ability to know the outcomes of our actions, is not fatal <a class="yt-timestamp" data-t="00:09:24">[00:09:24]</a>. Despite wide uncertainty about the future, we generally have an idea of the "better course of action" in specific situations, such as saving a child from an oncoming car <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>.

## The Future of Humanity and Existential Risk

### Views on Longevity and Extinction
Earlier versions of the book *Stubborn Attachments* heavily featured [[potential_existential_risks_and_benefits_of_agi | existential risk]] <a class="yt-timestamp" data-t="01:01:45">[01:01:45]</a>. Nick Bostrom's *Superintelligence* considers the vast potential for future happiness, imagining 10^58 possible mind lives that could exist through colonization of planets and [[the_philosophical_debate_on_consciousness_in_ai | conscious minds in computer operations]] <a class="yt-timestamp" data-t="01:02:50">[01:02:50]</a>. He vividly describes this potential as filling Earth's oceans with "teardrops of joy" for "a hundred billion billion millennia" <a class="yt-timestamp" data-t="01:03:20">[01:03:20]</a>.

However, a more pessimistic, biological perspective suggests that humanity, like other primate species, is likely to go extinct, possibly within another thousand years <a class="yt-timestamp" data-t="01:03:53">[01:03:53]</a>. The chance of self-destruction due to factors like weapons of mass destruction is considered quite high <a class="yt-timestamp" data-t="01:04:15">[01:04:15]</a>. This perspective relates to the [[philosophical_implications_of_longevity]].

### Implications for Growth Maximization
Different views on human longevity influence the focus of ethical concerns <a class="yt-timestamp" data-t="01:04:49">[01:04:49]</a>. If humanity has billions of years and trillions of minds ahead, then [[potential_existential_risks_and_benefits_of_agi | existential risk]] becomes the primary concern, making the next few hundred years less important <a class="yt-timestamp" data-t="01:05:04">[01:05:04]</a>. Conversely, if only a few hundred years are likely, the focus shifts to making that time on Earth as good as possible, as there is "less to preserve" in the long run <a class="yt-timestamp" data-t="01:05:26">[01:05:26]</a>. This discussion connects to [[the_importance_of_caring_for_the_distant_future]].