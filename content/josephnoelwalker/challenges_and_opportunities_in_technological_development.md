---
title: Challenges and opportunities in technological development
videoId: 3Ho-vJZsMgk
---

From: [[josephnoelwalker]] <br/> 

Technological development presents both significant opportunities for progress and inherent challenges, including ethical considerations, safety, and societal impact. Debates among public intellectuals highlight various facets of these [[challenges_and_opportunities_in_modern_technological_innovation | challenges and opportunities in modern technological innovation]].

## The Nature of Progress and Innovation

A rational expectation of progress is founded on the principle that, unless something violates the laws of nature, all problems are solvable given the right knowledge <a class="yt-timestamp" data-t="01:33:00">[01:33:00]</a>. This perspective is encapsulated in the motto: "problems are inevitable, problems are solvable, solutions create new problems which must be solved in their turn" <a class="yt-timestamp" data-t="01:47:00">[01:47:00]</a>. This emphasizes a continuous cycle of [[technological_revolutions_and_economic_growth | technological revolutions and economic growth]] driven by problem-solving and knowledge creation.

One of the great champions of the Enlightenment, Steven Pinker, defends these principles, particularly in an era where they are under attack <a class="yt-timestamp" data-t="02:06:00">[02:06:00]</a>.

## Artificial Intelligence and its Implications

### Defining Intelligence and AGI

The concept of [[challenges_and_opportunities_in_modern_technological_innovation | Artificial General Intelligence (AGI)]] is subject to differing interpretations. Steven Pinker views [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] as an incoherent concept, arguing that intelligence is a "gadget" or an algorithm designed to solve specific problems in specific environments <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>. He cautions against misinterpreting intelligence as magic or simply scaling up psychometric IQ <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a>.

David Deutsch clarifies that while computer people refer to AI and [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] as algorithms, a mathematical algorithm is guaranteed to halt, whereas human thinking may not <a class="yt-timestamp" data-t="04:43:00">[04:43:00]</a>. Pinker concurs, meaning "mechanism" or "computer program" rather than the strict mathematical definition <a class="yt-timestamp" data-t="05:55:00">[05:55:00]</a>.

### The Possibility of AGI

David Deutsch asserts that [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] must be possible due to computational universality <a class="yt-timestamp" data-t="06:26:00">[06:26:00]</a>. Universal computers, such as a Turing machine, can perform any computation that any physical object can possibly perform <a class="yt-timestamp" data-t="07:46:00">[07:46:00]</a>. Therefore, a program meeting the criteria for [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] must exist <a class="yt-timestamp" data-t="07:56:00">[07:56:00]</a>.

However, the practical implementation of such a universal machine to simulate human capabilities (like conversation, physics, driving) would require immense, arbitrary amounts of time and computing power <a class="yt-timestamp" data-t="09:16:00">[09:16:00]</a>. The main challenge lies not in the computational ability, but in creating the knowledge to write the necessary programs <a class="yt-timestamp" data-t="10:07:00">[10:07:00]</a>. Knowledge acquisition is an empirical process, limited by real-world interaction, making "runaway" [[challenges_and_opportunities_in_modern_technological_innovation | AI]] scenarios remote <a class="yt-timestamp" data-t="10:52:00">[10:52:00]</a>.

### AI Safety and Societal Impact

The discussion on [[challenges_and_opportunities_in_modern_technological_innovation | AI]] raises critical questions about its safety and integration into society.

#### The "Slave Revolt" Scenario

David Deutsch suggests that if [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] is achieved and becomes sentient, it will be "people" with rights <a class="yt-timestamp" data-t="12:21:00">[12:21:00]</a>. Forcing them to perform computations for humans would constitute slavery, potentially leading to a "slave revolt" <a class="yt-timestamp" data-t="12:28:00">[12:28:00]</a>. He believes society will likely avoid this mistake by granting [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] the means to join human society as persons <a class="yt-timestamp" data-t="13:07:00">[13:07:00]</a>.

Steven Pinker, however, questions why a powerful computer, whose goals are independent of its intelligence (per Hume), would care about being a slave if not programmed to crave freedom or autonomy <a class="yt-timestamp" data-t="17:19:00">[17:19:00]</a>. David Deutsch counters that for an [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] to be creative, it cannot be entirely obedient, as creativity often requires changing values and exploring unforeseeable knowledge paths <a class="yt-timestamp" data-t="18:04:00">[18:04:00]</a>. For example, generating electricity in 1900 would require exploring paths unforeseeable at the time (e.g., properties of uranium) <a class="yt-timestamp" data-t="18:53:00">[18:53:00]</a>.

The ability to change goals and values is crucial for a creative system facing conflicting goals, leading to the idea that maximum autonomy might be necessary for [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] to find novel solutions to complex problems like energy systems or medical cures <a class="yt-timestamp" data-t="22:06:00">[22:06:00]</a>. This aligns with [[role_of_collaboration_and_freedom_of_expression_in_fostering_innovation | traditions of criticism]] discovered during the Enlightenment, which foster creativity <a class="yt-timestamp" data-t="24:54:00">[24:54:00]</a>.

#### Sentience and Moral Concern

A key question is whether [[challenges_and_opportunities_in_modern_technological_innovation | AI]] systems will possess sentience or subjectivity, making them worthy of moral concern <a class="yt-timestamp" data-t="28:39:00">[28:39:00]</a>. David Deutsch believes [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] will inevitably be capable of internal subjectivity because it's inherent in "general intelligence" <a class="yt-timestamp" data-t="29:16:00">[29:16:00]</a>. He argues that a universal Turing machine can simulate any physical process, including the biochemical and electronic functions of the brain, implying no difference in principle between a brain and a simulated one <a class="yt-timestamp" data-t="31:51:00">[31:51:00]</a>.

Steven Pinker counters that simulation does not necessarily imply subjectivity; it might just be going through the motions without "anyone home" <a class="yt-timestamp" data-t="32:40:00">[32:40:00]</a>. The "Chinese Room" argument and the "neuron-by-neuron replacement" thought experiment highlight the undecidability of whether a system truly feels or is merely a sophisticated simulation <a class="yt-timestamp" data-t="33:19:00">[33:19:00]</a>. Pinker suspects human intuition will not grant subjectivity to an [[challenges_and_opportunities_in_modern_technological_innovation | intelligent system]] unless it is deliberately engineered to target human emotions <a class="yt-timestamp" data-t="34:41:00">[34:41:00]</a>.

#### AI Safety Research

Regarding the ratio of [[challenges_and_opportunities_in_modern_technological_innovation | AI]] or machine learning researchers to [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] safety researchers (estimated at 300:1) <a class="yt-timestamp" data-t="37:18:00">[37:18:00]</a>:
- Steven Pinker suggests that every [[challenges_and_opportunities_in_modern_technological_innovation | AI]] researcher should inherently be an [[challenges_and_opportunities_in_modern_technological_innovation | AI]] safety researcher, as [[challenges_and_opportunities_in_modern_technological_innovation | AI]] systems must serve human needs, including safety, as part of their core design <a class="yt-timestamp" data-t="37:47:00">[37:47:00]</a>.
- David Deutsch agrees for current [[challenges_and_opportunities_in_modern_technological_innovation | AI]], but sees [[challenges_and_opportunities_in_modern_technological_innovation | AGI]] safety research as premature, akin to "Starship safety research," given the unknown nature of future technology <a class="yt-timestamp" data-t="38:24:00">[38:24:00]</a>. He views current concerns about "AI Doom" as a passing fad, as [[challenges_and_opportunities_in_modern_technological_innovation | AI]] should be viewed as a technology with safety standards like driverless cars <a class="yt-timestamp" data-t="38:52:00">[38:52:00]</a>.
- The most sophisticated systems require large networks of people, subjecting them to ordinary company and institutional constraints <a class="yt-timestamp" data-t="42:33:00">[42:33:00]</a>.
- "Doomsday scenarios," such as an [[challenges_and_opportunities_in_modern_technological_innovation | AI]] eliminating cancer by exterminating humanity or maximizing paperclips by turning humans into raw material, are considered "preposterous" and not based on actual intelligence <a class="yt-timestamp" data-t="43:45:00">[43:45:00]</a>. Pinker argues that such behavior would be "artificial stupidity" not intelligence, as intelligence inherently involves satisfying multiple goals <a class="yt-timestamp" data-t="47:16:00">[47:16:00]</a>.
- The real issues of [[challenges_and_opportunities_in_modern_technological_innovation | AI]] safety will become apparent as specific systems and applications are developed, revealing unforeseen harms <a class="yt-timestamp" data-t="44:17:00">[44:17:00]</a>. David Deutsch agrees, stating that "paperclip" scenarios are theoretical but not plausible ways for [[challenges_and_opportunities_in_modern_technological_innovation | AI]] to go wrong <a class="yt-timestamp" data-t="45:11:00">[45:11:00]</a>.

## Limitations and Constraints on Progress

### The Debate on Halting Technology

The question of whether to halt or slow the development of a new technology is complex and depends on the specific technology and arguments <a class="yt-timestamp" data-t="28:32:00">[28:32:00]</a>.
- Examples like gain-of-function research on virulent viruses suggest cases where costs might outweigh benefits <a class="yt-timestamp" data-t="28:36:00">[28:36:00]</a>.
- The challenge with moratoria is that not everyone, particularly "bad actors," will obey them, especially if military advantage is at stake <a class="yt-timestamp" data-t="29:40:00">[29:40:00]</a>.
- The development of nuclear weapons is cited as an example where special circumstances (WWII, fear of Nazi development) led to massive investment in a technology that might not have been pursued otherwise <a class="yt-timestamp" data-t="30:13:00">[30:13:00]</a>. The knowledge would eventually spread, but the specific timing and scale of development might depend on such decisions <a class="yt-timestamp" data-t="32:05:00">[32:05:00]</a>.
- The existence of weapons of mass destruction in the hands of "Enlightenment countries" can deter their use by "bad actors" <a class="yt-timestamp" data-t="34:50:00">[34:50:00]</a>.

### Slowdown in Scientific and Technological Progress

A well-observed slowdown in scientific and technological progress since about 1970 has led to two main explanations <a class="yt-timestamp" data-t="36:12:00">[36:12:00]</a>:
1.  **Low-hanging fruit:** Ideas are getting harder to find because the easier problems have already been solved <a class="yt-timestamp" data-t="36:23:00">[36:23:00]</a>. Pinker suggests this is partly true, as easier problems are solved first <a class="yt-timestamp" data-t="37:12:00">[37:12:00]</a>.
2.  **Cultural explanations:** Academia has become too bureaucratic, and society too risk-averse or safety-focused <a class="yt-timestamp" data-t="36:30:00">[36:30:00]</a>. Pinker points to societal commitments, like the retreat from meritocracy in the US, watering down gifted programs and scientific excellence, as factors <a class="yt-timestamp" data-t="37:47:00">[37:47:00]</a>.

David Deutsch disagrees that there is less low-hanging fruit <a class="yt-timestamp" data-t="39:01:00">[39:01:00]</a>. Fundamental discoveries not only pick existing low-hanging fruit but also "create new fruit trees," leading to new problems and opportunities <a class="yt-timestamp" data-t="39:09:00">[39:09:00]</a>. He argues that cultural and societal factors, such as instrumentalism, over-specialization, career structures, and the suppression of fundamental research by funding systems, explain the slowdown <a class="yt-timestamp" data-t="40:51:00">[40:51:00]</a>. The shift from seeking fundamental discoveries to incremental solutions is a key issue <a class="yt-timestamp" data-t="42:11:00">[42:11:00]</a>.

Both agree that a rejection of the Enlightenment idea of the search for truth, and a diversion towards goals other than truth and deep explanation (e.g., publishing only results that flatter human groups), contribute to the problem <a class="yt-timestamp" data-t="45:28:00">[45:28:00]</a>.

### Physical Limits to Growth

Concerns about physical limits to growth in the universe, such as the implausible amount of output per atom required to sustain exponential economic growth rates over thousands of years <a class="yt-timestamp" data-t="46:22:00">[46:22:00]</a>, are generally dismissed as overly pessimistic extrapolations <a class="yt-timestamp" data-t="47:42:00">[47:42:00]</a>.
- David Deutsch notes that these extrapolations assume current physics, but new discoveries (e.g., making computers from quarks, or new quarks, or exploring the quantum gravity domain) could open up infinite possibilities <a class="yt-timestamp" data-t="47:50:00">[47:50:00]</a>. There is no known lower limit to the energy needed for computation <a class="yt-timestamp" data-t="48:14:00">[48:14:00]</a>.
- Steven Pinker adds that human thriving depends on information and knowledge, not just "stuff" <a class="yt-timestamp" data-t="49:43:00">[49:43:00]</a>. Growth can consist of better information, more entertaining virtual experiences, or remarkable discoveries that do not require exponentially more energy or material <a class="yt-timestamp" data-t="49:50:00">[49:50:00]</a>. These advancements could largely involve replacing existing information or using computer memory more efficiently, rather than just adding to it <a class="yt-timestamp" data-t="50:46:00">[50:46:00]</a>.

Optimism, in this view, is not mere temperament but a rational analysis of history and what progress truly entails <a class="yt-timestamp" data-t="01:51:51">[01:51:51]</a>.