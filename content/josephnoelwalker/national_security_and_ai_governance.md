---
title: National security and AI governance
videoId: wvBzGK72rgU
---

From: [[josephnoelwalker]] <br/> 

Larry Summers, former Secretary of the Treasury and current board member at OpenAI, has highlighted the profound implications of [[Artificial Intelligence and Its Impact on Governance | AI technology]], suggesting its potential impact is greater than any past technology due to its self-improving nature <a class="yt-timestamp" data-t="00:07:08">[00:07:08]</a>. His engagement with the topic includes understanding historical technological revolutions and the technical aspects of AI models <a class="yt-timestamp" data-t="00:03:08">[00:03:08]</a>.

## Historical Parallels and Security Concerns
Summers draws a parallel between the current era of [[Artificial Intelligence and Its Impact on Governance | AI development]] and the moment nuclear technology became possible, noting that in such times, it's crucial to understand previous moments of "staggering new destructive technology" <a class="yt-timestamp" data-t="00:06:03">[00:06:03]</a>. The historical analogy extends to concerns about industrial espionage and [[Nuclear proliferation and regional security dynamics in Asia | security infiltration]], referencing the Manhattan Project and Russian spies like Klaus Fuchs who provided blueprints for atomic devices <a class="yt-timestamp" data-t="00:36:09">[00:36:09]</a>.

Summers acknowledges that the security of [[Artificial Intelligence and Its Impact on Governance | AI labs]] is an important area for future consideration, particularly concerning potential infiltration and intellectual property theft by foreign entities <a class="yt-timestamp" data-t="00:36:50">[00:36:50]</a>. He identifies a tension between the open flow of information, which drives progress and maintains American leadership, and the need for secrecy <a class="yt-timestamp" data-t="00:37:14">[00:37:14]</a>. However, he cautions that overly restrictive measures might "chill our own capacity to make progress," echoing the US's advantage over the more closed Soviet Union during the Cold War <a class="yt-timestamp" data-t="00:38:20">[00:38:20]</a>. He also questions the extent to which complex technologies can truly be replicated through mere blueprints, citing the 19th-century difficulty Americans faced in emulating British textile factory technology <a class="yt-timestamp" data-t="00:37:42">[00:37:42]</a>.

## Government's Role and Nationalization
When discussing the idea of [[Artificial Intelligence and Its Impact on Governance | AI]] being nationalized, Summers expressed reservations about the premise that nationalization is the primary way governments should take responsibility for or nurture the development of technology for national security <a class="yt-timestamp" data-t="00:39:51">[00:39:51]</a>. He notes that computing, which has transformed virtually every military and civilian sector, was never nationalized <a class="yt-timestamp" data-t="00:40:11">[00:40:11]</a>. While open to the idea that some aspects might be nationalized, he considers it an "ahistoric view" to frame it as the principal policy response <a class="yt-timestamp" data-t="00:41:52">[00:41:52]</a>. He references the Apollo program, a government project that nonetheless relied on external entities and wasn't fully nationalized <a class="yt-timestamp" data-t="00:41:10">[00:41:10]</a>.

### Approach to Governance
Reflecting on his experience with presidents like Bill Clinton and Barack Obama, Summers suggests that effective governance of complex problems, such as those posed by [[Artificial Intelligence and Its Impact on Governance | AI]], requires evolutionary rather than revolutionary solutions <a class="yt-timestamp" data-t="00:43:19">[00:43:19]</a>. This approach involves multiple channels, planting seeds for solutions, and observing what works best <a class="yt-timestamp" data-t="00:43:31">[00:43:31]</a>. Government needs to be deeply familiar with the technology, maintain close relationships with major actors, but be cautious about establishing rigid structures that could lead to costly misdirections <a class="yt-timestamp" data-t="00:43:54">[00:43:54]</a>.

Regarding OpenAI's potential structural change from a partnership between a nonprofit and a capped for-profit to a public benefit corporation, Summers does not see this as a move away from public interest considerations <a class="yt-timestamp" data-t="00:45:42">[00:45:42]</a>. He states that a public benefit corporation can maintain incentives for responsible stewardship, and historically, not-for-profit entities have sometimes been driven by commercial incentives <a class="yt-timestamp" data-t="00:44:50">[00:44:50]</a>. He views such a change as a reflection of existing non-profit law limitations and the need for credible capital-raising vehicles to pursue a public interest mission <a class="yt-timestamp" data-t="00:45:54">[00:45:54]</a>.