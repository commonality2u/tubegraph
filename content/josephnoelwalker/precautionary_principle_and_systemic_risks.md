---
title: Precautionary principle and systemic risks
videoId: cP5tQGWagKc
---

From: [[josephnoelwalker]] <br/> 

The Precautionary Principle, as understood by Nasim Nicholas Taleb, is fundamentally about ensuring societal survival by seriously addressing potential threats <a class="yt-timestamp" data-t="01:11:36">[01:11:36]</a>. Taleb distinguishes between the general understanding of the principle and what he calls the "non-naive" precautionary principle, which incorporates specific restrictions and considerations <a class="yt-timestamp" data-t="01:11:48">[01:11:48]</a>.

## Non-Naive Precautionary Principle
The non-naive precautionary principle is not universally against technology, but rather targets specific classes of engineering or actions that have "reversal effects" or introduce multiplicative risks <a class="yt-timestamp" data-t="01:12:04">[01:12:04]</a>, <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>. These are situations where society does not fully understand the consequences of disrupting complex systems at a large scale <a class="yt-timestamp" data-t="01:13:00">[01:13:00]</a>.

A historical example of a reversal effect is Mao's sparrows campaign, where the attempt to eliminate sparrows led to an environmental problem with proliferating insects, demonstrating unintended and widespread consequences <a class="yt-timestamp" data-t="01:12:26">[01:12:26]</a>, <a class="yt-timestamp" data-t="01:12:30">[01:12:30]</a>, <a class="yt-timestamp" data-t="01:12:37">[01:12:37]</a>.

### Systemic vs. Localized Harms
A key distinction for applying the precautionary principle is between localized harms and systemic harms <a class="yt-timestamp" data-t="01:13:25">[01:13:25]</a>.
*   **Localized Harm**: Nuclear power, for example, is not considered "non-precautionary" because small reactors, even if one explodes, would have localized harm that does not impact other distant reactors <a class="yt-timestamp" data-t="01:13:18">[01:13:18]</a>, <a class="yt-timestamp" data-t="01:13:25">[01:13:25]</a>.
*   **Systemic Harm**: This contrasts with phenomena like pandemics, which have multiplicative effects and are therefore subject to precautionary measures <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>, <a class="yt-timestamp" data-t="01:13:36">[01:13:36]</a>.

Similarly, the principle is applied against the *implementation* of genetically modified organisms (GMOs) in nature, but not against research into genetic modification <a class="yt-timestamp" data-t="01:14:14">[01:14:14]</a>. Research itself cannot be stopped <a class="yt-timestamp" data-t="01:14:21">[01:14:21]</a>. The focus is on deployment that could pose systemic, irreversible risks <a class="yt-timestamp" data-t="01:13:50">[01:13:50]</a>.

### Application to Artificial Intelligence (AI)
Taleb expresses skepticism about applying the precautionary principle to AI in its current state <a class="yt-timestamp" data-t="01:14:56">[01:14:56]</a>. He does not see an immediate reason to stop AI development <a class="yt-timestamp" data-t="01:15:04">[01:15:04]</a>, particularly given that current AI (like a robot that "cannot climb stairs") is not autonomous in the way feared <a class="yt-timestamp" data-t="01:15:10">[01:15:10]</a>. Concerns about AI self-reproducing, becoming a "robot colony," or taking over the world are considered "stresses of imagination" when greater problems exist <a class="yt-timestamp" data-t="01:15:17">[01:15:17]</a>, <a class="yt-timestamp" data-t="01:15:22">[01:15:22]</a>.

For AI to become truly systemic, it would need to achieve genuine autonomy, beyond simply being shut down by turning off a computer <a class="yt-timestamp" data-t="01:15:43">[01:15:43]</a>, <a class="yt-timestamp" data-t="01:15:52">[01:15:52]</a>. The idea that AI could automate its own research and recursively self-improve is acknowledged, but Taleb suggests to "let's see if it can do that" before imposing constraints ahead of time <a class="yt-timestamp" data-t="01:17:02">[01:17:02]</a>, <a class="yt-timestamp" data-t="01:17:13">[01:17:13]</a>, <a class="yt-timestamp" data-t="01:17:16">[01:17:16]</a>.

He notes that AI models like LLMs (Large Language Models) reflect consensus and statistical probabilities of what "makes sense" based on current information, rather than generating genuine, novel insights or looking for exceptions <a class="yt-timestamp" data-t="01:18:07">[01:18:07]</a>, <a class="yt-timestamp" data-t="01:18:12">[01:18:12]</a>, <a class="yt-timestamp" data-t="01:21:21">[01:21:21]</a>. Therefore, they are unlikely to produce original scientific breakthroughs in the same way human intuition might <a class="yt-timestamp" data-t="01:17:43">[01:17:43]</a>.

## Policy Implications
Taleb is critical of how governments and policymakers, particularly in the US, have approached [[risk_assessment_in_talent_selection | risk management]] <a class="yt-timestamp" data-t="01:41:45">[01:41:45]</a>. He argues that their efforts to deal with risk have, if anything, increased it, due to advisors who misunderstand fat tails and adhere to textbooks that discourage worrying about such events <a class="yt-timestamp" data-t="01:41:54">[01:41:54]</a>, <a class="yt-timestamp" data-t="01:42:06">[01:42:06]</a>. He believes that once one understands fat tails, "things become very easy" and one starts thinking differently about various issues, including AI <a class="yt-timestamp" data-t="01:42:16">[01:42:16]</a>, <a class="yt-timestamp" data-t="01:42:20">[01:42:20]</a>.

He observes a general "incompetence dressed in sophistication" within foreign policy and decision-making bodies, which makes the world more dangerous <a class="yt-timestamp" data-t="01:31:56">[01:31:56]</a>, <a class="yt-timestamp" data-t="01:31:59">[01:31:59]</a>. This includes interventions that lead to unintended "feedback loops" and complex situations, rather than a simpler approach <a class="yt-timestamp" data-t="01:43:00">[01:43:00]</a>, <a class="yt-timestamp" data-t="01:43:10">[01:43:10]</a>.

Taleb's work during the COVID-19 pandemic highlighted the importance of understanding multiplicative processes. He and Yanir Bar-Yam, having been concerned about pandemics since 2014, advocated for early border controls and testing to cut off the distribution of the virus, thereby lowering the scale of the pandemic <a class="yt-timestamp" data-t="01:39:31">[01:39:31]</a>, <a class="yt-timestamp" data-t="01:39:55">[01:39:55]</a>, <a class="yt-timestamp" data-t="01:40:30">[01:40:30]</a>, <a class="yt-timestamp" data-t="01:40:37">[01:40:37]</a>. This approach aimed to utilize "effective lazarettos" or quarantines with modern testing <a class="yt-timestamp" data-t="01:41:13">[01:41:13]</a>. Their concern arose from the knowledge that pandemics, being multiplicative processes, would travel faster than historical plagues <a class="yt-timestamp" data-t="01:39:47">[01:39:47]</a>, <a class="yt-timestamp" data-t="01:39:55">[01:39:55]</a>. This aligns with his criticism of experts who mix multiplicative and additive processes, leading to underestimation of risks <a class="yt-timestamp" data-t="01:35:51">[01:35:51]</a>.