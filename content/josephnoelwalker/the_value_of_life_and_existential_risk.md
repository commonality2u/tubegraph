---
title: The value of life and existential risk
videoId: 2MLZxJuzT5E
---

From: [[josephnoelwalker]] <br/> 

The question of why one should not commit suicide if "God is dead, life is absurd, and there are no rules" suggests that life inherently holds some positive value <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>. Any argument for doing anything presupposes an underlying nexus of values and a form of agency, for which "some form of life is a presupposition" <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. While an economist might ask if particular individuals *should* commit suicide (where the answer might be yes), the obliteration of all life "seems... as close to self-evidently wrong as we can find a proposition in ethics" <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>.

## Caring for the Distant Future

A significant aspect of valuing life extends to future generations. The distant future will be inhabited by a very large number of people, and their pleasures and sufferings, though distant in time, "will be no less real" <a class="yt-timestamp" data-t="00:00:51">[00:00:51]</a>. The argument parallels how physical distance does not diminish a person's worth (e.g., someone in Australia compared to someone in Northern Virginia) <a class="yt-timestamp" data-t="00:01:05">[00:01:05]</a>. Time is not fundamentally different from space in this regard <a class="yt-timestamp" data-t="00:01:14">[00:01:14]</a>.

### Social Discount Rates

The appropriate social discount rate depends on what is being discounted <a class="yt-timestamp" data-t="00:01:30">[00:01:30]</a>.
*   **Cash Flows:** When discounting cash flows for the near or distant future, "some positivity of return is appropriate" due to opportunity cost <a class="yt-timestamp" data-t="00:01:51">[00:01:51]</a>.
*   **Happiness, Utility, or Well-being:** There should be no discount rate across either short or long time horizons for concepts like happiness or utility <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>. Consistency across choices in this regard is important <a class="yt-timestamp" data-t="00:02:17">[00:02:17]</a>.

Caring about the distant future doesn't come naturally to most people <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>. People tend to heavily discount choices that are even "a little bit out there" <a class="yt-timestamp" data-t="00:02:41">[00:02:41]</a>. The main issue is a "fixation on the very soon" rather than differences in discounting between 100 or 500 years out <a class="yt-timestamp" data-t="00:04:43">[00:04:43]</a>. However, it is not impossible to overcome this; many successful individuals, investors, and countries with high savings rates demonstrate the ability to focus beyond the immediate present <a class="yt-timestamp" data-t="00:02:59">[00:02:59]</a>.

## Navigating Uncertainty and Ethical Decision-Making

Decisions are made whether one wants to or not, and "doing nothing is just as much a decision as quote-unquote doing something" <a class="yt-timestamp" data-t="00:08:10">[00:08:10]</a>. Uncertainty should not lead to paralysis <a class="yt-timestamp" data-t="00:08:31">[00:08:31]</a>. The approach should be to "pursue maximum expected value" and avoid "moral nervousness" <a class="yt-timestamp" data-t="00:08:35">[00:08:35]</a>. This is encapsulated in the advice to "be a builder" <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>.

The epistemic critique (lack of perfect knowledge) is not fatal to consequentialism because "you typically have some idea what is the better course of action" <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>. Even with wide uncertainty about future outcomes, certain actions are clearly beneficial, such as pulling a child away from an oncoming car <a class="yt-timestamp" data-t="00:09:55">[00:09:55]</a>. There is no reason to believe such an action would lead to a negative ultimate outcome (e.g., the child becoming a future "Hitler") <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>.

### Rule Utilitarianism and Consequentialism

Rule utilitarianism and act utilitarianism differ in the constraints they specify for maximizing outcomes, not in giving different instructions <a class="yt-timestamp" data-t="00:05:15">[00:05:15]</a>. Societies that adopt a "rule consequentialist frame of mind" tend to "do much better" <a class="yt-timestamp" data-t="00:05:36">[00:05:36]</a>. For understanding these philosophical concepts, it is recommended to read classic works by Butler, Mill, Sidgwick, and Parfit, rather than focusing solely on the latest journal articles, as the questions involved are fundamental <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>.

## Existential Risk and Humanity's Future

The philosopher Nick Bostrom's work on [[Potential solutions to global existential risks | existential risk]] emphasizes the immense potential for future happiness and life. He posits that if humanity were to colonize planets and develop conscious minds in computer operations, the number of possible "mind lives" could reach 10 to the power of 58 <a class="yt-timestamp" data-t="01:02:50">[01:02:50]</a>. The happiness experienced during these lives could "fill and refill the Earth's oceans every second and keep doing so for a hundred billion billion millennia" <a class="yt-timestamp" data-t="01:03:20">[01:03:20]</a>, underscoring the critical importance of ensuring these are "tears of joy" <a class="yt-timestamp" data-t="01:03:39">[01:03:39]</a>.

Despite this optimistic potential, a more pessimistic, biological perspective suggests that humanity, like other primate species, might be lucky to have "another thousand years left" on Earth, given the high chance of self-destruction, particularly due to weapons of mass destruction <a class="yt-timestamp" data-t="01:04:07">[01:04:07]</a>.

### The Impact of Perceived Future Horizons

The perceived length of humanity's future significantly influences priorities:
*   **Long-term Optimism:** If one believes in a future spanning billions of years with trillions of simulated minds, the primary concern shifts to preserving this "incredibly valuable future" and less about the next few hundred years <a class="yt-timestamp" data-t="01:05:05">[01:05:05]</a>.
*   **Short-term Pessimism:** If the outlook is a more limited future, such as 800 years, the focus shifts to making "those 800 years on Earth as good as possible" <a class="yt-timestamp" data-t="01:05:26">[01:05:26]</a>. This perspective implies "less to preserve" <a class="yt-timestamp" data-t="01:05:39">[01:05:39]</a>.

Ultimately, regardless of the perceived length of time remaining, the goal should be to make that time "as good as possible" <a class="yt-timestamp" data-t="01:04:57">[01:04:57]</a>.