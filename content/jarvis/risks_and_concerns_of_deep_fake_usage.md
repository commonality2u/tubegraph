---
title: Risks and Concerns of Deep Fake Usage
videoId: n9_KeIfJdPM
---

From: [[jarvis]] <br/> 

## Understanding Deep Fakes

[[Understanding Deep Fakes | Deep fakes]] are a form of [[The Technology Behind Deep Fakes | synthetic media]] where an existing image or video of a person is replaced with the likeness of someone else <a class="yt-timestamp" data-t="00:59:00">[00:59:00]</a>. [[The Technology Behind Deep Fakes | This technology]] utilizes artificial intelligence (AI) and requires a significant number of photographs and references of the person being deep faked <a class="yt-timestamp" data-t="01:10:39">[01:10:39]</a>. Famous individuals, such as movie stars like Tom Cruise, are easier to create deep fakes of due to the abundance of available imagery <a class="yt-timestamp" data-t="01:42:00">[01:42:00]</a>. Beyond visual deep fakes, [[The Technology Behind Deep Fakes | there is also technology for audio deep fakes]] <a class="yt-timestamp" data-t="10:44:00">[10:44:00]</a>. The combination of audio and video deep fakes creates a concerning reality where "nothing is real" <a class="yt-timestamp" data-t="11:06:00">[11:06:00]</a>.

## Ethical and Social Concerns

The use of [[Understanding Deep Fakes | deep fakes]] raises significant [[Regulation and Ethical Implications of Deep Fakes | ethical implications]]. They have been used for "bad reasons," such as placing someone's likeness into lewd videos <a class="yt-timestamp" data-t="01:52:00">[01:52:00]</a>, which is considered "very bad" <a class="yt-timestamp" data-t="02:00:00">[02:00:00]</a>.

### Privacy Breach

[[Regulation and Ethical Implications of Deep Fakes | Deep fakes]] can lead to a breach of privacy <a class="yt-timestamp" data-t="15:50:00">[15:50:00]</a>. For example, on [[Concerns about TikTok content and platform safety | TikTok]], accounts attempting to impersonate public figures like Charli D'Amelio using deep fakes are removed because such actions infringe on an individual's privacy, regardless of whether they are a child or an adult <a class="yt-timestamp" data-t="15:09:00">[15:09:00]</a>. This highlights the need for policies to protect individuals from such unauthorized use of their likeness <a class="yt-timestamp" data-t="16:00:00">[16:00:00]</a>.

### Social Manipulation and Misinformation

[[Regulation and Ethical Implications of Deep Fakes | Deep fakes]] pose clear dangers when allowed to "run amuck" <a class="yt-timestamp" data-t="16:05:00">[16:05:00]</a>. They represent an "insidious foot in the door to more dangerous things down the line" <a class="yt-timestamp" data-t="17:07:00">[17:07:00]</a>, mirroring how [[Impact of fake stories on YouTube | fake news]] operates <a class="yt-timestamp" data-t="17:13:00">[17:13:00]</a>.

*   **Exploiting Cognitive Biases**: [[Impact of fake stories on YouTube | Fake news]] preys on the fact that people cannot be critical of "every single thing that comes out of the internet's fire hose" <a class="yt-timestamp" data-t="17:15:00">[17:15:00]</a>. If an individual already believes a public figure, like Tom Cruise, to be kooky, and then sees a deep fake video of him acting kooky with the audio off, it can reinforce their existing worldview without them questioning its authenticity <a class="yt-timestamp" data-t="17:24:00">[17:24:00]</a>. This can lead to [[Ethics of using technology for social manipulation | nefarious purposes]] <a class="yt-timestamp" data-t="17:41:00">[17:41:00]</a>.
*   **Real-world Consequences**: A notable instance of real-world misuse involved a Pennsylvania woman accused of doctoring photos and videos of her daughter's cheerleading rivals with deep fakes to get them kicked off the squad, leading to cyber harassment charges <a class="yt-timestamp" data-t="11:39:00">[11:39:00]</a>. This demonstrates that deep fakes are "a real problem" <a class="yt-timestamp" data-t="11:54:00">[11:54:00]</a>.

## Public Perception and the "Slippery Slope"

Despite the clear dangers, some members of the public remain unconcerned or overly confident in their ability to discern [[Understanding Deep Fakes | deep fakes]]. Comments on articles about deep fakes often dismiss them, claiming, for example, that the Tom Cruise deep fake "doesn't look anything like tom cruise" <a class="yt-timestamp" data-t="12:11:00">[12:11:00]</a>, or that their "giant brain is too sharp for your visual trickery" <a class="yt-timestamp" data-t="12:48:00">[12:48:00]</a>.

However, the reality is that while a deep fake might enter the "uncanny valley" in motion, making it appear unnatural <a class="yt-timestamp" data-t="12:29:00">[12:29:00]</a>, a still frame can look exactly like the target individual <a class="yt-timestamp" data-t="12:17:00">[12:17:00]</a>. Furthermore, many people are not paying close attention while scrolling and may not pick up on the subtle cues that indicate a deep fake <a class="yt-timestamp" data-t="12:34:00">[12:34:00]</a>. Expecting every individual to critically assess every piece of online content is "an impossible task" <a class="yt-timestamp" data-t="16:27:00">[16:27:00]</a>.

There is a "slippery slope" when it comes to [[Understanding Deep Fakes | deep fakes]] <a class="yt-timestamp" data-t="19:50:00">[19:50:00]</a>. While seemingly innocuous instances like [[Deep Fakes in Media and Entertainment | a deep fake of Tom Cruise golfing]] might seem harmless <a class="yt-timestamp" data-t="16:56:00">[16:56:00]</a>, they normalize the technology, making it easier for more dangerous applications to emerge later <a class="yt-timestamp" data-t="17:07:00">[17:07:00]</a>.

## Call for Awareness

While the regulation of [[Understanding Deep Fakes | deep fakes]] is a complex issue, it is crucial for society to be aware of what [[The Technology Behind Deep Fakes | this technology]] makes possible <a class="yt-timestamp" data-t="18:08:00">[18:08:00]</a>. Just as one must understand "sleight of hand" to avoid believing in magic, understanding deep fakes is essential to avoid being tricked <a class="yt-timestamp" data-t="18:13:00">[18:13:00]</a>. Many people are still unaware that deep fakes exist <a class="yt-timestamp" data-t="19:17:00">[19:17:00]</a>, and those who are fooled are less likely to admit it <a class="yt-timestamp" data-t="19:35:00">[19:35:00]</a>. It is important "not believe everything you see" online, as even without fancy visual effects, it's possible to be tricked and influenced <a class="yt-timestamp" data-t="18:25:00">[18:25:00]</a>.