---
title: Philosophical Perspectives on Consciousness and Free Will
videoId: EVwjofV5TgU
---

From: [[dwarkesh | The Dwarkesh Podcast]]

This article summarizes David Deutsch's perspectives on consciousness, qualia, and concepts related to agency and choice, as discussed in a podcast episode.

## Consciousness

Deutsch offers several viewpoints on the nature of consciousness, often contrasting them with other common conceptions, particularly in the context of [[artificial_intelligence_vs_human_intelligence | Artificial General Intelligence (AGI)]].

### The Nature of Consciousness and Subjective Experience

Deutsch critiques the idea of a "pure consciousness without content," often associated with some meditative practices, as a version of the "Cartesian theater" model <a class="yt-timestamp" data-t="00:37:30">[00:37:30]</a>. He suggests that even an imagined "empty stage" of consciousness still possesses content (the stage itself) <a class="yt-timestamp" data-t="00:38:36">[00:38:36]</a>. This relates to the idea that thoughts and senses are sometimes viewed as "intrusions into consciousness" <a class="yt-timestamp" data-t="00:37:06">[00:37:06]</a>. Deutsch posits that a sufficiently advanced virtual reality generator could, in principle, place not only sense data but also thoughts into the mind, though he bases this on his rejection of the "empty stage" model of consciousness <a class="yt-timestamp" data-t="00:37:21">[00:37:21]</a>.

### Qualia, Embodiment, and AGI

Deutsch addresses the question of whether AGIs could experience qualia, such as love, or exhibit traits like being good or evil <a class="yt-timestamp" data-t="00:00:46">[00:00:46]</a>. He argues against the notion that certain qualia are tied to specialized biological hardware in a way that would make them inaccessible to AGIs <a class="yt-timestamp" data-t="00:04:35">[00:04:35]</a>.
His reasoning is that any specialized brain hardware responsible for such experiences (e.g., love, mathematical insight) is still a computer connected via neurons and chemicals <a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a>, <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>. Therefore, an artificial device computing the necessary signals and chemical adjustments could replicate the function, making the experience indistinguishable <a class="yt-timestamp" data-t="00:05:32">[00:05:32]</a>. A person augmented with such a device, who previously couldn't feel love, could then potentially feel it <a class="yt-timestamp" data-t="00:05:51">[00:05:51]</a>. This implies that AGIs and humans could, in principle, [share the same range of cognitive and emotional capacities](ai_alignment_challenges_and_ethical_considerations) <a class="yt-timestamp" data-t="00:06:08">[00:06:08]</a>.

### Explaining Consciousness

Regarding the philosophical problem of how mere physical interactions could explain consciousness <a class="yt-timestamp" data-t="00:41:32">[00:41:32]</a>, Deutsch expresses optimism that such problems are soluble. He views claims that certain problems are in-principle insoluble as "bad explanations" unless supported by a robust argument demonstrating *why* they are insoluble, akin to proofs of undecidability in mathematics <a class="yt-timestamp" data-t="00:41:45">[00:41:45]</a>, <a class="yt-timestamp" data-t="00:43:36">[00:43:36]</a>.

## Agency and Choice

Deutsch's discussions touch on concepts related to agency, choice, and the ethical implications of creating entities with these capacities.

### The "Fun Criterion"

Deutsch introduces the "Fun Criterion" not as an emotion <a class="yt-timestamp" data-t="01:07:30">[01:07:30]</a>, but as a state characterized by the harmonious alignment of different kinds of knowledge—explicit, inexplicit, conscious, and unconscious <a class="yt-timestamp" data-t="01:08:07">[01:08:07]</a>. A key aspect is that "fun," in this sense, cannot be compulsorily enacted <a class="yt-timestamp" data-t="01:09:08">[01:09:08]</a>. It serves as a mode of criticism against arbitrarily privileging one type of knowledge over another, or dogmatically adhering to a theory (e.g., "no pain, no gain" in exercise) without allowing the criticism that an activity "isn't fun" or "can't be made fun" <a class="yt-timestamp" data-t="01:09:39">[01:09:39]</a>, <a class="yt-timestamp" data-t="01:11:11">[01:11:11]</a>. The criterion promotes rationality by not shielding any knowledge from criticism or replacement <a class="yt-timestamp" data-t="01:13:55">[01:13:55]</a>. One can experience physical pain while having fun, if that pain "sparks joy" rather than suffering, and if the underlying theory isn't immune to the critique that it should be, or could be, fun <a class="yt-timestamp" data-t="01:10:27">[01:10:27]</a>.

### The Experience Machine

When presented with Robert Nozick's "experience machine" thought experiment (a virtual world providing perfect experiences, where one forgets it's VR), Deutsch states he would not want to enter such a world if it involved erasing his memory of the real world <a class="yt-timestamp" data-t="01:19:04">[01:19:04]</a>. A significant objection is that the laws of physics in such a simulated world wouldn't be the true, unknown ones, but rather a finite puzzle designed by someone else <a class="yt-timestamp" data-t="01:19:18">[01:19:18]</a>, <a class="yt-timestamp" data-t="01:19:48">[01:19:48]</a>. This implies a valuation of engaging with actual reality and its open-ended problems.

### AGI Evolution and Suffering

Deutsch considers the prospect of creating AGIs through a simulated evolutionary process that mimics human evolution to be potentially "the greatest crime in history" <a class="yt-timestamp" data-t="01:14:46">[01:14:46]</a>. The suffering would arise if entities develop genuine creativity and personhood—even if initially constrained (e.g., for transmitting memes <a class="yt-timestamp" data-t="01:15:50">[01:15:50]</a>)—and experience unpleasantness due to their creativity being misused or severely limited by resources <a class="yt-timestamp" data-t="01:16:32">[01:16:32]</a>. He suggests there might be no clear point to stop such a simulation before suffering begins, as personhood could emerge gradually, and those proto-persons might already be suffering while, for instance, [blindly transmitting memes using genuine creativity](open_source_ai_models_and_their_implications) but to no good effect for themselves <a class="yt-timestamp" data-t="01:17:32">[01:17:32]</a>, <a class="yt-timestamp" data-t="01:17:48">[01:17:48]</a>.

### Implications for Advice-Giving

Deutsch expresses a reluctance to give direct advice, viewing it as establishing an authoritative and potentially immoral relationship <a class="yt-timestamp" data-t="01:20:23">[01:20:23]</a>, <a class="yt-timestamp" data-t="01:23:35">[01:23:35]</a>. He prefers to offer arguments that others can then critique, adapt, or reject, thereby respecting their individual agency in forming beliefs and making choices <a class="yt-timestamp" data-t="00:22:32">[01:22:32]</a>. He cautions against conditioning short-term goals too heavily on long-term goals that cannot be error-corrected in a timely manner, as this can prevent learning and adaptation <a class="yt-timestamp" data-t="01:20:46">[01:20:46]</a>.