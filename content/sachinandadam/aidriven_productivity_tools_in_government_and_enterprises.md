---
title: AIdriven productivity tools in government and enterprises
videoId: Q41lh1Qz6x8
---

From: [[sachinandadam]] <br/> 

The advent of [[artificial_intelligence_and_workforce_transformation | AI]] introduces both significant opportunities and profound challenges, particularly in the realm of productivity tools for governments and large enterprises. While these tools promise enhanced efficiency, they also expose critical vulnerabilities related to data security and governance.

## Government Adoption of AI Tools

The Australian government's experience with [[ai_agents_and_their_practical_applications_in_business | AI agents]] like Co-pilot highlights the dual nature of these technologies.
*   **Productivity Gains**: The Australian government utilized Co-pilot and observed substantial productivity improvements, estimating an additional 45 minutes of productivity per employee daily <a class="yt-timestamp" data-t="00:00:05">[00:00:05]</a> <a class="yt-timestamp" data-t="00:29:27">[00:29:27]</a>.
*   **Security Concerns and Churn**: Despite these gains, the government ultimately stopped using Co-pilot. Their decision was driven by national security concerns and the revelation that users could access significantly more information than intended due to poor data governance and permissioning on unstructured information <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a> <a class="yt-timestamp" data-t="00:29:48">[00:29:48]</a>.
*   **Zero Risk Tolerance**: Governments, especially those dealing with sensitive information like defense, are acutely aware of the risks associated with data leaks <a class="yt-timestamp" data-t="00:53:28">[00:53:28]</a>. While they recognize the competitiveness benefits of AI, their zero-risk tolerance for security breaches means they are slower to adapt and are willing to pay significant amounts for robust security solutions <a class="yt-timestamp" data-t="00:52:42">[00:52:42]</a>.

## Enterprise Challenges with AI Integration

Enterprises face similar hurdles in adopting [[artificial_intelligence_and_workforce_transformation | AI]] tools at scale.
*   **Data Access and Permissions**: A primary concern is ensuring that [[artificial_intelligence_and_workforce_transformation | AI]] tools, which access vast amounts of internal documents to build context and provide answers, do not inadvertently expose sensitive data <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>. Many companies are "blocked from really going all in on [[artificial_intelligence_and_workforce_transformation | AI]]" if they cannot get permissions right <a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a> <a class="yt-timestamp" data-t="00:41:40">[00:41:40]</a>.
*   **Real-World Examples of Leaks**: Specific instances of data leaks include:
    *   Users accessing plans for office closures <a class="yt-timestamp" data-t="00:30:44">[00:30:44]</a>.
    *   Co-pilot revealing information about upcoming firings <a class="yt-timestamp" data-t="00:30:50">[00:30:50]</a>.
    *   Sensitive Word documents, added to meetings, being accessed by unintended individuals through [[artificial_intelligence_and_workforce_transformation | AI]] tools <a class="yt-timestamp" data-t="00:31:02">[00:31:02]</a>.
*   **Need for Data Governance**: Enterprises express a desire to "put their data in the [[artificial_intelligence_and_workforce_transformation | AI]]" but emphasize the critical need to prevent it from reaching the wrong person <a class="yt-timestamp" data-t="00:29:00">[00:29:00]</a>.

## Redactive's Solution to AI Security

Redactive, an Australian startup, directly addresses these security challenges by focusing on [[artificial_intelligence_and_workforce_transformation | AI]] data security <a class="yt-timestamp" data-t="00:00:22">[00:00:22]</a> <a class="yt-timestamp" data-t="00:59:00">[00:59:00]</a>.
*   **Core Functionality**: Redactive's software understands unstructured information within a company and compares it against associated data permissions to identify abnormalities <a class="yt-timestamp" data-t="00:06:30">[00:06:30]</a>. It semantically analyzes text to determine if topics should be accessible by those who can view the file <a class="yt-timestamp" data-t="00:06:47">[00:06:47]</a>.
*   **Addressing the "Permissioning Challenge"**: The company's goal is to ensure permissions are correct before organizations can use [[artificial_intelligence_and_workforce_transformation | AI]] tools at scale <a class="yt-timestamp" data-t="00:07:12">[00:07:12]</a>. This is crucial for managing the wide-scale data access that [[artificial_intelligence_and_workforce_transformation | AI]] and [[ai_agents_and_their_practical_applications_in_business | AI agents]] perform <a class="yt-timestamp" data-t="00:06:58">[00:06:58]</a>.
*   **"Fight AI with AI"**: Redactive's approach is to use [[artificial_intelligence_and_workforce_transformation | AI]] itself to identify vulnerabilities and secure data, acknowledging that new [[artificial_intelligence_and_workforce_transformation | AI]]-driven threats (like agents attacking systems or sending spam) require [[artificial_intelligence_and_workforce_transformation | AI]]-driven defenses <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a> <a class="yt-timestamp" data-t="00:27:48">[00:27:48]</a>.
*   **Proprietary Innovation**: Redactive possesses proprietary intellectual property in its algorithms for identifying data abnormalities by leveraging Large Language Models (LLMs) and embeddings models, moving beyond simple keyword checking to understand semantic content <a class="yt-timestamp" data-t="00:42:40">[00:42:40]</a> <a class="yt-timestamp" data-t="00:33:53">[00:33:53]</a>.

## The Evolving Landscape of AI Security

The landscape of [[artificial_intelligence_and_workforce_transformation | AI]] security is dynamic, with [[ai_agents_and_their_practical_applications_in_business | AI agents]] playing an increasingly central role.
*   **Agent-Driven Security**: The security industry is expected to see [[ai_agents_and_their_practical_applications_in_business | agents]] performing more tasks, including identifying and fixing vulnerabilities <a class="yt-timestamp" data-t="00:26:50">[00:26:50]</a>. Redactive itself is moving towards a more agentic model, where its [[ai_agents_and_their_practical_applications_in_business | agents]] can not only identify abnormalities but also action them <a class="yt-timestamp" data-t="00:23:58">[00:23:58]</a>.
*   **New Threat Vectors**: The ease and low cost of using [[artificial_intelligence_and_workforce_transformation | AI]] for malicious purposes means a "plethora of problems" will emerge, including agents attacking external systems, sending spam, and phishing <a class="yt-timestamp" data-t="00:27:17">[00:27:17]</a>.
*   **Insider Risk**: A significant concern for American and European companies, particularly those in strategic sectors like power and aerospace, is "insider risk." This involves contractors or employees from non-friendly countries attempting to access sensitive files and exfiltrate them using internal [[artificial_intelligence_and_workforce_transformation | AI]] tools <a class="yt-timestamp" data-t="00:50:11">[00:50:11]</a> <a class="yt-timestamp" data-t="00:51:04">[00:51:04]</a>. These actors may exploit incrementally increasing access levels to find sensitive files within large document repositories <a class="yt-timestamp" data-t="00:51:43">[00:51:43]</a>. Such incidents are anticipated to be significant security breaches in the coming years <a class="yt-timestamp" data-t="00:48:48">[00:48:48]</a> <a class="yt-timestamp" data-t="00:51:16">[00:51:16]</a>.