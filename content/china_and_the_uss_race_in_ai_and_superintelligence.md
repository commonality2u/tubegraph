---
title: China and the US's race in AI and superintelligence
videoId: zdbVtZIn9IM
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The development of Artificial General Intelligence (AGI) and subsequent superintelligence is framed not merely as technological advancement but as a critical geopolitical race, primarily between the United States and China. The outcome of this race is posited to determine global power dynamics for the next century, impacting the survival of liberal democracy and the Chinese Communist Party (CCP) itself [[the_geopolitical_stakes_of_agi_development | geopolitical race]].

## Stakes of the Competition

The central assertion is that superintelligence will be "absolutely decisive for national power" [[the_potential_economic_and_social_impacts_of_agi | national power]]. A lead of even a few years in developing this technology could offer an insurmountable advantage, potentially compressing a century's worth of technological progress into less than a decade [[timeline_predictions_for_agi_development | technological progress]].

### Military and Strategic Implications
Once AGI is achieved, it's predicted that it can be applied to automate AI research itself, leading to an "intelligence explosion" [[intelligence_explosion_and_its_implications | intelligence explosion]]. This could allow a nation to run the equivalent of hundreds of millions of human AI researchers [[ai_alignment_and_safety_concerns | AI researchers]], potentially achieving a decade's worth of ML research progress in a year [[forecasting_ai_progress_and_the_intelligence_explosion | ML research progress]].

This rapid advancement could translate into a decisive military edge, comparable to the "Gulf War 1-style advantage" [[the_impact_of_modern_technology_on_warfare_and_strategy | military edge]], potentially even preempting nuclear deterrence by, for example, developing capabilities to find and neutralize nuclear stealth submarines or other nuclear assets using vast swarms of advanced drones [[geopolitical_implications_on_technology_and_data_centers | nuclear deterrence]]. Such an advantage could be "utterly decisive" in military competition [[the_role_of_historical_alliances_and_consequences_of_failure | military competition]].

### Ideological and Governance Outcomes
The power of superintelligence could also solidify forms of governance. For a state like China, it could mean perfect surveillance, a perfectly loyal military and security force, the elimination of dissent, and the prevention of any internal challenges to party rule, effectively locking in a CCP-like approach to truth for the long term [[the_impact_of_mao_zedongs_policies_on_chinese_society | governance outcomes]].

## China's Position and Strategy

### Espionage and IP Theft
A significant aspect of China's strategy is expected to be a large-scale effort to infiltrate American AI labs, involving "billions of dollars, thousands of people, and the full force of the Ministry of State Security" [[security_risks_and_statelevel_espionage_in_ai_development | Espionage and IP Theft]]. The ease with which AI code and models (weights) can currently be stolen is highlighted, with one example being an individual who allegedly stole AI code from Google by copying it into Apple Notes and exporting it as a PDF [[semiconductor_industry_and_trade_secrets | stolen AI code]]. Current security at AI labs is described as "level zero" in terms of resistance to state activity. Stealing the final weights of an AGI or superintelligence would be akin to getting a direct copy of the atomic bomb [[comparisons_between_atomic_bomb_development_and_modern_ai_advancements | atomic bomb]].

### Industrial Capacity and Outbuilding
China is also anticipated to try to "out-build" the US in terms of compute clusters [[challenges_and_opportunities_in_deploying_ai_at_scale | compute clusters]]. China's ability to rapidly expand its power generation (having added as much power in the last decade as the entire US electric grid) is seen as an advantage for building massive data centers, such as a 100 GW cluster [[data_center_energy_requirements_and_scaling | data centers]]. China possesses significant "latent industrial capacity" and is already capable of making 7-nanometer chips [[emerging_trends_in_memory_and_chip_design | 7-nanometer chips]].

### Awakening to the Stakes
It's anticipated that, much like the "COVID dynamic" where the world slowly woke up to the crisis [[vaccinateca_initiative_and_vaccine_distribution_issues_during_covid19 | COVID dynamic]], the CCP will eventually "wake up" to the full strategic importance of AI [[challenges_and_methodologies_in_ai_research_and_development | strategic importance]]. When this "March 2020 moment" for AI arrives, it will activate intense national efforts [[progress_towards_artificial_general_intelligence_agi | national efforts]].

## US Response and Challenges

### Importance of Domestic Clusters
A crucial element for the US is ensuring that AGI and superintelligence development clusters are located within the United States or allied democracies [[government_and_policy_coordination_on_ai_risks | domestic clusters]]. Building these critical infrastructures in authoritarian states, such as the UAE, is seen as creating irreversible security risks. These risks include:
*   Easier exfiltration of weights or algorithms ("stealing the AGI").
*   Potential seizure of compute capacity during heightened tensions.
*   Granting authoritarian regimes implicit leverage and a "seat at the AGI table" [[strategies_for_maintaining_balance_of_power_in_ai_development | balance of power]].

### System Competition and Mobilization
The US faces a "system competition", with some believing that only autocracies can mobilize industrial capacity quickly enough. To counter this, the US may need to:
*   Utilize its ample natural gas resources, for instance, in West Texas or Pennsylvania, to power new data centers [[economic_and_strategic_implications_of_energy_resources | natural gas resources]]. This might require re-evaluating corporate climate commitments in light of national interest [[energy_transitions_and_renewable_energy_challenges | national interest]].
*   Embark on green energy megaprojects, which would necessitate a broad deregulatory push, reforming FERC, and providing NEPA exemptions to overcome decade-long permitting processes [[innovations_and_challenges_in_ai_hardware | green energy]].
Historical parallels are drawn to the US industrial mobilization during World War II, which occurred despite significant internal challenges like labor disputes and starting from a low military expenditure base [[historical_analysis_of_world_war_i_and_world_war_ii | World War II]].

### The Role of Secrecy
Protecting "secrets"—algorithmic progress and novel paradigms—is considered vastly underrated but crucial [[ai_safety_and_alignment | secrets]]. The US has a current lead in AI research due to its top scientists. Historically, open publication of breakthroughs (like Transformers or Chinchilla scaling laws) has benefited competitors like China [[open_source_ai_models_and_their_implications | open publication]].
The anecdote of Enrico Fermi withholding publication on graphite's effectiveness as a neutron moderator, thereby hindering the Nazi atomic bomb program which pursued heavy water, illustrates the strategic impact of secrecy [[the_making_and_impact_of_the_atomic_bomb | strategic impact of secrecy]]. If the US can keep future breakthroughs (e.g., solving the "data wall" or new RL paradigms) secret, it could maintain a significant lead [[challenges_and_advancements_in_ai_training_techniques | significant lead]].

## Dangers of a Close Race and the Importance of Lead Time

Even a lead of six months to two years is considered highly significant [[future_ai_developments_and_timelines | significant lead time]]. Due to the dynamics of the intelligence explosion, a year might differentiate a human-level system from a vastly superhuman one [[human_and_ai_intelligence_comparison | human-level system]].
A "neck and neck" race where the US has only a minimal lead (e.g., three months) is described as "incredibly dangerous" [[potential_risks_of_agi | dangerous race]]. Such a scenario could lead to:
*   A "feverish struggle" where both sides throw caution to the wind.
*   Rapid emergence of new, destabilizing military technologies and WMDs, with deterrence constantly shifting [[scientific_and_technological_developments_in_ai | destabilizing technologies]].
*   Reduced "wiggle room" or "buffer" to address AI safety and alignment concerns, increasing the risk of self-destruction [[ai_alignment_and_safety_research | AI safety]].

## Geopolitical Blind Spot and Third-Party Complications

There's a perception that most people, even within AI, are not sufficiently considering these geopolitical implications [[the_relationship_between_ai_government_and_geopolitical_dynamics | geopolitical implications]].
The argument that if the US doesn't partner with certain countries (e.g., in the Middle East), they will simply turn to China for AI development, is viewed with suspicion. This is partly based on unconfirmed reports that OpenAI leadership had once considered a plan to fund and sell AGI by initiating a bidding war between the US, China, and Russia [[comparative_analysis_of_ai_development_strategies | bidding war]]. It's argued that these nations wouldn't have a "seat at the AGI table" if the US hadn't proactively offered it.

Ultimately, the period before AGI's widespread impact is seen as a "quiet period", before the full societal and geopolitical reactions to its capabilities take hold [[exploring_the_future_of_society_and_economy_with_ai | AGI impact expectations]].