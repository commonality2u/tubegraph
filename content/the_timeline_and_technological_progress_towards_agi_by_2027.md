---
title: The timeline and technological progress towards AGI by 2027
videoId: zdbVtZIn9IM
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The development of Artificial General Intelligence (AGI) has rapidly shifted from a theoretical concept to a tangible prospect, with significant advancements anticipated by 2027. This outlook is primarily driven by an exponential increase in computing power, breakthroughs in model capabilities, and a process termed "unhobbling," which aims to transform AI from sophisticated chatbots into versatile, agentic systems. Leopold Aschenbrenner, formerly of OpenAI's superalignment team, outlined this trajectory, emphasizing 2023 as a pivotal year where the path to AGI became visibly clear [[progress_towards_artificial_general_intelligence_agi | Progress towards Artificial General Intelligence (AGI)]].

## The Accelerating Compute Landscape: Towards the Trillion-Dollar Cluster

The foundation for AGI's rapid development lies in an "extraordinary techno-capital acceleration" in AI, conceptualized as an industrial process requiring massive infrastructure [[data_center_energy_requirements_and_scaling | Data Center Energy Requirements and Scaling]]. This involves building not just code, but giant new computing clusters, power plants, and eventually, new fabrication facilities.

### The 0.5 OOMs per Year Trend
For nearly a decade, the training compute for the largest AI systems has grown by approximately half an order of magnitude (0.5 OOMs) per year. Projecting this trend forward from GPT-4 (rumored to use a 25,000 A100s, $500 million, 10 MW cluster in 2022):
*   **2024:** Clusters are expected to reach 100 MW, using 100,000 H100 equivalents, costing billions.
*   **2026:** Projections indicate gigawatt-scale clusters (comparable to a large nuclear reactor or the Hoover Dam), requiring a million H100 equivalents and costing tens of billions of dollars.
*   **2028:** The scale increases to 10 GW clusters (more power than most US states), utilizing 10 million H100 equivalents, and costing hundreds of billions.
*   **2030:** The "trillion-dollar cluster" emerges, consuming 100 GW (over 20% of US electricity production) with 100 million H100 equivalents for training alone, with additional GPUs for inference.

These investments are already being planned. Reports indicate OpenAI and Microsoft are planning a $100 billion cluster, potentially on the scale of a 10 GW facility. AMD forecasted a $400 billion AI accelerator market by 2027, suggesting a trillion dollars of total AI investment by then is plausible. The feasibility of these massive expenditures hinges on AI generating substantial revenue, potentially hundreds of billions annually for Big Tech companies [[impact_and_future_of_ai_in_economic_systems | Impact and Future of AI in Economic Systems]]. For example, an AI add-on for a third of Microsoft Office's 300 million subscribers at $100/month could generate $100 billion [[the_role_and_future_of_microsoft_in_the_context_of_global_technological_advancements | The Role and Future of Microsoft in the Context of Global Technological Advancements]].

## Projected AI Capabilities and the Path to AGI by 2027-2028

The 10 GW cluster range, anticipated around 2028 (or potentially earlier), is Aschenbrenner's best guess for when true AGI might emerge. The progression of capabilities is envisioned as:

*   **2025-2026:** AI models are expected to be "basically smarter than most college graduates." Their economic utility will significantly depend on "unhobbling" them from current limitations, allowing them to perform agentic, long-horizon tasks beyond simple chatbot interactions.
*   **2027-2028:** AI is projected to reach the intelligence level of the "smartest experts." Through continued unhobbling, these systems will increasingly resemble agents or "drop-in remote workers." They could participate in Zoom calls, use Slack, autonomously work on projects, receive feedback, and iterate, much like human coworkers [[impact_of_ai_on_software_development_and_productivity | Impact of AI on Software Development and Productivity]]. Aschenbrenner refers to a "GPT-5.5 level" AI by 2027.

This "drop-in remote worker" AGI could potentially automate cognitive tasks directly, such as replacing a software engineer rather than merely making them more productive. This level of capability, an "overkill" compared to intermediate models, is seen as necessary to easily integrate AI and harvest economic gains without extensive workflow re-engineering ("schlep").

A critical accelerator for this timeline is the automation of AI research itself. Once AGI can perform the tasks of an AI researcher or engineer, progress could speed up dramatically [[ai_for_science_and_societal_challenges | AI for Science and Societal Challenges]]. With potentially hundreds of millions of automated AI researcher equivalents, a decade's worth of ML research might be achieved in a year.

## The "Unhobbling" Process: From Chatbots to Agents

"Unhobbling" is the key process to unlock the full potential of scaled AI models, transitioning them from powerful but limited systems to truly agentic AGI [[the_geopolitical_stakes_of_agi_development | The Geopolitical Stakes of AGI Development]]. This involves several components:

### Leveraging Test Time Compute
Current models like GPT-4 perform chain-of-thought reasoning over a few hundred tokens, akin to a human thinking for a few minutes. If models could effectively use millions of tokens for a single problem (+4 OOMs of test time compute), it could be equivalent to a 3.5x OOM larger model or months of human working time. The challenge is that models currently get "stuck" and cannot reliably correct their errors over long reasoning chains.

### Acquiring System 2 Capabilities
Unhobbling requires models to learn new types of tokens, such as "error correction tokens" (recognizing mistakes and rethinking) and "planning tokens" (strategizing before acting). This is likened to humans switching from autopilot (System 1) to conscious, deliberative thought (System 2) when encountering complex situations. While scaling improves the "System 1 autopilot," unhobbling aims to enable robust "System 2" processing [[reasoning_in_ai_models | Reasoning in AI Models]].

### The Power of Pre-training and RL
The "magic" of pre-training is that it allows models to learn rich representations and world models by predicting the next token, not just statistical artifacts. Techniques like RLHF (Reinforcement Learning from Human Feedback) have already demonstrated significant gains, with InstructGPT showing a 100x model size equivalent improvement on human preference ratings [[reinforcement_learning_from_human_feedback_rlhf | Reinforcement Learning from Human Feedback (RLHF)]].
Models are now entering a regime where they can begin to "learn by themselves," analogous to a college student teaching themselves, rather than passively receiving information like in grade school (pre-training). This self-learning process involves self-play, synthetic data, and RL. RL, while finicky, can provide the "best possible data" for a model by allowing it to learn through trial, error, and eventual understandingâ€”similar to a student working through practice problems until they "click". This process is expected to take between six months and three years to figure out.

## Algorithmic Progress as a Multiplier

Beyond raw compute, algorithmic progress contributes significantly, estimated at about 0.5 OOMs per year by default. This, combined with scaling, led to the jump from GPT-2 ("preschooler") to GPT-4 ("smart high schooler"). Another similar jump in per-token intelligence is anticipated by 2027-2028 due to continued scaling and algorithmic improvements, augmented by unhobbling to make these systems more agentic [[ai_alignment_and_cooperation_challenges | AI Alignment and Cooperation Challenges]]. A key algorithmic challenge is overcoming the "data wall," which will require a new paradigm, likely involving advanced self-play RL ("AlphaGo step two") [[alphazero_and_efficient_search_techniques | AlphaZero and Efficient Search Techniques]].

In summary, the convergence of rapidly scaling compute infrastructure, significant algorithmic advancements, and the successful "unhobbling" of AI models to unlock agentic, System 2-like capabilities, points towards the potential emergence of AGI around the 2027-2028 timeframe [[predicating_the_impact_and_management_of_superintelligence | Predicting the Impact and Management of Superintelligence]].