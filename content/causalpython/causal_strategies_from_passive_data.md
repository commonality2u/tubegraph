---
title: Causal strategies from passive data
videoId: zFeAtV7AN0A
---

From: [[causalpython]] <br/> 

The concept of learning [[causal inference in practical applications | causal strategies]] from passive data was a significant topic discussed at a workshop [00:21:45] focused on the intersection of causality and Large Language Models (LLMs) [00:02:29].

## Andrew Lampinen's Research

Andrew Lampinen from Google DeepMind presented a paper titled "Learning active causal strategies from passive data" [00:21:45]. This work addresses a critical area in [[causal inference in practical applications | causality]], which often differentiates between observational and interventional data [00:22:01], [00:22:07].

Key insights from his presentation include:
*   **Nature of LLM Training Data**: Large Language Models (LLMs) are trained on passive data [00:22:14]. However, this data often describes the outcomes of experiments, including the procedures followed, effectively making it interventional in a certain sense [00:22:20], [00:22:25].
*   **Generalizing Causal Strategies**: The research demonstrates that a language model, given specific conditions, can learn to generalize [[causal inference in practical applications | causal strategies]] by analyzing this "passive" data that describes interventional approaches [00:22:32], [00:22:39], [00:22:41].
*   **Performance Enhancement**: Allowing LLMs to interact with the environment at certain points or providing them with explanations can significantly boost their performance in learning these strategies [00:22:47], [00:22:50], [00:22:53], [00:22:55], [00:22:59].

### Core Insights
Two primary conclusions emerged from this research:
1.  Generalization of [[causal inference in practical applications | causal strategies]] is achievable in simpler scenarios, provided certain criteria are met [00:23:11], [00:23:13], [00:23:16].
2.  Achieving this generalization is not feasible with current standard training regimes and existing datasets [00:23:23], [00:23:26], [00:23:29].

This paper is conceptually linked to other recent work, including a Google DeepMind paper on agents learning causal models by identifying optimal or suboptimal policies within a sufficiently diverse range of environments [00:23:39], [00:23:42], [00:23:47], [00:23:50], [00:23:54], [00:23:56]. These ideas are considered to "open the gate to a very, very interesting New Paths" for [[causal inference in practical applications | causal methods]] [00:24:05], [00:24:07].