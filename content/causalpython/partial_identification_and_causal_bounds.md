---
title: Partial identification and causal bounds
videoId: Hc3rIGmX59k
---

From: [[causalpython]] <br/> 

Partial identification and causal bounds offer a nuanced perspective on [[assumptions_in_causal_inference | assumptions]] in causal inference, moving beyond a binary true/false state to a range of possibilities <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>. This approach aims to provide a more flexible and realistic understanding of causal effects, especially when strong [[assumptions_in_causal_inference | assumptions]] are difficult to justify <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>.

## Understanding Assumptions as a Spectrum

Traditionally, [[assumptions_in_causal_inference | assumptions]] in causal inference are often viewed as binary, either true or false <a class="yt-timestamp" data-t="00:00:02">[00:00:02]</a>. However, research in partial identification, particularly work led by Ricardo Silva, conceptualizes [[assumptions_in_causal_inference | assumptions]] more like a "slider" that can be adjusted up and down <a class="yt-timestamp" data-t="00:00:16">[00:00:16]</a>. This means that instead of making an all-or-nothing decision about an assumption, one can consider its degree of certainty or strength <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a>.

The "cost" of [[assumptions_in_causal_inference | assumptions]] is a key concept. For example, randomization, while providing high certainty about causal effects, comes at a high cost, such as millions or billions for clinical trials <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a>. Conversely, [[assumptions_in_causal_inference | assumptions]] in purely observational studies, like "no unmeasured confounding," might seem "free" but carry a higher risk of being wrong <a class="yt-timestamp" data-t="00:02:59">[00:02:59]</a>. Spending resources, such as engaging experts to discuss and justify [[assumptions_in_causal_inference | assumptions]], can help reduce this risk <a class="yt-timestamp" data-t="00:04:23">[00:04:23]</a>.

## The Concept of Partial Identification

Partial identification differs from traditional "point identification," which seeks to derive a single, precise causal effect based on specific [[assumptions_in_causal_inference | assumptions]] <a class="yt-timestamp" data-t="00:05:54">[00:05:54]</a>. Instead, partial identification provides a *range* for the true causal effect, specifically a lower and upper bound <a class="yt-timestamp" data-t="00:06:16">[00:06:16]</a>.

### Point Identification vs. Causal Bounds
When more [[assumptions_in_causal_inference | assumptions]] are added, these causal bounds become tighter <a class="yt-timestamp" data-t="00:06:20">[00:06:20]</a>. Eventually, with enough strong [[assumptions_in_causal_inference | assumptions]], the bounds can collapse onto a single point, resulting in point identification <a class="yt-timestamp" data-t="00:06:24">[00:06:24]</a>. This spectrum allows researchers to move flexibly between no identification (wide bounds) and point identification (collapsed bounds) <a class="yt-timestamp" data-t="00:06:10">[00:06:10]</a>.

### Benefits of Partial Identification
This perspective offers several benefits:
*   **Flexibility**: It allows for a more nuanced discussion of [[assumptions_in_causal_inference | assumptions]] at different levels, rather than an "all or nothing" approach <a class="yt-timestamp" data-t="00:06:36">[00:06:36]</a>.
*   **Wider Action Space**: It broadens the scope of [[causal_inference_in_practical_applications | causal analysis]] by allowing for valid conclusions even when strong [[assumptions_in_causal_inference | assumptions]] cannot be fully met <a class="yt-timestamp" data-t="00:11:03">[00:11:03]</a>.
*   **Weaker Assumptions**: It enables the provision of causal results with weaker [[assumptions_in_causal_inference | assumptions]], which are easier to justify, especially when communicating with policymakers or companies <a class="yt-timestamp" data-t="00:09:08">[00:09:08]</a>.
*   **Scientific Paradigm**: It aligns with a scientific paradigm that encourages questioning hypotheses and justifying answers by considering every possible perspective of a causal question <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>.

## Historical Development
Partial identification is a relatively early field, with its first written paper appearing around 1989 <a class="yt-timestamp" data-t="00:07:40">[00:07:40]</a>. Robins briefly introduced it, and Pearl also discussed it around the same time, using a DAG (Directed Acyclic Graph) approach <a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a>. Later, in the early 2000s, economist Charles Manski wrote a book on it, though it did not immediately gain widespread adoption <a class="yt-timestamp" data-t="00:08:21">[00:08:21]</a>. The field is currently experiencing a "third generation" of interest, driven by the frustration with the binary nature of full causal effect estimation versus no estimation <a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a>.

## Relation to Sensitivity Analysis
While partial identification can be seen as a form of sensitivity analysis in a broad sense, there's a strict distinction <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>. Sensitivity analysis typically introduces a subjective parameter that is dialed up and down to observe how results change <a class="yt-timestamp" data-t="00:10:01">[00:10:01]</a>. Partial identification, by design, is not subjective; its bounds are derived from the model itself, although a causal graph assumption might be subjective <a class="yt-timestamp" data-t="00:10:30">[00:10:30]</a>. One can, however, add sensitivity analysis to a partial identification framework <a class="yt-timestamp" data-t="00:10:42">[00:10:42]</a>. Both partial identification and sensitivity analysis are not yet widely known or applied in the community, partly due to a lack of bandwidth and readily available simplified tools <a class="yt-timestamp" data-t="00:11:40">[00:11:40]</a>.

## Challenges and Practicalities
One significant challenge with partial identification is that the bounds it provides can often be uninformative, meaning they are very wide <a class="yt-timestamp" data-t="00:12:54">[00:12:54]</a>. Despite this, it is crucial for scientists to report all results to provide the widest possible perspective on a causal problem <a class="yt-timestamp" data-t="00:13:12">[00:13:12]</a>.

Partial identification also adds a layer of complexity to already complex causal methods, not just in understanding but also in computational execution <a class="yt-timestamp" data-t="00:13:31">[00:13:31]</a>. Exact methods for partial identification do not scale well; they become computationally intractable beyond a small number of nodes (e.g., five nodes) or discrete states of a variable (e.g., three or four) <a class="yt-timestamp" data-t="00:13:55">[00:13:55]</a>. Approximate methods, like those based on belief propagation or the causal marginal polytope, offer a more [[causal_inference_in_practical_applications | practical application]] <a class="yt-timestamp" data-t="00:13:47">[00:13:47]</a>. These methods can tackle larger graphs (e.g., up to 10 nodes) by reducing a multi-node graph into subsets (e.g., four graphs each with three nodes) <a class="yt-timestamp" data-t="00:16:21">[00:16:21]</a>.

### The Polytop Analogy
A polytope is a geometric representation of the causal problem, often visualized as a cube <a class="yt-timestamp" data-t="00:48:30">[00:48:30]</a>. The lower and upper bounds of the causal effect correspond to the minimum and maximum points on this polytope <a class="yt-timestamp" data-t="00:48:57">[00:48:57]</a>. When [[assumptions_in_causal_inference | causal assumptions]] are made, it is analogous to "slicing" off parts of this cube, which tightens the bounds and reduces the causal space <a class="yt-timestamp" data-t="00:48:41">[00:48:41]</a>. This process incurs a "cost" (e.g., money, time spent discussing assumptions), but it leads to more justifiable results <a class="yt-timestamp" data-t="00:49:51">[00:49:51]</a>. Eventually, enough slices can collapse the polytope to a single point, representing point identification <a class="yt-timestamp" data-t="00:50:00">[00:50:00]</a>.

## Integration with Expert Knowledge and Experimentation
Expert knowledge plays a crucial role in tightening causal bounds in partial identification <a class="yt-timestamp" data-t="00:57:39">[00:57:39]</a>. By integrating expert insights, such as knowledge about graph structures (e.g., directed or bidirected edges), the search space for parameters can be limited, and the bounds can be constrained closer to the true causal effect <a class="yt-timestamp" data-t="00:58:07">[00:58:07]</a>. However, obtaining good expert knowledge can be expensive, and incorrect expert input can lead to inaccurate results, though Bayesian approaches can eventually overrule wrong expert knowledge as more true data is collected <a class="yt-timestamp" data-t="00:57:01">[00:57:01]</a>.

Partial identification can also be integrated with [[optimal_experimentation_in_causal_analysis | optimal experimentation]]. Experimental data can effectively "cut" or constrain the causal space defined by the marginal polytope <a class="yt-timestamp" data-t="00:51:03">[00:51:03]</a>. The challenge then becomes deciding which experiment to run next to most efficiently reduce the uncertainty <a class="yt-timestamp" data-t="00:51:11">[00:51:11]</a>. Techniques like Bayesian optimization can be used to intelligently acquire new data points, rather than relying on random or brute-force methods <a class="yt-timestamp" data-t="00:52:07">[00:52:07]</a>. This is particularly relevant in [[causal_inference_in_practical_applications | practical applications]] like marketing or material science, where experimentation costs are high <a class="yt-timestamp" data-t="00:33:31">[00:33:31]</a>, <a class="yt-timestamp" data-t="00:54:14">[00:54:14]</a>.

### Synthetic Control and DAGs
Synthetic control methods, used in various [[causal_inference_in_practical_applications | practical applications]] from economics to marketing, can be characterized using DAGs to understand their underlying [[assumptions_in_causal_inference | assumptions]] and derive non-parametric identification results <a class="yt-timestamp" data-t="00:34:30">[00:34:30]</a>. This approach can also incorporate sensitivity analysis by introducing additional parameters into the causal model <a class="yt-timestamp" data-t="00:35:42">[00:35:42]</a>. Using DAGs for methods typically associated with potential outcomes frameworks, such as synthetic control, can simplify reasoning about [[identifiability_in_causal_representation_learning | identification]] and facilitate [[communication_challenges_in_causal_inference | communication]] within research teams <a class="yt-timestamp" data-t="00:39:51">[00:39:51]</a>.