---
title: Machine learning versus causal inference for decisionmaking
videoId: y59_XLOnmgI
---

From: [[causalpython]] <br/> 

[[causal_inference_and_decision_making | Causal inference]], although often seen as a new field, is a collection of knowledge from multiple disciplines, including [[causality_and_machine_learning | machine learning]] and reinforcement learning <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. The core challenge [[causal_inference_and_decision_making | causal inference]] addresses is transforming predictions into optimal decisions <a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>.

## Limitations of Predictive Machine Learning
Traditional predictive models excel at generating numbers or probabilities, but they often fall short in translating these into actionable business decisions <a class="yt-timestamp" data-t="00:03:17">[00:03:17]</a>, <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>. Companies are primarily interested in taking predictions and transforming them into decisions that improve key metrics like customer acquisition, conversion rates, profitability, or cost reduction <a class="yt-timestamp" data-t="00:03:38">[00:03:38]</a>, <a class="yt-timestamp" data-t="00:06:26">[00:06:26]</a>.

For example, in debt collection, a predictive model might accurately assess the probability of someone paying their debt <a class="yt-timestamp" data-t="00:04:01">[00:04:01]</a>. However, it doesn't inherently tell you *who* to target â€“ whether to focus on those most likely to pay or those least likely <a class="yt-timestamp" data-t="00:04:15">[00:04:15]</a>. This gap between prediction and actionable strategy is where traditional [[causality_and_machine_learning | machine learning]] approaches are insufficient <a class="yt-timestamp" data-t="00:04:37">[00:04:37]</a>.

## The Value of Causal Inference in Decision Making
[[causal_inference_and_decision_making | Causal inference]] provides a formalized framework for evaluating and optimizing actions and decisions <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a>. It addresses how to apply predictive models to a decision-making process without forcing them <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.

### Addressing Stakeholder Concerns
When stakeholders question the investment in [[causal_ai_and_machine_learning | causal models]] given existing [[causality_and_machine_learning | machine learning]] infrastructure, the answer lies in clarifying business objectives <a class="yt-timestamp" data-t="05:51:00">[05:51:00]</a>. Businesses typically do not care about pure prediction, but about making decisions that drive business value <a class="yt-timestamp" data-t="00:06:18">[00:06:18]</a>.

Instead of focusing on technical terms like "[[causal_inference_and_decision_making | causal inference]]", the discussion should be framed around how a [[causal_inference_and_decision_making | causal framework]] helps make better decisions on top of predictions <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a>. A key selling point is **personalization** <a class="yt-timestamp" data-t="00:07:25">[00:07:25]</a>. While the technical term is "treatment effect heterogeneity," it translates directly to treating users differently based on how they specifically want to be treated, which is a powerful business goal <a class="yt-timestamp" data-t="00:07:35">[00:07:35]</a>, <a class="yt-timestamp" data-t="00:07:50">[00:07:50]</a>.

For instance, in fraud detection, a predictive model is often sufficient <a class="yt-timestamp" data-t="00:08:16">[00:08:16]</a>. However, for tasks like setting prices, targeting advertisements, or deciding who to call, where direct decisions are required, [[causal_inference_and_decision_making | causal inference]] becomes a natural formalization of the decision-making process <a class="yt-timestamp" data-t="00:08:23">[00:08:23]</a>, <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>.

## Personal Journey to Causal Inference
The realization of the value of [[causal_inference_and_decision_making | causal inference]] often comes from working with predictive models that, despite good performance metrics (e.g., AUC, cross-entropy), do not lead to tangible business improvements like increased revenue or profitability when put into production <a class="yt-timestamp" data-t="00:09:42">[00:09:42]</a>, <a class="yt-timestamp" data-t="00:09:55">[00:09:55]</a>. This indicates that the problem was misclassified as purely predictive when it was fundamentally a decision-making process requiring [[causal_inference_and_decision_making | causal inference]] <a class="yt-timestamp" data-t="00:09:59">[00:09:59]</a>, <a class="yt-timestamp" data-t="00:10:06">[00:10:06]</a>.

### Bridging the Language Barrier
A significant challenge is the language barrier between different fields within causality, such as econometrics (potential outcomes), epidemiology, and [[causality_and_machine_learning | machine learning]]/graphical models (Judea Pearl's language) <a class="yt-timestamp" data-t="00:11:21">[00:11:21]</a>. While graphical models are useful for formalizing problems and explaining assumptions to technical teams, they are not always used throughout the entire project for estimation or identification <a class="yt-timestamp" data-t="00:12:09">[00:12:09]</a>, <a class="yt-timestamp" data-t="00:13:07">[00:13:07]</a>, <a class="yt-timestamp" data-t="00:13:59">[00:13:59]</a>.

## Current Challenges in Applied Causal Inference
*   **Confounding**: In industrial settings, confounding is often less of an issue because companies can frequently intervene and randomize treatments (e.g., sending an email, changing a price) <a class="yt-timestamp" data-t="00:16:09">[00:16:09]</a>, <a class="yt-timestamp" data-t="00:16:50">[00:16:50]</a>.
*   **Effect Heterogeneity (Personalization)**: The main challenge shifts from identifying an average causal effect to understanding *who* will benefit most from a specific action (e.g., which customers to call for debt collection, who to cross-sell to) <a class="yt-timestamp" data-t="00:17:58">[00:17:58]</a>, <a class="yt-timestamp" data-t="00:19:19">[00:19:19]</a>.
*   **Non-linearity**: Dealing with non-linear response functions is tough, such as the impact of credit lines on default probability, where the effect might saturate after a certain point <a class="yt-timestamp" data-t="00:19:34">[00:19:34]</a>.
*   **Evaluation Metrics**: A significant challenge is developing robust evaluation metrics for [[causal_inference_and_decision_making | causal models]], which are often non-observables <a class="yt-timestamp" data-t="00:20:17">[00:20:17]</a>, <a class="yt-timestamp" data-t="00:20:35">[00:20:35]</a>. The goal is to establish a "meat grinder framework" like in traditional [[causality_and_machine_learning | machine learning]] (try many models, pick the best performance), allowing for causal cross-validation and feature selection <a class="yt-timestamp" data-t="00:21:00">[00:21:00]</a>. Trusting randomized data for validation is crucial for unbiased evaluation <a class="yt-timestamp" data-t="00:22:04">[00:22:04]</a>, <a class="yt-timestamp" data-t="00:23:28">[00:23:28]</a>.

### Reinforcement Learning and Causality
[[causality_and_machine_learning | Reinforcement learning]] can be seen as a "flavor" of [[causal_inference_and_decision_making | causal inference]] <a class="yt-timestamp" data-t="00:24:07">[00:24:07]</a>. Both fields involve optimizing actions to maximize a metric within an environment, with actions in RL being analogous to treatments in [[causal_inference_and_decision_making | causal inference]] <a class="yt-timestamp" data-t="00:24:48">[00:24:48]</a>, <a class="yt-timestamp" data-t="00:24:59">[00:24:59]</a>. This connection allows for applying RL techniques like offline policy evaluation to [[causal_inference_and_decision_making | causal problems]], evaluating policies that haven't been implemented yet <a class="yt-timestamp" data-t="00:25:25">[00:25:25]</a>.

However, RL agents can be susceptible to confounding if not careful <a class="yt-timestamp" data-t="00:27:32">[00:27:32]</a>. They might learn correlations instead of causation if trained on biased past decisions <a class="yt-timestamp" data-t="00:28:38">[00:28:38]</a>, <a class="yt-timestamp" data-t="00:29:44">[00:29:44]</a>. Human intervention is vital to debias the data, for example, by making actions probabilistic instead of deterministic and using techniques like propensity scores <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>, <a class="yt-timestamp" data-t="00:29:29">[00:29:29]</a>.

### CausalOps: Deploying Causal Models at Scale
For deploying [[causal_inference_and_decision_making | causal models]] at scale, the advice is to treat them as much as possible like standard [[causality_and_machine_learning | machine learning]] models <a class="yt-timestamp" data-t="00:31:13">[00:31:13]</a>. This includes using standard libraries and MLOps practices <a class="yt-timestamp" data-t="00:31:26">[00:31:26]</a>. A key consideration is the efficiency of implementations; for instance, pure Python implementations of [[causal_inference_and_decision_making | causal models]] (like Causal Trees) can be too slow for production compared to those with C++ backends <a class="yt-timestamp" data-t="00:31:42">[00:31:42]</a>.

### Challenges with Other Biases (e.g., Selection Bias)
Beyond confounding (common causes), other graphical structures can lead to causal bias, such as selection bias or conditioning on a collider <a class="yt-timestamp" data-t="00:33:30">[00:33:30]</a>, <a class="yt-timestamp" data-t="00:34:13">[00:34:13]</a>.

For instance, in credit or pricing, if one wants to understand the impact of interest rates on loan amounts, a naive approach might filter out customers who didn't take a loan (zero loan amount) <a class="yt-timestamp" data-t="00:35:52">[00:35:52]</a>, <a class="yt-timestamp" data-t="00:36:30">[00:36:30]</a>. However, this introduces bias because conversion (taking a loan) is on the path between the interest rate (treatment) and loan amount (outcome) <a class="yt-timestamp" data-t="00:36:40">[00:36:40]</a>. Conditioning on conversion essentially loses the benefits of randomization <a class="yt-timestamp" data-t="00:36:55">[00:36:55]</a>. Surprisingly, this bias can be mathematically corrected by breaking the problem into two parts: the effect of price on conversion and the effect of price on loan amount *given* conversion <a class="yt-timestamp" data-t="00:37:10">[00:37:10]</a>. Multiplying these two (one causal, one biased) removes the bias, which is highly counterintuitive <a class="yt-timestamp" data-t="00:37:26">[00:37:26]</a>. This mathematical truth holds for both linear and non-linear cases <a class="yt-timestamp" data-t="00:39:27">[00:39:27]</a>, <a class="yt-timestamp" data-t="00:40:39">[00:40:39]</a>.

## Advice for Starting with Causality
For data scientists looking to transition into or learn about [[causal_inference_and_decision_making | causal inference]]:
*   **Broaden Perspective**: Understand that [[causality_and_machine_learning | machine learning]] models are just one piece of a larger system designed to make decisions <a class="yt-timestamp" data-t="00:44:24">[00:44:24]</a>. The ultimate goal is to translate predictions into optimal decisions <a class="yt-timestamp" data-t="00:45:01">[00:45:01]</a>. The motivation should come from the thrill of making better decisions, not just better predictions <a class="yt-timestamp" data-t="00:45:41">[00:45:41]</a>.
*   **Recommended Resources**:
    *   Books that summarize [[causal_inference_and_decision_making | causal inference]] are excellent starting points <a class="yt-timestamp" data-t="00:46:00">[00:46:00]</a>.
    *   The American Economics Association webcasts, particularly the econometrics course by Joshua Angrist and Alberto Abadie (e.g., from 2020), offer strong theoretical fundamentals, even without coding <a class="yt-timestamp" data-t="00:46:42">[00:46:42]</a>.

## The Present of Causality
[[causal_inference_and_decision_making | Causal inference]] is becoming popular because companies are realizing that while they have many predictive models, these models often only partially solve problems <a class="yt-timestamp" data-t="00:48:27">[00:48:27]</a>. There's a strong need for a natural and seamless way to integrate decision-making with [[causality_and_machine_learning | machine learning]], and [[causal_inference_and_decision_making | causal inference]] provides that answer <a class="yt-timestamp" data-t="00:48:51">[00:48:51]</a>. Companies are starting to understand that the end goal is not just to output numbers, but to output decisions that improve and become more optimal over time <a class="yt-timestamp" data-t="00:49:17">[00:49:17]</a>.

## Non-Technical Skills
Effective **writing** and **communication** are crucial non-technical skills <a class="yt-timestamp" data-t="01:08:11">[01:08:11]</a>. Being able to structure thoughts clearly in written or spoken format, and translating complex technical challenges for diverse audiences (e.g., engineers, product managers) without "dumbing it down," is invaluable in the workplace <a class="yt-timestamp" data-t="01:08:25">[01:08:25]</a>, <a class="yt-timestamp" data-t="01:08:56">[01:08:56]</a>.

## Acknowledgements
The academic community, particularly in [[causal_inference_and_decision_making | causal inference]] and econometrics, is notably kind and accessible <a class="yt-timestamp" data-t="01:09:26">[01:09:26]</a>. Joshua Angrist is highlighted as a phenomenal teacher and a source of inspiration <a class="yt-timestamp" data-t="01:09:35">[01:09:35]</a>. The openness of researchers to answer questions and provide guidance is a significant asset to the community <a class="yt-timestamp" data-t="01:10:29">[01:10:29]</a>.