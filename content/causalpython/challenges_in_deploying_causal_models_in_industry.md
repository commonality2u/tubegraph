---
title: Challenges in deploying causal models in industry
videoId: y59_XLOnmgI
---

From: [[causalpython]] <br/> 

Matheus Furi, a staff data scientist at one of Brazil's largest banks and author, highlights that while "causal inference" may be a relatively new term, it encompasses concepts from various fields, including reinforcement learning <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a> <a class="yt-timestamp" data-t="00:00:06">[00:00:06]</a>. The core purpose of causal models in business is to enable better decision-making rather than just providing predictions <a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>. Companies are primarily interested in optimizations like increasing customers, conversion rates, profitability, or cutting costs <a class="yt-timestamp" data-t="00:06:26">[00:06:26]</a> <a class="yt-timestamp" data-t="00:06:31">[00:06:31]</a>.

## The Shift from Prediction to Decision-Making

Matheus shares his personal realization of the value of causal modeling while working with predictive models <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>. A predictive model provides a number, but it doesn't inherently tell a company how to transform that number into a decision <a class="yt-timestamp" data-t="00:03:39">[00:03:39]</a> <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>. For instance, in debt collection, knowing the probability of someone paying doesn't immediately dictate who to target – those likely to pay or those unlikely to pay <a class="yt-timestamp" data-t="00:04:10">[00:04:10]</a> <a class="yt-timestamp" data-t="00:04:21">[00:04:21]</a>. Causal inference provides a formalized framework to evaluate and optimize actions and decisions <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a> <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>. This principle extends beyond debt collection to various [[industrial_applications_of_causal_inference | industrial applications]] <a class="yt-timestamp" data-t="00:05:38">[00:05:38]</a>.

Matheus argues that companies don't care about pure prediction; they care about making decisions that lead to tangible business improvements <a class="yt-timestamp" data-t="00:06:18">[00:06:18]</a> <a class="yt-timestamp" data-t="00:06:20">[00:06:20]</a>. While predictive models are sufficient for some tasks (e.g., fraud detection), most require executing a decision, such as setting a price or targeting an ad <a class="yt-timestamp" data-t="00:08:10">[00:08:10]</a> <a class="yt-timestamp" data-t="00:08:23">[00:08:23]</a>. When decisions are involved, causal inference becomes a natural formalization of the decision-making process <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>.

## Specific Challenges in Deploying Causal Models

Matheus identifies several [[challenges_in_integrating_causal_ai_in_business_settings | challenges in integrating causal AI in business settings]]:

### 1. Confounding vs. Effect Heterogeneity
For Matheus, confounding bias (where other factors vary alongside the treatment, like health care alongside wine consumption and longevity) is often *not* the primary concern in his work <a class="yt-timestamp" data-t="00:16:09">[00:16:09]</a> <a class="yt-timestamp" data-t="00:16:19">[00:16:19]</a>. This is because he typically works in situations where companies can intervene and randomize actions (e.g., sending emails, making calls, changing prices) <a class="yt-timestamp" data-t="00:16:50">[00:16:50]</a> <a class="yt-timestamp" data-t="00:17:20">[00:17:20]</a>.

Instead, the main concern is **effect heterogeneity** (or "personalization") <a class="yt-timestamp" data-t="00:17:58">[00:17:58]</a> <a class="yt-timestamp" data-t="00:19:23">[00:19:23]</a>. This involves understanding how an action (treatment) will have a varied impact across different individuals or customer segments <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>. Examples include deciding which type of customer to call first for debt collection or who is most likely to benefit from a credit card cross-sell <a class="yt-timestamp" data-t="00:18:08">[00:18:08]</a> <a class="yt-timestamp" data-t="00:18:31">[00:18:31]</a>. The goal is not just to know if an action is good on average, but if it's better for a specific customer <a class="yt-timestamp" data-t="00:19:04">[00:19:04]</a>.

### 2. Non-linearity
Working with non-linear relationships is a significant challenge <a class="yt-timestamp" data-t="00:19:34">[00:19:34]</a>. For example, the impact of increasing credit lines on the probability of defaulting on a loan is not linear; it may increase but then saturate <a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a> <a class="yt-timestamp" data-t="00:20:04">[00:20:04]</a>.

### 3. [[evaluating_causal_models_in_practice | Evaluation Metrics]]
One of the hardest challenges is developing good [[evaluating_causal_models_in_practice | evaluation metrics]] for causal models <a class="yt-timestamp" data-t="00:20:17">[00:20:17]</a> <a class="yt-timestamp" data-t="00:21:42">[00:21:42]</a>. Causal quantities are typically non-observables, making it difficult to define traditional performance metrics like those used in machine learning (e.g., AUC, cross-entropy, R-squared) <a class="yt-timestamp" data-t="00:20:33">[00:20:33]</a> <a class="yt-timestamp" data-t="00:20:49">[00:20:49]</a>. The aspiration is to adapt the "meat grinder framework" from ML – trying many models, evaluating performance, and selecting the best – to causal inference, which requires methods for cross-validation and feature selection for causal models <a class="yt-timestamp" data-t="00:21:00">[00:21:00]</a> <a class="yt-timestamp" data-t="00:21:29">[00:21:29]</a>.

A key lesson learned is the importance of having randomized data to trust any evaluation metric <a class="yt-timestamp" data-t="00:22:07">[00:22:07]</a> <a class="yt-timestamp" data-t="00:22:28">[00:22:28]</a>. This "clean and pristine" dataset, even if not used for training, can serve as a validation set to ensure the model's performance in production <a class="yt-timestamp" data-t="00:22:52">[00:22:52]</a> <a class="yt-timestamp" data-t="00:23:08">[00:23:08]</a>.

### 4. Selection Bias (Conversion Issue)
Matheus discusses [[challenges_in_causal_analysis_in_different_settings | selection bias]], particularly the "conversion issue" <a class="yt-timestamp" data-t="00:34:06">[00:34:06]</a> <a class="yt-timestamp" data-t="00:34:48">[00:34:48]</a>. If you want to understand the impact of interest rates on loan size, most customers might not take a loan (zero loan amount) <a class="yt-timestamp" data-t="00:35:07">[00:35:07]</a> <a class="yt-timestamp" data-t="00:35:33">[00:35:33]</a>. Naively estimating the impact on all customers will dilute the effect due to these zeros <a class="yt-timestamp" data-t="00:36:03">[00:36:03]</a> <a class="yt-timestamp" data-t="00:36:10">[00:36:10]</a>.

A common but problematic approach is to filter out non-converters and only analyze those who took a loan <a class="yt-timestamp" data-t="00:36:30">[00:36:30]</a>. This introduces "spurious paths" because "conversion" is an intermediate factor between the treatment (price/interest rate) and the outcome (loan amount) <a class="yt-timestamp" data-t="00:36:40">[00:36:40]</a> <a class="yt-timestamp" data-t="00:36:51">[00:36:51]</a>. This action of conditioning on conversion effectively "loses the benefits of randomization" <a class="yt-timestamp" data-t="00:36:55">[00:36:55]</a>.

However, Matheus explains that if you break down the problem into two parts—the effect of price on conversion, and the (biased) effect of price on loan amount *given conversion*—multiplying these two effects together can surprisingly eliminate the bias and yield a valid causal estimate of the overall effect <a class="yt-timestamp" data-t="00:37:13">[00:37:13]</a> <a class="yt-timestamp" data-t="00:37:26">[00:37:26]</a>. This mathematical truth, derived from probability decomposition, is non-intuitive but holds true even in non-linear cases <a class="yt-timestamp" data-t="00:37:42">[00:37:42]</a> <a class="yt-timestamp" data-t="00:38:18">[00:38:18]</a> <a class="yt-timestamp" data-t="00:39:27">[00:39:27]</a>.

### 5. Language Barrier and Communication
[[challenges_in_integrating_causal_ai_in_business_settings | Integrating causal models]] requires overcoming a language barrier between econometricians and data scientists, especially since causal inference is relatively new to data science <a class="yt-timestamp" data-t="00:10:43">[00:10:43]</a> <a class="yt-timestamp" data-t="00:11:01">[00:11:01]</a>. Matheus primarily translates causal inference concepts for those unfamiliar with them, rather than bridging gaps between different causal languages (e.g., potential outcomes vs. graphical models) <a class="yt-timestamp" data-t="00:12:17">[00:12:17]</a> <a class="yt-timestamp" data-t="00:12:20">[00:12:20]</a>. He uses graphical models mainly at the beginning of a project to formalize assumptions and identify what needs to be controlled for, serving as a background picture for technical teams <a class="yt-timestamp" data-t="00:13:04">[00:13:04]</a> <a class="yt-timestamp" data-t="00:13:27">[00:13:27]</a>.

### 6. Computational Requirements
Many causal models, especially those implemented purely in Python (like `Causal Trees` in `EconML`), can be computationally very slow <a class="yt-timestamp" data-t="00:31:31">[00:31:31]</a> <a class="yt-timestamp" data-t="00:31:45">[00:31:45]</a>. For example, `Causal Forest` can be 39 times slower than other models like `S-Learner`, making them infeasible for large-scale production deployment <a class="yt-timestamp" data-t="00:32:00">[00:32:00]</a> <a class="yt-timestamp" data-t="00:32:33">[00:32:33]</a> <a class="yt-timestamp" data-t="00:33:05">[00:33:05]</a>.

## Causal Inference's Relationship with Reinforcement Learning
Matheus views reinforcement learning (RL) as a "flavor" of causal inference, or vice-versa <a class="yt-timestamp" data-t="00:24:09">[00:24:09]</a> <a class="yt-timestamp" data-t="00:24:11">[00:24:11]</a>. Both fields share a common goal: to find actions (treatments) that maximize a desired outcome (metric) given information about the environment (covariates) <a class="yt-timestamp" data-t="00:24:48">[00:24:48]</a> <a class="yt-timestamp" data-t="00:25:12">[00:25:12]</a>. This allows leveraging techniques from RL, such as offline policy evaluation, to assess how different policies would have performed on past data, even if they were never deployed <a class="yt-timestamp" data-t="00:25:25">[00:25:25]</a>.

However, Matheus warns that RL agents can be susceptible to confounding if not careful <a class="yt-timestamp" data-t="00:27:32">[00:27:32]</a> <a class="yt-timestamp" data-t="00:27:40">[00:27:40]</a>. Naively training a model on its past decisions can lead to learning correlations instead of causations <a class="yt-timestamp" data-t="00:28:54">[00:28:54]</a>. For example, if a debt collection agent only calls customers with low delinquencies, it might falsely conclude that calling has a high impact on payment, when in reality, those customers were likely to pay anyway <a class="yt-timestamp" data-t="00:28:13">[00:28:13]</a> <a class="yt-timestamp" data-t="00:28:40">[00:28:40]</a>. To mitigate this, Matheus advocates for human oversight in retraining the model, using techniques like making actions probabilistic (non-deterministic policies) and applying propensity scores to correct for biases <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a> <a class="yt-timestamp" data-t="00:29:31">[00:29:31]</a> <a class="yt-timestamp" data-t="00:29:34">[00:29:34]</a>.

## Advice for CausalOps and Beginners

### CausalOps Advice
For deploying causal models at scale (CausalOps), Matheus recommends treating them as much as possible like standard machine learning models <a class="yt-timestamp" data-t="00:31:13">[00:31:13]</a> <a class="yt-timestamp" data-t="00:31:17">[00:31:17]</a>. While causal models predict something unobservable (treatment effects), from a production standpoint, they are still predictive models <a class="yt-timestamp" data-t="00:30:57">[00:30:57]</a> <a class="yt-timestamp" data-t="00:31:12">[00:31:12]</a>. Key advice includes:
*   Using standard libraries and frameworks that are easy to deploy <a class="yt-timestamp" data-t="00:31:26">[00:31:26]</a>.
*   Avoiding pure Python models if they are not efficiently implemented in faster languages like C++ with Python wrappers <a class="yt-timestamp" data-t="00:31:31">[00:31:31]</a> <a class="yt-timestamp" data-t="00:31:50">[00:31:50]</a>.

### Causal Discovery
Causal Discovery algorithms can be very useful in industry, particularly in "enclosed systems" with well-documented processes and often without hidden confounding <a class="yt-timestamp" data-t="00:54:28">[00:54:28]</a> <a class="yt-timestamp" data-t="00:54:45">[00:54:45]</a> <a class="yt-timestamp" data-t="00:54:51">[00:54:51]</a>. However, they generally require additional assumptions for observational data <a class="yt-timestamp" data-t="00:58:33">[00:58:33]</a>. In more open systems, it's often an iterative process: combining expert knowledge, running algorithms, testing with data (randomized or observational), and reiterating <a class="yt-timestamp" data-t="00:55:04">[00:55:04]</a> <a class="yt-timestamp" data-t="00:55:07">[00:55:07]</a> <a class="yt-timestamp" data-t="00:55:20">[00:55:20]</a>.

An example of [[applications_of_causal_models_in_business_and_marketing | causal discovery application]] is in root cause analysis for failing solar panels: a predictive model can identify *which* panel will fail, but causal discovery can help determine *why* it will fail (e.g., overheating, wind, sand) to guide technicians <a class="yt-timestamp" data-t="00:56:04">[00:56:04]</a> <a class="yt-timestamp" data-t="00:56:50">[00:56:50]</a> <a class="yt-timestamp" data-t="00:57:00">[00:57:00]</a>. Causal discovery algorithms can identify connections within the system, which then can be used to train a structural model for root cause analysis <a class="yt-timestamp" data-t="00:57:33">[00:57:33]</a> <a class="yt-timestamp" data-t="00:58:04">[00:58:04]</a>.

### Advice for Aspiring Causal Practitioners
For data scientists transitioning to causal inference, Matheus advises:
*   **Broader Perspective**: Understand that machine learning models are just a small piece of a larger decision-making system <a class="yt-timestamp" data-t="00:44:32">[00:44:32]</a> <a class="yt-timestamp" data-t="00:45:01">[00:45:01]</a>. The ultimate goal is to make better decisions, not just better predictions <a class="yt-timestamp" data-t="00:45:43">[00:45:43]</a> <a class="yt-timestamp" data-t="00:45:16">[00:45:16]</a>.
*   **Fundamentals**: Learn the basics of econometrics, including concepts like treatment effects, potential outcomes, and framing problems as decision-making or identification problems <a class="yt-timestamp" data-t="00:47:16">[00:47:16]</a>.
*   **Resources**: Utilize books on causal inference and open-source materials like the American Economics Association webcasts, especially those by Joshua Angrist and Alberto Abadie for theoretical foundations <a class="yt-timestamp" data-t="00:46:00">[00:46:00]</a> <a class="yt-timestamp" data-t="00:46:42">[00:46:42]</a>.
*   **Community**: The Python `Causal Community` is a practical place to be, offering models that are easy to deploy and a maturing ecosystem of libraries like `EconML` and `DoWhy` <a class="yt-timestamp" data-t="01:03:40">[01:03:40]</a> <a class="yt-timestamp" data-t="01:03:54">[01:03:54]</a>.

## Overarching [[Causality in science and industry | Challenges in Causal Machine Learning Applications in Various Industries]]

Matheus reflects on his career, noting the ongoing challenge of balancing work and family life <a class="yt-timestamp" data-t="01:05:01">[01:05:01]</a>. Technically, working in credit has been particularly tough <a class="yt-timestamp" data-t="01:05:42">[01:05:42]</a>. The long delays between giving a loan/credit and observing defaults (sometimes years) make it difficult to assess impact <a class="yt-timestamp" data-t="01:06:21">[01:06:21]</a> <a class="yt-timestamp" data-t="01:06:34">[01:06:34]</a>. Credit is a risky business, often involving continuous treatments like credit lines or interest rates, which frequently exhibit non-linear response functions <a class="yt-timestamp" data-t="01:06:47">[01:06:47]</a> <a class="yt-timestamp" data-t="01:06:56">[01:06:56]</a>. Despite these challenges, banking offers a fertile ground for causal inference due to the inherent complexity and a culture already rooted in economics and econometrics <a class="yt-timestamp" data-t="01:07:27">[01:07:27]</a>.

A crucial non-technical skill Matheus highlights is effective writing and communication <a class="yt-timestamp" data-t="01:08:11">[01:08:11]</a>. Being able to structure thoughts clearly and translate complex technical challenges into understandable language for diverse stakeholders (engineers, product managers, non-technical leadership) is invaluable <a class="yt-timestamp" data-t="01:08:15">[01:08:15]</a> <a class="yt-timestamp" data-t="01:08:50">[01:08:50]</a>.

Matheus expresses gratitude to the academic causal community, particularly Joshua Angrist, for their kindness, openness, and willingness to share knowledge, which significantly aided his learning and contributions to the field <a class="yt-timestamp" data-t="01:09:29">[01:09:29]</a>.