---
title: Causality in science and industry
videoId: UQ8j-DEkB98
---

From: [[causalpython]] <br/> 

Dr. Naftali Weinberger, a philosopher of science, discusses the multifaceted role of [[causality_and_causal_models | causality]] across various scientific disciplines and its practical applications in industry. He emphasizes the importance of considering different time scales, the nature of interventions, and the value of explicit causal assumptions for understanding complex systems <a class="yt-timestamp" data-t="00:02:44">[00:02:44]</a>.

## Challenging Russell's Stance on Causality

Over a century ago, British philosopher Bertrand Russell famously stated that causality is a "relic of the bygone age" <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a>. Dr. Weinberger firmly refutes this argument, asserting that [[causality_and_causal_models | causality]] is far from obsolete <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>. While Russell's perspective was rooted in the physics of his time (e.g., gravitational astronomy, pre-quantum mechanics) <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a>, Weinberger argues that its scientific legitimacy and relevance are evident when examining fields like:
*   Epidemiology <a class="yt-timestamp" data-t="00:01:59">[00:01:59]</a>
*   Sociology <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>
*   Industry <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>

He maintains that these fields require causal knowledge, proving its extreme usefulness <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>. Although Russell was "vindicated" in the sense that physics doesn't strictly *need* causation for its theories to work <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a>, this does not apply to other sciences <a class="yt-timestamp" data-t="00:17:27">[00:17:27]</a>.

## Causality at Different Time Scales

A central focus of Dr. Weinberger's work is the examination of [[causality_and_causal_models | causation]] at different time scales <a class="yt-timestamp" data-t="00:02:44">[00:02:44]</a>. This concept is crucial for any scientific model, as phenomena and relationships can vary significantly depending on the temporal and spatial scale at which they are observed <a class="yt-timestamp" data-t="00:03:02">[00:03:02]</a>.

### Examples
*   **Flossing and Gums**: A dentist might say gums bleed because one *doesn't* floss. If one starts flossing, gums bleed that day (short-term effect), but if one flosses consistently, they stop bleeding (long-term effect) <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>. Both statements are true at their respective time scales <a class="yt-timestamp" data-t="00:04:40">[00:04:40]</a>.
*   **Rainfall and Crop Growth**: Over a short time scale (e.g., 5 years), rainfall is considered an "exogenous variable" affecting crop growth, with no influence from crops back on rainfall <a class="yt-timestamp" data-t="00:11:17">[00:11:17]</a>. However, over a longer period (e.g., 100-200 years), agriculture *can* influence climate, creating a feedback loop where crop growth affects future rainfall <a class="yt-timestamp" data-t="00:11:49">[00:11:49]</a>.

The key takeaway is that different causal relationships emerge at different time scales, and models must be applied appropriately to their intended scale <a class="yt-timestamp" data-t="00:13:02">[00:13:02]</a>. Problems arise when extrapolating across time scales <a class="yt-timestamp" data-t="00:13:12">[00:13:12]</a>.

## Hidden Confounders and Background Factors

In discussions about [[challenges_in_deploying_causal_models_in_industry | challenges in deploying causal models in industry]], hidden confounders are a common concern <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>. Dr. Weinberger argues against the idea of merely adding known confounders based on expertise <a class="yt-timestamp" data-t="00:05:20">[00:05:20]</a>. Instead, he states that *not* including potential confounders in a causal model is a strong assumption, as it implicitly supposes they are not there <a class="yt-timestamp" data-t="00:06:29">[00:06:29]</a>. Experiments, by design, can often remove the influence of confounders <a class="yt-timestamp" data-t="00:06:37">[00:06:37]</a>.

Long-term factors or "background context" are not necessarily confounders if they remain constant over the study's time frame <a class="yt-timestamp" data-t="00:08:18">[00:08:18]</a>. For example, a capitalist economy might be a constant background condition in a study of trading behavior, influencing observations but not acting as a varying confounder <a class="yt-timestamp" data-t="00:08:31">[00:08:31]</a>. These fixed factors can often be controlled for with an intercept in a model, representing a baseline <a class="yt-timestamp" data-t="00:09:26">[00:09:26]</a>. They become problematic if, on a longer time scale, they exhibit dynamics not observed in the short-term data <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>.

## Causality in Complex Systems and Emergence

The discussion of time scales naturally leads to [[causality_and_causal_models | causality]] in complex systems and the phenomenon of emergence <a class="yt-timestamp" data-t="00:15:45">[00:15:45]</a>. Weinberger suggests that understanding causal relationships as relative to a time scale can clarify much of what people mean by "emergence" <a class="yt-timestamp" data-t="00:16:37">[00:16:37]</a>. Patterns and regularities can "emerge" at higher levels of description, even if lower-level descriptions appear chaotic <a class="yt-timestamp" data-t="00:16:53">[00:16:53]</a>.

He distinguishes between "levels" of description, which often imply describing the same object differently (e.g., a physical object vs. a corkscrew) <a class="yt-timestamp" data-t="00:17:59">[00:17:59]</a>, and "scales," which involve "zooming in and zooming out," effectively considering different objects <a class="yt-timestamp" data-t="00:18:45">[00:18:45]</a>. The thermostat example illustrates this: turning on an oven makes a room hotter in 5 minutes, but not after an hour due to the thermostat's self-regulation <a class="yt-timestamp" data-t="00:18:56">[00:18:56]</a>. There is no metaphysical puzzle, just different causal patterns at different time scales <a class="yt-timestamp" data-t="00:19:17">[00:19:17]</a>.

## Defining Causality: A Methodological Approach

Dr. Weinberger's philosophical perspective on [[causality_and_causal_models | causality]] is fundamentally methodological <a class="yt-timestamp" data-t="00:21:04">[00:21:04]</a>. Influenced by Nancy Cartwright's "causal laws and effective strategies," he believes causal knowledge is essential for understanding the difference between mere prediction and the ability to intervene on a system <a class="yt-timestamp" data-t="00:21:10">[00:21:10]</a>. For example, it's not enough to know that people taking a drug are *more likely* to recover; you want to know that *giving* someone the drug makes them more likely to recover <a class="yt-timestamp" data-t="00:21:27">[00:21:27]</a>.

This approach focuses on interventions, which are formalized using the "do operator" in [[causality_and_machine_learning | causal models]] <a class="yt-timestamp" data-t="00:21:51">[00:21:51]</a>. While this may sound pragmatic, Weinberger argues that the effectiveness of causal methods implies underlying features of the world that make them work <a class="yt-timestamp" data-t="00:22:29">[00:22:29]</a>. By studying causal methodology, we can learn about the nature of causation and the world itself <a class="yt-timestamp" data-t="00:22:59">[00:22:59]</a>.

## Causality in Physics and Beyond

The role of [[causality_and_causal_models | causality]] in fundamental physics remains controversial <a class="yt-timestamp" data-t="00:24:40">[00:24:40]</a>. While physicists might use a "principle of causality" (often meaning locality) <a class="yt-timestamp" data-t="00:24:46">[00:24:46]</a>, this differs from the causal relations in causal graphs used in other sciences <a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>. However, in certain applied areas of physics, like building a large hadron collider, causal reasoning and interventions are clearly present <a class="yt-timestamp" data-t="00:25:20">[00:25:20]</a>.

The question of whether interventions, as understood in the causal framework, stop making sense at certain physical levels (e.g., quantum mechanics, due to Bell's inequalities) is an "unresolved" but "live possibility" <a class="yt-timestamp" data-t="00:26:01">[00:26:01]</a>. Even if [[causality_in_artificial_intelligence | causation]] breaks down at subatomic scales, it does not threaten its validity at other, higher levels <a class="yt-timestamp" data-t="00:26:43">[00:26:43]</a>.

### Mental States and Physical Reality
From a cognitive science perspective, Dr. Weinberger acknowledges that mental states can influence physical reality (e.g., a decision leading to a physical action) <a class="yt-timestamp" data-t="00:27:27">[00:27:27]</a>. He prefers the term "scales" over "levels" when discussing the relationship between the mental and physical, advocating for more precise and scientifically interesting characterizations <a class="yt-timestamp" data-t="00:28:20">[00:28:20]</a>.

## Interventions in Dynamical Systems

Dr. Weinberger discusses his paper "Intervening and Letting Go," which explores different types of interventions in dynamical systems <a class="yt-timestamp" data-t="00:40:42">[00:40:42]</a>. Using the example of an ideal gas system with pressure, volume, and temperature, he illustrates how causal models can differ based on the system's setup (e.g., a sealed container vs. a movable piston) <a class="yt-timestamp" data-t="00:41:07">[00:41:07]</a>.

A key puzzle arises when considering interventions:
*   **Movable Piston to Sealed Container**: Fixing the volume of a movable piston (an intervention) makes it behave like a sealed container <a class="yt-timestamp" data-t="00:42:25">[00:42:25]</a>. This intervention, however, doesn't align with the standard "do operator" semantics in some models <a class="yt-timestamp" data-t="00:42:57">[00:42:57]</a>.
*   **Dynamic Representation**: When the system is viewed dynamically, a feedback loop exists between pressure and volume away from equilibrium <a class="yt-timestamp" data-t="00:44:03">[00:44:03]</a>. A "clamp intervention" (holding a variable fixed indefinitely) prevents this feedback loop from operating, thus destroying the system's ability to reach certain equilibrium states <a class="yt-timestamp" data-t="00:46:28">[00:46:28]</a>.

This highlights that "letting go" (removing a constraint) is a distinct action from intervening, a blind spot in some formalisms <a class="yt-timestamp" data-t="00:47:22">[00:47:22]</a>. The paper argues that equilibrium models are valid on their own terms, and the choice of model depends on the specific intervention type and duration <a class="yt-timestamp" data-t="00:47:07">[00:47:07]</a>.

This research, in collaboration with Russell Steel and Ian Shrier, aims to systematically incorporate different types of interventions (clamp, shock, repeated shocks) into [[causality_and_causal_models | causal inference]] <a class="yt-timestamp" data-t="00:50:06">[00:50:06]</a>. The goal is to understand how interventions change system stability properties and influence feedback loops, as seen in complex scenarios like chemotherapy treatment <a class="yt-timestamp" data-t="00:51:14">[00:51:14]</a>.

### Bridging Dynamical Systems and Causal Models
Exciting work, particularly from the lab of Joris Mooij at the University of Amsterdam, is building bridges between dynamical systems (using differential equations) and [[causality_and_causal_models | causal models]] <a class="yt-timestamp" data-t="00:53:00">[00:53:00]</a>. This approach allows for understanding causal relationships both at and away from equilibrium <a class="yt-timestamp" data-t="00:53:30">[00:53:30]</a>. Herbert Simon, a pioneer in both structural equations and dynamic causal models, established this continuity <a class="yt-timestamp" data-t="00:55:27">[00:55:27]</a>.

## The Big Data Revolution and Causality

The "Big Data Revolution" of the early 2010s championed the idea that vast amounts of data could solve any problem through prediction, potentially rendering [[causality_and_causal_models | causality]] obsolete <a class="yt-timestamp" data-t="00:56:11">[00:56:11]</a>. Dr. Weinberger expresses suspicion towards this view <a class="yt-timestamp" data-t="00:56:54">[00:56:54]</a>. He argues that [[causality_in_marketing | causality]] isn't about indiscriminately feeding data into a machine, but rather about making explicit assumptions to simplify the complex world and enable localized, manageable interactions <a class="yt-timestamp" data-t="00:57:06">[00:57:06]</a>.

While acknowledging the empirical success of approaches like large language models (LLMs) that don't explicitly rely on causal grammar <a class="yt-timestamp" data-t="00:57:31">[00:57:31]</a>, he stresses that [[causality_and_causal_models | causal reasoning]] serves a different purpose <a class="yt-timestamp" data-t="00:59:37">[00:59:37]</a>. It caters to a "limited being operating at a particular time scale" who doesn't need to know "everything happening in the universe" to make local predictions or interventions <a class="yt-timestamp" data-t="00:58:45">[00:58:45]</a>.

## Advice for the Causal Community

Dr. Weinberger offers several pieces of advice for those working with [[causality_and_causal_models | causality]]:

*   **Embrace Being Wrong**: Building an explicit causal graph means that if it's wrong, it becomes a learning opportunity to modify and improve the model <a class="yt-timestamp" data-t="00:38:27">[00:38:27]</a>. Pushing assumptions into a "statistical subconscious" prevents learning <a class="yt-timestamp" data-t="00:38:39">[00:38:39]</a>.
*   **Explicit Assumptions**: Causal models make assumptions explicit through missing arrows in the graph, which is crucial for understanding how they work <a class="yt-timestamp" data-t="00:34:43">[00:34:43]</a>. As Nancy Cartwright said, "no causes in, no causes out" – causal conclusions require causal assumptions <a class="yt-timestamp" data-t="00:35:17">[00:35:17]</a>.
*   **Avoid Implicit Causal Claims**: Many fields, like psychology, might avoid explicit causal methods in their methodology sections but still make causal conclusions (e.g., "X promotes Y") in their discussions <a class="yt-timestamp" data-t="00:37:10">[00:37:10]</a>.
*   **Interdisciplinary Work**: [[Causality_and_causal_models | Causality]] is an excellent field for interdisciplinary work, engaging with various sciences that already care about it <a class="yt-timestamp" data-t="01:07:43">[01:07:43]</a>.
*   **Starting Point**: For beginners, find an aspect that genuinely interests you and relates to your existing knowledge <a class="yt-timestamp" data-t="01:05:28">[01:05:28]</a>. Resources like "The Book of Why" by Judea Pearl <a class="yt-timestamp" data-t="01:06:10">[01:06:10]</a> or introductions to causal algorithms are good starting points <a class="yt-timestamp" data-t="01:06:22">[01:06:22]</a>. Don't overthink where to start; delving into something appealing often leads to deeper understanding later <a class="yt-timestamp" data-t="01:07:06">[01:07:06]</a>.

## Future Outlook

Dr. Weinberger believes that while there has been significant algorithmic development in [[causality_and_machine_learning | causal inference]], many fundamental questions remain unasked <a class="yt-timestamp" data-t="01:18:08">[01:18:08]</a>. He encourages exploring the "conditions of causal representation" – what types of systems these models apply to, and why they work even when assumptions might seem imperfect <a class="yt-timestamp" data-t="01:19:00">[01:19:00]</a>. Understanding "scale relativity" and how causal relationships depend on scale is crucial for this <a class="yt-timestamp" data-t="01:19:46">[01:19:46]</a>.

The interaction between academic and industry causal researchers is seen as "fruitful" but requires more bridges to be built <a class="yt-timestamp" data-t="01:10:28">[01:10:28]</a>. The podcast aims to create an "agora for conversations" between different "clans" (e.g., potential outcomes, causal graphs, epidemiology, econometrics, computer science) that often discuss similar concepts with different terminologies <a class="yt-timestamp" data-t="01:11:04">[01:11:04]</a>. This cross-pollination can promote the usage and [[industrial_applications_of_causal_inference | application of causality in industry]] <a class="yt-timestamp" data-t="01:11:53">[01:11:53]</a>.

Ultimately, Dr. Weinberger asserts that [[applications_of_causal_models_in_business_and_marketing | causality]] is not merely a trend that will fade <a class="yt-timestamp" data-t="01:20:59">[01:20:59]</a>. Many problems, even those perceived as purely predictive, often involve a desire to intervene or understand invariant correlations, which requires causal thinking <a class="yt-timestamp" data-t="01:21:28">[01:21:28]</a>. The challenge lies in teaching people how to implement these tools effectively and aligning their usage with existing incentives and publishing norms in science and industry <a class="yt-timestamp" data-t="01:22:15">[01:22:15]</a>.

## Recommended Resources

*   **Felix Elwert**: Chapter in a handbook for causality (good for social scientists, covers confounding, d-separation, endogenous selection bias, time-varying treatments) <a class="yt-timestamp" data-t="01:13:30">[01:13:30]</a>.
*   **Felix Elwert and Chris Winship**: Paper on endogenous selection bias (conditioning on a collider) <a class="yt-timestamp" data-t="01:14:10">[01:14:10]</a>.
*   **Frederick Eberhardt (Caltech)**: Short introduction (around 12 pages) to [[causality_and_machine_learning | causal inference algorithms]] (covers traditional and machine learning algorithms) <a class="yt-timestamp" data-t="01:14:39">[01:14:39]</a>.
*   **Jonas Peters, Dominik Janzing, Bernhard Schölkopf**: Textbook for more detailed information on algorithms <a class="yt-timestamp" data-t="01:15:53">[01:15:53]</a>.
*   **Michael Nielsen**: Website with an accessible introduction to d-separation <a class="yt-timestamp" data-t="01:16:07">[01:16:07]</a>.
*   **Naftali Weinberger**: Article in the Stanford Encyclopedia of Philosophy on Simpson's Paradox (explains how causal modeling relates to earlier probabilistic theories) <a class="yt-timestamp" data-t="01:16:33">[01:16:33]</a>.