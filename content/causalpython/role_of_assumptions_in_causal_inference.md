---
title: Role of assumptions in causal inference
videoId: Hc3rIGmX59k
---

From: [[causalpython]] <br/> 

Assumptions are fundamental and basic in [[causal_inference_concepts_and_applications | causal inference]] <a class="yt-timestamp" data-t="01:56:45">[01:56:45]</a>. They represent things that are believed in, and faith is built that they work, similar to questioning beliefs in a church setting <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a> <a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>. The core task in [[causal_inference_concepts_and_applications | causal inference]] is to determine how to make it work and which assumptions are more reliable than others <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a> <a class="yt-timestamp" data-t="01:53:00">[01:53:00]</a>.

## Nature of Assumptions
Assumptions are not binary—they are not simply true or false <a class="yt-timestamp" data-t="00:02:00">[00:02:00]</a> <a class="yt-timestamp" data-t="05:10:00">[05:10:00]</a> <a class="yt-timestamp" data-t="03:34:00">[03:34:00]</a>. Instead, they can be thought of as a "slider" that can be pulled up and down, indicating a range of possibilities <a class="yt-timestamp" data-t="00:16:00">[00:16:00]</a> <a class="yt-timestamp" data-t="05:27:00">[05:27:00]</a>. This perspective allows for discussion of assumptions at various levels, moving beyond an "all or nothing" approach <a class="yt-timestamp" data-t="06:36:00">[06:36:00]</a> <a class="yt-timestamp" data-t="07:23:00">[07:23:00]</a>.

## The Cost of Assumptions
A crucial aspect of [[role_of_assumptions_in_machine_learning_models | assumptions in machine learning models]] is their associated "cost" <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a> <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a>.
*   **Expensive Assumptions**: Randomization, considered the best assumption for certainty about a causal effect (e.g., in clinical trials), comes at a significant financial cost, potentially millions or billions in the pharmaceutical industry <a class="yt-timestamp" data-t="02:35:00">[02:35:00]</a> <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>.
*   **"Free" Assumptions**: On the observational side, assumptions like "no unmeasured confounding" are "free" as they are simply stated and assumed true <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>. However, this raises the question of whether money can be spent to reduce the risk of such assumptions being wrong <a class="yt-timestamp" data-t="03:10:00">[03:10:00]</a>.
*   **Cost vs. Risk**: The heavier the assumptions, the larger the risk of being wrong <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a> <a class="yt-timestamp" data-t="03:48:00">[03:48:00]</a>. Spending money, for instance, on discussing untestable assumptions for observational studies, can reduce this risk <a class="yt-timestamp" data-t="04:23:00">[04:23:00]</a> <a class="yt-timestamp" data-t="04:42:00">[04:42:00]</a>.

## Partial Identification and Causal Bounds
The concept of [[challenges_and_methodologies_in_causal_inference | partial identification]] allows for a more nuanced approach to assumptions.
*   Traditionally, [[causal_inference_concepts_and_applications | causal inference]] might require specific assumptions (e.g., A, B, and C) to achieve a "point identification" (a single causal effect number) <a class="yt-timestamp" data-t="05:38:00">[05:38:00]</a>.
*   [[challenges_and_methodologies_in_causal_inference | Partial identification]], or causal bounds, offers an intermediate solution between doing nothing and making very strong assumptions <a class="yt-timestamp" data-t="05:59:00">[05:59:00]</a>. It provides a lower and upper bound on the true effect <a class="yt-timestamp" data-t="06:16:00">[06:16:00]</a>. As more assumptions are added, these bounds become tighter until they collapse into point identification <a class="yt-timestamp" data-t="06:20:00">[06:20:00]</a> <a class="yt-timestamp" data-t="06:26:00">[06:26:00]</a>.
*   **Historical Context**: This field began around 1989 with work by Robins and Pearl, and later expanded upon by economists like Charles Mansky <a class="yt-timestamp" data-t="07:43:00">[07:43:00]</a> <a class="yt-timestamp" data-t="08:00:00">[08:00:00]</a> <a class="yt-timestamp" data-t="08:21:00">[08:21:00]</a>.
*   **Flexibility and Justification**: There is a growing desire for more flexibility, different types of assumptions, and importantly, weaker assumptions, as strong assumptions are inherently difficult to justify <a class="yt-timestamp" data-t="08:45:00">[08:45:00]</a> <a class="yt-timestamp" data-t="08:51:00">[08:51:00]</a>. Providing causal results with weaker assumptions is easier to defend, especially when communicating with policymakers or companies <a class="yt-timestamp" data-t="09:08:00">[09:08:00]</a> <a class="yt-timestamp" data-t="09:11:00">[09:11:00]</a>.

## Relationship to Sensitivity Analysis
While [[challenges_and_methodologies_in_causal_inference | partial identification]] can be intuitively seen as a form of sensitivity analysis, it is more strictly a rephrasing of a causal model <a class="yt-timestamp" data-t="09:39:00">[09:39:00]</a> <a class="yt-timestamp" data-t="09:45:00">[09:45:00]</a>.
*   **Sensitivity Analysis**: Involves introducing a subjective parameter and observing how results change when dialing it up and down <a class="yt-timestamp" data-t="09:59:00">[09:59:00]</a> <a class="yt-timestamp" data-t="10:06:00">[10:06:00]</a>.
*   **Partial Identification**: Is not subjective by default; the only subjective element might be the assumed causal graph <a class="yt-timestamp" data-t="10:30:00">[10:30:00]</a> <a class="yt-timestamp" data-t="10:35:00">[10:35:00]</a>.
*   **Underutilization**: Both [[challenges_and_methodologies_in_causal_inference | partial identification]] and sensitivity analysis are not yet widely known or applied in the community <a class="yt-timestamp" data-t="10:52:00">[10:52:00]</a>. This is partly due to a lack of bandwidth and the significant investment required to implement them, despite ongoing efforts to simplify methods and provide tools <a class="yt-timestamp" data-t="11:40:00">[11:40:00]</a> <a class="yt-timestamp" data-t="12:41:00">[12:41:00]</a>.

## Assumptions in Synthetic Control Methods
Synthetic control, a powerful method used in marketing and time series analysis, also relies on assumptions <a class="yt-timestamp" data-t="33:05:00">[33:05:00]</a> <a class="yt-timestamp" data-t="33:15:00">[33:15:00]</a>.
*   Many of these assumptions are untestable <a class="yt-timestamp" data-t="34:07:00">[34:07:00]</a>.
*   Characterizing synthetic control with Directed Acyclic Graphs (DAGs) can help make the problem easier to analyze and think about identification more clearly <a class="yt-timestamp" data-t="34:30:00">[34:30:00]</a> <a class="yt-timestamp" data-t="39:51:00">[39:51:00]</a>.
*   Sensitivity analysis can be integrated into synthetic control by introducing additional parameters into the causal model <a class="yt-timestamp" data-t="35:39:00">[35:39:00]</a> <a class="yt-timestamp" data-t="36:09:00">[36:09:00]</a>.

## The Causal Hierarchy and Its Implications
The causal hierarchy, also known as Pearl's Causal Ladder, is an essential concept that clarifies the limitations of what can be inferred <a class="yt-timestamp" data-t="21:24:00">[21:24:00]</a> <a class="yt-timestamp" data-t="21:36:00">[21:36:00]</a>.
*   **Level 1 (Association)**: Deals with observational data, which is cheap <a class="yt-timestamp" data-t="23:31:00">[23:31:00]</a>.# Role of Assumptions in Causal Inference

Assumptions are fundamental and basic in [[causal_inference_concepts_and_applications | causal inference]] <a class="yt-timestamp" data-t="01:56:45">[01:56:45]</a>. They represent things that are believed in, and faith is built that they work, similar to questioning beliefs in a church setting <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a> <a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>. The core task in [[causal_inference_concepts_and_applications | causal inference]] is to determine how to make it work and which assumptions are more reliable than others <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a> <a class="yt-timestamp" data-t="01:53:00">[01:53:00]</a>.

## Nature of Assumptions
Assumptions are not binary—they are not simply true or false <a class="yt-timestamp" data-t="00:02:00">[00:02:00]</a> <a class="yt-timestamp" data-t="05:10:00">[05:10:00]</a> <a class="yt-timestamp" data-t="03:34:00">[03:34:00]</a>. Instead, they can be thought of as a "slider" that can be pulled up and down, indicating a range of possibilities <a class="yt-timestamp" data-t="00:16:00">[00:16:00]</a> <a class="yt-timestamp" data-t="05:27:00">[05:27:00]</a>. This perspective allows for discussion of assumptions at various levels, moving beyond an "all or nothing" approach <a class="yt-timestamp" data-t="06:36:00">[06:36:00]</a> <a class="yt-timestamp" data-t="07:23:00">[07:23:00]</a>.

## The Cost of Assumptions
A crucial aspect of [[role_of_assumptions_in_machine_learning_models | assumptions in machine learning models]] is their associated "cost" <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a> <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a>.
*   **Expensive Assumptions**: Randomization, considered the best assumption for certainty about a causal effect (e.g., in clinical trials), comes at a significant financial cost, potentially millions or billions in the pharmaceutical industry <a class="yt-timestamp" data-t="02:35:00">[02:35:00]</a> <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>.
*   **"Free" Assumptions**: On the observational side, assumptions like "no unmeasured confounding" are "free" as they are simply stated and assumed true <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>. However, this raises the question of whether money can be spent to reduce the risk of such assumptions being wrong <a class="yt-timestamp" data-t="03:10:00">[03:10:00]</a>.
*   **Cost vs. Risk**: The heavier the assumptions, the larger the risk of being wrong <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a> <a class="yt-timestamp" data-t="03:48:00">[03:48:00]</a>. Spending money, for instance, on discussing untestable assumptions for observational studies, can reduce this risk <a class="yt-timestamp" data-t="04:23:00">[04:23:00]</a> <a class="yt-timestamp" data-t="04:42:00">[04:42:00]</a>.

## Partial Identification and Causal Bounds
The concept of [[challenges_and_methodologies_in_causal_inference | partial identification]] allows for a more nuanced approach to assumptions.
*   Traditionally, [[causal_inference_concepts_and_applications | causal inference]] might require specific assumptions (e.g., A, B, and C) to achieve a "point identification" (a single causal effect number) <a class="yt-timestamp" data-t="05:38:00">[05:38:00]</a>.
*   [[challenges_and_methodologies_in_causal_inference | Partial identification]], or causal bounds, offers an intermediate solution between doing nothing and making very strong assumptions <a class="yt-timestamp" data-t="05:59:00">[05:59:00]</a>. It provides a lower and upper bound on the true effect <a class="yt-timestamp" data-t="06:16:00">[06:16:00]</a>. As more assumptions are added, these bounds become tighter until they collapse into point identification <a class="yt-timestamp" data-t="06:20:00">[06:20:00]</a> <a class="yt-timestamp" data-t="06:26:00">[06:26:00]</a>.
*   **Historical Context**: This field began around 1989 with work by Robins and Pearl, and later expanded upon by economists like Charles Mansky <a class="yt-timestamp" data-t="07:43:00">[07:43:00]</a> <a class="yt-timestamp" data-t="08:00:00">[08:00:00]</a> <a class="yt-timestamp" data-t="08:21:00">[08:21:00]</a>.
*   **Flexibility and Justification**: There is a growing desire for more flexibility, different types of assumptions, and importantly, weaker assumptions, as strong assumptions are inherently difficult to justify <a class="yt-timestamp" data-t="08:45:00">[08:45:00]</a> <a class="yt-timestamp" data-t="08:51:00">[08:51:00]</a>. Providing causal results with weaker assumptions is easier to defend, especially when communicating with policymakers or companies <a class="yt-timestamp" data-t="09:08:00">[09:08:00]</a> <a class="yt-timestamp" data-t="09:11:00">[09:11:00]</a>.

## Relationship to Sensitivity Analysis
While [[challenges_and_methodologies_in_causal_inference | partial identification]] can be intuitively seen as a form of sensitivity analysis, it is more strictly a rephrasing of a causal model <a class="yt-timestamp" data-t="09:39:00">[09:39:00]</a> <a class="yt-timestamp" data-t="09:45:00">[09:45:00]</a>.
*   **Sensitivity Analysis**: Involves introducing a subjective parameter and observing how results change when dialing it up and down <a class="yt-timestamp" data-t="09:59:00">[09:59:00]</a> <a class="yt-timestamp" data-t="10:06:00">[10:06:00]</a>.
*   **Partial Identification**: Is not subjective by default; the only subjective element might be the assumed causal graph <a class="yt-timestamp" data-t="10:30:00">[10:30:00]</a> <a class="yt-timestamp" data-t="10:35:00">[10:35:00]</a>.
*   **Underutilization**: Both [[challenges_and_methodologies_in_causal_inference | partial identification]] and sensitivity analysis are not yet widely known or applied in the community <a class="yt-timestamp" data-t="10:52:00">[10:52:00]</a>. This is partly due to a lack of bandwidth and the significant investment required to implement them, despite ongoing efforts to simplify methods and provide tools <a class="yt-timestamp" data-t="11:40:00">[11:40:00]</a> <a class="yt-timestamp" data-t="12:41:00">[12:41:00]</a>.

## Assumptions in Synthetic Control Methods
Synthetic control, a powerful method used in marketing and time series analysis, also relies on assumptions <a class="yt-timestamp" data-t="33:05:00">[33:05:00]</a> <a class="yt-timestamp" data-t="33:15:00">[33:15:00]</a>.
*   Many of these assumptions are untestable <a class="yt-timestamp" data-t="34:07:00">[34:07:00]</a>.
*   Characterizing synthetic control with Directed Acyclic Graphs (DAGs) can help make the problem easier to analyze and think about identification more clearly <a class="yt-timestamp" data-t="34:30:00">[34:30:00]</a> <a class="yt-timestamp" data-t="39:51:00">[39:51:00]</a>.
*   Sensitivity analysis can be integrated into synthetic control by introducing additional parameters into the causal model <a class="yt-timestamp" data-t="35:39:00">[35:39:00]</a> <a class="yt-timestamp" data-t="36:09:00">[36:09:00]</a>.

## The Causal Hierarchy and Its Implications
The causal hierarchy, also known as Pearl's Causal Ladder, is an essential concept that clarifies the limitations of what can be inferred <a class="yt-timestamp" data-t="21:24:00">[21:24:00]</a> <a class="yt-timestamp" data-t="21:36:00">[21:36:00]</a>.
*   **Level 1 (Association)**: Deals with observational data, which is cheap <a class="yt-timestamp" data-t="23:31:00">[23:31:00]</a>.
*   **Level 2 (Intervention)**: Making statements about interventions from observational data requires making assumptions that are often hard to defend <a class="yt-timestamp" data-t="22:22:00">[22:22:00]</a> <a class="yt-timestamp" data-t="22:35:00">[22:35:00]</a>. Interventional data is much more expensive than observational data <a class="yt-timestamp" data-t="23:40:00">[23:40:00]</a>.
*   **Level 3 (Counterfactuals)**: Moving from interventional data to counterfactual conclusions also requires strong assumptions, as counterfactual data basically does not exist except in specific cases like twin studies <a class="yt-timestamp" data-t="22:41:00">[22:41:00]</a> <a class="yt-timestamp" data-t="23:41:00">[23:41:00]</a>. The costs of assumptions increase significantly as one moves up the causal ladder <a class="yt-timestamp" data-t="23:27:00">[23:27:00]</a>.

## Expert Knowledge and Assumptions
Integrating expert knowledge is a main challenge in areas like optimal experimentation <a class="yt-timestamp" data-t="53:01:00">[53:01:00]</a> <a class="yt-timestamp" data-t="53:03:00">[53:03:00]</a>.
*   Expert knowledge can be used to tune parameters in surrogate models, helping to find "gold pockets" faster <a class="yt-timestamp" data-t="53:14:00">[53:14:00]</a> <a class="yt-timestamp" data-t="53:26:00">[53:26:00]</a> <a class="yt-timestamp" data-t="53:31:00">[53:31:00]</a>.
*   This knowledge, which can include physics knowledge, helps to exclude physically nonsensical or inconclusive areas in the parameter space <a class="yt-timestamp" data-t="53:47:00">[53:47:00]</a> <a class="yt-timestamp" data-t="54:02:00">[54:02:00]</a>.
*   Expert knowledge, also known as preference elicitation, helps limit the search space for parameters and can improve results <a class="yt-timestamp" data-t="56:11:00">[56:11:00]</a> <a class="yt-timestamp" data-t="56:37:00">[56:37:00]</a> <a class="yt-timestamp" data-t="56:22:00">[56:22:00]</a>.
*   While expert knowledge is valuable, it comes at a cost, and experts can be wrong <a class="yt-timestamp" data-t="56:53:00">[56:53:00]</a> <a class="yt-timestamp" data-t="57:01:00">[57:01:00]</a> <a class="yt-timestamp" data-t="57:11:00">[57:11:00]</a> <a class="yt-timestamp" data-t="58:18:00">[58:18:00]</a>. However, a Bayesian approach can eventually overrule wrong expert knowledge as more true data is collected <a class="yt-timestamp" data-t="58:26:00">[58:26:00]</a> <a class="yt-timestamp" data-t="58:30:00">[58:30:00]</a>. Expert knowledge helps to constrain the bounds of the causal effect, making the solution space smaller <a class="yt-timestamp" data-t="58:07:00">[58:07:00]</a> <a class="yt-timestamp" data-t="58:12:00">[58:12:00]</a>.

## Why Receptivity to Causality Now?
The increased receptivity to [[causal_inference_concepts_and_applications | causality]] in the community, despite the popularity of associative methods like generative models, stems from the failures of traditional machine learning models when the world changes <a class="yt-timestamp" data-t="24:45:00">[24:45:00]</a> <a class="yt-timestamp" data-t="24:52:00">[24:52:00]</a> <a class="yt-timestamp" data-t="24:58:00">[24:58:00]</a>.
*   Models trained on past data fail to predict in altered environments (e.g., airline ticket prices during a pandemic) because they rely on correlation, not underlying causal systems <a class="yt-timestamp" data-t="25:01:00">[25:01:00]</a> <a class="yt-timestamp" data-t="25:12:00">[25:12:00]</a> <a class="yt-timestamp" data-t="25:23:00">[25:23:00]</a>.
*   A lack of causal adjustment or discussion in traditional machine learning models leads to their failure <a class="yt-timestamp" data-t="27:04:00">[27:04:00]</a> <a class="yt-timestamp" data-t="27:13:00">[27:13:00]</a>. This highlights the need to think causally and characterize problems in a better way, rather than blindly retraining models <a class="yt-timestamp" data-t="27:44:00">[27:44:00]</a> <a class="yt-timestamp" data-t="27:46:00">[27:46:00]</a>.
*   The ability to use mathematics to characterize [[causal_inference_concepts_and_applications | causality]] has been a significant development <a class="yt-timestamp" data-t="26:41:00">[26:41:00]</a>.

## Conclusion and Advice
*   **Question Assumptions**: It is crucial to question every assumption, as this process is "pretty cheap" compared to the cost of verifying them <a class="yt-timestamp" data-t="59:35:00">[59:35:00]</a> <a class="yt-timestamp" data-t="59:37:00">[59:37:00]</a>.
*   **Cost-Benefit Analysis**: Think about the "dollar tag" or price of causal assumptions, as they are not free <a class="yt-timestamp" data-t="01:12:12">[01:12:12]</a> <a class="yt-timestamp" data-t="01:12:17">[01:12:17]</a>. Some are cheaper, some more expensive <a class="yt-timestamp" data-t="01:12:21">[01:12:21]</a>.
*   **Prioritize Experimentation**: Consider when experimentation is a good choice, especially to verify results from purely observational studies <a class="yt-timestamp" data-t="01:12:25">[01:12:25]</a> <a class="yt-timestamp" data-t="01:12:47">[01:12:47]</a>.
*   **Focus on Truth**: "Follow the truth, question your assumptions" <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>. One wrong assumption can cause significant damage, while ten well-justified assumptions can go a long way <a class="yt-timestamp" data-t="01:09:44">[01:09:44]</a> <a class="yt-timestamp" data-t="01:09:46">[01:09:46]</a>.
*   **Embrace Quality**: Emphasize quality over quantity in learning [[causal_inference_concepts_and_applications | causality]] <a class="yt-timestamp" data-t="01:07:25">[01:07:25]</a>. The field is not inherently difficult; the teaching methods have been lacking <a class="yt-timestamp" data-t="01:08:08">[01:08:08]</a>.