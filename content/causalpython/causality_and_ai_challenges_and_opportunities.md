---
title: Causality and AI Challenges and Opportunities
videoId: pKhUuwxBdX4
---

From: [[causalpython]] <br/> 

The journey into [[Causality in Artificial Intelligence | causal AI]] began around 2017 when it was a very niche topic, with only a handful of people involved, leading to a "very lonely" initial experience <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>, <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a>, <a class="yt-timestamp" data-t="00:51:00">[00:51:00]</a>. Despite this, there was an early conviction that [[Causality in Artificial Intelligence | causal AI]] would become significant, leading to the laying of foundational work to support the community's exponential growth seen by 2023 <a class="yt-timestamp" data-t="00:31:00">[00:31:00]</a>, <a class="yt-timestamp" data-t="00:39:00">[00:39:00]</a>.

## Motivation for Embracing Causal AI

The decision to focus on [[Causality in Artificial Intelligence | causal AI]] was a "contrarian bet" <a class="yt-timestamp" data-t="00:57:00">[00:57:00]</a>. This view stemmed from experiences in the hedge fund world, where relying solely on historical patterns and correlations in financial markets proved problematic because "the past almost never repeats" <a class="yt-timestamp" data-t="02:07:00">[02:07:00]</a>, <a class="yt-timestamp" data-t="02:12:00">[02:12:00]</a>, <a class="yt-timestamp" data-t="02:18:00">[02:18:00]</a>. The understanding was that winning big often requires taking a contrarian view <a class="yt-timestamp" data-t="02:27:00">[02:27:00]</a>.

A key turning point was observing the excitement around deep learning following AlphaGo's victory in Go around 2017 <a class="yt-timestamp" data-t="01:30:00">[01:30:00]</a>. While deep learning excels in fixed-rule environments like board games, it struggles in the real world where learning historical patterns can lead to trouble <a class="yt-timestamp" data-t="01:52:00">[01:52:00]</a>, <a class="yt-timestamp" data-t="02:07:00">[02:07:00]</a>.

Further personal experience during a PhD in computer vision highlighted these limitations <a class="yt-timestamp" data-t="03:51:00">[03:51:00]</a>. Deep learning models performed "incredibly" in the lab when backgrounds and conditions were consistent, benefiting from more data <a class="yt-timestamp" data-t="04:13:00">[04:13:00]</a>, <a class="yt-timestamp" data-t="04:20:00">[04:20:00]</a>. However, when deployed in the real world, they "catastrophically" broke down <a class="yt-timestamp" data-t="04:26:00">[04:26:00]</a>, <a class="yt-timestamp" data-t="04:42:00">[04:42:00]</a>. In contrast, a model-based approach, despite slightly worse lab performance, retained its performance in the real world, demonstrating much better generalization <a class="yt-timestamp" data-t="04:52:00">[04:52:00]</a>, <a class="yt-timestamp" data-t="05:22:00">[05:22:00]</a>, <a class="yt-timestamp" data-t="05:35:00">[05:35:00]</a>.

## [[Challenges and advancements in causal AI | Challenges of Traditional AI in the Real World]]

The fundamental issue is that without a clear model and understanding of cause and effect mechanisms, AI systems may perform well in controlled lab settings but fail to generalize to the complexities of the real world <a class="yt-timestamp" data-t="05:47:00">[05:47:00]</a>, <a class="yt-timestamp" data-t="05:50:00">[05:50:00]</a>. This explains why 85% to 90% of AI projects in enterprises never make it out of the lab <a class="yt-timestamp" data-t="05:59:00">[05:59:00]</a>, <a class="yt-timestamp" data-t="06:04:00">[06:04:00]</a>. When they do, they often fail to deliver or are not trusted by human users who don't understand the underlying model <a class="yt-timestamp" data-t="06:17:00">[06:17:00]</a>, <a class="yt-timestamp" data-t="06:24:00">[06:24:00]</a>, <a class="yt-timestamp" data-t="06:28:00">[06:28:00]</a>.

## [[Causal AI applications in business and technology | Opportunities and Advantages of Causal AI]]

[[Causality in Artificial Intelligence | Causal AI]] addresses two critical needs: ensuring real-world functionality and building human trust through interpretability <a class="yt-timestamp" data-t="06:41:00">[06:41:00]</a>, <a class="yt-timestamp" data-t="06:50:00">[06:50:00]</a>.

### Concrete Use Case: Manufacturing System Modeling
A client sought to model a physical manufacturing process with inherent cause-and-effect mechanisms <a class="yt-timestamp" data-t="07:23:00">[07:23:00]</a>, <a class="yt-timestamp" data-t="07:30:00">[07:30:00]</a>.
1.  **Deep Learning Failure**: Their initial attempt with deep learning, despite extensive data, worked well in the lab but failed catastrophically in the real world because "the real world was different" <a class="yt-timestamp" data-t="08:18:00">[08:18:00]</a>, <a class="yt-timestamp" data-t="08:26:00">[08:26:00]</a>. Even engaging six deep learning companies did not yield satisfactory results, as the senior leadership couldn't understand how the model explained the real-world connectivity of the machine <a class="yt-timestamp" data-t="08:41:00">[08:41:00]</a>, <a class="yt-timestamp" data-t="08:58:00">[08:58:00]</a>. This led them to nearly abandon AI <a class="yt-timestamp" data-t="09:16:00">[09:16:00]</a>.
2.  **Causal AI Success**: A data scientist introduced them to [[Causality in Artificial Intelligence | causal AI]]. Using automated [[Causality in Artificial Intelligence | causal discovery]] on their data, a "digital twin" of the machine's causal diagram was created <a class="yt-timestamp" data-t="09:35:00">[09:35:00]</a>, <a class="yt-timestamp" data-t="09:42:00">[09:42:00]</a>.
3.  **Human-in-the-Loop Validation**: This diagram was then given to domain experts who could validate and refine it, identifying links missed by the algorithm (e.g., due to lack of historical faults) <a class="yt-timestamp" data-t="09:51:00">[09:51:00]</a>, <a class="yt-timestamp" data-t="10:00:00">[10:00:00]</a>, <a class="yt-timestamp" data-t="10:20:00">[10:20:00]</a>. This iterative process, where humans are involved from the very beginning, is a fundamental difference from deep learning, ensuring trust and a robust causal model <a class="yt-timestamp" data-t="10:26:00">[10:26:00]</a>, <a class="yt-timestamp" data-t="10:31:00">[10:31:00]</a>, <a class="yt-timestamp" data-t="10:46:00">[10:46:00]</a>.

## [[Trends in causal AI | Future of Causal AI]] and Generative AI

While generative AI is seen as "the future" by some, [[Causality in Artificial Intelligence | causal AI]] or causal thinking is also believed to play a critical role in the development of intelligent decision-making systems <a class="yt-timestamp" data-t="19:01:00">[19:01:00]</a>, <a class="yt-timestamp" data-t="19:12:00">[19:12:00]</a>, <a class="yt-timestamp" data-t="19:18:00">[19:18:00]</a>.

[[Causal AI and machine learning | Generative AI]] and [[causal AI and machine learning | causal AI]] are both powerful building blocks <a class="yt-timestamp" data-t="20:01:00">[20:01:00]</a>. The greatest, largely unexploited, potential lies in combining these technologies, where "1 + 1 equals 3" <a class="yt-timestamp" data-t="19:43:00">[19:43:00]</a>, <a class="yt-timestamp" data-t="19:51:00">[19:51:00]</a>. While other building blocks are likely needed for Artificial General Intelligence (AGI), the immediate next step involves integrating these two <a class="yt-timestamp" data-t="20:04:00">[20:04:00]</a>, <a class="yt-timestamp" data-t="20:51:00">[20:51:00]</a>, <a class="yt-timestamp" data-t="20:56:00">[20:56:00]</a>.

A significant current gap is the lack of harmonization among [[causal AI and machine learning | causal AI]] packages <a class="yt-timestamp" data-t="21:26:00">[21:26:00]</a>. There is a need for unified interfaces for causal discovery, causal modeling, and decision intelligence engines, similar to what libraries like scikit-learn provide for traditional machine learning <a class="yt-timestamp" data-t="21:29:00">[21:29:00]</a>, <a class="yt-timestamp" data-t="21:40:00">[21:40:00]</a>, <a class="yt-timestamp" data-t="21:55:00">[21:55:00]</a>. Open-sourcing such interfaces is a key step towards broader adoption <a class="yt-timestamp" data-t="22:01:00">[22:01:00]</a>.

## Advice for Starting with Causality

For those new to [[Causality in Artificial Intelligence | causality]], advice includes:
*   **Confidence**: [[Causality in Artificial Intelligence | Causal AI]] is now much more accessible than in 2017, with available resources <a class="yt-timestamp" data-t="16:50:00">[16:50:00]</a>.
*   **Read "The Book of Why"**: This book is crucial for understanding foundational causal theory and terminology <a class="yt-timestamp" data-t="17:07:00">[17:07:00]</a>, <a class="yt-timestamp" data-t="17:20:00">[17:20:00]</a>.
*   **Experiment with Open-Source Tooling**: There are many new open-source [[causal AI and machine learning | causal packages]] with great examples available <a class="yt-timestamp" data-t="17:32:00">[17:32:00]</a>, <a class="yt-timestamp" data-t="17:37:00">[17:37:00]</a>. Efforts are underway to open-source more algorithms and offer free community versions of enterprise platforms to simplify the learning journey <a class="yt-timestamp" data-t="17:45:00">[17:45:00]</a>, <a class="yt-timestamp" data-t="17:52:00">[17:52:00]</a>.
*   **Engage with the Community**: Attend events like the Causal AI conference, which is a community event focused on learning <a class="yt-timestamp" data-t="18:36:00">[18:36:00]</a>, <a class="yt-timestamp" data-t="18:41:00">[18:41:00]</a>.