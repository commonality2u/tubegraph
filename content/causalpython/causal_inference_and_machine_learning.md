---
title: Causal inference and machine learning
videoId: eCtLAt-6yps
---

From: [[causalpython]] <br/> 
The intersection of [[Machine learning and causality]] is a rapidly evolving field, particularly for applications requiring robust decision-making and understanding underlying data generation processes <a class="yt-timestamp" data-t="00:00:15">[00:00:15]</a>. Dr. Andrew Lawrence, Director of Research at Calen, emphasizes that traditional machine learning algorithms, while successful in some domains, often overfit and fail to generalize when interventions occur because they do not capture the true data-generating process <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>, <a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a>.

## Dr. Andrew Lawrence's Background and Entry into Causality
Dr. Andrew Lawrence's journey into [[Causal AI and machine learning intersection]] began after his PhD from the University of Bath, which focused on Bayesian nonparametrics <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>. While not directly tied to causality, this work provided a strong foundational knowledge to quickly grasp causal topics <a class="yt-timestamp" data-t="01:13:00">[01:13:00]</a>. He joined Calen in late 2019, gaining his first experience with causality topics through technical interviews and learning on the job for four years <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a>.

His PhD research in Bayesian nonparametrics, specifically with Gaussian processes and Dirichlet processes for generative modeling and latent variable models, proved applicable to [[Integration of Causal Thinking in Machine Learning]] <a class="yt-timestamp" data-t="02:22:00">[02:22:00]</a>. He views causality as "figuring out the right way to factor the joint distribution" <a class="yt-timestamp" data-t="02:16:00">[02:16:00]</a>, emphasizing the direction of influence or information flow between variables <a class="yt-timestamp" data-t="03:15:00">[03:15:00]</a>. This structural thinking, though not involving structural equation models directly in his PhD, naturally led to understanding causal concepts <a class="yt-timestamp" data-t="03:41:00">[03:41:00]</a>, <a class="yt-timestamp" data-t="04:28:00">[04:28:00]</a>.

## Traditional Machine Learning vs. Causal Models
Today's data culture often prioritizes complex architectures that minimize in-sample error without deeply considering the data's origin or meaning <a class="yt-timestamp" data-t="04:47:00">[04:47:00]</a>. While successful in some domains, this approach, often seen in deep learning, can lead to overfitting <a class="yt-timestamp" data-t="05:49:00">[05:49:00]</a>. If the chosen covariates do not actually drive how the data is generated, models may perform well in the training domain but "fall apart" when applied to out-of-sample data or interventions <a class="yt-timestamp" data-t="06:00:00">[06:00:00]</a>. This highlights a key challenge in [[Challenges in causal machine learning compared to traditional methods]]: the need to find what truly drives the target of interest to generalize to unseen data <a class="yt-timestamp" data-t="06:17:00">[06:17:00]</a>.

## Distinction: Generative AI vs. Safety-Critical Applications
A crucial distinction between causal and associative models lies in their application contexts:

*   **Creative/Low-Risk Applications**: Generative AI (e.g., ChatGPT, Midjourney, DALL-E) and facial recognition (e.g., Facebook) use associative models <a class="yt-timestamp" data-t="07:09:00">[07:09:00]</a>. Errors in these domains are often tolerable, as users can correct them (e.g., a wrong facial tag) or the consequences are not safety-critical (e.g., starting a class with AI-generated code) <a class="yt-timestamp" data-t="07:25:00">[07:25:00]</a>. However, risks still exist, as seen with the lawyer who used hallucinated cases from ChatGPT, leading to job loss <a class="yt-timestamp" data-t="07:27:00">[07:27:00]</a>.
*   **High-Value/Safety-Critical Applications**: In domains like healthcare or multi-million dollar marketing campaigns, errors can be detrimental <a class="yt-timestamp" data-t="06:30:00">[06:30:00]</a>, <a class="yt-timestamp" data-t="08:34:00">[08:34:00]</a>. Here, minimizing in-sample error is insufficient; understanding causal drivers is paramount to avoid significant financial losses or safety risks <a class="yt-timestamp" data-t="06:36:00">[06:36:00]</a>. This directly relates to the [[Application of causal machine learning in medicine]].

## Prediction vs. Decision Making
Another fundamental difference is between prediction (blindly observing a stationary system) and decision-making (intervening in a system) <a class="yt-timestamp" data-t="08:58:00">[08:58:00]</a>. Associative models excel at blind prediction in stationary systems <a class="yt-timestamp" data-t="10:03:00">[10:03:00]</a>. However, when an intervention occurs (e.g., rebalancing a marketing budget, updating a manufacturing pipeline, changing a supply chain), the underlying data-generating process changes from an observational to an interventional distribution <a class="yt-timestamp" data-t="10:08:00">[10:08:00]</a>. An associative model cannot reliably predict in such scenarios <a class="yt-timestamp" data-t="10:28:00">[10:28:00]</a>.

## Calen's Causal Workflow and Structural Causal Models (SCMs)
At Calen, the focus is on the Pearl School of Causality, heavily utilizing structural causal models (SCMs) <a class="yt-timestamp" data-t="10:43:00">[10:43:00]</a>. Their proprietary SCM, called Causal Net, is used for customer problems <a class="yt-timestamp" data-t="10:39:00">[10:39:00]</a>. The typical workflow involves:

1.  **Iterative Graph Development with Customers**: Collaborating with clients to incorporate domain knowledge and understand the hierarchy of variables (e.g., age being a top-level variable, marketing channels as intervention points, click-through rate as a response) <a class="yt-timestamp" data-t="10:51:00">[10:51:00]</a>. This process helps reduce the search space for possible graphs <a class="yt-timestamp" data-t="11:34:00">[11:34:00]</a>.
2.  **Causal Discovery Algorithms**: Employing a suite of [[Causal discovery and inference in AI]] algorithms, including constraint-based, score-based, continuous optimization, and model-based methods (e.g., LinGAM) <a class="yt-timestamp" data-t="11:43:00">[11:43:00]</a>. The choice of method depends on data types (e.g., score-based for continuous, constraint-based for mixed data using conditional mutual information) <a class="yt-timestamp" data-t="11:58:00">[11:58:00]</a>. This iterative process aims to recover a Markov equivalence class of graphs, which is then refined with customer input <a class="yt-timestamp" data-t="12:27:00">[12:27:00]</a>.
3.  **Fitting SCMs**: Calen uses various backends to fit the SCM, learning the functional forms and aggregations (e.g., linear, polynomial, monotonic, or monotonic with saturation) for connections between variables:
    *   PyTorch (stochastic gradient descent) <a class="yt-timestamp" data-t="13:07:00">[13:07:00]</a>
    *   CVXPy (convex optimization) <a class="yt-timestamp" data-t="13:11:00">[13:11:00]</a>
    *   Pyro (distributional inference using stochastic variational inference) <a class="yt-timestamp" data-t="13:17:00">[13:17:00]</a>
    The modeling language is designed to be agnostic to the training engine, though some functional dependencies might be limited based on the engine <a class="yt-timestamp" data-t="14:06:00">[14:06:00]</a>.

## Improvements in SCM Implementation (Double ML Inspired Training)
Calen has developed an SCM training approach inspired by Double Machine Learning (Double ML) to provide unbiased effect estimators for any pair of nodes in the SCM <a class="yt-timestamp" data-t="15:05:00">[15:05:00]</a>, <a class="yt-timestamp" data-t="30:52:00">[30:52:00]</a>. Traditional Double ML is specific to known treatment and outcome variables <a class="yt-timestamp" data-t="15:13:00">[15:13:00]</a>. Calen's adaptation builds a "training graph" that defines the order and data splits for training nodes, preventing bias propagation from confounding variables <a class="yt-timestamp" data-t="17:20:00">[17:20:00]</a>. This approach makes it possible to query the causal effect of any variable on another within the SCM, even if it means a slight loss in predictive accuracy for specific target variables <a class="yt-timestamp" data-t="31:17:00">[31:17:17]</a>. This is a practical example of [[advances in causal machine learning research]].

## Uncertainty Quantification with Conformal Prediction
For uncertainty quantification, Calen has integrated conformal prediction (using the Mappy library) into its causal impact package, particularly for time series data <a class="yt-timestamp" data-t="18:55:00">[18:55:00]</a>. The causal impact package, inspired by Google's Bayesian state-space model, focuses on estimating intervention effects by comparing an intervened series with similar non-intervened series (synthetic controls) <a class="yt-timestamp" data-t="19:07:00">[19:07:00]</a>. While useful, the application of conformal prediction to non-stationary time series data is still an area of ongoing research <a class="yt-timestamp" data-t="20:53:00">[20:53:00]</a>. This demonstrates the company's work in [[Machine learning and causal inference methodologies]].

## Modular Product Architecture
Calen's product is a modular cloud platform deployable on various cloud providers (Azure, GCP, AWS) or on-site <a class="yt-timestamp" data-t="22:12:00">[22:12:00]</a>. It provides a Jupiter Lab environment where data scientists can access Calen's packages and seamlessly integrate open-source tools like Huawei's G-Castle or NetworkX <a class="yt-timestamp" data-t="22:34:00">[22:34:00]</a>, <a class="yt-timestamp" data-t="01:20:19">[01:20:19]</a>. This modularity extends to decision intelligence engines, which take trained SCMs for algorithmic recourse or root cause analysis <a class="yt-timestamp" data-t="01:21:55">[01:21:55]</a>.

## Handling Out-of-Range Data with Shape-Constrained Edges
A significant challenge in [[Benefits and challenges of causal machine learning]] is predicting behavior when data moves beyond the training range <a class="yt-timestamp" data-t="23:05:00">[23:05:00]</a>. Calen addresses this by using "shape-constrained edges" in their SCMs <a class="yt-timestamp" data-t="23:47:00">[23:47:00]</a>. These edges force specific extrapolating behaviors, such as:
*   **Monotonic edges**: Ensuring continuous increase or decrease outside the training domain <a class="yt-timestamp" data-t="24:03:00">[24:03:00]</a>.
*   **Monotonic with saturation**: Allowing for diminishing returns beyond a certain point <a class="yt-timestamp" data-t="24:17:00">[24:17:00]</a>.
*   **Piecewise linear edges**: Defining linear extrapolation outside fitted transition points <a class="yt-timestamp" data-t="24:28:00">[24:28:00]</a>.

This approach builds trust in models by providing predictable behavior in unobserved data regions, unlike complex neural networks that can behave arbitrarily outside the training domain <a class="yt-timestamp" data-t="24:44:00">[24:44:00]</a>. It also allows for incorporating expert knowledge about how relationships should extrapolate <a class="yt-timestamp" data-t="25:48:00">[25:48:00]</a>.

## Causal Discovery and Expert Knowledge
In [[Causal discovery and inference in AI]], Calen emphasizes the iterative nature of working with human experts <a class="yt-timestamp" data-t="27:22:00">[27:22:00]</a>. Customers may come with extensive domain knowledge, sometimes even full graphs, which Calen validates against data and various causal discovery algorithms <a class="yt-timestamp" data-t="27:49:00">[27:49:00]</a>. For those with less initial knowledge, Calen extracts hierarchical information (e.g., nodes that can only be sources or sinks) to significantly reduce the search space of possible graphs without introducing too much bias <a class="yt-timestamp" data-t="28:13:00">[28:13:00]</a>, <a class="yt-timestamp" data-t="48:12:00">[48:12:00]</a>.

It's acknowledged that obtaining a "perfect" DAG is often not necessary <a class="yt-timestamp" data-t="31:57:00">[31:57:00]</a>. The required graph structure depends on the specific estimation problem; a partial graph focusing on local structure might suffice for understanding drivers of a specific target variable <a class="yt-timestamp" data-t="32:31:00">[32:31:00]</a>, <a class="yt-timestamp" data-t="50:34:00">[50:34:00]</a>.

## Time Series Causal Discovery
Dr. Lawrence's research in time series causal discovery focused on breaking underlying assumptions of existing methods to test their sensitivity <a class="yt-timestamp" data-t="35:29:00">[35:29:00]</a>. This involved generating synthetic data to validate how methods like VAR-LinGAM and PCMC (using different conditional independence testers) performed under violations of linearity, Gaussian noise assumptions, or in the presence of hidden confounding <a class="yt-timestamp" data-t="35:51:00">[35:51:00]</a>. Their open-sourced software allows for quick generation of time series data to test algorithm robustness <a class="yt-timestamp" data-t="36:27:00">[36:27:00]</a>. This work addresses the challenge of applying theoretical causal discovery to real-world scenarios where assumptions are often violated (e.g., unobserved confounding, imperfect conditional independence testers) <a class="yt-timestamp" data-t="36:41:00">[36:41:00]</a>.

## A* Search Algorithm in Causal Discovery
Calen also explored the A* search algorithm for causal discovery, particularly for purely continuous data <a class="yt-timestamp" data-t="41:52:00">[41:52:00]</a>. This method, specifically its extensions like A* Superstructure and Local A*, uses an exact search score-based approach with the Bayesian Information Criterion (BIC) to find the shortest path (best parent graph) for each node <a class="yt-timestamp" data-t="42:53:00">[42:53:00]</a>. It assumes linearity, Gaussian additive noise, and causal sufficiency <a class="yt-timestamp" data-t="44:09:00">[44:09:00]</a>.

A* Superstructure uses Graphical Lasso as an initial filtering step to prune the set of potential parents <a class="yt-timestamp" data-t="44:34:00">[44:34:00]</a>. Graphical Lasso estimates a sparse Precision Matrix, providing a sparse undirected graph as a starting point, assuming Gaussian and linear data <a class="yt-timestamp" data-t="45:13:00">[45:13:00]</a>. Calen's paper extended this by encoding domain knowledge (e.g., known edges, forbidden edges, source/sink nodes) to further filter parent graphs, significantly speeding up the A* search <a class="yt-timestamp" data-t="46:47:00">[46:47:00]</a>. For example, defining three tiers (source, middle, sink nodes) can reduce BIC computations by half <a class="yt-timestamp" data-t="48:30:00">[48:30:00]</a>. This ability to incorporate even partial information helps reduce the "NP-hard problem" of discovering Bayesian networks and the super-exponential growth of the graph space <a class="yt-timestamp" data-t="49:57:00">[49:57:00]</a>.

## Addressing Hidden Confounding and Graph Types
The formalism of directed acyclic graphs (DAGs) can seem limiting due to potential hidden confounding <a class="yt-timestamp" data-t="52:19:00">[52:19:00]</a>. However, [[Causal discovery and inference in AI]] methods can resolve up to a Markov equivalence class of graphs, which can be encoded into mixed graph types like completed partial DAGs (CPDAGs) or partial ancestral graphs (PAGs) <a class="yt-timestamp" data-t="53:10:00">[53:10:00]</a>. Inference can be performed directly on these mixed graph types without needing to resolve to a single DAG, thus addressing identifiability challenges even with unobserved confounders <a class="yt-timestamp" data-t="53:43:00">[53:43:00]</a>.

## Real-World Challenges and Use Cases
Calen applies causality to complex real-world scenarios:

*   **Supply Chain Management**: Challenges include inherent insufficiency (not all variables can be captured) and high non-stationarity <a class="yt-timestamp" data-t="55:55:00">[55:55:00]</a>. Calen uses time series tools like fractional differencing to stationarize data before applying causal discovery techniques to understand drivers of KPIs like throughput or lead times <a class="yt-timestamp" data-t="56:45:00">[56:45:00]</a>.
*   **Manufacturing**: This domain often has an underlying physical system with constrained information flow (e.g., assembly lines), making causal modeling more straightforward <a class="yt-timestamp" data-t="57:36:00">[57:36:00]</a>. Use cases frequently involve root cause analysis to identify steps in the pipeline leading to anomalous outcomes like bad yield rates <a class="yt-timestamp" data-t="58:21:00">[58:21:00]</a>.

In both cases, the goal is not just prediction but to understand what interventions to make for optimal outcomes (e.g., algorithmic recourse, maximizing revenue) <a class="yt-timestamp" data-t="54:46:00">[54:46:00]</a>.

## The Future of Causal AI
The future of AI lies in causality, especially for decision-making in high-value or safety-critical systems where errors can be detrimental to life or revenue <a class="yt-timestamp" data-t="01:06:04">[01:06:04]</a>, <a class="yt-timestamp" data-t="01:26:04">[01:26:04]</a>. While associative models are valid for entertainment or low-risk use cases, causal methods are essential when needing to understand actions and their unbiased effects <a class="yt-timestamp" data-t="01:26:27">[01:26:27]</a>.

## Resources for Learning Causality
*   Brady Neal's online course/tutorial on causality <a class="yt-timestamp" data-t="01:13:25">[01:13:25]</a>
*   "Elements of Causal Inference" (more advanced) <a class="yt-timestamp" data-t="01:13:41">[01:13:41]</a>
*   "The Book of Why" by Judea Pearl (more narrative) <a class="yt-timestamp" data-t="01:13:48">[01:13:48]</a>
*   Summer school lectures and various online resources <a class="yt-timestamp" data-t="01:14:11">[01:14:11]</a>
*   Christopher Bishop's "Machine Learning and Pattern Recognition" (fundamental machine learning) <a class="yt-timestamp" data-t="01:11:44">[01:11:44]</a>

## Calen Resources
*   **Website**: causallens.com (includes research page) <a class="yt-timestamp" data-t="01:26:58">[01:26:58]</a>
*   **YouTube**: Talks and learning videos <a class="yt-timestamp" data-t="01:27:21">[01:27:21]</a>
*   **GitHub**: github.com/CausalLens (includes open-sourced front-end package Dara, causal graph library, and code for time series causal discovery paper and "Beware of the Simulated DAG" paper) <a class="yt-timestamp" data-t="01:27:31">[01:27:31]</a>, <a class="yt-timestamp" data-t="01:28:08">[01:28:08]</a>.