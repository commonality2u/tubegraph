---
title: Time series causal discovery
videoId: eCtLAt-6yps
---

From: [[causalpython]] <br/> 
[[Time scale in causal models | Time Series Causal Discovery]] is a crucial area in causal analysis, especially when dealing with dynamic systems where data is collected sequentially over time. The goal is to uncover causal relationships, including the direction and strength of influence, among variables that evolve through time <a class="yt-timestamp" data-t="03:00:54">[03:00:54]</a>.

### Challenges in [[Time scale in causal models | Time Series Causal Discovery]]

One significant challenge in [[Time scale in causal models | time series causal discovery]] is handling non-stationary data, where the underlying statistical properties change over time <a class="yt-timestamp" data-t="05:56:00">[05:56:00]</a>. This requires techniques to make the data stationary, such as fractional differences, which look at the change in data rather than absolute values <a class="yt-timestamp" data-t="05:59:00">[05:59:00]</a>.

Other challenges include:
*   **Instantaneous Effects**: While in reality, everything is lagged at a sufficiently fine resolution (e.g., nanoseconds), practical measurements at daily, weekly, or monthly resolutions can show instantaneous effects. Algorithms must account for this, as seen in extensions like PCMCI+ <a class="yt-timestamp" data-t="03:40:00">[03:40:00]</a>.
*   **Cyclic Structures**: At certain time scales, variables might appear to have cyclic relationships. However, when uncompressed to a finer time scale, these apparent cycles resolve into lagged, directed relationships <a class="yt-timestamp" data-t="03:19:00">[03:19:00]</a>. The choice of [[Time scale in causal models | time scale]] influences the perceived model <a class="yt-timestamp" data-t="03:22:00">[03:22:00]</a>.
*   **Unobserved Confounding**: It is almost certain that real-world datasets will contain unmeasured variables affecting observed covariates, which can bias [[causal_discovery_algorithms]] that assume no hidden confounding <a class="yt-timestamp" data-t="03:57:00">[03:57:00]</a>.
*   **Perfect Oracle/Conditional Independence Testers**: [[causal_discovery_algorithms]] often assume perfect conditional independence testers, which is unrealistic with small sample sizes where certainty cannot be 100% <a class="yt-timestamp" data-t="04:13:00">[04:13:00]</a>.
*   **Generalizability**: Models that perform well on training data may overfit and fail to generalize to out-of-sample data, especially when interventions change the underlying data-generating process <a class="yt-timestamp" data-t="05:58:00">[05:58:00]</a>.

### Methods and Approaches

Various [[causal_discovery_algorithms | causal discovery algorithms]] are applied in the time series domain:
*   **Vector Autoregressive (VAR) Lingam/No Tears**: These are model-based [[causal_discovery_algorithms]] that assume linearity and Gaussian additive noise <a class="yt-timestamp" data-t="03:51:00">[03:51:00]</a>. However, their assumptions regarding synthetic data may not always hold true in real-world scenarios <a class="yt-timestamp" data-t="03:56:00">[03:56:00]</a>.
*   **PCMCI**: This constraint-based method is often used for [[Time scale in causal models | time series causal discovery]], with extensions like PCMCI+ allowing for instantaneous effects <a class="yt-timestamp" data-t="03:57:00">[03:57:00]</a>. It uses different conditional independence testers <a class="yt-timestamp" data-t="03:59:00">[03:59:00]</a>.
*   **A* (A-star) Algorithm**: Used in methods like Triplet A* and A* Superstructure, this is an exact search score-based method that uses the Bayesian Information Criterion (BIC) to find the shortest path (best score) through potential parent graphs. It assumes linearity and Gaussian additive noise and requires causal sufficiency (all interacting variables are observed) <a class="yt-timestamp" data-t="04:22:00">[04:22:00]</a>. Graphical Lasso can be used as an initial filtering step to prune the search space for potential parents <a class="yt-timestamp" data-t="04:49:00">[04:49:00]</a>.
*   **Synthetic Control Framework**: This approach uses similar time series data from non-intervened units (e.g., countries, cities) to create a synthetic control, allowing for the estimation of an intervention's effect when only post-intervention data is available <a class="yt-timestamp" data-t="01:19:00">[01:19:00]</a>.
*   **Structural Causal Models (SCMs)**: At Calin, a proprietary Structural Causal Model called Causal Net is used. This involves iterating on an underlying graph with customers, incorporating domain knowledge, and using a suite of [[causal_discovery_algorithms]] (constraint-based, score-based, continuous optimization, model-based like Lingam) <a class="yt-timestamp" data-t="01:40:00">[01:40:00]</a>.

### Practical Implementation and Considerations

Practical implementation often involves:
*   **Iterative Approach**: Working closely with domain experts to build and refine the causal graph. Customers may provide initial graphs or insights into variable hierarchies (e.g., age as a top node) to reduce the search space of possible graphs <a class="yt-timestamp" data-t="01:09:00">[01:09:00]</a>.
*   **Modular [[Tools and frameworks for causal analysis | Tools and frameworks for causal analysis]]**: Using a suite of [[causal_discovery_algorithms]] tailored for different data types (e.g., score-based for continuous data, constraint-based with conditional mutual information for mixed data) <a class="yt-timestamp" data-t="01:11:00">[01:11:00]</a>.
*   **Functional Dependencies**: Training functional forms of connections between variables using different engines like PyTorch (stochastic gradient descent), CVXPy (convex optimization), and Pyro (stochastic variational inference for distributional forecasting) <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>.
*   **Shape-Constrained Edges**: To ensure models extrapolate reliably beyond the training domain, "shape-constrained" edges are used (e.g., monotonic, monotonic with saturation, piecewise linear). This helps build trust and predictability in the model's behavior for unseen data points <a class="yt-timestamp" data-t="02:34:00">[02:34:00]</a>.
*   **Double ML Inspired Training**: An approach to train SCMs that aims to provide unbiased effect estimates, similar to Double Machine Learning (DML). It involves splitting data and training nodes in a defined order to remove bias from confounding, though it might limit some dependencies to be linear <a class="yt-timestamp" data-t="03:37:00">[03:37:37]</a>.
*   **Uncertainty Quantification**: Methods like Conformal Prediction (e.g., Mappy library) can be integrated with [[Causal Impact and Analysis | causal impact]] packages to provide uncertainty estimations, especially in time series domains, although challenges exist due to non-stationarity <a class="yt-timestamp" data-t="01:54:00">[01:54:00]</a>.
*   **Validation**: It is crucial to validate causal models by performing training, validation, and test splits. This allows for checking predictive performance and verifying estimated effects against any available interventional data <a class="yt-timestamp" data-t="02:59:00">[02:59:00]</a>.
*   **Domain Knowledge**: Incorporating prior knowledge, such as known or forbidden edges, or defining tiers (source, sink, middle nodes) within the graph, can significantly reduce the search space for [[Causal Discovery Algorithms and Techniques | causal discovery algorithms]], which is an NP-hard problem <a class="yt-timestamp" data-t="04:49:00">[04:49:00]</a>.

### Distinction from Associative Models

A key distinction between causal and associative models lies in their applicability for decision-making versus mere prediction <a class="yt-timestamp" data-t="08:52:00">[08:52:00]</a>. Associative models excel at predicting outcomes based on passively observed systems, assuming stationarity <a class="yt-timestamp" data-t="09:51:00">[09:51:00]</a>. However, they fail when an intervention occurs, as this shifts the underlying data-generating process to an interventional distribution, which associative models are not designed to handle <a class="yt-timestamp" data-t="10:08:00">[10:08:00]</a>.

Causal models are essential for high-value or safety-critical applications, such as healthcare or multi-million dollar marketing campaigns, where erroneous predictions or decisions can have detrimental consequences <a class="yt-timestamp" data-t="06:32:00">[06:32:00]</a>. Unlike generative AI (e.g., ChatGPT or Midjourney), where occasional errors might be tolerable for creative tasks, causal models must be robust when used for critical decisions like optimizing manufacturing pipelines or rebalancing budgets <a class="yt-timestamp" data-t="07:02:00">[07:02:02]</a>.

### Future Outlook

The field of [[Causal Discovery and Analysis | causal discovery and analysis]] is progressing, but there's a recognized need for more real-world datasets with ground truth causal structures to properly benchmark [[causal_discovery_algorithms]] <a class="yt-timestamp" data-t="03:59:00">[03:59:00]</a>. Initiatives like the "call for data sets" at conferences aim to address this <a class="yt-timestamp" data-t="03:44:00">[03:44:00]</a>. Constant communication and collaboration within the [[Practical implementation of causal discovery using Python | causal Python community]] are vital for spurring new ideas and advancements <a class="yt-timestamp" data-t="01:25:57">[01:25:57]</a>. The future of decision-making, especially in safety-critical and high-value systems, relies on causal methods <a class="yt-timestamp" data-t="01:26:04">[01:26:04]</a>.