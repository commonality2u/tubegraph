---
title: Causal AI in Supply Chain Management
videoId: gmFWhAAeBfE
---

From: [[causalpython]] <br/> 

[[Causal AI and machine learning | Causal AI]], particularly [[causal AI and machine learning | causal machine learning]], is gaining significant traction in various industries, including supply chain management, by offering capabilities beyond mere prediction, such as explainability and business recommendations <a class="yt-timestamp" data-t="04:47:48">[04:47:48]</a>. This emerging field is seen as a crucial tool for businesses to make data-backed decisions and navigate increasingly complex global challenges <a class="yt-timestamp" data-t="08:29:21">[08:29:21]</a>.

## Isan Gupta's Journey to Causal AI
Isan Gupta, a lead data scientist at BMW Group, realized the potential of data at a young age and has a diverse background, including web and Android development <a class="yt-timestamp" data-t="03:05:37">[03:05:37]</a>. His fascination with predicting outcomes, initially for stock investments and sports results, led him to data science <a class="yt-timestamp" data-t="03:36:00">[03:36:00]</a>.

Gupta identified a "missing thing" in traditional data science: the explainability part, which often resulted in black-box models producing mere predictions rather than actionable business recommendations <a class="yt-timestamp" data-t="03:52:00">[03:52:00]</a>. With an entrepreneurial mindset, he sought ways to make a tangible difference beyond just predicting <a class="yt-timestamp" data-t="04:05:00">[04:05:00]</a>.

He discovered causality through self-research, Googling terms like "explainability" and "how to input tribal knowledge into models" <a class="yt-timestamp" data-t="05:01:00">[05:01:00]</a>. Reading "The Book of Why" by Judea Pearl was a pivotal moment, connecting the missing pieces and covering areas like explainability, black-box modeling, and the ability to conduct "what if" or counterfactual scenarios <a class="yt-timestamp" data-t="05:36:00">[05:36:00]</a>.

## PhD Focus: Causal AI in Supply Chain Management
Isan Gupta pursued a PhD program in Germany that combined theoretical research with practical industry application, allowing him to immediately apply his learnings and observe their impact on business decisions <a class="yt-timestamp" data-t="06:09:00">[06:09:00]</a>. His main area of focus was supply chain management <a class="yt-timestamp" data-t="07:17:00">[07:17:00]</a>.

Supply chains are increasingly complex due to geopolitical issues, pandemics (like COVID-19), and semiconductor shortages, particularly affecting the automotive industry <a class="yt-timestamp" data-t="07:54:00">[07:54:00]</a>. These challenges also present an opportunity for companies to leverage [[causal_ai_applications_in_business_and_technology | causal machine learning]] to make better, data-backed decisions and provide business recommendations beyond simple predictions <a class="yt-timestamp" data-t="08:17:00">[08:17:00]</a>.

## Challenges Addressed by Causal Machine Learning
Traditional statistical and machine learning solutions often fall short in addressing key business needs, particularly around explainability and trust <a class="yt-timestamp" data-t="08:45:00">[08:45:00]</a>.

Managers frequently ask data scientists to explain models, identify root causes, and provide actionable next steps <a class="yt-timestamp" data-t="09:06:00">[09:06:00]</a>. However, data scientists often struggle to explain traditional black-box models, relying on complex metrics like accuracy scores or post-hoc explainability methods (LIME, SHAP) that stakeholders find difficult to trust <a class="yt-timestamp" data-t="09:10:00">[09:10:00]</a>. This creates a gap where stakeholders lose faith in the models <a class="yt-timestamp" data-t="09:31:00">[09:31:00]</a>.

[[Causal AI and machine learning | Causal machine learning]] addresses these challenges by offering:
*   **Explainability**: Causal Discovery Graphs make models inherently more explainable <a class="yt-timestamp" data-t="10:01:00">[10:01:00]</a>.
*   **Simulations**: The ability to run "what if" (counterfactual) simulations, including historical and future scenarios, builds trust with management <a class="yt-timestamp" data-t="10:07:00">[10:07:00]</a>.
*   **Integration of Expert Knowledge**: Causal models can incorporate the "tribal knowledge" of business experts, making the models an extension of their own understanding <a class="yt-timestamp" data-t="10:25:00">[10:25:00]</a>. This involvement leads to increased trust and a desire from experts to improve the models <a class="yt-timestamp" data-t="10:40:00">[10:40:00]</a>.

## Iterative Approach to Causal Models
An iterative approach, where models start simple and gradually build complexity, is a highly effective strategy in corporate settings <a class="yt-timestamp" data-t="11:48:00">[11:48:00]</a>. This method helps build trust with stakeholders, as they can see tangible results from the outset <a class="yt-timestamp" data-t="12:00:00">[12:00:00]</a>. While models should offer "something extra" beyond obvious conclusions, starting small allows for continuous improvement and validation <a class="yt-timestamp" data-t="12:25:00">[12:25:27]</a>.

## Causal Discovery Challenges and Solutions
[[causality_and_ai_challenges_and_opportunities | Causal discovery]] can be challenging in real-world settings due to inherent limitations of the methods <a class="yt-timestamp" data-t="12:39:00">[12:39:00]</a>. However, Isan views these algorithms as a way to reduce human biases, emphasizing that neither models nor humans are perfect <a class="yt-timestamp" data-t="13:15:00">[13:15:00]</a>.

His experience with causal discovery algorithms has been positive. He conducted a study where he compared algorithmically discovered causal graphs with "ground truth" tribal knowledge graphs obtained from interviewing 25 experts <a class="yt-timestamp" data-t="13:35:00">[13:35:00]</a>. Algorithms like PC and Resist (which performed particularly well in his use case) yielded results very close to the expert-derived ground truth <a class="yt-timestamp" data-t="15:56:00">[15:56:00]</a>.

### Key Learnings for Applying Causal Discovery:
*   **Hands-on Experience**: Get your hands dirty and experiment with different algorithms and visualizations <a class="yt-timestamp" data-t="15:07:00">[15:07:00]</a>.
*   **Data Preparation**: Ensure clean data and follow conventional data science/engineering methods <a class="yt-timestamp" data-t="15:18:00">[15:18:00]</a>.
*   **Domain Expert Validation**: Always have a business expert validate the model's findings and correct any illogical edges <a class="yt-timestamp" data-t="15:33:00">[15:33:00]</a>. This interaction can even prompt experts to reconsider their own assumptions <a class="yt-timestamp" data-t="14:38:00">[14:38:00]</a>.

## Interviewing Subject Matter Experts
Interviewing experts is a critical and necessary step in building [[Causal AI and machine learning | causal machine learning]] models <a class="yt-timestamp" data-t="17:16:00">[17:16:00]</a>. It's essential to conduct these interviews in a non-biased way, using methods like multi-criteria decision-making techniques (FHP, TOPSIS, Analytic Hierarchy Process) to ensure consistency and minimize human biases <a class="yt-timestamp" data-t="17:30:00">[17:30:00]</a>.

The process involves collaborative building of a tribal knowledge graph, identifying cause-and-effect relationships, and then validating it with the experts <a class="yt-timestamp" data-t="18:09:00">[18:09:00]</a>. Experts sometimes don't initially realize the depth of their own knowledge, and the process of constructing the graph can be a revelation for them <a class="yt-timestamp" data-t="18:16:00">[18:18:00]</a>. This collaborative effort helps preserve valuable knowledge within an organization, even when experts retire or leave, acting as a "monument" to their legacy <a class="yt-timestamp" data-t="19:13:00">[19:13:00]</a>. This creates a win-win situation for both the expert and the company <a class="yt-timestamp" data-t="20:21:00">[20:21:00]</a>.

## Intersection with Generative AI (LLMs)
The intersection of [[Causal AI and machine learning | Causal AI]] and Generative AI, specifically Large Language Models (LLMs), is an exciting development <a class="yt-timestamp" data-t="21:11:00">[21:11:00]</a>. A major challenge in causal discovery is the time-consuming nature of gathering meaningful relationships from experts (e.g., 50+ hours for 25 experts) <a class="yt-timestamp" data-t="21:22:00">[21:22:00]</a>.

LLMs can significantly expedite this process by generating initial causal relationships and building a preliminary causal discovery graph <a class="yt-timestamp" data-t="21:50:00">[21:50:00]</a>. This pre-built graph can then be presented to experts for validation, criticism, and refinement, allowing them to leverage their knowledge more efficiently <a class="yt-timestamp" data-t="22:00:00">[22:00:00]</a>. Isan found that LLMs could produce results very close to the "ground truth" with just a few prompts <a class="yt-timestamp" data-t="23:04:00">[23:04:00]</a>.

This approach not only boosts efficiency but also motivates experts, as they appreciate the models' recommendations and are eager to contribute their unique experiences to refine them <a class="yt-timestamp" data-t="23:25:00">[23:25:00]</a>. This fosters greater trust between human experts and AI models, bridging the "trust deficit" often seen with traditional models <a class="yt-timestamp" data-t="24:20:00">[24:20:00]</a>.

## Evaluating Causal Systems
Evaluating causal models, especially in a [[Causal AI and machine learning | causal world]], remains a challenge <a class="yt-timestamp" data-t="24:41:00">[24:41:00]</a>. However, the role of stakeholders and business experts becomes even more critical <a class="yt-timestamp" data-t="24:48:00">[24:48:00]</a>. Causal discovery visualizations simplify complex relationships, allowing experts to see the effects of actions and run simulations <a class="yt-timestamp" data-t="24:58:00">[24:58:00]</a>.

While data evaluation metrics like Structural Hamming Distance (SHD) and number of indirect edges exist for causal discovery methods, they should not be solely relied upon <a class="yt-timestamp" data-t="25:33:00">[25:33:00]</a>. The iterative process of building and validating models, applying interventions, and comparing results with real data is key <a class="yt-timestamp" data-t="46:14:00">[46:14:00]</a>. Involving business experts in the evaluation process makes them feel the model is an extension of their knowledge, fostering trust and ensuring the model's accuracy <a class="yt-timestamp" data-t="30:38:00">[30:38:00]</a>. Interviewing multiple experts helps mitigate human bias <a class="yt-timestamp" data-t="30:55:00">[30:55:00]</a>.

### Handling Unforeseen Events
In scenarios like an "alien attack" on a supply chain, where expert knowledge is limited, causal models can still be useful <a class="yt-timestamp" data-t="49:44:00">[49:44:00]</a>. If the unforeseen event can be modeled as an exogenous distribution impacting variables within the system's Markov blanket, the causal model can propagate this distribution to still yield relevant outcomes <a class="yt-timestamp" data-t="50:55:00">[50:55:00]</a>. This requires a rich specification of the causal model, including its functions <a class="yt-timestamp" data-t="51:33:00">[51:33:00]</a>.

## [[Causal AI applications in various industries | Causal AI Applications]] Beyond Supply Chain
[[Causal AI applications in various industries | Causal AI]] is not restricted to any particular industry <a class="yt-timestamp" data-t="26:09:00">[26:09:00]</a>. In sports, for instance, it could be used for:
*   **Root cause analysis** of player injuries <a class="yt-timestamp" data-t="26:20:00">[26:20:00]</a>.
*   **"What if" scenarios** to predict the impact of changes (e.g., increased sleep) on match performance or injury risk <a class="yt-timestamp" data-t="26:26:00">[26:26:00]</a>.
*   **Tracking key performance indicators** like expected goals and injury status <a class="yt-timestamp" data-t="26:39:00">[26:39:00]</a>.

## The Future of Causal AI
Isan Gupta believes [[causal_ai_applications_in_business_and_technology | Causal AI]] is already the present, its importance highlighted by recent global events like the Eastern European conflict, pandemics, and semiconductor shortages <a class="yt-timestamp" data-t="27:09:00">[27:09:00]</a>. These events revealed the limitations of black-box models and the need for deeper understanding <a class="yt-timestamp" data-t="27:32:00">[27:32:00]</a>. Many companies are already exploring and implementing causal solutions, a trend expected to accelerate <a class="yt-timestamp" data-t="27:47:00">[27:47:00]</a>.

The future of dashboarding is envisioned as combining [[Causal AI and machine learning | Causal AI]] with LLMs, allowing decision-makers to ask complex "causal questions" directly (e.g., "Tell me which supplier will be affected if there's a tsunami in Miami, and in what way?") and receive quantifiable effects <a class="yt-timestamp" data-t="44:33:00">[44:33:00]</a>. This will enable actionable intelligence and more robust decision-making <a class="yt-timestamp" data-t="45:05:00">[45:05:00]</a>.

## Advice for Companies and Data Scientists
### For Companies:
Instead of following the traditional path from descriptive to diagnostic to predictive analytics, companies should consider moving directly to "actionable intelligence" or [[causal_ai_applications_in_business_and_technology | causal intelligence]] <a class="yt-timestamp" data-t="28:15:00">[28:15:00]</a>. Traditional predictive models often remain stuck in the experimental phase due to explainability and trust deficits <a class="yt-timestamp" data-t="28:45:00">[28:45:00]</a>. [[Challenges in integrating causal AI in business settings | Causal AI]] offers a way to overcome these issues, as it "just makes sense" to stakeholders <a class="yt-timestamp" data-t="29:21:00">[29:21:00]</a>.

### For Data Scientists:
*   **Get Hands Dirty**: Despite the theoretical complexity, start by applying causal concepts and trying out different algorithms <a class="yt-timestamp" data-t="15:07:00">[15:07:00]</a>.
*   **Recommended Resources**:
    *   "The Book of Why" by Judea Pearl, to change mindset <a class="yt-timestamp" data-t="31:56:00">[31:56:00]</a>.
    *   "Causal Inference and Discovery in Python" by You, for learning by doing <a class="yt-timestamp" data-t="32:06:00">[32:06:00]</a>.
    *   Open-source libraries like DoWhy <a class="yt-timestamp" data-t="33:04:00">[33:04:00]</a>.
*   **Stay Updated**: Follow recent research papers, especially those combining LLMs and [[Causal AI and machine learning | Causal AI]] (e.g., from Microsoft) <a class="yt-timestamp" data-t="33:25:00">[33:25:00]</a>.
*   **Leverage LinkedIn**: Connect with [[Causal AI and machine learning | causal AI]] ambassadors, companies (e.g., Causalens, Spotify, Netflix), and academics to stay informed and discuss problems <a class="yt-timestamp" data-t="33:57:00">[33:57:00]</a>.
*   **Think Causally**: Reframe conventional machine learning use cases as [[Causal AI and machine learning | causal problems]] to identify where [[Causal AI and machine learning | causal machine learning]] can provide greater value <a class="yt-timestamp" data-t="57:05:00">[57:05:00]</a>.

### Limitations and Expectations of Causal Models
Causal models are not an "ultimate solution" but an embodiment of the scientific method <a class="yt-timestamp" data-t="53:30:00">[53:30:00]</a>. They have limitations, and it's a disservice to build expectations that they are absolute <a class="yt-timestamp" data-t="53:51:00">[53:51:00]</a>. The key challenge for the AI community is to clearly distinguish between questions answerable by predictive, associative machine learning and those requiring a causal model <a class="yt-timestamp" data-t="55:10:00">[55:10:00]</a>.

### Overcoming Overwhelm for Beginners
For those starting in complex fields like [[Causal AI and machine learning | machine learning]] or causality, it's easy to feel overwhelmed by the vast amount of theoretical work and research papers <a class="yt-timestamp" data-t="56:16:00">[56:16:00]</a>. The advice is to:
*   **Balance Research with Application**: Read, but prioritize getting hands-on and applying concepts <a class="yt-timestamp" data-t="56:52:00">[56:52:00]</a>.
*   **Find Use Cases**: Actively seek out problems where [[Causal AI and machine learning | causal machine learning]] can be beneficial <a class="yt-timestamp" data-t="57:00:00">[57:00:00]</a>.
*   **Learn by Doing**: Execution leads to more learning as questions arise, prompting further research and community engagement <a class="yt-timestamp" data-t="57:27:00">[57:27:00]</a>.

## Personal Motivation and Challenges
Isan is motivated by the ability of data science to make a tangible difference in people's lives, from improving company profits to helping sports teams win championships, or even predicting health conditions early, comparing data scientists to "fancy doctors" <a class="yt-timestamp" data-t="58:08:00">[58:08:00]</a>. His most challenging career transition was moving from the sports industry to the automotive industry due to a initial lack of domain knowledge, which he overcame through networking and learning from role models <a class="yt-timestamp" data-t="59:25:00">[59:25:00]</a>.

## Qualities of a Good Leader
A good leader leads from the front but also deeply trusts their team members and gives them the freedom to do amazing work <a class="yt-timestamp" data-t="01:01:08">[01:01:08]</a>. They should prioritize "best ideas win" over hierarchy, and be open to both giving and receiving constructive criticism <a class="yt-timestamp" data-t="01:01:39">[01:01:39]</a>.

## Connect with Isan Gupta
Isan Gupta is active on LinkedIn, where he shares his work and enjoys networking with diverse people, discussing problem-solving mindsets, and different experiences <a class="yt-timestamp" data-t="01:02:19">[01:02:19]</a>. He encourages people to reach out, especially if they are in Munich <a class="yt-timestamp" data-t="01:02:36">[01:02:36]</a>.