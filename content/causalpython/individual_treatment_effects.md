---
title: Individual treatment effects
videoId: zTJFUaLjxfE
---

From: [[causalpython]] <br/> 

Scott Muller's current research focuses on making better decisions at an individual level and for policies affecting large populations, which relies on [[interventions_and_causal_models | counterfactual reasoning]] <a class="yt-timestamp" data-t="00:03:30">[00:03:30]</a>, <a class="yt-timestamp" data-t="00:03:44">[00:03:44]</a>.

## The Fundamental Problem of Causal Inference

The core challenge in [[Individual treatment effects]] stems from the "fundamental problem of causal inference," where it's impossible to observe two different outcomes for the same individual under different treatments <a class="yt-timestamp" data-t="00:03:49">[00:03:49]</a>, <a class="yt-timestamp" data-t="00:03:53">[00:03:53]</a>. For instance, one cannot observe a person taking a medicine and their outcome, then rewind time, not give them the medicine, and observe the alternate outcome <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>. While average outcomes can be estimated at a population level, achieving precise point estimates or identifying probabilities for individual cases remains challenging <a class="yt-timestamp" data-t="00:04:08">[00:04:08]</a>, <a class="yt-timestamp" data-t="00:04:11">[00:04:11]</a>, <a class="yt-timestamp" data-t="00:04:20">[00:04:20]</a>.

### Bounds on Probabilities of Causation

To address this, Jin Tian and [[Judea Pearl]] established bounds on probabilities of causation, specifically [[potential_outcomes_and_causal_identification | counterfactual probabilities]] like the probability of necessity (PN), probability of sufficiency (PS), and probability of necessity and sufficiency (PNS) <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>, <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>. Although these bounds have been proven "tight"—meaning mathematically optimal without further assumptions—they are often "too loose" to be practically useful for decision-making <a class="yt-timestamp" data-t="00:04:52">[00:04:52]</a>, <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>. The primary challenge then becomes narrowing these bounds, ideally to achieve point identification, or at least to a sufficient degree that allows for better understanding of data generating processes or making informed decisions <a class="yt-timestamp" data-t="00:05:14">[00:05:14]</a>, <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>, <a class="yt-timestamp" data-t="00:05:23">[00:05:23]</a>, <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>, <a class="yt-timestamp" data-t="00:05:32">[00:05:32]</a>. This requires identifying which additional assumptions are most reasonable and suitable for a given scenario <a class="yt-timestamp" data-t="00:05:44">[00:05:44]</a>, <a class="yt-timestamp" data-t="00:05:55">[00:05:55]</a>.

### Monotonicity Assumption

One particularly helpful assumption for narrowing these bounds is "monotonicity" <a class="yt-timestamp" data-t="00:06:07">[00:06:07]</a>. Monotonicity implies "no possibility of harm" in a counterfactual sense <a class="yt-timestamp" data-t="00:06:21">[00:06:21]</a>, <a class="yt-timestamp" data-t="00:06:26">[00:06:26]</a>.
*   **Example:** If a patient takes a medicine and recovers, "harm" would be if the medicine prevented recovery, but the patient would have recovered without it <a class="yt-timestamp" data-t="00:06:32">[00:06:32]</a>, <a class="yt-timestamp" data-t="00:06:36">[00:06:36]</a>. If the probability of this negative [[Individual treatment effects | counterfactual effect]] at an individual level is zero, then monotonicity holds <a class="yt-timestamp" data-t="00:06:53">[00:06:53]</a>, <a class="yt-timestamp" data-t="00:06:56">[00:06:56]</a>, <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>.
*   In scenarios where monotonicity is present—either by definition or through knowledge of underlying mechanisms—it enables the point identification of probabilities like "probability of benefit" and "probability of harm" (which would be zero) <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a>, <a class="yt-timestamp" data-t="00:07:13">[00:07:13]</a>, <a class="yt-timestamp" data-t="00:07:21">[00:07:21]</a>, <a class="yt-timestamp" data-t="00:07:29">[00:07:29]</a>.

### Practical Challenges and Falsification

A main challenge for wider adoption of methods relying on monotonicity is determining when this assumption holds <a class="yt-timestamp" data-t="00:07:42">[00:07:42]</a>, <a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a>, <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>. While it's rare to confirm monotonicity solely from data, it's often feasible to show from data that monotonicity *definitely does not* hold <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>, <a class="yt-timestamp" data-t="00:08:50">[00:08:50]</a>, <a class="yt-timestamp" data-t="00:08:56">[00:08:56]</a>. This aligns with the general scientific principle that disproving theories is often easier than proving them <a class="yt-timestamp" data-t="00:09:29">[00:09:29]</a>. When monotonicity is violated, research can still establish limits to the violation, further narrowing the bounds on [[potential_outcomes_and_causal_identification | counterfactual probabilities]] <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>, <a class="yt-timestamp" data-t="00:09:57">[00:09:57]</a>.

## Unit Selection Framework

The [[optimal_experimentation_in_causal_studies | Unit Selection Framework]], developed by Angley and [[Judea Pearl]], is a key application of [[Individual treatment effects | counterfactual reasoning]] in practice <a class="yt-timestamp" data-t="00:21:11">[00:21:11]</a>, <a class="yt-timestamp" data-t="00:21:14">[00:21:14]</a>. It allows decision-makers to assign values to four types of responders based on their individual (counterfactual) responses to a treatment:

1.  **Complier:** Buys the product if shown an ad, but not if not shown <a class="yt-timestamp" data-t="00:21:50">[00:21:50]</a>, <a class="yt-timestamp" data-t="00:21:54">[00:21:54]</a>. These are the desired target for advertising <a class="yt-timestamp" data-t="00:22:56">[00:22:56]</a>.
2.  **Always Taker:** Buys the product regardless of seeing the ad <a class="yt-timestamp" data-t="00:22:03">[00:22:03]</a>.
3.  **Never Taker:** Does not buy the product regardless of seeing the ad <a class="yt-timestamp" data-t="00:22:08">[00:22:08]</a>.
4.  **Defier:** Buys the product if *not* shown the ad, but *does not* buy if shown the ad <a class="yt-timestamp" data-t="00:22:13">[00:22:13]</a>, <a class="yt-timestamp" data-t="00:22:15">[00:22:15]</a>. This type is generally undesirable to advertise to <a class="yt-timestamp" data-t="00:22:46">[00:22:46]</a>.

By assigning economic values (positive or negative) to each response type, businesses can optimize advertising campaigns beyond traditional A/B testing <a class="yt-timestamp" data-t="00:21:28">[00:21:28]</a>, <a class="yt-timestamp" data-t="00:21:32">[00:21:32]</a>, <a class="yt-timestamp" data-t="00:23:45">[00:23:45]</a>, <a class="yt-timestamp" data-t="00:24:02">[00:24:02]</a>. Even though [[Individual treatment effects | individual level treatment effects]] cannot be identified, this framework, using observational or experimental data, can provide bounds on the overall value of advertising to specific subpopulations, enabling better decision-making <a class="yt-timestamp" data-t="00:25:27">[00:25:27]</a>, <a class="yt-timestamp" data-t="00:25:31">[00:25:31]</a>, <a class="yt-timestamp" data-t="00:25:50">[00:25:50]</a>, <a class="yt-timestamp" data-t="00:26:15">[00:26:15]</a>.

## Importance for Artificial Intelligence

The ability to perform [[interventions_and_causal_models | causal]] and [[potential_outcomes_and_causal_identification | counterfactual reasoning]] is considered fundamental to human thinking and is crucial for developing human-level artificial general intelligence (AGI) <a class="yt-timestamp" data-t="00:37:58">[00:37:58]</a>, <a class="yt-timestamp" data-t="00:38:01">[00:38:01]</a>, <a class="yt-timestamp" data-t="00:38:04">[00:38:04]</a>, <a class="yt-timestamp" data-t="00:38:34">[00:38:34]</a>. Scott Muller believes that the mathematics and science behind causality need to be "baked in" to machine learning models and architectures, as he has not seen these properties emerge naturally from simply increasing model size or parameters <a class="yt-timestamp" data-t="00:39:50">[00:39:50]</a>, <a class="yt-timestamp" data-t="00:39:55">[00:39:55]</a>, <a class="yt-timestamp" data-t="00:39:58">[00:39:58]</a>, <a class="yt-timestamp" data-t="00:40:01">[00:40:01]</a>, <a class="yt-timestamp" data-t="00:40:33">[00:40:33]</a>, <a class="yt-timestamp" data-t="00:40:52">[00:40:52]</a>. His work aims to contribute to this by developing expertise in [[causal_inference_in_single_subject_studies | causal inference]] that can be applied to advanced AI architectures <a class="yt-timestamp" data-t="00:41:10">[00:41:10]</a>, <a class="yt-timestamp" data-t="00:41:15">[00:41:15]</a>.