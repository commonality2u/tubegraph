---
title: Collaboration Between Academia and Industry
videoId: _mJclm_aJlc
---

From: [[causalpython]] <br/> 

Professor Stefan Wager, Head of the Institute for AI and Management at LMU, emphasizes the critical role of [[communication_and_collaboration_in_causal_research | communication and collaboration]] between academia and industry to ensure that [[causal_machine_learning_applications_in_various_industries | causal machine learning]] (ML) models make a tangible impact in the real world <a class="yt-timestamp" data-t="01:45:00">[01:45:00]</a>. His career path, transitioning from computer science to AI and management, is driven by a desire to make a distinctive impact in practice <a class="yt-timestamp" data-t="00:47:00">[00:47:00]</a>.

## The Concept of Clinical Translation

Professor Wager introduces the notion of "clinical translation," which, in the context of [[causal_machine_learning_applications_in_various_industries | causal machine learning]], refers to the challenge of getting medical professionals to actually use these advanced tools <a class="yt-timestamp" data-t="02:05:00">[02:05:00]</a>. It's not about waiting for them to realize the value of [[causality_in_science_and_industry | causal ML]], but rather for the causal community to proactively approach them and demonstrate how these tools can assist in their day-to-day work, such as improving treatment selection <a class="yt-timestamp" data-t="02:22:00">[02:22:00]</a>.

This concept extends beyond medicine to other disciplines like marketing and business decision-making <a class="yt-timestamp" data-t="03:07:00">[03:07:00]</a>. The key is for the causal community to "move to their field and speak their language," rather than expecting practitioners to adapt to academic terminology <a class="yt-timestamp" data-t="03:14:00">[03:14:00]</a>. This requires translating both methods and language into terms that decision-makers and end-users can understand and utilize <a class="yt-timestamp" data-t="04:06:00">[04:06:00]</a>.

## Real-World [[causal_ai_applications_in_various_industries | Applications of Causal AI]]

Professor Wager provides several examples of successful industry collaborations where [[causal_machine_learning_applications_in_various_industries | causal machine learning]] has driven real-world outcomes:

*   **ABB Hitachi**: A rigorous field experiment showed that a [[causal_machine_learning_applications_in_various_industries | causal machine learning]] tool could reduce yield loss in semiconductor fabrication by almost 50% (49%) <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>, <a class="yt-timestamp" data-t="14:43:00">[14:43:00]</a>, <a class="yt-timestamp" data-t="16:04:00">[16:04:00]</a>.
*   **Booking.com**: The company runs [[causal_machine_learning_applications_in_various_industries | causal machine learning]] algorithms at a large scale <a class="yt-timestamp" data-t="00:18:00">[00:18:00]</a>, <a class="yt-timestamp" data-t="15:09:00">[15:09:00]</a>.
*   **Health Insurance in the Middle East**: A two-stage [[causal_machine_learning_applications_in_various_industries | causal machine learning]] model was developed to optimize the allocation of limited resources for diabetes prevention programs. It first estimated the potential benefit of preventive care from electronic health records, then identified patients who would benefit most, enabling cost-effective resource allocation <a class="yt-timestamp" data-t="10:34:00">[10:34:00]</a>.
*   **Large Media Company**: [[causal_machine_learning_applications_in_various_industries | Causal inference]] was used to optimize the front page of a newspaper by framing content promotion as a causal task. This system augmented editors' choices, empowering them to make better decisions and drive long-term impact and revenue <a class="yt-timestamp" data-t="13:15:00">[13:15:00]</a>.
*   **OECD Development Aid**: A paper presented at KDD 2024 uses [[causal_machine_learning_applications_in_various_industries | causal machine learning]] to suggest how to allocate development aid, a complex problem involving trillions of dollars, hundreds of stakeholders, and nearly a hundred recipient countries <a class="yt-timestamp" data-t="24:42:00">[24:42:00]</a>.

## Overcoming [[challenges_in_deploying_causal_models_in_industry | Criticisms]] of [[causality_in_science_and_industry | Causal ML]] in Practice

To those who claim that [[causal_machine_learning_applications_in_various_industries | causal machine learning]] is impossible to implement or use to drive real-world outcomes, Professor Wager strongly disagrees <a class="yt-timestamp" data-t="13:05:00">[13:05:00]</a>. He outlines three key elements for success:

1.  **Augment, Don't Replace**: Instead of aiming to replace human decision-makers, [[causal_machine_learning_applications_in_various_industries | causal ML]] should augment them. This fosters trust and drives top management investment in projects <a class="yt-timestamp" data-t="15:25:00">[15:25:00]</a>.
2.  **Rigorous Field Experiments**: Demonstrating impact through rigorous field experiments is crucial. The ABB Hitachi example, showing a 49% reduction in yield loss over four months, highlights the financial and practical gains <a class="yt-timestamp" data-t="15:59:00">[15:59:00]</a>.
3.  **Education**: Educating people about [[causality_in_science_and_industry | causality]] and [[causal_machine_learning_applications_in_various_industries | causal machine learning]] is vital for its broader adoption <a class="yt-timestamp" data-t="16:37:00">[16:37:00]</a>.

## The Importance of [[communication_and_collaboration_in_causal_research | Communication and Education]]

A recurring theme is the need to simplify complex [[causality_in_science_and_industry | causal ML]] concepts for domain experts and managers <a class="yt-timestamp" data-t="04:06:00">[04:06:00]</a>, <a class="yt-timestamp" data-t="17:10:00">[17:10:00]</a>. Professor Wager shares an anecdote about explaining "AUC" (Area Under the Curve) repeatedly for years, emphasizing the challenge and importance of crisp, simple explanations that enable actionable insights <a class="yt-timestamp" data-t="04:32:00">[04:32:00]</a>.

He likens the managerial need for [[causality_in_science_and_industry | causal ML]] to wanting "two crystal balls" – one for decision A and another for decision B – allowing them to compare future outcomes based on different choices and pick the best one for their company <a class="yt-timestamp" data-t="18:02:00">[18:02:00]</a>. This simple analogy helps clarify the goal of [[causal_machine_learning_applications_in_various_industries | causal ML]]: to help managers *change* the future, not just predict it <a class="yt-timestamp" data-t="18:10:00">[18:10:00]</a>.

## Building an Effective [[interdisciplinary_approaches_in_ai_research | Interdisciplinary Team]]

Professor Wager attributes his team's success in publishing at top AI conferences to having a great team, emphasizing diversity in backgrounds <a class="yt-timestamp" data-t="19:52:00">[19:52:00]</a>, <a class="yt-timestamp" data-t="21:10:00">[21:10:00]</a>. His team comprises individuals with backgrounds in:
*   Mathematics <a class="yt-timestamp" data-t="21:22:00">[21:22:00]</a>
*   Data science <a class="yt-timestamp" data-t="21:23:00">[21:23:00]</a>
*   Statistics <a class="yt-timestamp" data-t="21:24:00">[21:24:00]</a>
*   Computer science <a class="yt-timestamp" data-t="21:25:00">[21:25:00]</a>
*   Economics <a class="yt-timestamp" data-t="21:27:00">[21:27:00]</a>

This diversity allows different perspectives on problems and different approaches, leading to strengths that complement each other <a class="yt-timestamp" data-t="21:30:00">[21:30:00]</a>. For example, an economics student once identified a flaw in randomization in a medical experiment that computer scientists missed <a class="yt-timestamp" data-t="21:40:00">[21:40:00]</a>, while computer scientists are adept at running GPU clusters <a class="yt-timestamp" data-t="22:05:00">[22:05:00]</a>. The team's ability to combine these diverse expertises, for instance, by linking complex generative models with theoretical proofs, strengthens their research <a class="yt-timestamp" data-t="22:35:00">[22:35:00]</a>.

## Lessons from [[transition_from_academic_to_industry_data_science | Entrepreneurship]]

Professor Wager's experience founding a startup in 2015 to improve corporate [[communication_and_collaboration_in_causal_research | communication]] using machine learning provided valuable lessons for [[challenges_in_integrating_causal_ai_in_business_settings | industry integration]]:

*   **Timing**: They were "way too early," facing the challenge of educating customers to trust AI systems <a class="yt-timestamp" data-t="28:18:00">[28:18:00]</a>.
*   **Product Customization**: The product required too much customization, making the sales funnel overly complex <a class="yt-timestamp" data-t="28:35:00">[28:35:00]</a>.
*   **Testing Ideas Early**: It's crucial to test ideas early and not be too attached to them. Academics, in particular, may struggle with this due to their passion for their own algorithms <a class="yt-timestamp" data-t="28:48:00">[28:48:00]</a>.

He applies these lessons to research, advocating for a "one-day rule" for standard machine learning projects: if a linear regression or random forest doesn't yield satisfying performance on a dataset on the first day, the data or task might not be suitable for machine learning <a class="yt-timestamp" data-t="29:57:00">[29:57:00]</a>. This avoids investing too much time in projects that are unlikely to succeed <a class="yt-timestamp" data-t="30:34:00">[30:34:00]</a>.

## Advice for Managers and Entrepreneurs

For managers and entrepreneurs, Professor Wager advises experimenting with AI tools to identify effective use cases <a class="yt-timestamp" data-t="32:51:00">[32:51:00]</a>. He highlights that while simple methods (like an S-learner, a traditional machine learning method) might suffice for many applications, more rigorous [[causal_machine_learning_applications_in_various_industries | causal ML]] methods (like a Causal Forest or models from the doubleML package) are needed for scenarios requiring greater rigor or the "extra mile" <a class="yt-timestamp" data-t="33:04:00">[33:04:00]</a>. The challenges of observing counterfactual values necessitate testing and validating what works robustly in practice <a class="yt-timestamp" data-t="33:33:00">[33:33:00]</a>.