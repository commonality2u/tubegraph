---
title: Intersection of Causal AI and Generative AI
videoId: gmFWhAAeBfE
---

From: [[causalpython]] <br/> 

The integration of [[causal_ai_and_machine_learning | Causal AI]] and [[Generative AI and Causal Models | Generative AI]], particularly Large Language Models (LLMs), is an exciting and rapidly developing area with significant potential to enhance various processes, especially in fields like supply chain management <a class="yt-timestamp" data-t="00:21:14">[00:21:14]</a>.

## Expediting Causal Discovery

One of the primary challenges in building [[causal_ai_and_machine_learning | causal models]] is the time-consuming process of gathering "tribal knowledge" or expert insights <a class="yt-timestamp" data-t="00:21:22">[00:21:22]</a>. Interviewing numerous experts to map out complex relationships can take dozens of hours <a class="yt-timestamp" data-t="00:21:38">[00:21:38]</a>.

LLMs offer a solution by significantly expediting the [[causal_ai_and_machine_learning | causal discovery]] process <a class="yt-timestamp" data-t="00:21:50">[00:21:50]</a>. Instead of starting from scratch, LLMs can be used to:
*   Identify [[causal_ai_and_machine_learning | causal relationships]] <a class="yt-timestamp" data-t="00:22:05">[00:22:05]</a>.
*   Build an initial [[causal_ai_and_machine_learning | causal discovery graph]] <a class="yt-timestamp" data-t="00:22:09">[00:22:09]</a>.

This initial model can then be presented to human experts for validation, criticism, and refinement <a class="yt-timestamp" data-t="00:22:11">[00:22:11]</a>. This approach leverages the human tendency to criticize and validate, which can be an effective way to extract deeper insights and unique experiences from experts <a class="yt-timestamp" data-t="00:22:22">[00:22:22]</a>.

### Practical Experience

In a personal research project, an experiment involving LLMs to understand how the external world affects suppliers yielded results "really close to the ground truth" after only one or two prompts <a class="yt-timestamp" data-t="00:23:04">[00:23:04]</a>. This demonstrates the potential for LLMs to provide strong initial recommendations, which can then be built upon <a class="yt-timestamp" data-t="00:23:19">[00:23:19]</a>.

### Benefits Beyond Efficiency

The use of LLMs in [[causal_ai_and_machine_learning | causal discovery]] is not just an efficiency booster; it also serves as an additional element that can motivate experts <a class="yt-timestamp" data-t="00:23:25">[00:23:25]</a>. When experts see an AI model reflecting a significant portion of their knowledge, they are often motivated to contribute more, sharing their unique experiences and insights to enhance the model further <a class="yt-timestamp" data-t="00:24:02">[00:24:02]</a>. This iterative process fosters greater trust in the models among stakeholders <a class="yt-timestamp" data-t="00:24:20">[00:24:20]</a>.

## Evaluating Causal Models with AI

Even with the advancements of [[causal_ai_and_machine_learning | Causal AI]], evaluation remains a challenge <a class="yt-timestamp" data-t="00:24:41">[00:24:41]</a>. The role of stakeholders and business experts becomes even more critical in this context <a class="yt-timestamp" data-t="00:24:48">[00:24:48]</a>. While quantitative metrics like Hamming distance or number of indirect edges exist for [[causal_ai_and_machine_learning | causal discovery]] methods, relying solely on these numbers is not sufficient <a class="yt-timestamp" data-t="00:25:32">[00:25:32]</a>.

Involving business experts in the evaluation process helps build trust, as they see the model as an extension of their own knowledge <a class="yt-timestamp" data-t="00:30:36">[00:30:36]</a>. They can validate specific causal links and identify where the model might be incorrect <a class="yt-timestamp" data-t="00:30:47">[00:30:47]</a>. Interviewing multiple experts helps mitigate human biases and leads to more accurate and reliable tribal knowledge graphs <a class="yt-timestamp" data-t="00:30:55">[00:30:55]</a>.

## Future Directions

The [[Future directions for causal AI and generative models | future directions for causal AI and generative models]] are highly promising. A key area of interest is the combination of LLMs with [[causal_ai_and_machine_learning | Causal AI]] for improved dashboarding and decision-making <a class="yt-timestamp" data-t="00:44:33">[00:44:33]</a>.

Imagine a scenario where decision-makers can query an application:
*   "Tell me the next player who will be injured because their stress level has increased due to XYZ" <a class="yt-timestamp" data-t="00:44:46">[00:44:46]</a>.
*   "If there's a tsunami in Miami, which supplier will be affected and in what way?" <a class="yt-timestamp" data-t="00:44:59">[00:44:59]</a>.

This capability to quantify effects and run "what if" scenarios, even for "black swan" events like an alien attack (if variables are properly defined and distribution can be modeled exogenously), represents a significant leap forward in actionable intelligence <a class="yt-timestamp" data-t="00:45:03">[00:45:03]</a>. LLMs can enhance the retrieval of expert knowledge from documents, potentially using techniques like Retrieval Augmented Generation (RAG) to reduce hallucination and provide more reliable information for [[causal_ai_and_machine_learning | causal model]] construction <a class="yt-timestamp" data-t="00:47:26">[00:47:26]</a>.

This integration aims to bridge the gap between mere predictions and actionable business recommendations, providing explainability and the capability to perform counterfactual simulations <a class="yt-timestamp" data-t="00:04:42">[00:04:42]</a>.

> [!NOTE] Causal AI is not a replacement for traditional machine learning but rather a complementary approach that addresses questions about "why" and "what if" scenarios, which traditional predictive models often cannot <a class="yt-timestamp" data-t="00:55:00">[00:55:00]</a>. The challenge is to identify which questions require which type of model <a class="yt-timestamp" data-t="00:55:10">[00:55:10]</a>.