---
title: Challenges of Causal Inference and Counterfactual Thinking
videoId: xkx1tXLAP-o
---

From: [[causalpython]] <br/> 

In the realm of machine learning and particularly in recommended systems, a significant shift is occurring from purely predictive models to those integrating [[causal_inference_and_decision_making|causal inference]]. This shift introduces several [[challenges in causal analysis in different settings|challenges]] related to understanding counterfactual outcomes and human behavior <a class="yt-timestamp" data-t="01:49:00">[01:49:00]</a>.

## Moving Beyond Prediction
Traditional recommended systems are often designed as predictive or associative devices, aiming to identify the most suitable item or recommendation based on correlations <a class="yt-timestamp" data-t="01:36:00">[01:36:00]</a>. However, even a highly accurate recommender might not "move the needle" in a [[causal_inference_concepts_and_applications|causal]] way <a class="yt-timestamp" data-t="03:09:00">[03:09:00]</a>. For instance, recommending a destination a user already planned to visit doesn't generate incremental impact <a class="yt-timestamp" data-t="03:21:00">[03:21:00]</a>. The true value lies in changing customer behavior incrementally <a class="yt-timestamp" data-t="03:32:00">[03:32:00]</a>.

This necessitates a focus on [[causal_discovery_versus_causal_inference|counterfactual thinking]] <a class="yt-timestamp" data-t="03:50:00">[03:50:00]</a>: understanding what would happen if an intervention (treatment) *wasn't* applied <a class="yt-timestamp" data-t="03:44:00">[03:44:00]</a>. The goal is to incentivize customers to act differently than they would have otherwise <a class="yt-timestamp" data-t="03:41:00">[03:41:00]</a>.

### The Discount Dilemma
A prime example of this challenge is in offering discounts. While discounts can significantly change customer behavior and expand the customer base <a class="yt-timestamp" data-t="07:00:00">[07:00:00]</a>, they come with a cost <a class="yt-timestamp" data-t="07:21:00">[07:21:00]</a>. The [[challenges_in_causal_inference_and_statistical_analysis|counterfactual problem]] arises: should discounts be given to customers less likely to book, or only to those whose behavior would be changed by the discount <a class="yt-timestamp" data-t="07:37:00">[07:37:00]</a>? Ideally, discounts should only be offered when they positively change customer behavior, not when the customer would have booked anyway <a class="yt-timestamp" data-t="08:35:00">[08:35:00]</a>. This requires understanding the "trigger cost" â€“ the cost incurred only if the offer leads to a booking <a class="yt-timestamp" data-t="09:21:00">[09:21:00]</a>.

Furthermore, these promotional strategies often operate under strict budget constraints, requiring optimization to maximize incremental volumes (new customers, reservations) while controlling incremental costs <a class="yt-timestamp" data-t="10:25:00">[10:25:00]</a>. This combines [[causal_inference_and_its_applications|causal inference]] with optimization problems, like the knapsack problem, where each interaction has an incremental value and cost <a class="yt-timestamp" data-t="12:48:00">[12:48:00]</a>.

## Technical and Practical Challenges
Combining optimization, machine learning, and [[challenges_and_methodologies_in_causal_inference|causal inference]] presents several difficulties <a class="yt-timestamp" data-t="13:00:00">[13:00:00]</a>:
*   **Noisy Data and Overfitting:** Real-world data is often noisy, prone to overfitting, and affected by seasonality <a class="yt-timestamp" data-t="14:28:00">[14:28:00]</a>.
*   **Dynamic Environments:** The problem evolves constantly, with new constraints, platforms, or products <a class="yt-timestamp" data-t="15:03:00">[15:03:00]</a>. Solutions must be robust rather than merely optimal <a class="yt-timestamp" data-t="15:51:00">[15:51:00]</a>.
*   **Online vs. Offline Evaluation:** A significant challenge is the mismatch between offline model evaluations and online performance <a class="yt-timestamp" data-t="17:46:00">[17:46:00]</a>. This requires ensuring metric consistency and data collection alignment between online and offline processes <a class="yt-timestamp" data-t="18:40:00">[18:40:00]</a>.
*   **Simplicity vs. Complexity:** While complex models with many features might perform well offline, they are harder to deploy, maintain, and are more susceptible to data drift and seasonality <a class="yt-timestamp" data-t="20:30:00">[20:30:00]</a>. Simple models are often more robust and impactful in a business environment <a class="yt-timestamp" data-t="51:53:00">[51:53:00]</a>.

## The Human Element
[[Importance of understanding causal inference for decision making|Causal inference]] is not just about discovering complex dynamics; it heavily involves understanding human psychology <a class="yt-timestamp" data-t="03:11:00">[03:11:00]</a>.
*   **Irrational Decisions:** Humans often make decisions that are not necessarily rational or predictable <a class="yt-timestamp" data-t="30:50:00">[30:50:00]</a>. Their behavior can be counterintuitive <a class="yt-timestamp" data-t="31:17:00">[31:17:00]</a>.
*   **Inconsistency:** What works on one platform or for one demographic might not work on another, or even for the same person at a different time <a class="yt-timestamp" data-t="32:10:00">[32:10:00]</a>. For example, a recommendation for a multi-night stay in Paris might be accurate based on popular booking data, but showing a cheaper one-night option could be more effective in encouraging users to explore further due to perceived affordability and availability <a class="yt-timestamp" data-t="29:01:00">[29:01:00]</a>.
*   **Limited External Validity:** A/B tests, while crucial, have limitations. Their external validity cannot be taken for granted; an effect observed in one environment or population may not automatically translate to another <a class="yt-timestamp" data-t="34:24:00">[34:24:00]</a>.

## Bridging Gaps in the Causal Community
There is a need to [[challenges_in_identifying_causal_relationships|bridge gaps]] between different sub-areas of causality. People in various disciplines (e.g., economics, healthcare) often work on similar problems using different terminology, leading to a "citation gap" <a class="yt-timestamp" data-t="01:03:01">[01:03:01]</a>. For example, "heterogeneous treatment effect" and "uplift modeling" refer to similar concepts but originate from different literatures <a class="yt-timestamp" data-t="01:03:49">[01:03:49]</a>. Sharing knowledge, building communities, and aligning terminology are crucial for advancing the field <a class="yt-timestamp" data-t="01:05:17">[01:05:17]</a>.

Despite these [[challenges in causal analysis in different settings|challenges]], the ability to measure outcomes and uncover counterintuitive human behavior through experimentation is a rewarding aspect of working in [[causal_inference_and its_applications|causal inference]] <a class="yt-timestamp" data-t="03:07:00">[03:07:00]</a>.