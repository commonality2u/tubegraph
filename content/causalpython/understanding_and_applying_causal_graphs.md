---
title: Understanding and applying causal graphs
videoId: HwNLE945Uv8
---

From: [[causalpython]] <br/> 

[[structural_causal_models_and_graph_theory | Causal graphs]] are a fundamental concept in causal analysis, but their understanding and practical application present several challenges. The Cole AI Conference 2024 highlighted various perspectives on these challenges from industry professionals.

## Challenges in Understanding and Applying Causal Graphs

One of the significant challenges identified by experts is the dynamic nature of causal relationships. A key question is what happens when the [[structural_causal_models_and_graph_theory | causal graph]] changes over time, given that nothing is truly stationary or static <a class="yt-timestamp" data-t="02:56:49">[02:56:49]</a>. This implies a need for methods that can adapt to evolving causal structures.

Another practical challenge arises during the design phase of a [[causal_inference_in_practical_applications | causal analysis]]. Analysts must determine the appropriate scope and boundaries for their causal diagrams <a class="yt-timestamp" data-t="04:50:52">[04:50:52]</a>. This includes deciding which factors should be included and at what level of detail, avoiding going too far into unnecessary intricacies <a class="yt-timestamp" data-t="05:03:05">[05:03:05]</a>.

A crucial concern in the application of [[structural_causal_models_and_graph_theory | causal graphs]] is ensuring their accuracy. A data scientist highlighted the difficulty in "ensuring our [[structural_causal_models_and_graph_theory | C graphs]] are actually true" <a class="yt-timestamp" data-t="11:57:42">[11:57:42]</a>. This speaks to the challenge of validating the assumed causal relationships represented in the graph.

Furthermore, integrating the insights from [[causal_reasoning_in_ai | causal AI]], often derived from [[structural_causal_models_and_graph_theory | causal graphs]], with business intuition is a significant hurdle. The aim is to align these two perspectives and effectively present [[causal_reasoning_in_ai | causal results]] to business stakeholders <a class="yt-timestamp" data-t="19:59:02">[19:59:02]</a>.

## Unanswered Questions Regarding Causal Graphs

Experts posed several open questions about [[structural_causal_models_and_graph_theory | causal graphs]]:
*   **Dynamic Causal Graphs** What happens when the [[structural_causal_models_and_graph_theory | causal graph]] changes over time, acknowledging that real-world systems are not static <a class="yt-timestamp" data-t="02:56:49">[02:56:49]</a>?
*   **Scope and Detail** When designing a causal analysis, how does one determine the appropriate boundaries and level of detail for a causal diagram, deciding where to stop adding factors <a class="yt-timestamp" data-t="04:50:52">[04:50:52]</a>?
*   **Uncertainty in Prediction and Completeness** How can the uncertainty in predictions derived from a [[structural_causal_models_and_graph_theory | causal graph]] be understood, especially regarding its completeness, given that the "ground truth" is often unknown <a class="yt-timestamp" data-t="18:35:54">[18:35:54]</a>? This also involves understanding how close the derived graph is to the true underlying causal structure <a class="yt-timestamp" data-t="18:50:18">[18:50:18]</a>.

## Practical Considerations for Implementing Causal Analysis

Effective communication is highlighted as key to success in implementing [[causal_inference_in_practical_applications | causal methods]] within a company <a class="yt-timestamp" data-t="02:13:54">[02:13:54]</a>. This includes communicating at all stages, from understanding the problem set to modeling and transmitting knowledge to stakeholders, regardless of their technical background <a class="yt-timestamp" data-t="02:16:18">[02:16:18]</a>. This approach can determine the success of a project <a class="yt-timestamp" data-t="03:48:07">[03:48:07]</a>.

It is crucial to help business stakeholders grasp the value of answering problems in a causal way <a class="yt-timestamp" data-t="05:57:49">[05:57:49]</a>, using analogies and careful approaches to convey the benefits of [[practical_applications_of_causal_methods | causal methods]] <a class="yt-timestamp" data-t="06:04:47">[06:04:47]</a>. This involves making it clear how [[causal_reasoning_in_ai | AI]] complements existing processes without completely substituting them, in a way that clients can trust without excessive technical detail <a class="yt-timestamp" data-t="08:42:06">[08:42:06]</a>.

While [[causal_reasoning_in_ai | causal AI]] offers a breakthrough in understanding directional flows and feature importance, contributing significantly to explainable AI <a class="yt-timestamp" data-t="14:00:23">[14:00:23]</a>, its adoption is still relatively new <a class="yt-timestamp" data-t="16:19:12">[16:19:12]</a>. The ability to explain "why" decisions are made is a major benefit, differentiating from mere correlation <a class="yt-timestamp" data-t="14:50:06">[14:50:06]</a>.