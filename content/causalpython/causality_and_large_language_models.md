---
title: Causality and Large Language Models
videoId: Y4wMksHyMFg
---

From: [[causalpython]] <br/> 

## Introduction
The intersection of [[Causality and large language models | causality and large language models (LLMs)]] is a rapidly evolving field, with ongoing discussions focusing on their capabilities, limitations, and potential applications. This topic was a key focus at AAAI 2024, highlighting areas like explainability, generalization, and fairness <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.

## Current Understanding and Challenges
Initial assessments of [[Large language models and causality | LLMs' ability to perform causal inference tasks]] suggest significant limitations. A study using a dataset (possibly "CausEVAL" or similar, referred to as "seather") indicated that [[Large language models LLMs learning limitations | LLMs are currently "really bad" at solving these tasks]] <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a>. Despite this, the creation of such datasets is crucial for developing benchmarks and fostering a deeper understanding of how [[Large language models and causality | LLMs understand the world]] <a class="yt-timestamp" data-t="00:04:09">[00:04:09]</a>.

There's a growing body of work exploring the [[integration of language models and causality | integration of LLMs and causality]] <a class="yt-timestamp" data-t="00:20:09">[00:20:09]</a>. However, many papers in this area tend to identify open problems rather than providing solutions <a class="yt-timestamp" data-t="00:20:20">[00:20:20]</a>. A key challenge is that while LLMs can process and discuss causal concepts, they are not inherently causal <a class="yt-timestamp" data-t="00:20:03">[00:20:03]</a>.

## Future Research Directions
A significant goal for future research is to actively address and solve the open problems in [[Causality and large language models | causality and LLMs]] <a class="yt-timestamp" data-t="00:20:29">[00:20:29]</a>. This includes scaling causal models and developing better benchmarks for evaluation <a class="yt-timestamp" data-t="00:22:24">[00:22:24]</a>.

One notable paper by Amit Sharma from Microsoft suggests that [[Large language models and causality | LLMs *can* learn causality under specific assumptions]], challenging the notion that they are entirely incapable <a class="yt-timestamp" data-t="00:21:34">[00:21:34]</a>. This indicates that while LLMs might rely on correlations of causal facts, certain assumptions could enable them to grasp causality <a class="yt-timestamp" data-t="00:21:48">[00:21:48]</a>.

A dedicated [[Workshop on Large Language Models and Causality at AAAI 2024 | workshop on Large Language Models and Causality]] was organized at AAAI 2024, signifying the community's interest in this intersection <a class="yt-timestamp" data-t="00:20:00">[00:20:00]</a>. This workshop aimed to bridge fields like continual learning and causality, recognizing that combining them is essential for scaling to real-world applications <a class="yt-timestamp" data-t="00:18:36">[00:18:36]</a>.