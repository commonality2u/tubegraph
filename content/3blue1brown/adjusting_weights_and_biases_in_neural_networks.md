---
title: Adjusting weights and biases in neural networks
videoId: Ilg3gGewQ5U
---

From: [[3blue1brown]] <br/> 

[[Neural network learning process | Learning]] in [[Structure of neural networks | neural networks]] is fundamentally about adjusting its internal parameters, specifically the weights and biases, to minimize a defined cost function. The core algorithm that facilitates this adjustment is **backpropagation** <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>.

## Neural Network Fundamentals Recap
A [[Structure of neural networks | neural network]] takes input information and [[Structure of neural networks | feeds forward information]] through its layers <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>. A classic example is [[training_neural_networks_with_mnist_data | recognizing handwritten digits]], where pixel values are fed into an initial layer of 784 neurons <a class="yt-timestamp" data-t="00:00:31">[00:00:31]</a>. Networks typically include one or more [[role_of_hidden_layers_in_neural_networks | hidden layers]] (e.g., two [[role_of_hidden_layers_in_neural_networks | hidden layers]] with 16 neurons each) and an output layer (e.g., 10 neurons to indicate the chosen digit) <a class="yt-timestamp" data-t="00:00:39">[00:00:39]</a>.

The objective of [[Neural network learning process | learning]] is to find the specific weights and biases that minimize a chosen cost function <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>. For a single training example, the cost is calculated by summing the squares of the differences between the network's output and the desired output for each component <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>. The total cost of the network is the average of these individual costs across all training examples <a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a>.

To efficiently decrease this cost, the network seeks the negative [[gradient_descent_in_neural_networks | gradient]] of the cost function <a class="yt-timestamp" data-t="00:01:26">[00:01:26]</a>. This [[gradient_descent_in_neural_networks | gradient]] dictates how all weights and biases should change to achieve the most efficient cost reduction <a class="yt-timestamp" data-t="00:01:30">[00:01:30]</a>. Backpropagation is the algorithm specifically designed to compute this complex [[gradient_descent_in_neural_networks | gradient]] <a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>.

The magnitude of each component in the [[gradient_descent_in_neural_networks | gradient]] vector indicates how sensitive the cost function is to changes in that specific weight or bias <a class="yt-timestamp" data-t="00:02:04">[00:02:04]</a>. For instance, if a weight's associated gradient component is 3.2 and another's is 0.1, the cost function is 32 times more sensitive to changes in the first weight <a class="yt-timestamp" data-t="00:02:26">[00:02:26]</a>. This means a small adjustment to the more sensitive weight will cause a significantly greater change in cost compared to the same adjustment on a less sensitive weight <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a>.

## Intuitive Walkthrough of Backpropagation
Backpropagation's core idea is to determine how each training example influences the desired adjustments to weights and biases <a class="yt-timestamp" data-t="00:03:07">[00:03:07]</a>. While in principle, every training example influences each [[gradient_descent_in_neural_networks | gradient descent]] step, computational efficiency usually leads to techniques like mini-batches <a class="yt-timestamp" data-t="00:03:17">[00:03:17]</a>.

Let's consider a single training example, such as an image of the digit '2' <a class="yt-timestamp" data-t="00:03:42">[00:03:42]</a>. If the network is untrained, its output layer activations might be random <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a>. For the image '2', we want the neuron corresponding to '2' in the output layer to increase its activation, while all other output neurons should decrease theirs <a class="yt-timestamp" data-t="00:04:13">[00:04:13]</a>. The size of these desired "nudges" should be proportional to how far each current activation is from its target value <a class="yt-timestamp" data-t="00:04:22">[00:04:22]</a>.

To increase a specific neuron's activation (e.g., the '2' neuron), three avenues can be leveraged <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>:
1.  **Increase its bias** <a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a>.
2.  **Increase the weights** of its connections <a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a>.
3.  **Change the activations from the previous layer** <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a>.

### Weight Adjustments
Weights connected to more highly activated neurons in the preceding layer have a greater influence on the current neuron's activation <a class="yt-timestamp" data-t="00:05:17">[00:05:17]</a>. Therefore, increasing these weights has a stronger effect on the overall cost function <a class="yt-timestamp" data-t="00:05:31">[00:05:31]</a>. When thinking about [[gradient_descent_in_neural_networks | gradient descent]], the goal is to identify which adjustments yield the most significant "bang for your buck" in reducing cost <a class="yt-timestamp" data-t="00:05:46">[00:05:46]</a>.

This concept resonates loosely with Hebbian theory in neuroscience, often summarized as "neurons that fire together wire together" <a class="yt-timestamp" data-t="00:05:55">[00:05:55]</a>. In artificial networks, the largest weight increases occur between neurons that are most active and those that are desired to become more active <a class="yt-timestamp" data-t="00:06:07">[00:06:07]</a>.

### Propagating Backwards
The third way to influence a neuron's activation is by adjusting the activations of neurons in the previous layer <a class="yt-timestamp" data-t="00:06:41">[00:06:41]</a>. If neurons connected with a positive weight become brighter, and those with a negative weight become dimmer, the current neuron's activation will increase <a class="yt-timestamp" data-t="00:06:49">[00:06:49]</a>. These desired changes in the previous layer's activations are also proportional to the corresponding weights <a class="yt-timestamp" data-t="00:07:02">[00:07:02]</a>.

Crucially, this is where the "propagating backwards" idea comes in <a class="yt-timestamp" data-t="00:08:01">[00:08:01]</a>. While the network cannot directly change activations, it can note what those desired changes are <a class="yt-timestamp" data-t="00:07:12">[00:07:12]</a>. Every output neuron has its own "desires" for how the second-to-last layer should change <a class="yt-timestamp" data-t="00:07:29">[00:07:29]</a>. These desires are then summed up, creating a comprehensive list of "nudges" for the second-to-last layer <a class="yt-timestamp" data-t="00:07:42">[00:07:42]</a>. This process is then recursively applied, moving backward through the network to determine adjustments for all preceding weights and biases <a class="yt-timestamp" data-t="00:08:14">[00:08:14]</a>.

## Averaging Desired Changes and Stochastic Gradient Descent
The process described above calculates how a *single* training example would like to adjust the weights and biases <a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a>. To perform a true [[gradient_descent_in_neural_networks | gradient descent]] step, this backpropagation routine would need to be run for *every* training example, and then all the desired changes would be averaged together <a class="yt-timestamp" data-t="00:08:44">[00:08:44]</a>. This collection of averaged nudges represents the negative [[gradient_descent_in_neural_networks | gradient]] of the cost function <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>.

However, running backpropagation for tens of thousands of examples for every single [[gradient_descent_in_neural_networks | gradient descent]] step is computationally slow <a class="yt-timestamp" data-t="00:09:33">[00:09:33]</a>. To address this, **stochastic [[gradient_descent_in_neural_networks | gradient descent]]** is commonly used <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>. Training data is randomly shuffled and divided into "mini-batches" (e.g., 100 examples per batch) <a class="yt-timestamp" data-t="00:09:45">[00:09:45]</a>. Each [[gradient_descent_in_neural_networks | gradient descent]] step is then computed based only on one mini-batch <a class="yt-timestamp" data-t="00:09:52">[00:09:52]</a>. While this doesn't yield the exact [[gradient_descent_in_neural_networks | gradient]] of the total cost function, it provides a good approximation and significantly speeds up computation <a class="yt-timestamp" data-t="00:09:56">[00:09:56]</a>. This approach can be visualized as a "drunk man stumbling aimlessly down a hill but taking quick steps" rather than a "carefully calculating man" <a class="yt-timestamp" data-t="00:10:12">[00:10:12]</a>.

## Summary of Backpropagation
Backpropagation is the algorithm that determines how a single training example would like to nudge the weights and biases <a class="yt-timestamp" data-t="00:10:40">[00:10:40]</a>, specifying not only the direction (up or down) but also the relative proportions for the most rapid decrease in cost <a class="yt-timestamp" data-t="00:10:47">[00:10:47]</a>. By repeatedly processing mini-batches and making these adjustments, the network converges towards a local minimum of the cost function, allowing it to perform well on training examples <a class="yt-timestamp" data-t="00:11:14">[00:11:14]</a>.

The underlying [[calculus in neural networks | calculus]] for backpropagation will be explored in a subsequent video <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. The activation function, such as the sigmoid "squishification" function or [[activation_functions_in_neural_networks | ReLU]], plays a crucial role in how activations are computed <a class="yt-timestamp" data-t="00:04:55">[00:04:55]</a>.

## Importance of Training Data
A fundamental requirement for backpropagation and other machine [[Neural network learning process | learning]] algorithms is a substantial amount of training data <a class="yt-timestamp" data-t="00:11:57">[00:11:57]</a>. For handwritten digits, the [[training_neural_networks_with_mnist_data | MNIST database]] provides numerous human-labeled examples <a class="yt-timestamp" data-t="00:12:06">[00:12:06]</a>. Acquiring sufficiently labeled training data, whether images or other data types, is a common challenge in machine [[Neural network learning process | learning]] <a class="yt-timestamp" data-t="00:12:15">[00:12:15]</a>.