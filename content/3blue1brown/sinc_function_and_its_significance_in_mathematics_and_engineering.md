---
title: Sinc function and its significance in mathematics and engineering
videoId: 851U557j6HE
---

From: [[3blue1brown]] <br/> 

The sinc function, formally defined as `sine(x) / x`, is a mathematical function that appears frequently in [[Applications of complex numbers in engineering and mathematics | mathematics]] and engineering <a class="yt-timestamp" data-t="00:00:45">[00:00:45]</a>. It is often visualized as a normal oscillating [[Understanding basic trigonometric functions and waves | sine curve]] that gets progressively "squished down" as `x` moves further from zero, due to the multiplication by `1/x` <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>.

At `x = 0`, the function appears to be `0/0` <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>. However, for values increasingly closer to zero, the function approaches `1` <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a>. By redefining the sinc function at `x = 0` to be `1`, a smooth continuous curve is achieved <a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a>.

## The Integral of the Sinc Function

A particularly interesting property of the sinc function is its integral from negative infinity to infinity <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>. This integral represents the signed area between the curve and the x-axis, where areas above are added and areas below are subtracted <a class="yt-timestamp" data-t="00:01:31">[00:01:31]</a>. Surprisingly, this integral evaluates to exactly pi (π) <a class="yt-timestamp" data-t="00:01:42">[00:01:42]</a>, a result not easily derived using standard [[Basics and significance of differential equations | calculus]] tools <a class="yt-timestamp" data-t="00:01:50">[00:01:50]</a>.

## The Mystery of the Stable Pi Integrals

A sequence of computations highlights a peculiar pattern involving the sinc function:
1.  The integral of `sinc(x)` from negative infinity to infinity equals π <a class="yt-timestamp" data-t="00:01:42">[00:01:42]</a>.
2.  Multiplying `sinc(x)` by a horizontally stretched version, `sinc(x/3)`, results in a more complicated wave <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>. Unexpectedly, the integral of this product also equals π <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>.
3.  Continuing this pattern, by multiplying by `sinc(x/5)`, `sinc(x/7)`, and so on, each successive integral in the sequence *still* equals π <a class="yt-timestamp" data-t="00:02:31">[00:02:31]</a>, <a class="yt-timestamp" data-t="00:02:44">[00:02:44]</a>.

This stability is counterintuitive because, except at `x = 0`, each additional multiplication factor is smaller than `1`, suggesting the function should be "squished down" and the area should decrease <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>, <a class="yt-timestamp" data-t="00:03:00">[00:03:00]</a>.

### The Breakdown Point

The pattern of equaling pi does not continue indefinitely <a class="yt-timestamp" data-t="00:00:25">[00:00:25]</a>. At some point, the integral breaks, yielding a value only *barely* less than π <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>, <a class="yt-timestamp" data-t="00:03:08">[00:03:08]</a>. This occurs when the sequence includes `sinc(x/15)` as a factor <a class="yt-timestamp" data-t="00:03:16">[00:03:16]</a>. The exact value of this last integral is a fraction of pi with an astronomically large numerator and denominator <a class="yt-timestamp" data-t="00:03:27">[00:03:27]</a>.

This phenomenon was described by Jonathan and David Borwein, who noted that a researcher computing these integrals initially assumed it was a computer bug <a class="yt-timestamp" data-t="00:03:40">[00:03:40]</a>.

Even stranger, if an additional factor of `2 * cosine(x)` is included in these integrals, the pattern of equaling pi persists for much longer, breaking only at the factor `sinc(x/113)` <a class="yt-timestamp" data-t="00:03:58">[00:03:58]</a>, <a class="yt-timestamp" data-t="00:04:09">[00:04:09]</a>.

## An Analogous Phenomenon: Moving Averages of Rect Functions

To understand this mysterious behavior, an seemingly unrelated phenomenon can be examined: iterative moving averages of a "rect" function.
The `rect(x)` function is defined as `1` if `x` is between `-1/2` and `1/2`, and `0` otherwise <a class="yt-timestamp" data-t="00:04:52">[00:04:52]</a>. Let's call this `f1(x)` <a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a>.

A sequence of functions `fn(x)` is generated by taking a moving average of the previous function `f(n-1)(x)`:
*   `f2(x)` is the moving average of `f1(x)` with a window width of `1/3` <a class="yt-timestamp" data-t="00:06:15">[00:06:15]</a>.
*   `f3(x)` is the moving average of `f2(x)` with a window width of `1/5` <a class="yt-timestamp" data-t="00:06:52">[00:06:52]</a>.
*   This continues with window widths of `1/7`, `1/9`, and so on <a class="yt-timestamp" data-t="00:07:38">[00:07:38]</a>.

When computing `f(n)(0)` (the value of the function at `x=0`), a similar pattern emerges <a class="yt-timestamp" data-t="00:06:37">[00:06:37]</a>. As long as the "plateau" of the function at `1` is wider than the current moving average window, `f(n)(0)` remains `1` <a class="yt-timestamp" data-t="00:07:02">[00:07:02]</a>. The length of this plateau shrinks with each iteration by the width of the window <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>.

This pattern breaks when the sum of the reciprocals of the odd numbers (`1/3 + 1/5 + 1/7 + ...`) becomes greater than `1` <a class="yt-timestamp" data-t="00:08:20">[00:08:20]</a>, at which point the plateau effectively disappears at `x=0` <a class="yt-timestamp" data-t="00:08:38">[00:08:38]</a>. This happens at the `1/15` iteration <a class="yt-timestamp" data-t="00:08:03">[00:08:03]</a>, causing `f(n)(0)` to fall slightly below `1` <a class="yt-timestamp" data-t="00:08:14">[00:08:14]</a>.

This analogous pattern (1, 1, 1... then slightly less than 1) is quantitatively the same as the factor by which the integral sequence drops below pi <a class="yt-timestamp" data-t="00:09:10">[00:09:10]</a>, <a class="yt-timestamp" data-t="00:09:10">[00:09:10]</a>.
For the case where the integral pattern extended to `113`, the analogy is a starting rect function with a longer plateau (length `2` instead of `1`) <a class="yt-timestamp" data-t="00:09:33">[00:09:33]</a>. It takes longer for the sum of reciprocals to exceed `2`, which occurs at `1/113` <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>.

### Generalization
The specific sequence of odd numbers (`1/3, 1/5, 1/7...`) was chosen for illustration by the Borweins <a class="yt-timestamp" data-t="00:10:12">[00:10:12]</a>. More generally, if any sequence of positive numbers is used in the sinc functions, the integral will equal pi as long as the sum of those numbers is less than `1` <a class="yt-timestamp" data-t="00:10:22">[00:10:22]</a>. If the sum exceeds `1`, the integral drops below pi <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>.

## The Deeper Connection: Fourier Transforms and Convolutions

The seemingly unrelated nature of these two phenomena is resolved through powerful mathematical tools: [[Fourier transforms and convolutions | Fourier transforms]] and [[Fourier transforms and convolutions | convolutions]] <a class="yt-timestamp" data-t="00:10:41">[00:10:41]</a>, <a class="yt-timestamp" data-t="00:10:48">[00:10:48]</a>.

First, the sinc function can be normalized by replacing `x` with `pi*x` in its input, `sin(pi*x)/(pi*x)` <a class="yt-timestamp" data-t="00:11:21">[00:11:21]</a>. This "engineer's sinc" function has an integral of `1` instead of `pi` <a class="yt-timestamp" data-t="00:11:37">[00:11:37]</a>.

The core connection lies in these [[Mathematical notation and conventions | facts]]:
*   **[[Fourier transforms and convolutions | Fourier Transform]] of Sinc is Rect**: The sinc function (or its normalized version) is related to the rect function via a [[Fourier transforms and convolutions | Fourier transform]] <a class="yt-timestamp" data-t="00:12:18">[00:12:18]</a>. Applying a [[Fourier transforms and convolutions | Fourier transform]] to the sinc function yields the rect function, and vice versa <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>. Stretched versions of the sinc function transform into stretched and squished versions of the rect function <a class="yt-timestamp" data-t="00:13:17">[00:13:17]</a>.
*   **Integral = [[Fourier Transform]] at Zero**: The integral of a function from negative infinity to infinity is equivalent to evaluating its [[Fourier transforms and convolutions | Fourier transformed]] version at the input zero <a class="yt-timestamp" data-t="00:13:55">[00:13:55]</a>, <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a>.
    *   This explains why the integral of sinc(x) is pi (or 1 for the normalized sinc): `Integral[sinc(x) dx]` corresponds to `rect(0)`, which is `1` <a class="yt-timestamp" data-t="00:14:39">[00:14:39]</a>.

*   **Product in one domain = [[Fourier transforms and convolutions | Convolution]] in the other (The [[Fourier transforms and convolutions | Convolution]] Theorem)**: If you take the product of two functions and then apply a [[Fourier transforms and convolutions | Fourier transform]], the result is the same as individually taking the [[Fourier transforms and convolutions | Fourier transforms]] of the original functions and then combining them using a new operation called a [[Fourier transforms and convolutions | convolution]] <a class="yt-timestamp" data-t="00:15:11">[00:15:11]</a>. Crucially, in this specific case with rectangular functions, a [[Fourier transforms and convolutions | convolution]] mathematically *looks exactly like* the moving average process described earlier <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>, <a class="yt-timestamp" data-t="00:15:35">[00:15:35]</a>.

> [!NOTE]
> This means that multiplying more and more sinc functions together (the integral problem) can be understood as progressively performing moving averages on the rect functions (the analogous problem), and then always evaluating the result at zero <a class="yt-timestamp" data-t="00:15:55">[00:15:55]</a>, <a class="yt-timestamp" data-t="00:15:59">[00:15:59]</a>. This provides an intuitive explanation for the long period of stability before the pattern breaks down <a class="yt-timestamp" data-t="00:16:03">[00:16:03]</a>.

The [[Fourier transforms and convolutions | convolution]] theorem is a fundamental concept in [[Applications of complex numbers in engineering and mathematics | mathematics]] and engineering, enabling a shift in perspective that often simplifies complex problems <a class="yt-timestamp" data-t="00:16:17">[00:16:17]</a>, <a class="yt-timestamp" data-t="00:16:37">[00:16:37]</a>. For example, it can be used to develop algorithms for very fast multiplication of large numbers <a class="yt-timestamp" data-t="00:16:49">[00:16:49]</a>.