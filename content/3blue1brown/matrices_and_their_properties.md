---
title: Matrices and their properties
videoId: PFDu9oVAE-g
---

From: [[3blue1brown]] <br/> 

Matrices are fundamental to understanding [[linear_transformations_and_matrices | linear transformations]] <a class="yt-timestamp" data-t="01:00:59">[01:00:59]</a>. A matrix represents a [[linear_transformations_and_matrices | linear transformation]] by using its columns to show where the basis vectors (like i-hat and j-hat) land after the transformation <a class="yt-timestamp" data-t="01:25:00">[01:25:00]</a>, <a class="yt-timestamp" data-t="04:53:00">[04:53:00]</a>. For example, if a transformation moves i-hat to (3, 0) and j-hat to (1, 2), the matrix representing it will have columns [3, 0] and [1, 2] <a class="yt-timestamp" data-t="01:31:00">[01:31:00]</a>.

Understanding matrices requires a solid visual understanding of preceding topics, including [[linear_transformations_and_matrices | matrices as linear transformations]], determinants, [[linear_algebra_foundations | linear systems of equations]], and change of basis <a class="yt-timestamp" data-t="00:51:00">[00:51:00]</a>, <a class="yt-timestamp" data-t="01:02:00">[01:02:00]</a>, <a class="yt-timestamp" data-t="01:06:00">[01:06:00]</a>.

## Eigenvectors and Eigenvalues

Eigenvectors and eigenvalues are topics that become intuitive with a visual understanding of matrices as [[linear_transformations_and_matrices | linear transformations]] <a class="yt-timestamp" data-t="00:19:00">[00:19:00]</a>, <a class="yt-timestamp" data-t="00:36:00">[00:36:00]</a>, <a class="yt-timestamp" data-t="00:51:00">[00:51:00]</a>.

### Definition and Properties
Most vectors are "knocked off" their original span (the line passing through their origin and tip) during a [[linear_transformations_and_matrices | transformation]] <a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>. However, some special vectors remain on their own span, meaning the matrix's effect on them is merely to stretch or squish them like a scalar <a class="yt-timestamp" data-t="01:57:00">[01:57:00]</a>, <a class="yt-timestamp" data-t="02:00:00">[02:00:00]</a>, <a class="yt-timestamp" data-t="02:05:00">[02:05:00]</a>.

These special vectors are called **eigenvectors** of the transformation <a class="yt-timestamp" data-t="03:22:00">[03:22:00]</a>, <a class="yt-timestamp" data-t="03:27:00">[03:27:00]</a>. Each eigenvector has an associated **eigenvalue**, which is the factor by which it is stretched or squished <a class="yt-timestamp" data-t="03:31:00">[03:31:00]</a>. The eigenvalue can be positive (stretching), negative (flipping and squishing), or even 1 (staying fixed in place) <a class="yt-timestamp" data-t="03:43:00">[03:43:00]</a>, <a class="yt-timestamp" data-t="03:46:00">[03:46:00]</a>, <a class="yt-timestamp" data-t="04:37:00">[04:37:00]</a>. The key property is that the vector remains on its own span without being rotated off of it <a class="yt-timestamp" data-t="03:56:00">[03:56:00]</a>, <a class="yt-timestamp" data-t="03:59:00">[03:59:00]</a>.

### Conceptual Significance
Eigenvectors and eigenvalues help in understanding the "heart" of what a [[linear_transformations_and_matrices | linear transformation]] does, independent of a specific coordinate system <a class="yt-timestamp" data-t="05:00:00">[05:00:00]</a>, <a class="yt-timestamp" data-t="05:03:00">[05:03:00]</a>. For instance, finding an eigenvector for a 3D rotation reveals the **axis of rotation**, making the rotation much easier to conceptualize than its full 3x3 matrix representation <a class="yt-timestamp" data-t="04:07:00">[04:07:00]</a>, <a class="yt-timestamp" data-t="04:11:00">[04:11:00]</a>, <a class="yt-timestamp" data-t="04:14:00">[04:14:00]</a>, <a class="yt-timestamp" data-t="04:22:00">[04:22:00]</a>.

### Computational Ideas
Symbolically, for a matrix `A` representing a transformation, a vector `v` is an eigenvector if `A * v = λ * v`, where `λ` (lambda) is the corresponding eigenvalue <a class="yt-timestamp" data-t="05:27:00">[05:27:00]</a>, <a class="yt-timestamp" data-t="05:31:00">[05:31:00]</a>, <a class="yt-timestamp" data-t="05:35:00">[05:35:00]</a>. Finding `v` and `λ` that satisfy this equation is the goal <a class="yt-timestamp" data-t="05:51:00">[05:51:00]</a>.

To work with this equation, the right side (`λ * v`) can be rewritten as a matrix-vector product: `λ` times the identity matrix `I` times `v` (`λIv`) <a class="yt-timestamp" data-t="06:11:00">[06:11:00]</a>, <a class="yt-timestamp" data-t="06:15:00">[06:15:00]</a>. The **identity matrix** `I` has `1`s down its diagonal and zeros elsewhere <a class="yt-timestamp" data-t="06:40:00">[06:40:00]</a>.
The equation becomes `Av = λIv`, which can be rearranged to `(A - λI)v = 0` <a class="yt-timestamp" data-t="06:48:00">[06:48:00]</a>, <a class="yt-timestamp" data-t="06:54:00">[06:54:00]</a>.

For a non-zero eigenvector `v` to exist that satisfies this equation, the transformation associated with the matrix `(A - λI)` must "squish space into a lower dimension" <a class="yt-timestamp" data-t="07:11:00">[07:11:00]</a>, <a class="yt-timestamp" data-t="07:14:00">[07:14:00]</a>, <a class="yt-timestamp" data-t="07:18:00">[07:18:00]</a>. This "squishification" corresponds to the matrix `(A - λI)` having a **zero determinant** <a class="yt-timestamp" data-t="07:29:00">[07:29:00]</a>. Thus, eigenvalues `λ` are found by solving the characteristic equation: `det(A - λI) = 0` <a class="yt-timestamp" data-t="07:58:00">[07:58:00]</a>, <a class="yt-timestamp" data-t="08:02:00">[08:02:00]</a>. Once an eigenvalue is found, it can be plugged back into `(A - λI)v = 0` to solve for the corresponding eigenvectors `v` <a class="yt-timestamp" data-t="10:09:00">[10:09:00]</a>, <a class="yt-timestamp" data-t="10:14:00">[10:14:00]</a>, <a class="yt-timestamp" data-t="10:19:00">[10:19:00]</a>.

### Examples of Eigenvectors and Eigenvalues

*   **Example 1 (Stretch/Squish):** A matrix with columns [3, 0] and [1, 2] has eigenvectors on the x-axis (eigenvalue 3) and eigenvectors on the line spanned by (-1, 1) (eigenvalue 2) <a class="yt-timestamp" data-t="02:09:00">[02:09:00]</a>, <a class="yt-timestamp" data-t="02:26:00">[02:26:00]</a>, <a class="yt-timestamp" data-t="02:38:00">[02:38:00]</a>, <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>, <a class="yt-timestamp" data-t="02:44:00">[02:44:00]</a>, <a class="yt-timestamp" data-t="02:59:00">[02:59:00]</a>, <a class="yt-timestamp" data-t="10:02:00">[10:02:00]</a>.
*   **Rotation:** A 90-degree rotation matrix (columns [0, 1] and [-1, 0]) has no real eigenvectors because it rotates every vector off its span. Its characteristic polynomial (lambda squared plus 1) has only imaginary roots <a class="yt-timestamp" data-t="10:50:00">[10:50:00]</a>, <a class="yt-timestamp" data-t="10:53:00">[10:53:00]</a>, <a class="yt-timestamp" data-t="11:00:00">[11:00:00]</a>, <a class="yt-timestamp" data-t="11:04:00">[11:04:00]</a>, <a class="yt-timestamp" data-t="11:06:00">[11:06:00]</a>, <a class="yt-timestamp" data-t="11:11:00">[11:11:00]</a>, <a class="yt-timestamp" data-t="11:18:00">[11:18:00]</a>, <a class="yt-timestamp" data-t="11:22:00">[11:22:00]</a>, <a class="yt-timestamp" data-t="11:28:00">[11:28:00]</a>.
*   **Shear:** A shear matrix (columns [1, 0] and [1, 1]) has eigenvectors only on the x-axis, all with an eigenvalue of 1 (they remain fixed). Its characteristic polynomial (1 minus lambda squared) has only one root, lambda equals 1 <a class="yt-timestamp" data-t="11:35:00">[11:35:00]</a>, <a class="yt-timestamp" data-t="11:40:00">[11:40:00]</a>, <a class="yt-timestamp" data-t="11:48:00">[11:48:00]</a>, <a class="yt-timestamp" data-t="11:51:00">[11:51:00]</a>, <a class="yt-timestamp" data-t="11:55:00">[11:55:00]</a>, <a class="yt-timestamp" data-t="11:58:00">[11:58:00]</a>, <a class="yt-timestamp" data-t="12:03:00">[12:03:00]</a>, <a class="yt-timestamp" data-t="12:09:00">[12:09:00]</a>, <a class="yt-timestamp" data-t="12:14:00">[12:14:00]</a>.
*   **Scaling:** A matrix that scales everything by a factor (e.g., by 2) has only one eigenvalue (e.g., 2), but *every* vector in the plane is an eigenvector with that eigenvalue <a class="yt-timestamp" data-t="12:29:00">[12:29:00]</a>, <a class="yt-timestamp" data-t="12:33:00">[12:33:00]</a>, <a class="yt-timestamp" data-t="12:37:00">[12:37:00]</a>.

## Diagonal Matrices and Eigenbases

### Diagonal Matrices
A **diagonal matrix** is a matrix with zeros everywhere except along its main diagonal <a class="yt-timestamp" data-t="13:38:00">[13:38:00]</a>, <a class="yt-timestamp" data-t="13:42:00">[13:42:00]</a>. In a diagonal matrix, the basis vectors themselves are eigenvectors, and the diagonal entries are their corresponding eigenvalues <a class="yt-timestamp" data-t="13:45:00">[13:45:00]</a>, <a class="yt-timestamp" data-t="13:48:00">[13:48:00]</a>, <a class="yt-timestamp" data-t="13:50:00">[13:50:00]</a>.

Diagonal matrices are much easier to work with than non-diagonal ones <a class="yt-timestamp" data-t="13:57:00">[13:57:00]</a>, <a class="yt-timestamp" data-t="14:01:00">[14:01:00]</a>. For example, computing a high power of a diagonal matrix (e.g., 100th power) simply involves raising each diagonal entry (eigenvalue) to that power, as the matrix just scales each basis vector by its eigenvalue <a class="yt-timestamp" data-t="14:05:00">[14:05:00]</a>, <a class="yt-timestamp" data-t="14:09:00">[14:09:00]</a>, <a class="yt-timestamp" data-t="14:14:00">[14:14:00]</a>.

### Eigenbasis
If a transformation has enough eigenvectors to span the full space, these eigenvectors can be chosen as a new coordinate system's basis vectors <a class="yt-timestamp" data-t="14:42:00">[14:42:00]</a>, <a class="yt-timestamp" data-t="14:45:00">[14:45:00]</a>, <a class="yt-timestamp" data-t="14:49:00">[14:49:00]</a>, <a class="yt-timestamp" data-t="14:54:00">[14:54:00]</a>. A set of basis vectors that are also eigenvectors is called an **eigenbasis** <a class="yt-timestamp" data-t="15:55:00">[15:55:00]</a>, <a class="yt-timestamp" data-t="15:59:00">[15:59:00]</a>.

To express a transformation from a standard coordinate system into this new eigenbasis system, a **change of basis matrix** is used <a class="yt-timestamp" data-t="15:00:00">[15:00:00]</a>, <a class="yt-timestamp" data-t="15:03:00">[15:03:00]</a>. This matrix's columns are the coordinates of the chosen eigenvectors (the new basis vectors) <a class="yt-timestamp" data-t="15:08:00">[15:08:00]</a>, <a class="yt-timestamp" data-t="15:12:00">[15:12:00]</a>. By "sandwiching" the original transformation matrix between the change of basis matrix and its inverse, the resulting matrix in the new coordinate system will be diagonal, with the eigenvalues along its diagonal <a class="yt-timestamp" data-t="15:20:00">[15:20:00]</a>, <a class="yt-timestamp" data-t="15:22:00">[15:22:00]</a>, <a class="yt-timestamp" data-t="15:26:00">[15:26:00]</a>, <a class="yt-timestamp" data-t="15:31:00">[15:31:00]</a>, <a class="yt-timestamp" data-t="15:41:00">[15:41:00]</a>, <a class="yt-timestamp" data-t="15:46:00">[15:46:00]</a>. This simplification makes matrix operations significantly easier <a class="yt-timestamp" data-t="16:02:00">[16:02:00]</a>, <a class="yt-timestamp" data-t="16:07:00">[16:07:00]</a>. However, not all transformations, such as a shear, have enough eigenvectors to form an eigenbasis <a class="yt-timestamp" data-t="16:18:00">[16:18:00]</a>, <a class="yt-timestamp" data-t="16:23:00">[16:23:00]</a>.