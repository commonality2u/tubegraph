---
title: Transformers and attention in language models
videoId: LPZh9BOjkQs
---

From: [[3blue1brown]] <br/> 

[[large_language_models_and_prediction | Large language models]] (LLMs) are sophisticated mathematical functions that predict the next word for any given text <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>. Instead of predicting one word with certainty, they assign a probability to all possible next words <a class="yt-timestamp" data-t="00:00:44">[00:00:44]</a>. When interacting with a chatbot, this word-by-word prediction process is exactly what occurs, completing a dialogue by repeatedly predicting the next word <a class="yt-timestamp" data-t="00:00:33">[00:00:33]</a>. The output appears more natural when the model is allowed to randomly select less likely words, leading to different answers for the same prompt each time it's run, despite the model itself being deterministic <a class="yt-timestamp" data-t="00:01:13">[00:01:13]</a>.

## [[training_process_of_language_models | Training Process]]

LLMs learn to make predictions by processing an enormous amount of text, typically sourced from the internet <a class="yt-timestamp" data-t="00:01:28">[00:01:28]</a>. For example, the text used to [[generative_pretrained_transformers | train GPT-3]] would take a human over 2600 years to read non-stop <a class="yt-timestamp" data-t="00:01:34">[00:01:34]</a>. Larger models have since been [[training_process_of_language_models | trained]] on even more data <a class="yt-timestamp" data-t="00:01:44">[00:01:44]</a>.

The behavior of a language model is determined by continuous values known as parameters or weights, which can number in the hundreds of billions <a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>. These parameters are not set by humans; they begin at random and are refined through a process of repeated adjustment based on many example texts <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>. During [[training_process_of_language_models | training]], the model is given a text example with the last word removed, and its prediction is compared to the true last word <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a>. An algorithm called backpropagation tweaks the parameters to make the model more likely to choose the correct word and less likely to choose others <a class="yt-timestamp" data-t="00:02:43">[00:02:43]</a>. This process, performed over trillions of examples, improves prediction accuracy on both [[training_process_of_language_models | training]] data and unseen text <a class="yt-timestamp" data-t="00:02:55">[00:02:55]</a>. This initial phase is called **pre-training** <a class="yt-timestamp" data-t="00:03:47">[00:03:47]</a>.

To make chatbots more effective AI assistants, they undergo a second type of [[training_process_of_language_models | training]] called **reinforcement learning with human feedback** <a class="yt-timestamp" data-t="00:03:56">[00:03:56]</a>. Human workers flag unhelpful or problematic predictions, and their corrections further adjust the model's parameters to align with user preferences <a class="yt-timestamp" data-t="00:04:04">[00:04:04]</a>.

### [[computation_and_infrastructure_for_training_language_models | Computation and Infrastructure]]

The scale of [[computation_and_infrastructure_for_training_language_models | computation]] for [[training_process_of_language_models | training]] LLMs is immense <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>. Performing all the operations for [[training_process_of_language_models | training]] the largest models would take over 100 million years for a machine capable of a billion additions and multiplications per second <a class="yt-timestamp" data-t="00:03:19">[00:03:19]</a>. This is made possible by special computer chips optimized for parallel operations, known as GPUs <a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a>.

## [[Transformers and attention mechanism | Transformers and Attention]]

Prior to 2017, most language models processed text one word at a time <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>. However, a team at Google introduced the [[Transformers and attention mechanism | transformer]] model, which can process entire texts in parallel <a class="yt-timestamp" data-t="00:04:36">[00:04:36]</a>.

### Core Mechanisms

1.  **Word Embeddings**: The first step in a [[Transformers and attention mechanism | transformer]] is to associate each word with a long list of numbers, known as embeddings. This is necessary because the [[training_process_of_language_models | training]] process only works with continuous values, and these numbers encode the meaning of the corresponding word <a class="yt-timestamp" data-t="00:04:49">[00:04:49]</a>.
2.  **[[Attention Mechanism in Transformers | Attention]]**: What makes [[Transformers and attention mechanism | transformers]] unique is their reliance on a special operation called [[Attention Mechanism in Transformers | attention]] <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a>. This operation allows these lists of numbers (embeddings) to interact with each other and [[the_process_of_updating_embeddings_using_attention | refine the meanings they encode based on the context around them]], all in parallel <a class="yt-timestamp" data-t="00:05:16">[00:05:16]</a>. For example, the numbers for the word "bank" might change to encode the specific notion of a "riverbank" based on surrounding words <a class="yt-timestamp" data-t="00:05:27">[00:05:27]</a>.
3.  **Feed-Forward [[Neural Networks and Transformers | Neural Network]]**: [[Transformers and attention mechanism | Transformers]] also incorporate a feed-forward [[Neural Networks and Transformers | neural network]] operation, which provides extra capacity to store more language patterns learned during [[training_process_of_language_models | training]] <a class="yt-timestamp" data-t="00:05:37">[00:05:37]</a>.

Data repeatedly flows through many iterations of these two fundamental operations <a class="yt-timestamp" data-t="00:05:49">[00:05:49]</a>. The goal is for each list of numbers to be enriched with the information needed to accurately predict the next word <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>. At the end, a final function is performed on the last vector in the sequence, which has been influenced by all input context and learned patterns, to produce a probability prediction for every possible next word <a class="yt-timestamp" data-t="00:06:07">[00:06:07]</a>.

While researchers design the framework, the specific behavior of [[Transformers and attention mechanism | transformers]] is an emergent phenomenon resulting from the tuning of billions of parameters during [[training_process_of_language_models | training]] <a class="yt-timestamp" data-t="00:06:28">[00:06:28]</a>. This makes it challenging to determine precisely why a model makes specific predictions <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>. However, the resulting word generations are remarkably fluent, fascinating, and useful <a class="yt-timestamp" data-t="00:06:48">[00:06:48]</a>.

### Further Information
For more details on how [[Transformers and attention mechanism | transformers]] and [[Attention Mechanism in Transformers | attention]] work, deeper resources are available <a class="yt-timestamp" data-t="00:07:05">[00:07:05]</a>. One option is a series on deep learning that visualizes the details of [[Attention Mechanism in Transformers | attention]] and other [[Transformers and attention mechanism | transformer]] steps <a class="yt-timestamp" data-t="00:07:12">[00:07:12]</a>. Additionally, a talk on the topic given at TNG in Munich is available <a class="yt-timestamp" data-t="00:07:22">[00:07:22]</a>.