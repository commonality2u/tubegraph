---
title: Data privacy and ethical considerations in generative AI
videoId: lwtU_NfFH8o
---

From: [[redpointai]] <br/> 

Adobe places significant emphasis on [[trust_and_data_security_in_ai | trust and data security in AI]], especially concerning the data used for training its generative models and the content generated by them <a class="yt-timestamp" data-t="00:26:26">[00:26:26]</a>. This focus addresses [[regulatory_and_safety_issues_in_ai_model_development | regulatory and safety issues in AI model development]] and broader [[concerns_and_considerations_for_ai_safety_and_regulation | concerns and considerations for AI safety and regulation]].

## Data Sourcing and Privacy
A key part of Adobe's Firefly strategy is training its models on data from its own Adobe Stock database of content <a class="yt-timestamp" data-t="00:26:41">[00:26:41]</a>. This means Firefly models are not trained on data scraped from the internet <a class="yt-timestamp" data-t="00:26:50">[00:26:50]</a>. This approach is intended to reduce concerns from artists about consent, control, or compensation for their work <a class="yt-timestamp" data-t="00:26:52">[00:26:52]</a>.

Training on Adobe Stock data provides several advantages:
*   **High-quality content:** Access to professionally curated content <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>.
*   **Clear usage rights:** Adobe has the right to train on data stored in its marketplace <a class="yt-timestamp" data-t="00:27:06">[00:27:06]</a>.
*   **Reduced IP infringement risk:** Minimizes the potential for generated content to infringe on existing intellectual property <a class="yt-timestamp" data-t="00:27:10">[00:27:10]</a>.
*   **Minimized harmful content:** Adobe Stock has a content moderation process, including automated and manual curation, that rejects harmful content, thus reducing its presence in the training data <a class="yt-timestamp" data-t="00:27:21">[00:27:21]</a>.

Crucially, Adobe explicitly states that it does not train its models on customer data stored in Creative Cloud <a class="yt-timestamp" data-t="00:33:30">[00:33:30]</a>.

## Bias Mitigation
Recognizing that every dataset has inherent bias, Adobe actively works to mitigate bias in its models <a class="yt-timestamp" data-t="00:28:10">[00:28:10]</a>.

*   **Internal Testing:** An internal test with tens of thousands of Adobe employees provided valuable feedback on areas where bias was evident in early versions of Firefly <a class="yt-timestamp" data-t="00:28:29">[00:28:29]</a>. This feedback led to significant improvements in a short period <a class="yt-timestamp" data-t="00:28:51">[00:28:51]</a>.
*   **Person Detector Model:** Adobe developed a "person detector" model to identify references to people or jobs in prompts <a class="yt-timestamp" data-t="00:29:19">[00:29:19]</a>. This model debiases the generated content to introduce a fair distribution of skin tones, genders, and age groups, often referencing the demographic distribution of the user's country of origin <a class="yt-timestamp" data-t="00:29:55">[00:29:55]</a>.

## Content Moderation and Safety
To ensure content is safe and commercially usable, Adobe has implemented several measures:
*   **Toxicity Detectors:** Various toxicity detector models have been trained to differentiate terms and prevent the generation of Not Safe For Work (NSFW) content <a class="yt-timestamp" data-t="00:31:01">[00:31:01]</a>.
*   **Deny and Block Lists:** These lists further restrict unwanted content generation <a class="yt-timestamp" data-t="00:31:06">[00:31:06]</a>.
*   **NSFW Filters:** Filters are applied at the end of the generation process <a class="yt-timestamp" data-t="00:31:13">[00:31:13]</a>.
*   **Child Protection Systems:** Specific systems detect prompts referencing children and minimize the chance of generating inappropriate content in relation to them <a class="yt-timestamp" data-t="00:31:24">[00:31:24]</a>.

## Customer Feedback and Model Refinement
Adobe values customer feedback as a crucial component of its safety and refinement process <a class="yt-timestamp" data-t="00:32:02">[00:32:02]</a>.
*   **Feedback Mechanisms:** Firefly.com and Photoshop include mechanisms for beta customers to report what they like and dislike, including bias and harm issues <a class="yt-timestamp" data-t="00:19:08">[00:19:08]</a>, <a class="yt-timestamp" data-t="00:32:03">[00:32:03]</a>. This feedback provides new [[data_labeling_and_the_role_of_synthetic_data_in_ai | training data points]] for rules and models <a class="yt-timestamp" data-t="00:32:11">[00:32:11]</a>.
*   **Reinforcement Learning from Human Feedback (RLHF):** On firefly.com, Adobe's terms of use allow the storage of prompts and generated images for training <a class="yt-timestamp" data-t="00:33:59">[00:33:59]</a>. This acts as Adobe's way of doing RLHF <a class="yt-timestamp" data-t="00:34:07">[00:34:07]</a>. Explicit signals (like/dislike, report) and implicit signals (download, save, share) are collected <a class="yt-timestamp" data-t="00:34:18">[00:34:18]</a>. These signals are integrated into future Firefly models to teach the generation process to create content users prefer and avoid content they dislike <a class="yt-timestamp" data-t="00:34:38">[00:34:38]</a>.