---
title: Product market fit in AI
videoId: P6y0gr-W2-k
---

From: [[redpointai]] <br/> 

Characterizing genuine [[product_development_and_prioritization_in_ai_startups | product market fit]] in AI today is challenging, especially for early-stage investments where success is unclear <a class="yt-timestamp" data-t="00:24:28">[00:24:28]</a>. The focus for investors is often on finding innovations that, if successful, will clearly be adopted <a class="yt-timestamp" data-t="00:24:41">[00:24:41]</a>.

## Identifying Product Market Fit

The definition of product market fit in AI evolves, but historically, a bar of $100 million in revenue for a use case has been considered a strong indicator <a class="yt-timestamp" data-t="00:26:09">[00:26:09]</a>. This addresses skeptics who view AI tools as mere "toys" lacking reliability <a class="yt-timestamp" data-t="00:26:00">[00:26:00]</a>.

Early examples of applications demonstrating product market fit include:
*   **Co-pilot tools** <a class="yt-timestamp" data-t="00:26:17">[00:26:17]</a>.
*   **Writing assistance** tools like Jasper <a class="yt-timestamp" data-t="00:26:20">[00:26:20]</a>.
*   **Coding agents** like Cursor <a class="yt-timestamp" data-t="00:26:26">[00:26:26]</a>.

The list of "form factors" that demonstrate product market fit is expected to grow over time <a class="yt-timestamp" data-t="00:26:35">[00:26:35]</a>.

### Recent Additions to PMF Category

*   **Deep research tools**: Anything that facilitates long-term, agentic reporting and automates more aspects of a job shows product market fit <a class="yt-timestamp" data-t="00:26:42">[00:26:42]</a>. OpenAI's Deep Research feature, despite initial pricing adjustments, generated significant revenue, indicating strong demand <a class="yt-timestamp" data-t="00:27:09">[00:27:09]</a>.
*   **Customer support agents**: Companies like Sierra are tackling this market, indicating a belief in its long-term viability and ability to provide a durable business <a class="yt-timestamp" data-t="00:31:26">[00:31:26]</a>.
*   **Voice AI**: These applications do not require 100% precision and recall to be valuable <a class="yt-timestamp" data-t="00:33:17">[00:33:17]</a>. For instance, scheduling intake companies for home services, where 50% of calls are currently missed, can significantly increase revenue with an AI that is only 75% effective <a class="yt-timestamp" data-t="00:33:30">[00:33:30]</a>.
*   **Specific niche applications**: Focused solutions, such as AI for appointment scheduling for veterinarians, demonstrate that addressing a significant pain point can lead to willingness to pay <a class="yt-timestamp" data-t="00:34:15">[00:34:15]</a>.

## Evolution of AI Applications

The first wave of AI applications primarily focused on [[evaluating_ai_progress_with_roi | cost cutting]] <a class="yt-timestamp" data-t="00:32:02">[00:32:02]</a>. These often targeted areas where businesses were already comfortable outsourcing and accepting some performance reduction for cost savings <a class="yt-timestamp" data-t="00:32:30">[00:32:30]</a>. While these areas might face fierce price competition, the next wave is expected to focus on [[evaluating_ai_progress_with_roi | growth and revenue generation]] <a class="yt-timestamp" data-t="00:32:06">[00:32:06]</a>. This includes capabilities that directly increase top-line revenue, such as AI for go-to-market strategies, which may prove more defensible and command higher prices due to clear [[evaluating_ai_progress_with_roi | ROI]] <a class="yt-timestamp" data-t="00:32:56">[00:32:56]</a>.

## Future Potential Applications

Areas with emerging product market fit include:
*   Screen sharing assistance <a class="yt-timestamp" data-t="00:35:56">[00:35:56]</a>.
*   Outbound sales agents <a class="yt-timestamp" data-t="00:36:06">[00:36:06]</a>.
*   Hiring and recruiting <a class="yt-timestamp" data-t="00:36:14">[00:36:14]</a>.
*   Personalized education, which is surprisingly underdeveloped given its potential <a class="yt-timestamp" data-t="00:36:16">[00:36:16]</a>.
*   Finance-specific applications <a class="yt-timestamp" data-t="00:36:31">[00:36:31]</a>.
*   Personal AI <a class="yt-timestamp" data-t="00:36:35">[00:36:35]</a>.

Even with current model capabilities, there are "trillions of dollars of application value to be unlocked" <a class="yt-timestamp" data-t="00:36:56">[00:36:56]</a>. For example, amazing education apps could be built with the existing generation of models <a class="yt-timestamp" data-t="00:37:03">[00:37:03]</a>. The challenge in areas like education may be more societal and human-related rather than technological <a class="yt-timestamp" data-t="00:37:24">[00:37:24]</a>.

## Defensibility at the Application Layer

[[Challenges in AI product development | Defensibility at the app layer]] is often underestimated. Key factors include:
*   **Network effects**: Prioritizing the multiplayer experience over just the single-player experience can create a robust defense <a class="yt-timestamp" data-t="00:39:16">[00:39:16]</a>. Chai Research, a character AI competitor, outlasted others by building a network of people submitting models, demonstrating the power of network effects over proprietary IP <a class="yt-timestamp" data-t="00:40:18">[00:40:18]</a>.
*   **Brand recognition**: A company can quickly become synonymous with an entire category within six to nine months, giving them a significant advantage in customer access <a class="yt-timestamp" data-t="00:41:17">[00:41:17]</a>. This brand premium can even lead to higher average contract values (ACVs) <a class="yt-timestamp" data-t="00:41:41">[00:41:41]</a>.
*   **User experience and design**: The "thousand small things" a company does to create a delightful user experience contributes significantly to defensibility, akin to traditional SaaS applications <a class="yt-timestamp" data-t="00:42:06">[00:42:06]</a>.
*   **Velocity**: The speed at which a company can develop a broad product and adapt to new models (which can be an "existential event" every 3-6 months) is crucial <a class="yt-timestamp" data-t="00:42:12">[00:42:12]</a>.

Initially, many AI app developers mistakenly believed that defensibility would come from unique datasets or proprietary models <a class="yt-timestamp" data-t="00:41:51">[00:41:51]</a>. However, this has proven to be a "total head fake," as the ability to adapt and provide a superior user experience is more critical <a class="yt-timestamp" data-t="00:41:59">[00:41:59]</a>.

## Infrastructure and Model Specialization

The application layer is often considered more interesting than infrastructure due to the ability to charge for utility rather than just cost-plus <a class="yt-timestamp" data-t="00:43:33">[00:43:33]</a>. While there are interesting infrastructure plays, especially those related to model integration (e.g., code execution, memory, search, cybersecurity), companies focusing solely on serving models face a capital-intensive business model <a class="yt-timestamp" data-t="00:44:51">[00:44:51]</a>.

It is questioned whether new model companies are still viable, as the larger players like Google and OpenAI are moving more into the product space <a class="yt-timestamp" data-t="00:18:07">[00:18:07]</a>. The trend has shown that general-purpose models tend to outperform hyper-specific models in quality <a class="yt-timestamp" data-t="00:19:18">[00:19:18]</a>. For example, a specialized Bloomberg GPT model was ultimately surpassed by general OpenAI models <a class="yt-timestamp" data-t="00:19:42">[00:19:42]</a>. However, the data pipelines and teams assembled for such specialized models remain valuable <a class="yt-timestamp" data-t="00:20:12">[00:20:12]</a>.

The shift towards [[enterprise_adoption_and_use_cases_for_ai | enterprise use cases and model specialization]] is observed, particularly in areas like robotics, biology, and material science, where unique datasets are crucial <a class="yt-timestamp" data-t="00:17:34">[00:17:34]</a>. The general LLM agent space remains highly competitive with tech giants <a class="yt-timestamp" data-t="00:18:02">[00:18:02]</a>.

## Overhyped vs. Underhyped

### Overhyped
*   **Agent frameworks**: The proliferation of agent frameworks is seen as overhyped, as the underlying workloads are in such flux that it's difficult to build stable frameworks <a class="yt-timestamp" data-t="00:10:43">[00:10:43]</a>. The current stage is compared to the "jQuery era" of single-file, big frameworks, while a "React" equivalent for AI is still needed <a class="yt-timestamp" data-t="00:11:25">[00:11:25]</a>.
*   **New model training companies**: There is skepticism about the need for many new companies focused solely on training models, especially given the dominance of large players aiming for AGI <a class="yt-timestamp" data-t="00:16:16">[00:16:16]</a>.

### Underhyped
*   **Memory / Stateful AI**: The ability for AI agents to maintain memory beyond simple conversation history, such as storing knowledge graphs, is underhyped <a class="yt-timestamp" data-t="00:14:03">[00:14:03]</a>. This is a hard problem but crucial for smarter, learning agents <a class="yt-timestamp" data-t="00:14:42">[00:14:42]</a>.
*   **Apple's Private Cloud Compute (PCC)**: This technology, which extends on-device security to the cloud, is considered under the radar but has significant potential for secure multi-tenant AI environments where GPUs are scarce <a class="yt-timestamp" data-t="00:12:45">[00:12:45]</a>. This addresses the need for single-tenant guarantees in multi-tenant environments <a class="yt-timestamp" data-t="00:13:55">[00:13:55]</a>.
*   **AI for DevOps (AISR)**: While currently limited by technology, the potential for AI to significantly improve mean time to resolution (MTR) in operations is an interesting opportunity <a class="yt-timestamp" data-t="00:48:50">[00:48:50]</a>.
*   **Agent authentication**: The emerging need for agents to authenticate themselves when accessing websites or services on behalf of a user is a crucial, yet under-discussed, problem that requires a new form of "SSO for agents" <a class="yt-timestamp" data-t="00:54:41">[00:54:41]</a>.

## Unanswered Questions with Broad Implications

*   **Scalability of RL to non-verifiable domains**: The biggest unanswered question is whether Reinforcement Learning (RL) can be successfully applied to domains where outcomes are not easily verifiable, such as law (contracts) or marketing/sales (simulating conversations) <a class="yt-timestamp" data-t="00:50:15">[00:50:15]</a>. If not, agents may remain confined to verifiable domains, while co-pilots will be needed in non-verifiable ones where human "taste makers" are still essential <a class="yt-timestamp" data-t="00:50:46">[00:50:46]</a>. This could lead to a "weird future" where AI excels in coding and math but struggles with basic sales emails <a class="yt-timestamp" data-t="00:51:00">[00:51:00]</a>.
*   **Hardware scaling and competition**: How the industry will scale compute given the "rule of nines" (an order of magnitude increase in compute for each jump in reliability, e.g., 90% to 99%) <a class="yt-timestamp" data-t="00:51:34">[00:51:34]</a>. The continued dominance of Nvidia and the potential for competitors like AWS, AMD, Microsoft, and Facebook to offer viable alternatives are key <a class="yt-timestamp" data-t="00:52:00">[00:52:00]</a>. The general-purpose nature of GPUs has allowed Nvidia to remain dominant, but if transformer architecture remains stable, specialized ASICs could emerge <a class="yt-timestamp" data-t="00:53:57">[00:53:57]</a>.