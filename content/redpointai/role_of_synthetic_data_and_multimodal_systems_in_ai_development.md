---
title: Role of Synthetic Data and Multimodal Systems in AI Development
videoId: NLFboNNKCME
---

From: [[redpointai]] <br/> 

## Synthetic Data in AI

The success of [[role_of_data_labeling_and_synthetic_data_in_ai | synthetic data]] has been somewhat unexpected in the AI field <a class="yt-timestamp" data-t="00:30:45">[00:30:45]</a>. It addresses concerns about running out of tokens for training large language models <a class="yt-timestamp" data-t="00:32:38">[00:32:38]</a>. Society produces vast amounts of data daily <a class="yt-timestamp" data-t="00:33:07">[00:33:07]</a>, and while not all of it is high quality, it can still be learned from, albeit requiring more quantity for lower quality data <a class="yt-timestamp" data-t="00:33:20">[00:33:20]</a>.

A paper suggesting that [[role_of_data_labeling_and_synthetic_data_in_ai | synthetic data]] cannot be used to train language models on their own data is considered flawed and based on unrealistic scenarios <a class="yt-timestamp" data-t="00:34:46">[00:34:46]</a>. When implemented correctly, [[role_of_data_labeling_and_synthetic_data_in_ai | synthetic data]] is highly powerful <a class="yt-timestamp" data-t="00:35:17">[00:35:17]</a>. Combining [[role_of_data_labeling_and_synthetic_data_in_ai | synthetic data]] with smarter algorithms like KTO (Kahneman-Tversky Optimization) and APO (Anchored Preference Optimization) can significantly reduce the need for manual data annotation and heavy computational resources <a class="yt-timestamp" data-t="00:35:20">[00:35:20]</a>.

Furthermore, the concept of [[role_of_data_labeling_and_synthetic_data_in_ai | synthetic data]] is inherently linked to [[developers_approach_to_ai_models_and_agents | agents]], as one agent might train another <a class="yt-timestamp" data-t="00:43:33">[00:43:33]</a>.

## Multimodal Systems in AI Development

Early in his career, the speaker focused on grounding language in perceptual information, which laid the foundation for [[applications_and_implications_of_multimodal_ai_models | multimodal systems]] <a class="yt-timestamp" data-t="00:09:35">[00:09:35]</a>. An example of this is trying to understand the meaning of a word like "cat" more deeply by integrating pictures of cats into machine learning and NLP systems <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>.

The field of [[applications_and_implications_of_multimodal_ai_models | multimodal AI models]] is still in its nascent stages, with much potential yet to be explored <a class="yt-timestamp" data-t="00:33:52">[00:33:52]</a>. Video data, for instance, offers a massive untapped resource for training <a class="yt-timestamp" data-t="00:33:56">[00:33:56]</a>. By training on extensive video content, such as cat videos, [[applications_and_implications_of_multimodal_ai_models | multimodal AI models]] can develop a much better understanding of concepts and the world, moving beyond relying solely on linguistic behaviors (text produced on the internet) as a proxy for observation <a class="yt-timestamp" data-t="00:34:01">[00:34:01]</a>.

[[applications_and_implications_of_multimodal_ai_models | Multimodality]] is considered a significant way to incorporate even more data into AI training <a class="yt-timestamp" data-t="00:34:38">[00:34:38]</a>. The speaker anticipates that [[applications_and_implications_of_multimodal_ai_models | multi-agent systems]], which are related to this [[ai_inference_and_compound_ai_systems | systems]] approach, will be the next major trend in AI <a class="yt-timestamp" data-t="00:40:33">[00:40:33]</a>.