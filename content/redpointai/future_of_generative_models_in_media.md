---
title: Future of generative models in media
videoId: YyEqtw-21Ko
---

From: [[redpointai]] <br/> 

Artificial intelligence (AI) is actively transforming creative tooling across various media, including images, video, and music <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. Scott Belsky, founder of Behance and Chief Product Officer/Chief Strategy Officer at Adobe, emphasizes that the focus in generative AI is shifting from the "next best model" to the controls applied on top of these models <a class="yt-timestamp" data-t="00:02:09">[00:02:09]</a>.

## Adobe's Approach to Generative Media

Adobe's strategy in generative media is centered on three core pillars:
*   **Interfaces** <a class="yt-timestamp" data-t="00:03:00">[00:03:00]</a>
*   **Models** <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>
*   **Data** <a class="yt-timestamp" data-t="00:03:06">[00:03:06]</a>

Adobe's in-house generative models, known as the Firefly family, are trained on licensed content. Adobe offers a compensation program for content contributors and aims to provide indemnification to all customers, ensuring compliance and commercial safety <a class="yt-timestamp" data-t="00:03:10">[00:03:10]</a>.

### Key Initiatives
*   **Product Integration:** Firefly models are integrated into Adobe products like Photoshop <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>.
*   **Third-Party Access:** Models are increasingly available to third parties and large companies for complex, at-scale workflows <a class="yt-timestamp" data-t="00:03:42">[00:03:42]</a>.
*   **Enhanced Controls:** Development of control capabilities such as structure reference and Style Match <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>.
*   **Custom Models:** Focus on enabling customers to unleash custom models, for instance, Nickelodeon training Firefly on SpongeBob SquarePants for ideation and character development without intellectual property concerns <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>.
*   **LLM Partnerships:** Adobe partners for Large Language Models (LLMs) used in products like Acrobat, AI Assistant, and digital experience products for marketing analytics <a class="yt-timestamp" data-t="00:04:27">[00:04:27]</a>.

One notable example of combining features was the unexpected use of Project Neo (a 3D illustration program) with Adobe Firefly for extreme precision in image generation. This demonstrated how users can discover new workflows not initially anticipated by developers <a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a>.

## User Experience and the Role of Taste

Generative AI tools enable creative professionals to explore a far wider range of possibilities much more quickly <a class="yt-timestamp" data-t="00:06:31">[00:06:31]</a>. For instance, Generative Recolor in Illustrator allows for instantly applying hundreds or thousands of color palettes to vector creations, a process that used to take days <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>.

The challenge of the "blank canvas problem" in AI tools is addressed by focusing on user education <a class="yt-timestamp" data-t="00:07:24">[00:07:24]</a>. Just as photography evolved into an art form through choices of capture, lens, and lighting, generative AI elevates the importance of "taste" and vision in selecting and refining outputs <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>. Adobe's goal is to empower users to flex their taste through prompt augmentation, onboarding experiences, and tools that translate their mind's eye vision into better outcomes <a class="yt-timestamp" data-t="00:09:10">[00:09:10]</a>.

## The Model Landscape

The future of generative models likely involves not a single dominant model, but rather thousands of models, many of which will become commodities or focus on very niche use cases, tuned for specific data and reasons <a class="yt-timestamp" data-t="00:09:56">[00:09:56]</a>. Adobe's tools aim to allow users to choose different models for different purposes <a class="yt-timestamp" data-t="00:10:17">[00:10:18]</a>.

For example, models trained on other content might be acceptable for ideation and mood boards, where commercial use is not the primary purpose, while commercially safe models trained on licensed data are essential for final outputs <a class="yt-timestamp" data-t="00:10:23">[00:10:23]</a>.

Adobe's strategy to build its own models is reserved for areas where they believe they can deliver a superior end-to-end experience due to their world expertise, leveraging fine-tune controls, custom model capabilities, and proprietary data on user behavior within their tools <a class="yt-timestamp" data-t="00:11:33">[00:11:33]</a>. For commoditized areas or those where other companies will always invest more, Adobe opts for partnerships <a class="yt-timestamp" data-t="00:12:41">[00:12:41]</a>.

## [[Future Directions for Video Models | Future of Video Models]]

The development of video models, while promising, faces high expectations for "professional grade" and "commercial grade" media creation <a class="yt-timestamp" data-t="00:14:17">[00:14:17]</a>. While many startups claim to have video models, the bar for quality is very high, and the difference between "cool happy path demos" and "pragmatic everyday commercially viable quality use cases" is significant, similar to the long journey of self-driving cars <a class="yt-timestamp" data-t="00:14:39">[00:14:39]</a>.

> "The demos are great and then you prompt it yourself and you're like that didn't quite look like the demo." <a class="yt-timestamp" data-t="00:15:14">[00:15:14]</a>

Meaningful milestones for video models include pragmatic solutions like extending a scene by a few seconds in professional editing software like Premiere Pro, which could save immense time and resources compared to re-shooting <a class="yt-timestamp" data-t="00:15:28">[00:15:28]</a>. Generative aerial footage or 4K b-roll might be further off <a class="yt-timestamp" data-t="00:16:10">[00:16:10]</a>.

## Market Opportunities and Hyper-Personalization

In the [[generative_ai_for_business_applications | creative and marketing space]], differentiation lies at the interface and data levels, as models may become commoditized <a class="yt-timestamp" data-t="00:16:59">[00:16:59]</a>. The industry is moving towards hyper-personalized digital experiences at scale <a class="yt-timestamp" data-t="00:17:22">[00:17:22]</a>. This requires:
*   Customer data platforms <a class="yt-timestamp" data-t="00:17:45">[00:17:45]</a>
*   Workflows for deploying, measuring, and optimizing campaigns <a class="yt-timestamp" data-t="00:17:53">[00:17:53]</a>
*   Creative stacks connected with guardrails and "brand check AI" to prevent inappropriate content <a class="yt-timestamp" data-t="00:18:00">[00:18:00]</a>

This shift creates opportunities for startups to innovate in areas previously cumbersome, such as enabling small businesses to operate with the capabilities of large enterprises <a class="yt-timestamp" data-t="00:18:49">[00:18:49]</a>. It also opens doors in antiquated industries like law and government <a class="yt-timestamp" data-t="00:19:29">[00:19:29]</a>.

## Societal Implications of Hyper-Personalization

The future promises an inundation of hyper-personalized content from brands <a class="yt-timestamp" data-t="00:20:18">[00:20:18]</a>. As content becomes free to generate and highly varied, there will be a counter-craving for scarcity, meaning, and craft in digital experiences <a class="yt-timestamp" data-t="00:20:50">[00:20:50]</a>. This could "reboot the role of humans in content creation" <a class="yt-timestamp" data-t="00:21:58">[00:21:58]</a>. Shared social experiences, like discussing entertainment, are expected to remain important and not be replaced by personalized versions <a class="yt-timestamp" data-t="00:22:06">[00:22:06]</a>.

## [[Future possibilities and visions for AI and music collaboration | Music and Generative AI]]

In music, while AI can lower the barrier for participation, the human story behind a song remains crucial for resonance and driving value <a class="yt-timestamp" data-t="00:22:27">[00:22:27]</a>. AI tools should enable both music generation and the telling of compelling human stories to foster a relationship between artist and consumer <a class="yt-timestamp" data-t="00:22:56">[00:22:56]</a>.

## Future Capabilities and Business Models

The next tier of generative AI capabilities involves:
*   **Proactive Suggestions:** AI agents suggesting actions or explorations users didn't know they needed, for instance, warning against poor performance in a specific demographic or suggesting variations <a class="yt-timestamp" data-t="00:24:28">[00:24:28]</a>.
*   **Increased Speed and Quality:** Continuous improvements in output speed and quality <a class="yt-timestamp" data-t="00:24:56">[00:24:56]</a>.
*   **UI on Demand:** A future where models not only generate content but also provide custom user interfaces to fine-tune the output, appearing and disappearing as needed for specific use cases <a class="yt-timestamp" data-t="00:13:17">[00:13:17]</a>.

Adobe's business model incorporates "generative credits" with existing plans, allowing for tiered upgrades based on usage intensity <a class="yt-timestamp" data-t="00:25:57">[00:25:57]</a>. This model allows for flexibility in pricing more intensive capabilities (like generative video) while aiming to keep access as cheap and accessible as possible to make AI a ubiquitous part of everyone's workflow <a class="yt-timestamp" data-t="00:27:10">[00:27:10]</a>. It's anticipated that soon, everything created will incorporate some degree of generative AI <a class="yt-timestamp" data-t="00:27:33">[00:27:33]</a>.

### Unexpected Learnings
*   **Defaults are Key:** Making AI features like "generative fill" a default in Photoshop significantly increased utilization, highlighting the importance of intuitive integration rather than hiding new features <a class="yt-timestamp" data-t="00:28:16">[00:28:16]</a>.
*   **Model Proliferation:** Initial expectations of only a few dominant models have changed; it's now believed there will be thousands of models, many operating "on the edge" and focusing on cost-efficiency as capabilities advance rapidly beyond everyday use cases <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>.

Scott Belsky remains excited about [[the_role_of_generative_ai_in_preserving_memories | personalization]] and the potential for AI to scale intimate experiences (like a personal driver or being "known" at a restaurant) to everyone <a class="yt-timestamp" data-t="00:32:30">[00:32:30]</a>. This represents an opportunity for startups to build businesses around capabilities previously accessible only to a select few <a class="yt-timestamp" data-t="00:33:38">[00:33:38]</a>.