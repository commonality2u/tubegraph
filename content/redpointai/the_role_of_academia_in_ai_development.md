---
title: The role of academia in AI development
videoId: ZEi4OTuFa3I
---

From: [[redpointai]] <br/> 

Percy Liang, a leading AI researcher and co-founder of Together AI, provides insights into the evolving role of academia in the field of [[challenges_and_opportunities_in_ai_development | AI development]] <a class="yt-timestamp" data-t="00:00:03">[00:00:03]</a>. He highlights how academic institutions, such as Stanford where he is based <a class="yt-timestamp" data-t="00:10:13">[00:10:13]</a>, must adapt their research strategies to remain relevant amidst the rapid advancements from large commercial labs.

## Academia's Unique Position
Academia faces a unique challenge as powerful models like OpenAI's O1 (GPT-4o) and GPT-5 emerge, possessing significantly more resources than academic institutions <a class="yt-timestamp" data-t="00:10:38">[00:10:38]</a>. Liang emphasizes that directly competing with these entities "head and head" is pointless <a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>. Instead, academia should play a different, complementary role <a class="yt-timestamp" data-t="00:10:55">[00:10:55]</a>.

### Orthogonal Research Strategies
For academic research to thrive, it must be "orthogonal" to the progress made by large model developers <a class="yt-timestamp" data-t="00:11:02">[00:11:02]</a>. This means selecting research projects that are either:
*   **Enhanced by better models:** If models like GPT-4 or GPT-5 improve, the academic research should benefit. For example, Liang's work on [[role_of_ai_in_general_intelligence_and_application_development | generative agents]], which creates virtual worlds where AI agents interact, is enhanced by more capable language models <a class="yt-timestamp" data-t="00:11:21">[00:11:21]</a>. The goal is not the raw language model, but novel use cases built upon them <a class="yt-timestamp" data-t="00:11:40">[00:11:40]</a>.
*   **Irrelevant to model advancements:** The core contribution of the research should not be directly superseded by new model releases <a class="yt-timestamp" data-t="00:11:16">[00:11:16]</a>.

This approach is similar to that taken by startups in the AI space, which benefit from, rather than compete against, foundational model advancements <a class="yt-timestamp" data-t="00:14:33">[00:14:33]</a>.

### Emphasis on Open Science and Open Source
A crucial role for academia is contributing to the [[impact_of_open_source_models_in_ai_development | open source models in AI development]] <a class="yt-timestamp" data-t="00:12:06">[00:12:06]</a>. Academia is inherently about "open science" and creating knowledge for the public domain <a class="yt-timestamp" data-t="00:12:15">[00:12:15]</a>. Unlike commercial labs, which may keep knowledge proprietary, academia can discover or even reinvent concepts and publish them <a class="yt-timestamp" data-t="00:12:31">[00:12:31]</a>. This fosters a broader community adoption, leading to new models and products <a class="yt-timestamp" data-t="00:12:40">[00:12:40]</a>. Examples include understanding data quality in pre-training or how to weight data <a class="yt-timestamp" data-t="00:12:55">[00:12:55]</a>.

### Role in Transparency, Benchmarking, and Auditing
Academia holds a unique position to conduct impartial assessments of AI systems due to its lack of commercial interests <a class="yt-timestamp" data-t="00:13:30">[00:13:30]</a>. This includes:
*   **Benchmarking:** Developing and maintaining benchmarks to assess AI capabilities <a class="yt-timestamp" data-t="00:13:27">[00:13:27]</a>. An example is Sidebench, a Capture the Flag cyber security exercise, which includes challenges human competitors take over 24 hours to solve <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a>. These benchmarks can reveal subtleties in model performance and system compatibility <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>. Liang also notes the evolution of evaluation, including using language models to benchmark other language models, and developing rubrics for more objective assessments <a class="yt-timestamp" data-t="00:31:24">[00:31:24]</a>. The Helm (Holistic Evaluation of Language Models) framework has evolved to cover various aspects and verticals, including safety, language, medical, and finance evaluations <a class="yt-timestamp" data-t="00:34:42">[00:34:42]</a>.
*   **Transparency and Auditing:** Projects that assess the transparency of different AI providers <a class="yt-timestamp" data-t="00:13:52">[00:13:52]</a>. Liang advocates for regulation that emphasizes transparency and disclosure, akin to nutrition labels for food, to help policymakers and third-party auditors understand the risks and benefits of AI <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>. He believes that regulating "downstream" (end-products) is often more effective, with "upstream" (foundation model developers) providing transparency and obligations for downstream decision-makers <a class="yt-timestamp" data-t="00:20:59">[00:20:59]</a>.
*   **Interpretability:** Research into understanding *why* AI models make certain decisions, which is crucial for regulated industries like finance and healthcare <a class="yt-timestamp" data-t="00:35:56">[00:35:56]</a>. Liang notes that access to model weights and training data, which is often withheld by commercial labs, is essential for interpretability research <a class="yt-timestamp" data-t="00:39:47">[00:39:47]</a>.

## Challenges and Future Directions
Despite the unique advantages, academia faces challenges, particularly the lack of direct access to proprietary model weights and training data, which hinders research into interpretability <a class="yt-timestamp" data-t="00:36:28">[00:36:28]</a>. This makes it difficult to debug or deeply understand model behavior.

Looking ahead, Liang sees significant opportunities for academia in:
*   **Scientific Discovery:** Utilizing AI for [[challenges_in_using_ai_for_research_advancements | research advancements]] and fundamental scientific discovery, such as solving open math problems or creating new research that extends human knowledge <a class="yt-timestamp" data-t="00:48:22">[00:48:22]</a>.
*   **Productivity Tools:** Developing AI tools that improve researcher productivity <a class="yt-timestamp" data-t="00:59:26">[00:59:26]</a>.
*   **Exploring Underexplored Applications:** Moving beyond commercial needs like RAG solutions and summarization to address more "fundamental science" applications <a class="yt-timestamp" data-t="00:59:18">[00:59:18]</a>.
*   **New Architectures:** While current models like Transformers are dominant, new architectures may emerge from tackling different problem types, such as video generation or more complex agentic settings <a class="yt-timestamp" data-t="00:42:07">[00:42:07]</a>. For example, the Mamba state space model architecture was inspired by mathematical breakthroughs <a class="yt-timestamp" data-t="00:41:03">[00:41:03]</a>.
*   **Robotics:** While a "ChatGPT moment" for robotics is still a few years away, the progress in language and vision models can provide infrastructure and inspiration for [[role_of_ai_models_in_advancing_robotics and_autonomous_driving | AI models in advancing robotics and autonomous driving]], especially by factoring out language and vision problems from purely robotic ones <a class="yt-timestamp" data-t="00:52:02">[00:52:02]</a>.
*   **Creative Augmentation:** Developing AI as a "co-pilot" for creative endeavors, such as music composition, allowing artists to realize their visions without needing extensive traditional skills <a class="yt-timestamp" data-t="00:54:35">[00:54:35]</a>.
*   **Education:** Leveraging AI as extremely good teachers and coaches, capable of breaking down complicated concepts into simple terms for diverse audiences <a class="yt-timestamp" data-t="00:56:20">[00:56:20]</a>.

Liang suggests that while AI capabilities are still rapidly advancing, qualitative changes are occurring, such as O1's approach to "test time compute," which represents a different way of using these systems <a class="yt-timestamp" data-t="00:49:50">[00:49:50]</a>. He remains optimistic that AI agents will contribute novel insights into ML work in the coming years, similar to how AI has expanded the capabilities of software developers <a class="yt-timestamp" data-t="00:58:33">[00:58:33]</a>.