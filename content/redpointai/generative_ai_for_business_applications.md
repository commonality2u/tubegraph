---
title: Generative AI for business applications
videoId: FudGqDZDSx4
---

From: [[redpointai]] <br/> 

Haen, an AI video platform, has recently raised $60 million at a $500 million valuation from investors including Benchmark and Thrive, highlighting the growing interest in [[enterprise_applications_for_ai_including_business_intelligence_and_data_extraction | AI video tools for enterprises]] <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>. The company's CEO, Joshua Xu, shared insights on how enterprises are leveraging AI video tools today, addressing security guidelines for voice cloning, the dilemma platforms like TikTok face with AI-generated content, and future product expansion <a class="yt-timestamp" data-t="00:00:11">[00:00:11]</a>.

## The "Magic Moment" of Generative AI

Haen aims to disrupt traditional content creation by building an "AI experience" that feels magical <a class="yt-timestamp" data-t="00:01:22">[00:01:22]</a>. A notable "magic moment" occurred when Haen's video translation and dubbing technology was used to translate the speech of the president of Argentina at the World Economic Forum into different languages, gaining viral attention <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>. For Joshua, his first personal "magic moment" was creating his own avatar and watching it speak <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>. He now uses his avatar to generate internal product update videos, simplifying communication <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>.

## Current and Future State of AI for Creative Tools

Haen's platform enables users to create, localize, and personalize video content <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a>. Historically, video production involved filming with a camera and then editing the footage <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a>. With [[generative_ai_and_adobes_firefly_suite | generative AI]], it is now possible to generate footage directly using AI, effectively replacing the need for a camera <a class="yt-timestamp" data-t="00:04:36">[00:04:36]</a>. Haen's initial mission was to replace the camera, making video creation 10 times faster and 10 times cheaper for businesses and individuals who lack access to expensive equipment or are uncomfortable on camera <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.

The evolution of video editing is also anticipated; traditional timeline editors, which exist due to the high cost of cameras requiring multiple takes, may become obsolete <a class="yt-timestamp" data-t="00:06:04">[00:06:04]</a>. In the future, editing could involve generating video from text, combining scriptwriting with intuitive 2D canvas navigation <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>.

## Building High-Quality AI Avatars

The primary focus for Haen is on AI quality, ensuring generated footage can replace traditional camera processes <a class="yt-timestamp" data-t="00:07:50">[00:07:50]</a>. Quality encompasses various aspects beyond mathematical models, including:
*   Lighting of the footage <a class="yt-timestamp" data-t="00:08:27">[00:08:27]</a>
*   Realism and expressions of the person <a class="yt-timestamp" data-t="00:08:30">[00:08:30]</a>
*   Body motion and gestures matching the script <a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a>

Haen's dedicated research team builds all avatar models in-house, focusing on lip-syncing, body motion, and full-body rendering <a class="yt-timestamp" data-t="00:15:11">[00:15:11]</a>. Their AI 3.0 model renders the entire body <a class="yt-timestamp" data-t="00:15:28">[00:15:28]</a>. Training good avatar models involves observing extensive talking video data, similar to how a human learns, and continuously improving model architecture to capture nuanced dimensions <a class="yt-timestamp" data-t="00:15:53">[00:15:53]</a>.

To create a personalized "video avatar," users submit 30 seconds to 2 minutes of footage, allowing the AI model to learn their unique talking style, including mouth movements, gestures, and facial expressions <a class="yt-timestamp" data-t="00:17:04">[00:17:04]</a>. Future developments aim to capture different "modes" (e.g., presentation mode, interview mode) and adapt avatar behavior based on the script or content <a class="yt-timestamp" data-t="00:17:40">[00:17:40]</a>.

## Haen's Business Use Cases

With over 40,000 customers, Haen's platform is primarily used for three key applications <a class="yt-timestamp" data-t="00:09:37">[00:09:37]</a>:
1.  **Create:** Users can create videos using their own avatar or stock avatars by simply typing text, eliminating the need for a camera <a class="yt-timestamp" data-t="00:09:48">[00:09:48]</a>.
2.  **Localize:** Existing videos (even non-Haen ones) can be localized into over 175 different languages and dialects, maintaining voice tone, facial expression, and lip-sync <a class="yt-timestamp" data-t="00:10:01">[00:10:01]</a>. This was exemplified by the viral dubbing of the Argentine president's speech <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>.
3.  **Personalize:** A single video can be personalized into more than 100,000 variations, tailoring messaging based on the specific customer, industry, or problem <a class="yt-timestamp" data-t="00:10:19">[00:10:19]</a>.

Haen is designed for the "non-professional player" â€“ the 99% of users who are not professional video editors <a class="yt-timestamp" data-t="00:11:18">[00:11:18]</a>. This includes marketers, content creators, and those in sales, support, customer success, and training, who write scripts but may lack the skills or tools to produce videos <a class="yt-timestamp" data-t="00:11:29">[00:11:29]</a>. The mission is to enable visual storytelling for everyone, especially those without expensive cameras or complex software <a class="yt-timestamp" data-t="00:11:40">[00:11:40]</a>. A key challenge is educating users on this new way of creating video and demonstrating its diverse applications across different verticals <a class="yt-timestamp" data-t="00:12:00">[00:12:00]</a>.

## Future of AI Video Technology

### Synchronous Generation and Streaming
Haen has a beta version of "interactive avatars" that can attend Zoom meetings and interact in real-time <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>. The main technical challenge for synchronous generation is optimizing inference speed as models become larger and more complex <a class="yt-timestamp" data-t="00:19:42">[00:19:42]</a>. Joshua is optimistic that real-time AI video technology will be available within 12 months, possibly even running on devices <a class="yt-timestamp" data-t="00:20:46">[00:20:46]</a>. This could unlock new use cases, such as personalized video advertisements tailored to individual user preferences and watch history <a class="yt-timestamp" data-t="00:20:17">[00:20:17]</a>.

### Full Body Movement
The importance of full-body rendering and gestures for engaging human presenters is a key focus <a class="yt-timestamp" data-t="00:21:10">[00:21:10]</a>. Haen's 3.0 avatar version offers full-body rendering, with gesture integration as the next step <a class="yt-timestamp" data-t="00:21:32">[00:21:32]</a>. Challenges include a lack of sufficient data and finding the right model architecture to capture complex body movements <a class="yt-timestamp" data-t="00:21:50">[00:21:50]</a>.

### Intersection with Text-to-Video Models
Haen primarily focuses on business videos, prioritizing control, consistency, and quality <a class="yt-timestamp" data-t="00:22:30">[00:22:30]</a>. While some text-to-video technologies generate video pixel by pixel, Haen believes in an orchestration engine approach <a class="yt-timestamp" data-t="00:22:50">[00:22:50]</a>. This involves combining text, script, voice, sound, music, avatar footage, and background generation to deliver a more controlled and consistent output for businesses <a class="yt-timestamp" data-t="00:23:00">[00:23:00]</a>. Haen plans to work closely with text-to-video partners, integrating their capabilities as building blocks within Haen's broader orchestration engine <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a>.

### Brand Personalization
A significant future area for video is brand personalization, allowing AI to learn a company's brand tone, context, history, and product details from prompts or existing content <a class="yt-timestamp" data-t="00:25:03">[00:25:03]</a>. The AI model could learn color palettes, styles, and common video elements (like opening clips) by analyzing past company videos or URLs, then bake these elements into newly generated videos <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>. This involves disassembling video into components and reassembling them with brand-specific elements, similar to how large language models use a context window <a class="yt-timestamp" data-t="00:25:32">[00:25:32]</a>.

## Impact of AI Advancements on Business Models

[[impact_of_ai_advancements_on_business_models | AI's impact on business models]] is evident in the shift from traditional software companies, where marginal cost is near zero, to AI companies, where GPU consumption incurs significant marginal costs <a class="yt-timestamp" data-t="00:37:50">[00:37:50]</a>. However, AI also increases the efficiency of individual employees <a class="yt-timestamp" data-t="00:38:24">[00:38:24]</a>. The growth trajectory of AI companies is "insane," as exemplified by ChatGPT reaching 100 million users extremely fast <a class="yt-timestamp" data-t="00:39:10">[00:39:10]</a>. Surprisingly, building a great AI company may require less capital than anticipated due to accelerated go-to-market strategies and efficiency gains <a class="yt-timestamp" data-t="00:39:36">[00:39:36]</a>. Haen proactively designs products based on anticipated model capabilities and costs 12 months in advance <a class="yt-timestamp" data-t="00:40:51">[00:40:51]</a>.

### Competition with Incumbents
Haen's strategy is to build for a new market of users (content people) who don't have access to cameras or sophisticated editing tools, rather than directly competing with platforms like Snap or TikTok that cater to professional video editors <a class="yt-timestamp" data-t="00:28:02">[00:28:02]</a>. These incumbents, focused on mobile camera-based content and creators, will face a dilemma as AI-generated content becomes more prevalent <a class="yt-timestamp" data-t="00:29:12">[00:29:12]</a>. If AI-generated content grows to 50% of platform content, existing human creators might see significantly reduced views, potentially leading to the emergence of new platforms specifically for AI-generated content <a class="yt-timestamp" data-t="00:30:15">[00:30:15]</a>.

### Enterprise Adoption and Integration
For [[enterprise_applications_for_ai_including_business_intelligence_and_data_extraction | enterprise customers]], quality requirements are much higher, especially concerning brand consistency <a class="yt-timestamp" data-t="00:31:41">[00:31:41]</a>. Integration into existing workflows is crucial <a class="yt-timestamp" data-t="00:32:07">[00:32:07]</a>. For marketing use cases, integration with CRMs and go-to-market tools is vital, as demonstrated by Haen's partnership and app integration with HubSpot <a class="yt-timestamp" data-t="00:32:25">[00:32:25]</a>.

## Data Privacy and Ethical Considerations in Generative AI

[[data_privacy_and_ethical_considerations_in_generative_ai | Trust and safety]] are critical for Haen's business, especially when serving large enterprise customers <a class="yt-timestamp" data-t="00:33:45">[00:33:45]</a>. Key measures include:
*   **Avatar Creation:** Requires a video consent format to ensure the person creating the avatar is the same as in the footage <a class="yt-timestamp" data-t="00:34:11">[00:34:11]</a>. Dynamic generated passwords with short expiry times (10-15 seconds) add a secure layer to prevent unauthorized avatar creation <a class="yt-timestamp" data-t="00:34:25">[00:34:25]</a>.
*   **Content Moderation:** A hybrid approach using AI models and a human moderation team reviews all content to ensure compliance with policies against hate speech, misinformation, fraud, and political campaigns <a class="yt-timestamp" data-t="00:35:01">[00:35:01]</a>.

Haen also engages in partnerships with existing actors to create stock avatars <a class="yt-timestamp" data-t="00:35:49">[00:35:49]</a>. The ability to generate new voices and persons through AI could lead to the creation of future intellectual property (IP), particularly with models that persist consistency across different generations, opening possibilities for "AI influencers" <a class="yt-timestamp" data-t="00:36:10">[00:36:10]</a>.

## The Future of Video Creation Workflows

By 2030, Joshua envisions a world where "everyone will have their video agency on their pocket" <a class="yt-timestamp" data-t="00:48:30">[00:48:30]</a>. This means interacting with products like Haen as if talking to a personal video agency, from ideation to filming (generating footage), editing, and iterative feedback <a class="yt-timestamp" data-t="00:47:56">[00:47:56]</a>. AI will enable faster and cheaper generation of any text, audio, or video content <a class="yt-timestamp" data-t="00:49:16">[00:49:16]</a>. The true power of creative tools lies in their ability to lower creation barriers, which will unlock entirely new use cases, similar to how mobile cameras led to platforms like Instagram, Snapchat, and TikTok <a class="yt-timestamp" data-t="00:49:52">[00:49:52]</a>.