---
title: Future of AI agents in software development
videoId: n6PazYmo_Qo
---

From: [[redpointai]] <br/> 

Omj, founder of Replit, is notably bullish on the [[the_future_and_current_state_of_ai_agents | future of AI agents]] and their role in software development <a class="yt-timestamp" data-t="00:00:23">[00:00:23]</a>. While the overall [[impact_of_ai_on_software_engineering | impact of AI on software engineering]] is rapid, Omj expresses surprise at how slow the integration of AI has been into everyday technology compared to his expectations <a class="yt-timestamp" data-t="00:24:41">[00:24:41]</a>.

## Current State and Capabilities
Currently, AI models like GPT-4 exhibit some agentic capabilities, sometimes accidentally <a class="yt-timestamp" data-t="00:41:03">[00:41:03]</a>. The real power of Large Language Models (LLMs) lies in interpolating different data distributions <a class="yt-timestamp" data-t="00:11:53">[00:11:53]</a>. This means they can perform tasks like writing a rap song in Shakespeare's style <a class="yt-timestamp" data-t="00:11:58">[00:11:58]</a>, and by chaining these models, a complete AI-generated piece of art can be created <a class="yt-timestamp" data-t="00:12:25">[00:12:25]</a>.

However, the efficacy of agents, especially complex ones, still needs significant improvement <a class="yt-timestamp" data-t="00:40:43">[00:40:43]</a>. Background agentic workflows are currently expensive with models like GPT-4, making them cost-prohibitive for most consumers and developers <a class="yt-timestamp" data-t="00:40:30">[00:40:30]</a>.

## Replit's Approach to AI Agents
Replit conducts research projects on how to train more effective agentic models <a class="yt-timestamp" data-t="00:40:55">[00:40:55]</a>. While Replit focuses on delivering value to its customers, they are willing to engage in research and training if it's necessary <a class="yt-timestamp" data-t="00:56:18">[00:56:18]</a>. The company aims to be an "applied AI company" <a class="yt-timestamp" data-t="00:56:18">[00:56:18]</a>.

Omj believes that entrepreneurs looking to build with agents shouldn't wait for "AI Gods" to drop APIs <a class="yt-timestamp" data-t="00:48:22">[00:48:22]</a>. Instead, they should try to achieve product-market fit with existing tools, even if it's expensive like using GPT-4 for prototypes <a class="yt-timestamp" data-t="00:48:48">[00:48:48]</a>.

## Future Milestones for AI Agents
Omj outlines several key milestones for the advancement of AI agents:
*   **Reliable Task Execution**: Agents should be able to follow a bulleted list of actions without going "off the rails" or requiring "insane amounts of Chain of Thought and recursive debugging" <a class="yt-timestamp" data-t="00:49:38">[00:49:38]</a>.
*   **Dependable Function Calls**: Commercial models need a non-hacky and dependable way to perform function calls. Currently, while they work in 90% of cases, the 10% catastrophic failures make them unreliable for critical financial or legal workflows <a class="yt-timestamp" data-t="00:50:05">[00:50:05]</a>.
*   **High Pull Request Acceptance Rate**: For tasks like converting issues to pull requests (as seen with startups like Sweep.dev), an acceptance rate of 80% or 90% would indicate significant improvement in agent capabilities <a class="yt-timestamp" data-t="00:50:50">[00:50:50]</a>.

Omj predicts that some version of agentic workflows will start happening this year <a class="yt-timestamp" data-t="00:48:01">[00:48:01]</a>. He views agents as the "next big thing" beyond multimodal AI, which he sees as an incremental improvement rather than a "ChatGPT moment" <a class="yt-timestamp" data-t="00:46:56">[00:46:56]</a>. The concept of LLMs (Large Language Models) having agent capabilities was somewhat surprising <a class="yt-timestamp" data-t="00:41:19">[00:41:19]</a>, as he initially thought agents would require "action transformers" <a class="yt-timestamp" data-t="00:41:35">[00:41:35]</a> or large action models (LAMs) <a class="yt-timestamp" data-t="00:42:08">[00:42:08]</a>.

## Economic and Strategic Considerations
The cost of inference for AI models, especially for complex or recursive calls, remains a significant factor <a class="yt-timestamp" data-t="00:40:00">[00:40:00]</a>. If AI models were cheap enough to run in the background, like in Continuous Integration/Continuous Deployment (CI/CD) pipelines, it would become extremely expensive <a class="yt-timestamp" data-t="00:46:04">[00:46:04]</a>.

> "I would have expected now we would have some kind of LLMs doing doing things in the background." <a class="yt-timestamp" data-t="00:46:26">[00:46:26]</a>

The increasing affordability of models, such as GPT-3.5's price reduction, is making it more rational for companies not to train their own models for all use cases <a class="yt-timestamp" data-t="00:27:47">[00:27:47]</a>. However, for companies like Replit, building their own models was crucial due to specific latency and cost characteristics desired for integration into a free product <a class="yt-timestamp" data-t="00:28:07">[00:28:07]</a>.

Ultimately, the future of AI agents and their widespread adoption depends on reduced costs and improved reliability, potentially leading to scenarios where agents fix bugs or perform tasks while developers are away <a class="yt-timestamp" data-t="01:07:12">[01:07:12]</a>.