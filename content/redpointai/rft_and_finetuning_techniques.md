---
title: RFT and finetuning techniques
videoId: NNGbaiN1L7Y
---

From: [[redpointai]] <br/> 

## Introduction to Finetuning
[[Pretraining and finetuning AI models | Finetuning]] is a process that allows models to be adapted for specific use cases and user preferences <a class="yt-timestamp" data-t="0:55:00">[00:55:00]</a>. It is considered a great way to please a wider range of users <a class="yt-timestamp" data-t="0:55:00">[00:55:00]</a>.

## Evolution of Finetuning Perception
Initially, some people questioned the helpfulness of [[finetuning_approaches_and_considerations_in_ai | fine-tuning]] <a class="yt-timestamp" data-t="21:22:31">[00:21:22]</a>. However, there has been a "renaissance" for [[finetuning_approaches_and_considerations_in_ai | fine-tuning]] with newer models, demonstrating its actual utility <a class="yt-timestamp" data-t="21:26:55">[00:21:26]</a>. Michelle Prokris, a post-training research lead at OpenAI, noted that she used to be a "fine-tuning bear" but now believes it is worth the time for specific domains where pushing the frontier is necessary <a class="yt-timestamp" data-t="44:10:00">[00:44:10]</a>. This shift is partly due to the fact that the RFT (Reinforcement Finetuning) process is similar to the internal reinforcement learning algorithms OpenAI uses to train its models <a class="yt-timestamp" data-t="44:42:00">[00:44:42]</a>.

## Types of Finetuning
Michelle Prokris categorizes [[finetuning_approaches_and_considerations_in_ai | fine-tuning]] into two main camps:
1.  **Fine-tuning for speed and latency (SFT - Supervised Fine-Tuning)** <a class="yt-timestamp" data-t="21:40:00">[00:21:40]</a>. This is the "workhorse" of OpenAI's SFT offering, allowing models like GPT-4.1 to run at a fraction of their usual latency <a class="yt-timestamp" data-t="21:49:00">[00:21:49]</a>. If a model works well but faster performance is desired, finetuning with SFT (and considering models like Mini and Nano) is recommended <a class="yt-timestamp" data-t="27:39:00">[00:27:39]</a>. It can be used for simpler tasks, such as classifying things where a small percentage of cases are incorrect <a class="yt-timestamp" data-t="24:13:00">[00:24:13]</a>.
2.  **Fine-tuning for frontier capabilities (RFT - Reinforcement Fine-Tuning)** <a class="yt-timestamp" data-t="22:01:00">[00:22:01]</a>.
    *   **Purpose**: RFT allows users to push the frontier in their specific area <a class="yt-timestamp" data-t="22:08:00">[00:22:08]</a>. It is extremely data efficient, potentially requiring only hundreds of samples <a class="yt-timestamp" data-t="22:16:00">[00:22:16]</a> and is less fragile than SFT <a class="yt-timestamp" data-t="23:38:00">[00:23:38]</a>. RFT was scheduled to be generally available (GA) in the week following the podcast recording <a class="yt-timestamp" data-t="22:25:00">[00:22:25]</a>.
    *   **Applications**:
        *   Teaching an agent how to pick a workflow or work through its decision process <a class="yt-timestamp" data-t="22:37:00">[00:22:37]</a>.
        *   Deep tech applications where an organization has unique, verifiable data, leading to the "absolute best results" <a class="yt-timestamp" data-t="22:48:00">[00:22:48]</a>. Examples of such domains include chip design and biology (e.g., drug discovery), where exploration is needed but successes are easily verifiable <a class="yt-timestamp" data-t="24:47:00">[00:24:47]</a>.
    *   **When to use**: RFT should be considered when "no model in the market does what you need" <a class="yt-timestamp" data-t="24:22:00">[00:24:22]</a>.

3.  **Preference Fine-Tuning**: Used primarily for stylistic preferences <a class="yt-timestamp" data-t="24:02:00">[00:24:02]</a>. This was launched somewhat recently <a class="yt-timestamp" data-t="24:07:00">[00:24:07]</a>.

## Strategic Considerations for Companies
For companies using OpenAI's APIs, especially with rapid model releases, the most successful ones are those with strong internal [[ai_evaluations_and_benchmarking | evals]] tailored to their specific use cases <a class="yt-timestamp" data-t="17:57:00">[00:17:57]</a>. They can then quickly run these [[ai_evaluations_and_benchmarking | evals]] on new models when they are released <a class="yt-timestamp" data-t="18:06:00">[00:18:06]</a>. Successful customers also adapt their prompts and scaffolding to particular models <a class="yt-timestamp" data-t="18:15:00">[00:18:15]</a>.

A key recommendation for companies is to "build stuff which is maybe just out of reach of the current models" <a class="yt-timestamp" data-t="18:25:00">[00:18:25]</a>. If a use case works only one out of ten times (10% pass rate) but can be fine-tuned to 50%, it's likely something a future model will "crush" within a few months, making it a good candidate to work on <a class="yt-timestamp" data-t="18:53:00">[00:18:53]</a>. Building scaffolding to make a product work is worthwhile for a few months of "arbitrage" until the capability becomes more easily available natively in future models <a class="yt-timestamp" data-t="19:54:00">[00:19:54]</a>. However, it's crucial to be prepared to change things and keep an eye on future trends like improving context windows, reasoning capabilities, and instruction following <a class="yt-timestamp" data-t="20:16:00">[00:20:16]</a>. Connecting the model to as much information about a task as possible is also beneficial, even if current results are mediocre, as future models will likely improve <a class="yt-timestamp" data-t="21:09:00">[00:21:09]</a>.

## Generalization vs. Specialized Models
OpenAI's general philosophy leans into the "G" in AGI (Artificial General Intelligence), aiming to make one general model rather than purpose-built models for different groups <a class="yt-timestamp" data-t="15:52:00">[00:15:52]</a>. The goal is to simplify the product offering and have one model for both chat and API use cases <a class="yt-timestamp" data-t="16:06:00">[00:16:06]</a>. However, the development of GPT-4.1, which focused on developers, was an exception due to a particularly acute need and the ability to move faster by decoupling from ChatGPT <a class="yt-timestamp" data-t="16:15:00">[00:16:15]</a>. This allowed for specific choices in model training, such as removing ChatGPT-specific datasets and significantly upweighting coding data <a class="yt-timestamp" data-t="16:35:00">[00:16:35]</a>.

Despite this targeted approach, the general trend indicates that combining everything into one model typically produces a much better result <a class="yt-timestamp" data-t="26:05:00">[00:26:05]</a>. For example, learning to use one set of tools makes a model better at using other sets of tools <a class="yt-timestamp" data-t="34:21:00">[00:34:21]</a>. The capabilities of models like GPT-3 already encompass many deep research functions, offering a quicker alternative to specialized deep research agents <a class="yt-timestamp" data-t="34:38:00">[00:34:38]</a>. The future challenge in models like GPT-5 is to combine diverse capabilities, such as being a delightful chitchat partner and knowing when to engage in deep reasoning <a class="yt-timestamp" data-t="37:57:00">[00:37:57]</a>.