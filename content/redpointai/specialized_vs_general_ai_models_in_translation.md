---
title: Specialized vs General AI models in translation
videoId: JW6DiD_V9hk
---

From: [[redpointai]] <br/> 

DeepL, a company valued at $2 billion and supporting over 100,000 businesses worldwide in AI translation, has a distinctive perspective on the role of [[enterprise_use_of_ai_and_model_specialization | specialized models]] versus generalized models in the field of AI translation <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. CEO and founder Yerkoisky emphasizes that while general models capture much attention, the real value is created through [[enterprise_use_of_ai_and_model_specialization | specialized models]] <a class="yt-timestamp" data-t="00:48:52">[00:48:52]</a>.

## DeepL's Approach: Specialization and Vertical Integration

DeepL has been engaged in cutting-edge AI research long before it became mainstream <a class="yt-timestamp" data-t="00:41:43">[00:41:43]</a>. Their approach to building AI models is very much a "build it yourself" philosophy <a class="yt-timestamp" data-t="00:59:56">[00:59:56]</a>, stemming from a time when necessary tooling, models, and data centers were not readily available <a class="yt-timestamp" data-t="01:06:00">[01:06:00]</a>.

This strategy involves:
*   **Specialization on Use Cases**: DeepL specializes in high-value translation use cases for businesses <a class="yt-timestamp" data-t="00:08:34">[00:08:34]</a>. They believe that for "super big use cases" like translation, [[enterprise_use_of_ai_and_model_specialization | specialized models]] make significant sense <a class="yt-timestamp" data-t="00:37:11">[00:37:11]</a>.
*   **Ownership of the Vertical Stack**: Having ownership of the entire vertical stack—from go-to-market strategy and product to engineering and research—allows DeepL to effectively identify and solve problems that might be missed with mere [[developers_approach_to_ai_models_and_agents | prompt engineering]] <a class="yt-timestamp" data-t="01:05:06">[01:05:06]</a>. This control over model parameters, training, and architecture enables them to integrate features like custom terminology embedding, which other translation providers have struggled to implement effectively <a class="yt-timestamp" data-t="01:41:38">[01:41:38]</a>.
*   **Tight Feedback Loops**: The combination of in-house research, model building, and application deployment creates a tight feedback loop, leading to better and more tailored products <a class="yt-timestamp" data-t="01:15:07">[01:15:07]</a>.
*   **Language-Specific Models**: DeepL runs different sets of models depending on languages and language pairs, adjusting for available data sizes (e.g., more data for German-English than Polish-English) <a class="yt-timestamp" data-t="01:45:48">[01:45:48]</a>. Sometimes, models are grouped by language similarity or bundled for operational efficiency on their infrastructure <a class="yt-timestamp" data-t="01:53:07">[01:53:07]</a>. For inference compute, it often makes more sense to have slightly smaller models handling individual language pairs <a class="yt-timestamp" data-t="02:06:00">[02:06:00]</a>.

## Advantages Over General Models

DeepL attributes its success against giants like Google Translate to a strong focus on academic-level research combined with specialization <a class="yt-timestamp" data-t="00:25:00">[00:25:00]</a>.

Key benefits of specialized models include:
*   **Accuracy and Quality**: For high-value use cases in businesses, accuracy and quality are paramount <a class="yt-timestamp" data-t="00:06:03">[00:06:03]</a>. [[enterprise_use_of_ai_and_model_specialization | Specialized models]] are better able to maintain a high and steady quality, especially when augmented by [[the_role_and_future_of_human_translators_in_the_ai_era | human translators]] for quality assurance and training data annotation <a class="yt-timestamp" data-t="01:31:00">[01:31:00]</a>.
*   **Tailored Performance**: DeepL's models can infer whether a text is technical (optimizing for accuracy) or marketing (optimizing for native-like fluency) to provide the most appropriate translation <a class="yt-timestamp" data-t="00:40:00">[00:40:00]</a>.
*   **Efficiency**: There is a desire to achieve "more with less compute" <a class="yt-timestamp" data-t="02:47:41">[02:47:41]</a>, and [[enterprise_use_of_ai_and_model_specialization | specialized models]] can potentially achieve high quality without the brute-force compute of very large general models <a class="yt-timestamp" data-t="02:50:01">[02:50:01]</a>.
*   **Customer-Centricity**: Businesses prefer ready-made, vertically integrated solutions that "just plug it in and it works" rather than needing to perform internal [[developers_approach_to_ai_models_and_agents | prompt engineering]] <a class="yt-timestamp" data-t="00:37:21">[00:37:21]</a>.

## Limitations of General Models

While acknowledging the "magic" and increased public awareness brought by large general models like ChatGPT <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>, DeepL views them as "overhyped" compared to [[enterprise_use_of_ai_and_model_specialization | specialized models]] <a class="yt-timestamp" data-t="00:48:46">[00:48:46]</a>. They believe that general models, particularly those developed by "big gen players," may not be incentivized to invest in creating smaller, more efficient models due to their current "monopoly on huge compute" <a class="yt-timestamp" data-t="02:50:00">[02:50:00]</a>.

In the context of translation, the reasoning capabilities highlighted in new models like OpenAI's O1, while fundamental to understanding the world, are not necessarily at the core of what makes a translation excellent <a class="yt-timestamp" data-t="02:36:00">[02:36:00]</a>.

## The Future of AI Translation

DeepL believes that the current state of AI translation is very good for well-resourced languages and common use cases like translating newspaper articles or emails <a class="yt-timestamp" data-t="03:00:00">[03:00:00]</a>. However, for high-stakes content like marketing websites for billion-dollar companies or operating manuals for nuclear power plants, human oversight remains crucial for quality and accountability <a class="yt-timestamp" data-t="03:17:00">[03:17:00]</a>. This highlights the ongoing [[the_role_and_future_of_human_translators_in_the_ai_era | role and future of human translators]] in the AI era.

The next frontier for DeepL is synchronous speech translation and voice-based solutions <a class="yt-timestamp" data-t="03:12:00">[03:12:00]</a>. This will eventually enable seamless cross-language communication in business and daily life, fostering more global collaboration <a class="yt-timestamp" data-t="03:40:00">[03:40:00]</a>. Technical challenges include reducing latency and handling the inherent ambiguity and unstructured nature of spoken language <a class="yt-timestamp" data-t="04:55:00">[04:55:00]</a>.

Despite advancements, it's predicted that the average person might learn fewer languages in the future due to improved AI capabilities, but language learning will persist as a personal interest and cultural pursuit <a class="yt-timestamp" data-t="04:34:00">[04:34:00]</a>. DeepL also notes the exciting potential of [[ai_in_language_learning | AI in language learning]] to democratize access to language proficiency, making fluent conversations with models possible and affordable <a class="yt-timestamp" data-t="04:45:00">[04:45:00]</a>.

In conclusion, DeepL's experience suggests that while [[limitations_of_ai_language_models | general-purpose large language models]] are powerful, [[enterprise_use_of_ai_and_model_specialization | specialized models]], particularly in domains like translation, are critical for delivering the high quality, reliability, and tailored solutions that businesses demand <a class="yt-timestamp" data-t="00:38:00">[00:38:00]</a>. The ongoing competition between specialized and general AI models will be fascinating to observe in the coming years <a class="yt-timestamp" data-t="00:27:00">[00:27:00]</a>.