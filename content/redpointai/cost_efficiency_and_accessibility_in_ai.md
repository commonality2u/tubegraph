---
title: Cost efficiency and accessibility in AI
videoId: ZtY8VXswa2o
---

From: [[redpointai]] <br/> 

Eric Reese and Jeremy Howard are building the "Bell Labs of AI" through their company, Answer AI. Their goal is to build smaller, cheaper, and more affordable AI models and applications, particularly in the legal and education sectors <a class="yt-timestamp" data-t="00:00:05">[00:00:05]</a>.

## Challenges in AI Development and Adoption
A current trend in the AI world involves significant funding rounds and substantial spending on models and compute resources long before products reach the market <a class="yt-timestamp" data-t="00:00:57">[00:00:57]</a>. This contrasts with traditional Lean Startup principles.

While AI applications often produce "unbelievably good demos" that can be convincing, it is crucial to test products with actual customers <a class="yt-timestamp" data-t="00:01:36">[00:01:36]</a>. Companies are too readily applying the Software as a Service (SaaS) stack model to AI, which may not be suitable <a class="yt-timestamp" data-t="00:02:19">[00:02:19]</a>. The [[the_economics_and_resource_costs_of_ai_model_scaling | economics of AI]] are vastly different from traditional software, bearing more resemblance to physical manufacturing, deep-sea oil drilling, or nuclear power plants, which involve significant infrastructure and operating costs <a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>.

This approach often pushes the product-market fit question to different layers of the supposed "stack" <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>. Many AI companies, especially those providing APIs, assume their customers will define the product-market fit with end-users, leading to a disconnect multiple layers deep between the model and the final product <a class="yt-timestamp" data-t="00:03:03">[00:03:03]</a>. It is essential to understand the "end-end-end customer" regardless of where a company operates in the stack <a class="yt-timestamp" data-t="00:03:21">[00:03:21]</a>.

Despite the theoretical risk of large platforms "nuking" smaller players, these giants cannot focus on everything simultaneously, creating opportunities for specialized applications <a class="yt-timestamp" data-t="00:05:23">[00:05:23]</a>. However, there is a tendency for fundraising gravity to push entrepreneurs towards science fiction and speculative ventures rather than practical utility <a class="yt-timestamp" data-t="00:45:26">[00:45:26]</a>.

## Answer AI's Approach to Accessibility

Jeremy Howard's prior initiative, fast.ai, aimed to maximize the public benefit of AI for as many people as possible <a class="yt-timestamp" data-t="00:09:42">[00:09:42]</a>. However, fast.ai was "hamstrung" because its resources and software required a strong coding background, restricting access to less than 1% of the world's population <a class="yt-timestamp" data-t="00:12:18">[00:12:18]</a>. Answer AI seeks to overcome this by leveraging natural language and other natural modalities (like vision) to make AI more accessible <a class="yt-timestamp" data-t="00:12:40">[00:12:40]</a>.

A core concern for Answer AI is to counteract the potential for AI to lead to massive centralization of power and decreased opportunities <a class="yt-timestamp" data-t="00:13:07">[00:13:07]</a>. Answer AI is structured as a for-profit R&D lab, an unconventional model that doesn't fit the typical startup mold with clear proprietary technology or a defined five-year financial plan <a class="yt-timestamp" data-t="00:14:35">[00:14:35]</a>.

The company aims to reintegrate research and development, believing that the best research occurs when the researcher is closely connected to the application <a class="yt-timestamp" data-t="00:16:02">[00:16:02]</a>. This approach encourages continuous feedback from customers to scientific inquiry and back <a class="yt-timestamp" data-t="00:16:21">[00:16:21]</a>.

### Focus on Cost Reduction and Efficiency
Answer AI believes there is an overinvestment in training large Foundation models from scratch and using expensive hardware <a class="yt-timestamp" data-t="00:25:40">[00:25:40]</a>. They prioritize addressing the "real world," which is resource-constrained <a class="yt-timestamp" data-t="00:25:52">[00:25:52]</a>. Their breakthrough in efficient fine-tuning of Llama 3 exemplifies this, demonstrating how cost can be significantly reduced, making AI more accessible <a class="yt-timestamp" data-t="00:26:18">[00:26:18]</a>.

A "difference in degree becomes a difference in kind" when costs are dramatically reduced <a class="yt-timestamp" data-t="00:27:17">[00:27:17]</a>. Cheaper inference costs not only improve margins but also enable new applications that are currently too expensive <a class="yt-timestamp" data-t="00:27:52">[00:27:52]</a>. For example, sufficiently low costs could enable continuous fine-tuning or "continuous pre-training" of individual AI agents on inexpensive virtual machines, leading to hyper-personalization and persistent memory for AI agents <a class="yt-timestamp" data-t="00:28:45">[00:28:45]</a>.

This focus aligns with Thomas Edison's approach, prioritizing practical application and solving obstacles to make technology deployable and usable <a class="yt-timestamp" data-t="00:29:17">[00:29:17]</a>. There is a need for more "deployed products" rather than just "splashy demos" <a class="yt-timestamp" data-t="00:29:54">[00:29:54]</a>.

## Opportunities in Legal and Education AI
Answer AI sees significant opportunities in law and education due to their heavy reliance on language <a class="yt-timestamp" data-t="00:34:51">[00:34:51]</a>.

*   **Legal Sector**: The law is often used as a "weapon" by the wealthy, creating injustice <a class="yt-timestamp" data-t="00:35:36">[00:35:36]</a>. Reducing the cost of high-quality legal advice can make the law more equitable and accessible to those with fewer resources <a class="yt-timestamp" data-t="00:36:14">[00:36:14]</a>. AI can help break down "gatekeeping" mechanisms in regulated markets <a class="yt-timestamp" data-t="00:36:43">[00:36:43]</a>.
*   **Education Sector**: There are many opportunities to improve education, especially by overcoming the constraints of a "one-size-fits-all" system <a class="yt-timestamp" data-t="00:37:22">[00:37:22]</a>. AI can help personalize learning paths, enabling more people to build and achieve their goals <a class="yt-timestamp" data-t="00:37:59">[00:37:59]</a>.

## Policy Implications of AI Advancements
Jeremy Howard raised concerns about proposed legislation, such as California's SB 147, which aims to ensure the safety of AI models <a class="yt-timestamp" data-t="00:39:02">[00:39:02]</a>. He argues that regulating the "safety" of AI models themselves, which are dual-use technologies like a pen or a calculator, is ineffective and potentially counterproductive <a class="yt-timestamp" data-t="00:40:01">[00:40:01]</a>.

Such policies could:
*   **Prevent Model Release**: If a company must "ensure the safety" of a raw model, it effectively means they cannot release the model, only products built on top of it <a class="yt-timestamp" data-t="00:42:31">[00:42:31]</a>.
*   **Centralize Power**: This makes raw models an "extremely rivalrous good" and a "jealously guarded secret," accessible only to large states and corporations <a class="yt-timestamp" data-t="00:43:08">[00:43:08]</a>.
*   **Reduce Transparency**: It limits the ability to study how models work, hindering defensive applications like cybersecurity or vaccine development <a class="yt-timestamp" data-t="00:43:57">[00:43:57]</a>.

Jeremy suggests that allowing open-source models and the ability to fine-tune them leads to a safer ecosystem because it enables a wider class of intrinsically safe applications and prevents default reliance on potentially less safe frontier models <a class="yt-timestamp" data-t="00:46:32">[00:46:32]</a>.

## Future Breakthroughs
Key breakthroughs that would significantly impact the field include:
*   **Energy and Resource Efficiency**: A major reduction in the massive energy and other resource requirements for AI models <a class="yt-timestamp" data-t="00:50:34">[00:50:34]</a>.
*   **Advanced Planning and Reasoning**: A breakthrough in AI's planning and reasoning capabilities that moves beyond current subgraph matching, potentially through approaches like "Jeeper-based models" or diffusion models for text <a class="yt-timestamp" data-t="00:51:14">[00:51:14]</a>.

The hosts note the changing perception of human intelligence, suggesting that more of it is encoded in language than previously thought <a class="yt-timestamp" data-t="00:52:38">[00:52:38]</a>. There's a possibility that current large language models (LLMs) are a "brute force" and inefficient way of discovering critical algorithms in cognition, and a direct breakthrough in understanding human cognition could revolutionize AI development <a class="yt-timestamp" data-t="00:53:12">[00:53:12]</a>.

## Conclusion
The emphasis on cost efficiency and accessibility, rather than solely pursuing cutting-edge AGI, allows for the development of practical applications using current AI capabilities <a class="yt-timestamp" data-t="00:56:30">[00:56:30]</a>. Industries like legal and education, with their clear language-in, language-out processes, offer fertile ground for such applications <a class="yt-timestamp" data-t="00:57:03">[00:57:03]</a>. The importance of understanding end-user incentives and rapid iteration remains paramount in navigating the complex AI landscape <a class="yt-timestamp" data-t="00:57:16">[00:57:16]</a>.