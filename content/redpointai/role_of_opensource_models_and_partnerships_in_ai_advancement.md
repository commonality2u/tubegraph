---
title: Role of opensource models and partnerships in AI advancement
videoId: FhIPUFZhKzI
---

From: [[redpointai]] <br/> 

Baris Gultekin, Snowflake's Head of AI, discusses the company's strategies in AI development, highlighting the significance of open source models and strategic partnerships in advancing the field <a class="yt-timestamp" data-t="00:00:01">[00:00:01]</a>. Snowflake's approach focuses on building infrastructure that supports AI tools in production <a class="yt-timestamp" data-t="00:00:15">[00:00:15]</a>.

## Snowflake's Investment in Open Source AI Models

Snowflake has made a notable investment in [[the_future_of_ai_models_and_open_source_development | open source models]] with the launch of its own LLM, Arctic <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>.
This initiative began around December, driven by customer demand for building AI-driven business intelligence (BI) experiences, particularly text-to-SQL capabilities <a class="yt-timestamp" data-t="00:00:59">[00:00:59]</a>.

### Arctic LLM: An Enterprise-Focused Open Source Model
Arctic LLM was designed with enterprise needs in mind, excelling in SQL generation and high-quality chatbot functions rather than general creative tasks like composing poetry <a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>. Key optimizations for Arctic LLM include:
*   **Innovative Architecture** <a class="yt-timestamp" data-t="00:02:25">[00:02:25]</a>: Focused on efficiency in both training and inference <a class="yt-timestamp" data-t="00:02:29">[00:02:29]</a>.
*   **Cost Efficiency** <a class="yt-timestamp" data-t="00:02:36">[00:02:36]</a>: The model was built at 1/8th the cost of similar models <a class="yt-timestamp" data-t="00:02:38">[00:02:38]</a>.
*   **Data Recipe Optimization** <a class="yt-timestamp" data-t="00:02:47">[00:02:47]</a>: Significant time was invested in ensuring the correct data recipe <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>.

Baris Gultekin notes that the goal for Arctic is not to compete with general-purpose models like GPT-5, but to meet the specific needs of Snowflake customers, focusing on SQL generation and RAG quality <a class="yt-timestamp" data-t="00:26:17">[00:26:17]</a>.

### Broader [[impact_of_open_source_models_in_ai_development | Impact of Open Source Models]]
The presence of [[open_source_models_versus_proprietary_ai_models | open source models]] from companies like Meta (with Llama) and Mistral has been hugely influential, fostering an ecosystem where flexibility allows for diverse innovations <a class="yt-timestamp" data-t="00:42:12">[00:42:12]</a>. This has opened the AI industry beyond just a few dominant players <a class="yt-timestamp" data-t="00:42:25">[00:42:25]</a>.

## Strategic Partnerships and Acquisitions

Snowflake actively engages in strategic partnerships and acquisitions to bolster its AI capabilities and offer comprehensive solutions.

### Key Acquisitions
*   **Neva Acquisition**: Instrumental in kickstarting many of Snowflake's AI efforts <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>. Neva's technology forms the underlying basis for Cortex Search and the embedding model <a class="yt-timestamp" data-t="00:29:12">[00:29:12]</a>.
*   **TruEra Acquisition**: This brought TruEra Lens, an [[open_source_ai_models_and_limitations | open source]] observability and LLM evaluation platform, to Snowflake <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>. This platform is crucial for evaluating LLMs at scale using LLMs as judges, easing customer concerns about production systems <a class="yt-timestamp" data-t="00:14:49">[00:14:49]</a>. Evaluation is currently an underhyped but critical aspect of AI development <a class="yt-timestamp" data-t="00:40:43">[00:40:43]</a>.

### Partnerships for an Integrated Ecosystem
Snowflake partners with various entities to integrate AI capabilities directly within its platform, ensuring data security and governance.
*   **Model Providers**: Collaborates with model providers such as Mistral, Reka AI, and AI21 <a class="yt-timestamp" data-t="00:29:38">[00:29:38]</a>. Snowflake is also an investor in some of these companies <a class="yt-timestamp" data-t="00:29:44">[00:29:44]</a>.
*   **End-to-End Solution Companies**: Partners with companies like Landing AI, enabling their full end-to-end solutions to run as applications directly on Snowflake data <a class="yt-timestamp" data-t="00:29:50">[00:29:50]</a>. This allows customers to leverage advanced AI products without moving their data out of Snowflake, maintaining security and governance <a class="yt-timestamp" data-t="00:30:00">[00:30:00]</a>.

## Advancing AI with a Data-Centric Approach

Snowflake's core strategy leverages its data cloud, which offers inherent advantages for AI development and deployment.

### Data Governance and Security
A significant focus for Snowflake is ensuring trust and security for AI systems. Large companies often have AI governance boards that prioritize data security and policy compliance <a class="yt-timestamp" data-t="00:13:10">[00:13:10]</a>. Snowflake's platform provides granular access controls, which are built from the ground up <a class="yt-timestamp" data-t="00:17:02">[00:17:02]</a>. This allows for sensitive use cases, such as an HR chatbot providing different answers based on user permissions or preventing data leakage <a class="yt-timestamp" data-t="00:17:14">[00:17:14]</a>.

### Optimizing Model Deployment
Snowflake generally recommends starting with large models for Proof of Concepts (POCs), often combined with RAG solutions <a class="yt-timestamp" data-t="00:19:23">[00:19:23]</a>. For production systems, the focus shifts to optimization, potentially involving fine-tuning smaller models for latency and cost advantages <a class="yt-timestamp" data-t="00:19:38">[00:19:38]</a>. For companies with large, unique datasets, building custom pre-trained models can also be viable, especially in regulated industries like healthcare, where control over training data and specific language understanding is crucial <a class="yt-timestamp" data-t="00:20:00">[00:20:00]</a>.

### The Future of AI Infrastructure
Baris Gultekin emphasizes that the inference stack in AI is rapidly developing, with continuous improvements leading to cost reductions <a class="yt-timestamp" data-t="00:35:55">[00:35:55]</a>. He anticipates a significant bloom in the application space over the next two years, as customers transition from wanting AI building blocks to requiring end-to-end products <a class="yt-timestamp" data-t="00:45:28">[00:45:28]</a>. This shift indicates a maturing market where comprehensive, integrated solutions built on robust infrastructure will be key to [[the_future_of_ai_models_and_open_source_development | AI advancement]] <a class="yt-timestamp" data-t="00:45:45">[00:45:45]</a>.