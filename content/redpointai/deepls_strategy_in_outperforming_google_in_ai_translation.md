---
title: DeepLs strategy in outperforming Google in AI translation
videoId: JW6DiD_V9hk
---

From: [[redpointai]] <br/> 

DeepL, a company recently valued at $2 billion, supports over 100,000 businesses in AI translation worldwide <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. CEO and founder Jarek Kutylowski discussed how DeepL has managed to outperform tech giants like Google in the AI translation space, a market Google has been involved with since the inception of the Transformer paper <a class="yt-timestamp" data-t="00:07:42">[00:07:42]</a>.

## Core Strategy: Specialization and Innovation

DeepL attributes its success to a few key pillars:

### Market Focus and Pace <a class="yt-timestamp" data-t="00:08:13">[00:08:13]</a>
DeepL's primary strategy was to enter the market with a "big fuss" and maintain a relentless pace of innovation <a class="yt-timestamp" data-t="00:08:13">[00:08:13]</a>. Kutylowski believes that [[competing_with_tech_giants_in_the_ai_market | competition is good]] as it drives the best outcomes for the user <a class="yt-timestamp" data-t="00:01:50">[00:01:50]</a>. The presence of major players like Google has instilled a "sense of urgency" within DeepL, which has been a driving force for the company <a class="yt-timestamp" data-t="00:02:16">[00:02:16]</a>.

### Specialized Models over General Models <a class="yt-timestamp" data-t="00:48:46">[00:48:46]</a>
A cornerstone of DeepL's strategy is its focus on [[specialized_vs_general_ai_models_in_translation | specialized models]] for high-value business translation use cases <a class="yt-timestamp" data-t="00:08:30">[00:08:30]</a>. While general models receive more attention, DeepL argues that specialized models are where significant value is created <a class="yt-timestamp" data-t="00:48:54">[00:48:54]</a>. This focus allows DeepL to build ready-made solutions that vertically integrate into customer workflows, which businesses prefer over complex internal processes <a class="yt-timestamp" data-t="00:37:21">[00:37:21]</a>.

### Academic Research and Vertical Integration <a class="yt-timestamp" data-t="00:08:25">[00:08:25]</a>
DeepL emphasizes building strong academic-level research capabilities within the company <a class="yt-timestamp" data-t="00:08:27">[00:08:27]</a>. The company adopts a "build it yourself" approach, owning the entire vertical stack from product and engineering to research, including building its own tooling and data centers <a class="yt-timestamp" data-t="00:10:00">[00:10:00]</a>. This allows DeepL to maintain control over model parameters, training, and architecture, enabling them to fine-tune solutions for specific customer problems more effectively than relying solely on prompt engineering <a class="yt-timestamp" data-t="00:10:49">[00:10:49]</a>. This tight feedback loop between application deployment and model refinement leads to a more tailored product <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>. An example of this is the ability for DeepL's customers to embed specific terminology into models, a crucial feature for businesses that other translation providers have struggled to integrate effectively <a class="yt-timestamp" data-t="00:11:36">[00:11:36]</a>.

### Geographical Advantage <a class="yt-timestamp" data-t="00:08:46">[00:08:46]</a>
Being established in Europe, a region with many different languages in close proximity, has given DeepL's team a deep understanding of translation problems and a strong motivation to solve them <a class="yt-timestamp" data-t="00:08:48">[00:08:48]</a>.

## Challenges and Solutions in AI Translation

### Data Size Variation <a class="yt-timestamp" data-t="00:13:30">[00:13:30]</a>
The availability of translated material differs significantly across language pairs (e.g., German-English vs. Polish-English) <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>. DeepL addresses this by running different sets of models, varying in size based on the available data <a class="yt-timestamp" data-t="00:12:47">[00:12:47]</a>. Smaller models are sometimes used for individual language pairs, especially when optimizing for inference compute <a class="yt-timestamp" data-t="00:14:04">[00:14:04]</a>.

### The Role of Human Translators and Data Labeling <a class="yt-timestamp" data-t="00:14:48">[00:14:48]</a>
[[the_role_and_future_of_human_translators_in_the_ai_era | Human data]] and translators play an increasingly important role in DeepL's development <a class="yt-timestamp" data-t="00:14:48">[00:14:48]</a>. DeepL has run internal data annotation projects for years, utilizing human translators to train models and ensure quality assurance <a class="yt-timestamp" data-t="00:15:04">[00:15:04]</a>. This in-house approach, requiring native speakers from across the globe, is deemed crucial for the high quality expected of specialized models <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>. While considering outsourcing parts of this, DeepL emphasizes the importance of control over the process and the quality of data labeling <a class="yt-timestamp" data-t="00:17:10">[00:17:10]</a>.

### Infrastructure Decisions: Own Data Centers vs. Hyperscalers <a class="yt-timestamp" data-t="00:26:43">[00:26:43]</a>
DeepL chose to operate its own data centers from the beginning due to the lack of alternatives at the time <a class="yt-timestamp" data-t="00:27:04">[00:27:04]</a>. This decision now provides cost advantages and ensures access to the newest hardware for faster market deployment <a class="yt-timestamp" data-t="00:29:20">[00:29:20]</a>. While hyperscalers are great for kickstarting operations, DeepL advises considering owning data centers for significant scale due to cost efficiency and hardware availability <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>. However, running internal infrastructure is more complex and incurs development speed costs, leading DeepL to move large parts of its stack to hybrid cloud solutions, retaining on-premise infrastructure only for efficiency, security, or data protection requirements <a class="yt-timestamp" data-t="00:29:49">[00:29:49]</a>.

## The Future of AI in Language

### Synchronous Speech Translation <a class="yt-timestamp" data-t="00:39:11">[00:39:11]</a>
Kutylowski sees spoken language and voice as the "next frontier" in translation <a class="yt-timestamp" data-t="00:39:14">[00:39:14]</a>. While text translation has significantly changed how content is consumed, synchronous speech translation will transform conversations <a class="yt-timestamp" data-t="00:39:34">[00:39:34]</a>. This technology could enable seamless communication in businesses across continents, allowing employees to access information and education more easily regardless of location <a class="yt-timestamp" data-t="00:40:48">[00:40:48]</a>.

The main challenges for synchronous speech models include latency, ambiguity in spoken language, and the unstructured nature of conversations <a class="yt-timestamp" data-t="00:46:01">[00:46:01]</a>. DeepL expects early products in a few years, but perfecting it will take time, similar to text translation <a class="yt-timestamp" data-t="00:45:28">[00:45:28]</a>.

### Impact on Language Learning <a class="yt-timestamp" data-t="00:47:05">[00:47:05]</a>
[[ai_in_language_learning | AI in language learning]] holds promise for democratizing access to language practice, making it less expensive than traditional in-person teachers <a class="yt-timestamp" data-t="00:47:25">[00:47:25]</a>. While AI models can facilitate fluent conversations, the intrinsic human desire for cultural connection and intellectual challenge suggests that people will continue to learn languages, perhaps more for personal interest than business necessity <a class="yt-timestamp" data-t="00:43:56">[00:43:56]</a>. Kutylowski speculates that the average person might learn fewer languages in the future, but those who do will find more enjoyment in it <a class="yt-timestamp" data-t="00:43:34">[00:43:34]</a>.

### Current State of AI Translation <a class="yt-timestamp" data-t="00:30:30">[00:30:30]</a>
The quality of AI translation still varies significantly by language pair, with more widely used languages generally performing better due to greater training data availability <a class="yt-timestamp" data-t="00:30:46">[00:30:46]</a>. While one-to-one communication like emails is largely "solved" for well-resourced languages, high-stakes contexts (e.g., marketing websites for billion-dollar companies, nuclear power plant manuals) still require human oversight and accountability <a class="yt-timestamp" data-t="00:31:50">[00:31:50]</a>.

## Learnings and Reflections

*   **Beating Tech Giants:** Kutylowski admits that beating tech giants like Google was a significant surprise, emphasizing the importance of pace and delivery <a class="yt-timestamp" data-t="00:49:19">[00:49:19]</a>.
*   **Beyond Technology:** He learned that technology alone is not enough; a successful company needs to build a complete product with commercial considerations to effectively deploy technology to users <a class="yt-timestamp" data-t="00:49:43">[00:49:43]</a>.
*   **Innovation Mindset:** DeepL's philosophy embraces the idea that innovation means throwing away many results, including failed experiments and superseded solutions. Each failed attempt offers a deeper understanding of the problem, leading to the next level of development <a class="yt-timestamp" data-t="00:32:32">[00:32:32]</a>.
*   **Radical Candor:** Kutylowski highlights the power of "radical candor" – direct, open, and honest communication within the company – as a crucial cultural aspect that he initially underestimated <a class="yt-timestamp" data-t="00:50:18">[00:50:18]</a>.

## Moats and Defensibility in AI <a class="yt-timestamp" data-t="00:35:40">[00:35:40]</a>
For DeepL, the moat lies in its [[specialized_vs_general_ai_models_in_translation | specialized models]] compared to very general ones <a class="yt-timestamp" data-t="00:36:32">[00:36:32]</a>. In specific, large-scale use cases like translation, specialized models make significant sense and allow for the creation of vertically integrated, ready-made solutions that customers prefer <a class="yt-timestamp" data-t="00:37:14">[00:37:14]</a>. While general AI can do many things, it is complicated to deploy reliably as an SDK <a class="yt-timestamp" data-t="00:38:00">[00:38:00]</a>. DeepL's experience suggests that models specifically trained and reinforced with good labeled data for translation outperform general models <a class="yt-timestamp" data-t="00:38:16">[00:38:16]</a>.

The company continues to optimize its models, focusing on smarter architectures to achieve more with less compute, as opposed to just brute-force compute investments <a class="yt-timestamp" data-t="00:25:06">[00:25:06]</a>.