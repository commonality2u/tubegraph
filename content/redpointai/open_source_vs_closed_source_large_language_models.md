---
title: Open source vs closed source large language models
videoId: _N2KPEdh69s
---

From: [[redpointai]] <br/> 

Mistral AI, co-founded by Arthur Mensch, is positioned at the epicenter of the AI landscape, [[building_and_utilizing_large_language_models | building]] one of the leading [[the_role_and_potential_of_open_source_models_in_ai | open source LLMs]] <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>. This article explores the evolving dynamic between [[open_source_versus_closed_source_models_in_ai | open source and closed source models]] as discussed by Arthur Mensch.

## The Evolving AI Landscape

The current AI landscape is characterized by a divide between closed-source offerings, such as those from OpenAI, Anthropic, and Google, and the [[the_role_and_potential_of_open_source_models_in_ai | open-source]] side, which includes Meta and Mistral <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>. Arthur Mensch believes this landscape will solidify with open source prevailing <a class="yt-timestamp" data-t="00:03:31">[00:03:31]</a>. He views AI as an infrastructure technology that should be modifiable and owned by customers <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>.

## Mistral's Dual Offering

Mistral currently offers both an [[open_source_versus_closed_source_models_in_ai | open source]] and a commercial offering, a strategy that may evolve as they seek to establish a sustainable business model for open-source development <a class="yt-timestamp" data-t="00:03:45">[00:03:45]</a>. The goal is to be the most relevant platform for developers <a class="yt-timestamp" data-t="00:05:29">[00:05:29]</a>.

Mistral's decision on what goes into [[open_source_versus_closed_source_models_in_ai | closed-source versus open-source]] is tactical and subject to competitive and commercial pressures <a class="yt-timestamp" data-t="00:05:17">[00:05:17]</a>. Generally, their very best models are shipped with commercial licenses, while those just below are [[the_role_and_potential_of_open_source_models_in_ai | open source]] <a class="yt-timestamp" data-t="00:05:05">[00:05:05]</a>.

### Challenges for Open Source Adoption

While open-source offerings are gaining traction, there have been slight gaps in performance and usability compared to closed-source options <a class="yt-timestamp" data-t="00:04:04">[00:04:04]</a>. Closed-source offerings previously had better software surrounding APIs <a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a>. Mistral is actively working to close these gaps <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>.

### Licensing Weights for Enterprises

Mistral provides enterprises with access to model weights for its commercial offerings, such as Mistral Large <a class="yt-timestamp" data-t="00:04:56">[00:04:56]</a>. This approach offers several benefits:
*   **Deployment Flexibility** Enterprises can deploy models where their data resides, addressing data governance concerns <a class="yt-timestamp" data-t="00:06:00">[00:06:00]</a>.
*   **Specialization** Access to weights allows enterprises to perform the necessary specialization and connect models to their specific data and tools, enabling more involved applications than simple API usage <a class="yt-timestamp" data-t="00:06:11">[00:06:11]</a>.

This contrasts with other providers who typically charge via API access <a class="yt-timestamp" data-t="00:05:43">[00:05:43]</a>. Small companies and digital natives often prefer to go directly to Mistral's platform for direct support <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a>. Larger enterprises, particularly in Europe, often prefer to use existing procurement processes via partners like Azure <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>.

## Competition and Efficiency in LLM Development

The competition in [[building_and_utilizing_large_language_models | building and utilizing large language models]] is intense. While some companies like Meta have vast GPU resources (e.g., 600,000 GPUs), Mistral focuses on efficiency and a high concentration of GPUs per person <a class="yt-timestamp" data-t="00:12:01">[00:12:01]</a>. This lean approach allows them to be efficient and innovative in training models, having achieved significant results with 1.5K H100 GPUs <a class="yt-timestamp" data-t="00:12:17">[00:12:17]</a>.

Arthur emphasizes the importance of unit economics, ensuring that compute spending translates to revenue <a class="yt-timestamp" data-t="00:12:46">[00:12:46]</a>. Being efficient with training compute is key to a valid business model <a class="yt-timestamp" data-t="00:13:02">[00:13:02]</a>.

### Future of [[understanding_language_models | Language Models]]

Arthur believes there's still an "efficiency frontier" to push in [[understanding_language_models | LLMs]] <a class="yt-timestamp" data-t="00:10:25">[00:10:25]</a>. Improvements will come from:
*   **Architectural Innovations**: Making models more efficient than plain Transformers, which spend the same compute on every token <a class="yt-timestamp" data-t="00:11:09">[00:11:09]</a>.
*   **Controllability**: Significant research is still needed to make models more controllable and follow instructions precisely <a class="yt-timestamp" data-t="00:10:44">[00:10:44]</a>.
*   **Deployment**: Deploying models on smaller devices and improving latency will open up new applications that use LLMs as basic building blocks for complex tasks like planning and exploration <a class="yt-timestamp" data-t="00:11:27">[00:11:27]</a>.

While new architectures are proposed, the co-adaptation of training algorithms, debugging methods, and hardware to Transformers makes it challenging to switch to entirely new architectures <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a>. Mistral's innovations focus on improving sparse attention for memory efficiency within the Transformer framework <a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a>.

## Regulation and Sovereignty

Regarding regulation, Mistral advocates for addressing AI safety from a product safety perspective, similar to general software safety <a class="yt-timestamp" data-t="00:17:17">[00:17:17]</a>. They believe the focus should be on evaluating the product's expected performance, rather than regulating the underlying technology based on arbitrary thresholds <a class="yt-timestamp" data-t="00:17:25">[00:17:25]</a>.

Arthur suggests that policymakers should pressure application makers to verify that their AI products perform as expected, similar to car safety testing <a class="yt-timestamp" data-t="00:21:17">[00:21:17]</a>. This would create a "second-order pressure" on foundational model makers to provide controllable models <a class="yt-timestamp" data-t="00:21:34">[00:21:34]</a>. Regulating the technology directly, as seen in parts of the EU AI Act, can favor large players who can deploy legal teams to influence standards <a class="yt-timestamp" data-t="00:22:45">[00:22:45]</a>.

The rise of foundation models for different countries (e.g., India, Japan) highlights the importance of:
*   **Portability**: Enabling countries and developers to deploy technology where they want is Mistral's approach to sovereignty <a class="yt-timestamp" data-t="00:23:23">[00:23:23]</a>.
*   **Multilinguality**: Since LLMs speak languages, models need to be great in every language, not just English <a class="yt-timestamp" data-t="00:23:31">[00:23:31]</a>. Mistral started with French and aims for global multilingual capability <a class="yt-timestamp" data-t="00:23:55">[00:23:55]</a>.

Arthur believes that if companies offer a "platform play" by shipping portable models to various countries, it should be enough for countries to feel confident they control the technology <a class="yt-timestamp" data-t="00:25:28">[00:25:28]</a>. However, if only a few companies offer Software-as-a-Service (SaaS) exclusively, a sovereignty problem could arise <a class="yt-timestamp" data-t="00:25:41">[00:25:41]</a>.

## Future Directions for [[building_and_utilizing_large_language_models | LLMs]]

Mistral is also exploring how to help enterprises with data for [[open_source_ecosystem_and_model_specialization | model specialization]]. While large datasets are useful, Arthur notes that many enterprises lack readily available "demonstration data" (traces of user actions) needed for robust fine-tuning <a class="yt-timestamp" data-t="00:29:31">[00:29:31]</a>. He suggests that using retrieval augmentation generation (RAG) and empowering assistants with tools and database access should be the first steps for enterprises with large data volumes <a class="yt-timestamp" data-t="00:29:08">[00:29:08]</a>. This suggests a more even playing field for companies looking to leverage AI, as they will need to acquire new types of data <a class="yt-timestamp" data-t="00:29:58">[00:29:58]</a>.

Arthur expressed excitement for "hard science" applications of AI, specifically mentioning Material Science, which he believes still lacks a foundational model <a class="yt-timestamp" data-t="00:32:36">[00:32:36]</a>. He sees immense potential in accelerating processes like ammonium synthesis, a carbon-intensive process, through AI-driven exploration <a class="yt-timestamp" data-t="00:32:49">[00:32:49]</a>.