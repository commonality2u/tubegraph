---
title: Speech recognition and AI
videoId: nFC3asFKlH0
---

From: [[redpointai]] <br/> 

Connor Wick, CEO of Speak.com, leads an English language learning platform that has garnered over 10 million users in more than 40 countries since its 2019 launch in South Korea <a class="yt-timestamp" data-t="00:00:20">[00:00:20]</a>. Backed by OpenAI, Speak recently achieved a $500 million valuation <a class="yt-timestamp" data-t="00:00:16">[00:00:16]</a>. The company focuses on developing an AI-driven solution for language fluency, emphasizing conversational skills over traditional grammar or memorization <a class="yt-timestamp" data-t="00:06:30">[00:06:30]</a>.

## An Entrepreneurial Spark

Connor Wick's entrepreneurial journey began in high school with a flashcard app for early iPhones <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>. This app gained several million users and facilitated the creation of hundreds of millions of "knowledge pairs" <a class="yt-timestamp" data-t="00:01:32">[00:01:32]</a>. Wick envisioned aggregating this data into a graph to "generate anything and teach anything that anyone wants to learn," ultimately creating an "omniscient tutor" <a class="yt-timestamp" data-t="00:02:04">[00:02:04]</a>. He notes that the technology to achieve this, specifically Large Language Models (LLMs) that can crawl the internet, now largely exists <a class="yt-timestamp" data-t="00:02:16">[00:02:16]</a>. Flashcard data, he believes, would be "really good data specifically for learning" due to its structured nature <a class="yt-timestamp" data-t="00:02:47">[00:02:47]</a>.

Wick's formal exposure to AI began in 2015 when he "crashed" a Berkeley course, becoming convinced that underlying models would significantly improve <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>. At that time, the focus was on Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs), before the Transformer architecture was invented <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>. Initial ideas for AI applications included computer vision tasks like automated parking enforcement (deemed "horrible for the world") and measuring bodies for custom clothing or medical imaging <a class="yt-timestamp" data-t="00:05:05">[00:05:05]</a>. The team was ultimately "more drawn to... speech recognition" due to the potential to build technology that felt like it had a "persona" and fostered a "relationship" <a class="yt-timestamp" data-t="00:05:57">[00:05:57]</a>.

## Speak's AI-Driven Product Evolution

Speak teaches language learners "chunks of words" that frequently occur in everyday speech, encouraging repetition until automaticity <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>. Users then practice in simulated conversations aimed at achieving specific communication goals relevant to their motivation for learning <a class="yt-timestamp" data-t="00:07:25">[00:07:25]</a>. The entire experience is "extremely individuated to the individual user," adapting to their motivation, interests, and proficiency level <a class="yt-timestamp" data-t="00:07:45">[00:07:45]</a>. This approach makes Speak a prime example of [[ai_in_language_learning | AI in language learning]].

Connor emphasizes Speak's "long-term oriented" vision, anticipating that with more data and compute, models would improve and eventually surpass human capabilities in various tasks, leading to the full replacement of humans in the learning process <a class="yt-timestamp" data-t="00:08:21">[00:08:21]</a>. Early "unlocks" for the product focused on highly accurate speech recognition to ensure a positive user experience, later incorporating phoneme recognition and basic language understanding <a class="yt-timestamp" data-t="00:09:28">[00:09:28]</a>.

## Building Defensibility in AI

Speak's strategy for building a "technological moat" involves several key areas:

*   **Specialized In-House Models**: While acknowledging that large foundational models will eventually "subsume" many tasks, Speak develops its own specialized models for short-to-medium-term advantages <a class="yt-timestamp" data-t="00:12:00">[00:12:00]</a>.
    *   **Accented Speech Recognition**: Speak has an in-house speech recognition model specifically trained to understand users speaking with accents, identify specific mistakes, and provide fast, reliable, streaming feedback <a class="yt-timestamp" data-t="00:12:24">[00:12:24]</a>.
    *   **Phoneme Recognition**: A system built on their data detects pronunciation errors and "prosodic types of mistakes" <a class="yt-timestamp" data-t="00:12:45">[00:12:45]</a>.
*   **ML Scaffolding / AI Firmware**: Connor identifies the "ML scaffolding" or "AI firmware" as a significant long-term technological moat <a class="yt-timestamp" data-t="00:15:24">[00:15:24]</a>. This includes:
    *   Orchestrating models for specific tasks <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>.
    *   Continuously collecting new data <a class="yt-timestamp" data-t="00:16:39">[00:16:39]</a>.
    *   Fine-tuning models <a class="yt-timestamp" data-t="00:16:41">[00:16:41]</a>.
    *   Building robust evaluation frameworks <a class="yt-timestamp" data-t="00:16:42">[00:16:42]</a>.
    *   Developing infrastructure for language representation, such as knowledge graphs to track user proficiency <a class="yt-timestamp" data-t="00:16:51">[00:16:51]</a>. This area accounts for at least 50% of Speak's product development and time <a class="yt-timestamp" data-t="00:17:09">[00:17:09]</a>.
*   **End-to-End User Experience**: The focus is on the core problem of teaching language effectively and engaging users, even if underlying technology needs to be swapped out <a class="yt-timestamp" data-t="00:11:02">[00:11:02]</a>.

## User Experience and Interface Design

Speak is inventing "new interface paradigms around like audio first experiences" <a class="yt-timestamp" data-t="00:19:02">[00:19:02]</a>. Users are unfamiliar with "talking into Speak in a way that is kind of fundamentally unfamiliar when it comes to technology" <a class="yt-timestamp" data-t="00:19:06">[00:19:06]</a>. An example is the onboarding process, which features a microphone button and a simple question like "Why are you learning English?" <a class="yt-timestamp" data-t="00:19:19">[00:19:19]</a> Users often wonder about the expected length or language of their response <a class="yt-timestamp" data-t="00:19:30">[00:19:30]</a>.

Connor believes the interface will become more "fluid" and "hybrid," allowing users to "talk or type or tap" at any point <a class="yt-timestamp" data-t="00:21:00">[00:21:00]</a>. While speech isn't "always better," it's "definitely better some of the time," especially as [[the_future_of_voice_interfaces_in_ai | speech-to-speech models]] improve <a class="yt-timestamp" data-t="00:21:25">[00:21:25]</a>. However, typing can be faster with a keyboard, and there will always be scenarios where tapping is preferred <a class="yt-timestamp" data-t="00:21:38">[00:21:38]</a>. The increasing familiarity with paradigms from apps like ChatGPT has already led to a "meaningful shift in... the average user's understanding of these paradigms" <a class="yt-timestamp" data-t="00:20:25">[00:20:25]</a>.

A future interface "unlock" lies in the AI "thinking about you in the background," observing data and proactively taking actions <a class="yt-timestamp" data-t="00:22:56">[00:22:56]</a>. For instance, after an hour of using Speak, the system could process a user's activity overnight and generate "distilled analysis and lessons" to start their next day <a class="yt-timestamp" data-t="00:23:46">[00:23:46]</a>.

## AI's Impact on Learning and Industries

### Curriculum Design
Speak aims for a hybrid approach to curriculum design. While there's a "right sequence of ways to learn a language" (e.g., common high-frequency words first), the specific ordering and the exact set of words can be "individual and bespoke for the user" <a class="yt-timestamp" data-t="00:25:22">[00:25:22]</a>. Humans will likely remain "in the loop" for "artistic creation of the actual curriculum," but the machine learning team is increasingly involved in this process, necessitating cross-functional understanding <a class="yt-timestamp" data-t="00:26:01">[00:26:01]</a>.

### Model Costs and Pricing
Speak does not feel "constrained" by model reference costs, as they operate at scale with a subscription model <a class="yt-timestamp" data-t="00:28:06">[00:28:06]</a>. They believe that if they were constrained, they would "build it anyway and eat the costs" because costs are expected to decrease over time, leading to increased demand <a class="yt-timestamp" data-t="00:28:27">[00:28:27]</a>.

Speak's pricing strategy considers both extremes:
*   **Radical Accessibility**: Providing a software solution with low marginal cost to "literally hundreds of millions of people" <a class="yt-timestamp" data-t="00:29:21">[00:29:21]</a>.
*   **Premium Pricing**: Charging significantly more for a consumer product that competes with offline tutoring or classroom education, which can cost hundreds of dollars per month <a class="yt-timestamp" data-t="00:29:51">[00:29:51]</a>.

### Evaluation of Models
Connor stresses the importance and difficulty of evaluation, particularly for open-ended LLM tasks <a class="yt-timestamp" data-t="00:30:57">[00:30:57]</a>. For speech, evaluation goes beyond mere word error rates to include catching individual mistakes and understanding when a user's speech is "substantially unintelligible" even if a model *could* understand it <a class="yt-timestamp" data-t="00:31:34">[00:31:34]</a>. The goal is sometimes to "dumb down your understanding model to human level" to better assess real-world communication <a class="yt-timestamp" data-t="00:32:05">[00:32:05]</a>. A well-defined evaluation framework provides "execution clarity" for the team <a class="yt-timestamp" data-t="00:32:16">[00:32:16]</a>.

When new models like GPT-4o are released, Speak has a detailed process involving running them against 40+ major internal tasks and eval loops, including human-in-the-loop evaluations <a class="yt-timestamp" data-t="00:33:31">[00:33:31]</a>. They also track product metrics with subsets of customers to see if the new models improve engagement <a class="yt-timestamp" data-t="00:34:12">[00:34:12]</a>.

### Disruptive vs. Sustaining Technologies
Connor differentiates between AI as a "sustaining technology" (improving an existing solution) and a "disruptive technology" (fundamentally changing the problem or its solution) <a class="yt-timestamp" data-t="00:35:06">[00:35:06]</a>. He argues that Duolingo, primarily focused on casual language learning for native English speakers who weren't previously learning languages <a class="yt-timestamp" data-t="00:36:11">[00:36:11]</a>, might not be as directly impacted by AI as Speak, which targets users seeking conversational fluency who lack access to human speakers <a class="yt-timestamp" data-t="00:37:34">[00:37:34]</a>.

While tools like real-time translation might obviate the need for some casual users to learn a language <a class="yt-timestamp" data-t="00:38:05">[00:38:05]</a>, Connor points out the inherent [[latency_and_system_integration_challenges_in_aibased_voice_systems | latency and imperfection of translation]] due to fundamental linguistic differences <a class="yt-timestamp" data-t="00:38:25">[00:38:25]</a>. For Speak's users, the core motivation is "human connection" and the desire to connect with more people globally, which a "live Babble fish" cannot fully address <a class="yt-timestamp" data-t="00:38:50">[00:38:50]</a>.

The release of models like GPT-4o, even if causing stock fluctuations for companies like Duolingo <a class="yt-timestamp" data-t="00:39:37">[00:39:37]</a>, is seen by Speak as a positive development. More people using ChatGPT to learn and practice languages will realize the potential of [[ai_in_language_learning | AI in language learning]] and then seek specialized, more effective solutions like Speak <a class="yt-timestamp" data-t="00:40:35">[00:40:35]</a>.

## Future Outlook

### General AI Capabilities
Connor anticipates significant advancements in "multimodal audio" connected to LLMs <a class="yt-timestamp" data-t="00:44:51">[00:44:51]</a>. The "Holy Grail" is a single, continuous model that can handle speech recognition, LLM processing, and speech synthesis in one turn with lower latency and less information loss <a class="yt-timestamp" data-t="00:45:34">[00:45:34]</a>. This would allow for a more natural, human-like tutor experience, understanding nuances, tone, emotions, and mistakes directly from speech <a class="yt-timestamp" data-t="00:45:56">[00:45:56]</a>.

He also notes room for improvement in the "cognition piece," specifically "reasoning and general ability to like actually follow a task through completion and do that well and reliably" <a class="yt-timestamp" data-t="00:46:27">[00:46:27]</a>. This would enable "much smarter planning around the curriculum" <a class="yt-timestamp" data-t="00:46:44">[00:46:44]</a>.

### Expansion Areas
Speak's current advantage in [[ai_in_language_learning | language learning]] is that AI can already offer a "fully useful" and disruptive solution, potentially "fully take the human out of the loop" <a class="yt-timestamp" data-t="00:47:20">[00:47:20]</a>. Other higher-stakes industries may still require human intervention due to the need for higher reasoning and lower hallucinations <a class="yt-timestamp" data-t="00:47:44">[00:47:44]</a>.

Future expansion areas for AI in education include:
*   **Schools**: Improving the quality of education beyond just digital quizzes or video lectures <a class="yt-timestamp" data-t="00:50:18">[00:50:18]</a>.
*   **Businesses and Professional Skills**: Developing and certifying professional skills, such as public speaking or giving presentations in English, which is a significant part of Speak's growing Enterprise business in South Korea <a class="yt-timestamp" data-t="00:48:11">[00:48:11]</a>.
*   **Personal Learning**: This "invisible" but "massive" sector includes daily activities like reading books, listening to podcasts, watching videos, and reading articles, all driven by the desire to "become like a better version of yourself" <a class="yt-timestamp" data-t="00:50:37">[00:50:37]</a>. Connor envisions personal learning in 10-15 years as "highly individuated," with an AI that has "long-term memory" and a "good mental mapping of everything you kind of know" <a class="yt-timestamp" data-t="00:52:05">[00:52:05]</a>.

Connor believes education will be one of the "biggest and most exciting areas of change and disruption" in the AI era <a class="yt-timestamp" data-t="00:53:57">[00:53:57]</a>. He notes that while software has "eaten the world," the fundamental quality of education hasn't changed much in 20 years, still relying on methods similar to those from 2,000 years ago <a class="yt-timestamp" data-t="00:54:10">[00:54:10]</a>.

### Challenges in AI Progress
While optimistic about the decade ahead, Connor expresses concern that the current "obsession" with the Transformer architecture might be a "local maximum" and hopes research continues into other AI approaches <a class="yt-timestamp" data-t="00:55:51">[00:55:51]</a>. He notes that for subjects like math, the "bar to... having a thing that people will really enjoy using is much higher" than for language learning, because current solutions are already relatively effective <a class="yt-timestamp" data-t="00:57:27">[00:57:27]</a>.

### Lessons Learned
A continuous challenge is that new AI capabilities, while exciting, are "Never As Good as you think it will be" and are not a "Panacea" <a class="yt-timestamp" data-t="01:00:48">[01:00:48]</a>. Building something that actually changes user behavior remains "really really hard" <a class="yt-timestamp" data-t="01:00:54">[01:00:54]</a>. An example of this is the introduction of "human level transcription" tied to GPT-4 for open-ended lessons, which was "good but it wasn't a game changer" <a class="yt-timestamp" data-t="01:01:08">[01:01:08]</a>.

Originally, Speak aimed to build all its models in-house, but later realized that some models would be too costly to develop independently, leading to a shift in strategy <a class="yt-timestamp" data-t="01:01:45">[01:01:45]</a>.

## Conclusion
Speak continues to innovate in [[ai_in_language_learning | AI in language learning]], focusing on specialized models, robust ML scaffolding, and intuitive user experiences. The company is actively hiring and can be found at [speak.com](https://speak.com) <a class="yt-timestamp" data-t="01:02:44">[01:02:44]</a>.