---
title: The future of AI architectures beyond transformers
videoId: sLsYzhk_4CY
---

From: [[redpointai]] <br/> 

Aiden, a co-author of the Transformer paper, expressed his hope that transformers are not the final [[model_architectures_in_ai | architecture in AI]] <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>. He has anticipated a shift away from transformers for some time <a class="yt-timestamp" data-t="00:35:44">[00:35:44]</a>.

## Current State of Architectures

Despite expectations for new [[model_architectures_in_ai | architectures]], the longevity of transformers has been surprising <a class="yt-timestamp" data-t="00:37:17">[00:37:17]</a>. Aiden stated that if asked in 2018 (a year after the Transformer paper was published) about the likelihood of still using transformers seven years later, he would have put it "pretty close to zero" <a class="yt-timestamp" data-t="00:36:57">[00:36:57]</a>.

## Emerging Alternatives and Hybrid Approaches

While new [[model_architectures_in_ai | architectures]] are emerging, they do not always fully replace existing ones:
*   **SSMs (State Space Models):** Aiden initially believed SSMs would replace transformers, even naming a meeting room after them <a class="yt-timestamp" data-t="00:35:58">[00:35:58]</a>. However, it was found that beneficial components of an SSM could be integrated into a transformer, negating the immediate need for a full swap <a class="yt-timestamp" data-t="00:36:06">[00:36:06]</a>.
*   **Discrete Diffusion Models:** These models offer a "super cool UX" where responses emerge from a "wall of noisy tokens and text" <a class="yt-timestamp" data-t="00:36:13">[00:36:13]</a>. However, it is not yet clear if they are inherently better language models than transformers <a class="yt-timestamp" data-t="00:36:31">[00:36:31]</a>.

## The Need for New Architectures

Aiden expressed a strong desire for new [[model_architectures_in_ai | architectures]] to emerge within the next 5-10 years <a class="yt-timestamp" data-t="00:36:46">[00:36:46]</a>. He noted that the "scale is all you need" hypothesis is "breaking," with diminishing returns on capital and compute <a class="yt-timestamp" data-t="00:09:21">[00:09:21]</a>. This indicates that new approaches will be necessary to achieve the next step in technological advancement <a class="yt-timestamp" data-t="00:09:35">[00:09:35]</a>.