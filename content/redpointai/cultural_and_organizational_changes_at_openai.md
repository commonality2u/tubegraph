---
title: Cultural and organizational changes at OpenAI
videoId: a0bEU83P8g8
---

From: [[redpointai]] <br/> 

OpenAI, initially founded as a non-profit, has undergone numerous significant cultural and organizational transformations throughout its history, which its former Chief Research Officer, Bob McGrew, likens to being "refounded" multiple times <a class="yt-timestamp" data-t="00:40:52">[00:40:52]</a>.

## Evolution of OpenAI's Mission and Structure
When Bob McGrew joined OpenAI, it operated as a non-profit organization with a vision to achieve [[the_future_of_ai_models_and_open_source_development | AGI]] by publishing research papers <a class="yt-timestamp" data-t="00:41:01">[00:41:01]</a>. However, early team members, many with startup backgrounds, felt this approach was incorrect <a class="yt-timestamp" data-t="00:41:14">[00:41:14]</a>.

Key organizational shifts include:
*   **Transition to For-Profit** The move from a non-profit to a for-profit entity occurred after a couple of years and was highly controversial internally <a class="yt-timestamp" data-t="00:41:28">[00:41:28]</a>. This change was driven by the necessity to raise funds and eventually interact with products and generate revenue <a class="yt-timestamp" data-t="00:41:31">[00:41:31]</a>.
*   **Microsoft Partnership** The partnership with Microsoft was another controversial "refounding moment" <a class="yt-timestamp" data-t="00:41:41">[00:41:41]</a>. The initial concern was about partnering with "Big Tech," but it also led to the decision to build OpenAI's own products with an API <a class="yt-timestamp" data-t="00:41:48">[00:41:48]</a>.
*   **Shift to Consumer Focus with ChatGPT** The decision to expand from Enterprise to consumer products with ChatGPT was a deliberate choice, particularly after [[the_evolution_and_impact_of_OpenAIs_models | GPT-3]] <a class="yt-timestamp" data-t="00:43:38">[00:43:38]</a>. Although deliberate in concept, its release was somewhat accidental, with the team setting a low bar for success (e.g., 1,000 users) and deciding not to use a waitlist <a class="yt-timestamp" data-t="00:44:02">[00:44:02]</a> <a class="yt-timestamp" data-t="00:44:44">[00:44:44]</a>. The initial days post-release were marked by disbelief, anxiety about GPU acquisition, and uncertainty about whether it would be a fad like the [[the_evolution_and_impact_of_OpenAIs_models | DALL-E 2]] model <a class="yt-timestamp" data-t="00:44:59">[00:44:59]</a>.

These pivots, occurring every 18 months to two years, fundamentally altered the company's purpose and the identity of its workforce <a class="yt-timestamp" data-t="00:42:20">[00:42:20]</a>. The mission evolved from writing papers to building a single model for global use, a goal that was not initially known but discovered through exploration <a class="yt-timestamp" data-t="00:42:30">[00:42:30]</a>.

## Research Culture
OpenAI's research organization was designed to be the "mirror image" of academia, emphasizing collaboration over individual credit <a class="yt-timestamp" data-t="00:55:09">[00:55:09]</a>.

> [!NOTE] Academic incentives, such as extreme focus on credit and diluting contributions through collaboration, were intentionally avoided <a class="yt-timestamp" data-t="00:57:16">[00:57:16]</a>.

The culture at OpenAI was likened to a startup, with a strong opinion on direction, yet offering significant freedom to great researchers to pursue foundational problems they were deeply committed to <a class="yt-timestamp" data-t="00:58:33">[00:58:33]</a>. The ultimate goal was to build "one thing" rather than just publishing many papers <a class="yt-timestamp" data-t="00:58:59">[00:58:59]</a>.

## Key Decisions and Their Impact
A pivotal and controversial decision was to "double down" on language modeling as OpenAI's central focus <a class="yt-timestamp" data-t="00:59:34">[00:59:34]</a>. This required restructuring and job changes <a class="yt-timestamp" data-t="00:59:48">[00:59:48]</a>. Earlier major efforts, such as the [[role_of_opensource_models_and_partnerships_in_ai_advancement | Dota 2]] game-playing project, were successful and provided conviction that problems could be solved by increasing scale <a class="yt-timestamp" data-t="01:00:04">[01:00:04]</a>. The decision to halt more exploratory projects, like robotics and games teams, to refocus on language models and generative modeling (including multimodal work), was critical but painful <a class="yt-timestamp" data-t="01:00:47">[01:00:47]</a>.

## Continuous Progress and Future Outlook
Despite significant progress, Bob McGrew maintains that his fundamental views on AI have not changed since 2020-2021 <a class="yt-timestamp" data-t="00:45:59">[00:45:59]</a>. He believes that many foreseen developments, such as larger and multimodal models, and the use of [[the_evolution_and_impact_of_OpenAIs_models | reinforcement learning]] for language models, have largely materialized <a class="yt-timestamp" data-t="00:46:10">[00:46:10]</a>.

> [!TIP] The difference between 2021 and 2024 is not *what* needed to happen, but the fact that it *was made to happen* <a class="yt-timestamp" data-t="00:46:38">[00:46:38]</a>.

He views the future as "predestined" in terms of reaching [[the_future_of_ai_models_and_open_source_development | AGI]] through scaling pre-training and test-time compute, as reasoning is considered the last fundamental challenge <a class="yt-timestamp" data-t="00:47:01">[00:47:01]</a> <a class="yt-timestamp" data-t="00:47:59">[00:47:59]</a>. However, he cautions that scaling is a significant and hard undertaking, involving systems, hardware, optimization, and data problems <a class="yt-timestamp" data-t="00:48:17">[00:48:17]</a>.