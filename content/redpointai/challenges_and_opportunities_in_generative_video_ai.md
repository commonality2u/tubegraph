---
title: Challenges and opportunities in generative video AI
videoId: FudGqDZDSx4
---

From: [[redpointai]] <br/> 

Generative video AI tools are transforming content creation by enabling the generation of video footage using artificial intelligence, rather than traditional camera filming <a class="yt-timestamp" data-t="00:04:36">[00:04:36]</a>. Haen, an AI video platform, aims to make video production faster and more affordable, serving individuals who may be camera-shy or businesses without access to expensive equipment <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.

## Evolution of Video Production

Historically, video production involved filming with a camera and then extensive post-production editing <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a>. The advent of generative AI allows for the creation of footage directly from AI, potentially replacing the need for physical cameras <a class="yt-timestamp" data-t="00:04:29">[00:04:29]</a>. This shift could also revolutionize editing, moving away from traditional timeline editors, which were necessitated by the high cost of camera footage <a class="yt-timestamp" data-t="00:06:15">[00:06:15]</a>. Future editing experiences are envisioned to be vastly different, possibly involving text-to-video generation and documentation-like script editing <a class="yt-timestamp" data-t="00:06:50">[00:06:50]</a>.

## Haen's Capabilities and Use Cases

Haen raised $60 million at a $500 million valuation from investors including Benchmark <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>. The company experienced a viral moment when its video translation tool was used to dub the Argentinian President's speech at the World Economic Forum into different languages <a class="yt-timestamp" data-t="00:00:51">[00:00:51]</a>. This showcased the "magic moment" of speaking in various languages with natural voice and expression <a class="yt-timestamp" data-t="00:01:45">[00:01:45]</a>.

Haen serves over 40,000 customers with three primary use cases <a class="yt-timestamp" data-t="00:09:37">[00:09:37]</a>:
*   **Create**: Users can generate videos by typing text, using custom avatars or stock avatars, eliminating the need for a camera <a class="yt-timestamp" data-t="00:09:48">[00:09:48]</a>.
*   **Localize**: Existing videos can be localized into over 175 languages and dialects, preserving voice tone, facial expression, and lip-sync <a class="yt-timestamp" data-t="00:10:01">[00:10:01]</a>.
*   **Personalize**: A single video can be personalized into over 100,000 variations based on customer demographics, industry, and problems faced <a class="yt-timestamp" data-t="00:10:19">[00:10:19]</a>.

Haen is designed for the "99% of users who are not professional players" <a class="yt-timestamp" data-t="00:11:18">[00:11:18]</a>, such as marketers who write content but lack video production skills <a class="yt-timestamp" data-t="00:11:29">[00:11:29]</a>. The mission is to enable visual storytelling for everyone, especially those without access to expensive cameras or sophisticated software <a class="yt-timestamp" data-t="00:11:40">[00:11:40]</a>. Key to user adoption is demonstrating the diverse use cases across different verticals like marketing, sales, customer support, and training <a class="yt-timestamp" data-t="00:12:47">[00:12:47]</a>.

## Technical Aspects and Challenges

### Avatar Quality
A critical aspect of generative video AI is the quality and engagement of the generated avatars <a class="yt-timestamp" data-t="00:07:47">[00:07:47]</a>. An effective avatar must deliver messages effectively, which means being engaging beyond just lip-sync <a class="yt-timestamp" data-t="00:13:56">[00:13:56]</a>. This includes realistic head movement, eyebrow expressions, and body motion/gesture that match the script <a class="yt-timestamp" data-t="00:14:17">[00:14:17]</a>.

Creating an avatar requires submitting a video footage (e.g., 30 seconds to 2 minutes) so the AI model can learn and mimic the individual's full talking style, including all bodily movements and expressions <a class="yt-timestamp" data-t="00:17:04">[00:17:04]</a>. Haen's AI 3.0 model can render full bodies and aims to incorporate gestures as the next step <a class="yt-timestamp" data-t="00:21:32">[00:21:32]</a>. The ongoing [[challenges_and_opportunities_in_ai_model_development_and_infrastructure | challenges and opportunities in AI model development and infrastructure]] include continuously improving model architecture to capture diverse variations and dimensions <a class="yt-timestamp" data-t="00:16:18">[00:16:18]</a>.

### Synchronous Generation and Performance
While much of the current generative video creation is asynchronous, the potential for synchronous, real-time generative streaming is significant <a class="yt-timestamp" data-t="00:18:53">[00:18:53]</a>. Haen offers a beta interactive avatar that can attend Zoom meetings in real-time <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>.
The main technical [[challenges_and_innovations_in_ai_hardware | challenges and innovations in AI hardware]] for real-time generation include optimizing inference speed as models become larger and more complex <a class="yt-timestamp" data-t="00:19:42">[00:19:42]</a>. There is optimism that real-time AI video generation, even on-device, will be possible within 12 months <a class="yt-timestamp" data-t="00:20:46">[00:20:46]</a>. This capability would enable new use cases like personalized video ads tailored to individual preferences <a class="yt-timestamp" data-t="00:20:17">[00:20:17]</a>.

### Integration with other AI models and Brand Personalization
Haen primarily focuses on business videos, prioritizing control, consistency, and quality <a class="yt-timestamp" data-t="00:23:24">[00:23:24]</a>. The company believes in an orchestration engine approach, combining text, script, voice, music, avatar footage, and background generation, rather than pixel-by-pixel, frame-by-frame generation, which can be less controllable <a class="yt-timestamp" data-t="00:23:00">[00:23:00]</a>. Haen aims to integrate with text-to-video partners, using their output as a base layer while building its own orchestration engine on top to provide a holistic video experience <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a>.

Another key area for future development is "brand personalization" within video <a class="yt-timestamp" data-t="00:25:03">[00:25:03]</a>. Similar to how ChatGPT can generate text in a specific brand tone, video AI models could learn a company's visual style, color palette, and opening/closing elements from existing videos and integrate them into new generated content <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>. This would involve disassembling video into components and assembling them with user-inputted brand memory <a class="yt-timestamp" data-t="00:26:16">[00:26:16]</a>.

## Business Strategy and Market Positioning

Haen's business model is built on serving Enterprise customers who demand high quality and brand consistency <a class="yt-timestamp" data-t="00:31:41">[00:31:41]</a>. A key challenge is integrating the technology into existing day-to-day workflows <a class="yt-timestamp" data-t="00:32:09">[00:32:09]</a>. For marketing use cases, integration with CRM and go-to-market tools like HubSpot is crucial, as demonstrated by Haen's partnership with HubSpot <a class="yt-timestamp" data-t="00:32:27">[00:32:27]</a>.

Regarding competition with incumbents like Snap and TikTok, Haen believes it's creating a new market rather than directly competing in the old one <a class="yt-timestamp" data-t="00:28:22">[00:28:22]</a>. Traditional platforms are built around mobile cameras and creators who use them <a class="yt-timestamp" data-t="00:29:12">[00:29:12]</a>. Haen, however, aims to make the camera obsolete and enable video creation *without* a camera <a class="yt-timestamp" data-t="00:29:30">[00:29:30]</a>.

A potential [[challenges_of_integrating_ai_generated_content_with_traditional_content | dilemma for platforms like TikTok]] is how to balance and recommend AI-generated content alongside creator-based content <a class="yt-timestamp" data-t="00:30:00">[00:30:00]</a>. If AI content becomes 50% of the platform, it could reduce views for existing creators, potentially necessitating new platforms specifically for AI-generated content <a class="yt-timestamp" data-t="00:30:15">[00:30:15]</a>. Haen's mission is not to be a consumption platform, but to build creative tools, though a new platform for AI-generated content is a possible future opportunity <a class="yt-timestamp" data-t="00:31:10">[00:31:10]</a>.

## Capital and Growth
The AI category has different financial models compared to traditional software companies because of significant GPU and talent costs, meaning marginal costs are not close to zero <a class="yt-timestamp" data-t="00:37:29">[00:37:29]</a>. However, AI-native companies and teams are highly efficient, allowing for faster growth trajectories and potentially requiring less capital than expected to build a great AI company <a class="yt-timestamp" data-t="00:38:50">[00:38:50]</a>. Haen plans product development 12 months ahead, anticipating future model capabilities and cost reductions <a class="yt-timestamp" data-t="00:41:00">[00:41:00]</a>.

## Ethical and Security Considerations
Trust and safety are critical for Haen, especially when serving large Enterprise customers <a class="yt-timestamp" data-t="00:34:01">[00:34:01]</a>. Policies include:
*   **Avatar Creation**: Requires video consent from the person whose avatar is being created, verified by advanced AI to match the person in the footage <a class="yt-timestamp" data-t="00:34:11">[00:34:11]</a>. Dynamic generated passwords with short expiry times (e.g., 10-15 seconds) add a secure layer to prevent unauthorized avatar creation <a class="yt-timestamp" data-t="00:34:25">[00:34:25]</a>.
*   **Content Moderation**: A hybrid system of AI model review and human moderation is in place to prevent hate speech, misinformation, and political campaign content <a class="yt-timestamp" data-t="00:35:01">[00:35:01]</a>.

Haen also engages in IP partnerships with actors who allow their likeness to be used for stock avatars <a class="yt-timestamp" data-t="00:35:49">[00:35:49]</a>. The ability to generate new voices and persistent AI-generated persons opens up possibilities for creating new intellectual property, such as AI influencers <a class="yt-timestamp" data-t="00:36:10">[00:36:10]</a>.

## The Future of Generative Video AI

Joshua Xu envisions that by 2030, everyone will have a "video agency in their pocket" <a class="yt-timestamp" data-t="00:48:30">[00:48:30]</a>. This personal AI video agency, exemplified by Haen, would allow users to interact with the product as if talking to a personal video agency, translating ideas into filmed footage and edited content, with feedback loops <a class="yt-timestamp" data-t="00:48:04">[00:48:04]</a>.

The power of creative tools like generative video AI lies in opening up new use cases that are currently unimaginable <a class="yt-timestamp" data-t="00:49:29">[00:49:29]</a>. Just as the mobile camera led to the rise of Instagram, Snapchat, and TikTok, lowering the barrier to video creation will unlock a whole new world of possibilities <a class="yt-timestamp" data-t="00:49:56">[00:49:56]</a>.

To learn more about Haen and try the product, visit haen.com <a class="yt-timestamp" data-t="00:51:14">[00:51:14]</a>.