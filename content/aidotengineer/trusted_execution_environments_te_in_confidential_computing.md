---
title: Trusted Execution Environments TE in confidential computing
videoId: A0PxE39xaMc
---

From: [[aidotengineer]] <br/> 

[[Confidential AI and its applications | AI]] is transforming various sectors, including healthcare, finance, automation, and digital marketing <a class="yt-timestamp" data-t="00:00:11">[00:00:11]</a>. However, a major barrier to its widespread adoption is trust, particularly when running models on sensitive data or deploying proprietary models without losing control <a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a>. This is where [[confidential_ai_and_its_applications | confidential AI]] and Trusted Execution Environments (TEEs) become crucial <a class="yt-timestamp" data-t="00:00:36">[00:00:36]</a>.

## What are Trusted Execution Environments (TEEs)?

Trusted Execution Environments (TEEs) address the overlooked problem that data and models are most vulnerable during processing, whether it's for training, fine-tuning, or inference <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>.

At the hardware level, a TEE is a secure and isolated part of the processor <a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>. Examples include Intel TDX, AMD SEV-SMP, and Nvidia GPU TEEs <a class="yt-timestamp" data-t="00:01:47">[00:01:47]</a>. This component creates a confidential environment where code and data are protected even during execution <a class="yt-timestamp" data-t="00:01:53">[00:01:53]</a>. The isolation is provided by instructions built into the chip during manufacturing <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>.

Once a workload enters a TEE, it is protected in memory and becomes invisible to the host operating system, hypervisor, or even anyone with system access, including the hardware owner <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.

## Cryptographic Attestation

Beyond isolation, a TEE also generates a cryptographic attestation <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>. This is a signed proof that the workload ran inside verified hardware using unmodified code <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a>. Attestation is critical for two reasons:
*   It provides strong assurances that the workload is truly protected by the hardware <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>.
*   It allows for statements about what the workload actually is, confirming that it's running in a real TEE on a properly manufactured, TEE-capable chip <a class="yt-timestamp" data-t="00:02:50">[00:02:50]</a>.

In essence, TEEs enable sensitive computations to run securely and provide proof that they ran as intended, which is foundational for [[confidential_ai_and_its_applications | confidential AI]] <a class="yt-timestamp" data-t="00:03:14">[00:03:14]</a>.

## TEEs and Confidential AI

TEEs are the core technology behind [[confidential_ai_and_its_applications | confidential AI]] <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a>. They allow AI models to run on sensitive data without exposing either the model or the data <a class="yt-timestamp" data-t="00:03:24">[00:03:24]</a>.

Traditional cloud setups often fall short because they rely on trust and legal contracts rather than provable guarantees <a class="yt-timestamp" data-t="00:07:56">[00:07:56]</a>. TEEs address this by offering:
*   **Data Protection**
    *   Hospitals and labs are reluctant to share raw data sets, even for medical AI models that could improve patient outcomes, due to tight controls and regulations <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>. [[Confidential AI and its applications | Confidential AI]] powered by TEEs helps solve this <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>.
    *   Personal AI agents require deep access to private, sensitive data, but users and developers have concerns about exposure and misuse, while enterprises and regulators demand strong guarantees <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>. TEEs provide the missing piece for mass adoption <a class="yt-timestamp" data-t="00:05:34">[00:05:34]</a>.
    *   In digital marketing, fine-tuning models on real user behavior is desired, but privacy laws (like GDPR and CCPA) and ethical considerations often block access to such data <a class="yt-timestamp" data-t="00:05:47">[00:05:47]</a>.
*   **Model Monetization and Protection**
    *   Developers of domain-specific AI models want to monetize their work but fear losing control over proprietary models or their weights if users run them unprotected <a class="yt-timestamp" data-t="00:06:36">[00:06:36]</a>. Simultaneously, customers are unwilling to expose their sensitive data for testing or production <a class="yt-timestamp" data-t="00:06:47">[00:06:47]</a>. [[Confidential AI and its applications | Confidential AI]] allows both parties to benefit without relinquishing control <a class="yt-timestamp" data-t="00:07:04">[00:07:04]</a>.
*   **Model Training and Provenance**
    *   TEEs enable the provenance of data to be assured, allowing users to track back to the initial data sets and guarantee that a model was trained exactly as stated <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>.

### Super Protocol's Leverage of TEEs

Super Protocol is a [[confidential_ai_and_its_applications | confidential AI]] cloud and marketplace built for secure collaboration and monetization of AI models, data, and compute <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>. It makes [[confidential_ai_and_its_applications | confidential AI]] usable <a class="yt-timestamp" data-t="00:08:11">[00:08:11]</a>. Key aspects include:
*   **TEE Agnostic Infrastructure**: Super Protocol runs on Intel, Nvidia, and AMD TEEs, with plans to support future platforms <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.
*   **Edge-Ready Architecture**: It has validated ARM [[confidential_ai_and_its_applications | confidential computing]] via ARM 9 emulation, aiming to deliver end-to-end [[confidential_ai_and_its_applications | confidential AI]] from personal edge devices to the cloud <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>.
*   **Trustless Design**: The open-source architecture and nature of TEEs ensure that no unauthorized access is technically possible by the hardware provider, Super Protocol, or any third party <a class="yt-timestamp" data-t="00:11:02">[00:11:02]</a>. This makes [[confidential_ai_and_its_applications | confidential computing]] the foundation of trustless AI <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>.
*   **Verifiable Execution**: Every workload on Super Protocol generates a cryptographic attestation, a signed proof from the hardware itself, based on the attestation capabilities inherent in [[confidential_ai_and_its_applications | confidential computing]] <a class="yt-timestamp" data-t="00:32:20">[00:32:20]</a>. This verifies that the model executed in a real TEE using unmodified code on verified hardware inside a secure open-source runtime <a class="yt-timestamp" data-t="00:32:35">[00:32:35]</a>.

## Real-World Applications Featuring TEEs

### Secure AI Marketplace
The SuperAI marketplace is built on a [[confidential_ai_and_its_applications | confidential]] and decentralized architecture with no centralized components <a class="yt-timestamp" data-t="00:18:13">[00:18:13]</a>. [[Confidentiality in AI model training and deployment | Confidential computing]] ensures that models remain private and authors retain full control and ownership <a class="yt-timestamp" data-t="00:18:31">[00:18:31]</a>. Models can be leased but not downloaded, and nobody has access to the TEE during processing, meaning models and user data are off-limits even to clients <a class="yt-timestamp" data-t="00:18:38">[00:18:38]</a>. Models are deployed in the TEE and accessible via link or API <a class="yt-timestamp" data-t="00:18:51">[00:18:51]</a>.
*   **Deployment Demonstration**: A DeepSeek model can be deployed on an H100 GPU <a class="yt-timestamp" data-t="00:20:07">[00:20:07]</a>. The engine and model are downloaded into the [[confidential_ai_and_its_applications | confidential computing]] environment and prepared for execution within the TEE <a class="yt-timestamp" data-t="00:20:27">[00:20:27]</a>. Verification tools can confirm the model is deployed in a [[confidential_ai_and_its_applications | confidential environment]], the connection is encrypted, and the AI engine has not been tampered with <a class="yt-timestamp" data-t="00:21:18">[00:21:18]</a>.

### Secure Automated AI Workflows for Medical Data
Super Protocol allows building secure automated AI workflows for processing sensitive medical data, for example, using N8N deployed on Super Protocol <a class="yt-timestamp" data-t="00:21:50">[00:21:50]</a>. By running everything inside TEEs—inaccessible even to server admins or Super Protocol—and combining low-code automation with decentralized infrastructure, it delivers fully [[confidential_ai_and_its_applications | confidential]], compliant, and verifiable medical AI <a class="yt-timestamp" data-t="00:22:01">[00:22:01]</a>.
*   **X-ray Analysis Use Case**: A doctor uploads an X-ray image and patient data via a protected web form <a class="yt-timestamp" data-t="00:22:17">[00:22:17]</a>. This data is passed into an automated workflow built with N8N, running inside a TEE on Super Protocol <a class="yt-timestamp" data-t="00:22:25">[00:22:25]</a>. The workflow cleans data, invokes an AI model to analyze the X-ray, generates a medical report, and securely emails it to the doctor <a class="yt-timestamp" data-t="00:22:35">[00:22:35]</a>. API keys and login details (e.g., Gmail credentials) are securely stored and isolated inside the TEE <a class="yt-timestamp" data-t="00:23:36">[00:23:36]</a>. This process adapts to other medical use cases like CT scans or MRIs, secured by Super Protocol's TEEs <a class="yt-timestamp" data-t="00:25:57">[00:25:57]</a>.

### Distributed Inference and Scaling (GPUless)
Super Protocol enables distributed inference using VLLM across multiple GPU servers without reliance on a single provider <a class="yt-timestamp" data-t="00:26:19">[00:26:19]</a>. While VLLM partitions a model across nodes, by default, these run in unprotected environments <a class="yt-timestamp" data-t="00:26:42">[00:26:42]</a>. Super Protocol secures this by running every VLLM node inside a [[microvms_in_ai_sandboxes | confidential VM]] powered by TEE hardware, all connected over a private overlay network <a class="yt-timestamp" data-t="00:27:04">[00:27:04]</a>. Data, model weights, and intermediate activations are decrypted and processed only inside each [[microvms_in_ai_sandboxes | confidential environment]], with all inter-node communication encrypted, ensuring no sensitive material leaves the secure boundary or is exposed to any host <a class="yt-timestamp" data-t="00:27:14">[00:27:14]</a>. This provides security through TEE hardware and improved performance through parallel processing <a class="yt-timestamp" data-t="00:31:26">[00:31:26]</a>.

### Verifiable Trust
Super Protocol replaces blind trust with built-in cryptographic proofs <a class="yt-timestamp" data-t="00:31:40">[00:31:40]</a>. Every workload generates a cryptographic proof showing what ran, where, and how, without exposing the actual workload data <a class="yt-timestamp" data-t="00:32:03">[00:32:03]</a>. This means every run is verifiable independently and transparently down to the hardware level <a class="yt-timestamp" data-t="00:31:49">[00:31:49]</a>.
*   **Multi-Party Medical AI Training**: Super Protocol facilitates secure collaboration between multiple parties, such as labs, clinics, and research centers, for training AI models on medical data where privacy is crucial <a class="yt-timestamp" data-t="00:33:16">[00:33:16]</a>. Alice's lab and Bob's clinic hold sensitive data, while Carol's research center brings a training engine <a class="yt-timestamp" data-t="00:33:30">[00:33:30]</a>.
    *   All three inputs (data and engine) run inside a TEE, ensuring no one (cloud host, Super Protocol, or even participants) can access the contents <a class="yt-timestamp" data-t="00:33:50">[00:33:50]</a>.
    *   A [[microvms_in_ai_sandboxes | confidential virtual machine]] (CVM) handles multiple jobs, and upon boot, it contacts an open-source certification authority (also in [[confidential_ai_and_its_applications | confidential mode]]) for a remote attestation <a class="yt-timestamp" data-t="00:34:49">[00:34:49]</a>. If the check passes, a certificate is issued proving the CVM is genuine and running inside an attested TEE <a class="yt-timestamp" data-t="00:35:08">[00:35:08]</a>.
    *   Before data enters, an open-source security mechanism within the CVM, the trusted loader, is attested and then checks every component <a class="yt-timestamp" data-t="00:35:18">[00:35:18]</a>. If any check fails, the process stops to protect data and models <a class="yt-timestamp" data-t="00:35:31">[00:35:31]</a>.
    *   Data owners upload their encrypted datasets to their own decentralized storage <a class="yt-timestamp" data-t="00:36:39">[00:36:39]</a>. Only the specified CVM with its private key can decrypt the data <a class="yt-timestamp" data-t="00:37:35">[00:37:35]</a>.
    *   The training process only starts inside the TEE if all component hashes match an approved list, and data and the engine are only decrypted within the TEE <a class="yt-timestamp" data-t="00:37:56">[00:37:56]</a>. Participants and even the system owner remain unable to access them during execution <a class="yt-timestamp" data-t="00:38:18">[00:38:18]</a>.
    *   An integrity report, signed inside the TEE, is published on OPBNB as part of the order report, providing public, tamper-proof evidence that the job ran in a certified environment with approved inputs <a class="yt-timestamp" data-t="00:39:56">[00:39:56]</a>. This report includes certificates, processed inputs, and timing <a class="yt-timestamp" data-t="00:40:23">[00:40:23]</a>, verifying that the executable workload and input data hashes match <a class="yt-timestamp" data-t="00:40:32">[00:40:32]</a>.
    *   After every job, raw inputs are wiped, and the order report is published on-chain, proving the run was genuine <a class="yt-timestamp" data-t="00:41:07">[00:41:07]</a>. An app inside a CVM can sign data with its private key, which can be verified on-chain as coming from a trusted, decentralized, [[confidential_ai_and_its_applications | confidential environment]] <a class="yt-timestamp" data-t="00:41:21">[00:41:21]</a>.

Super Protocol provides a simple, transparent, and verifiable path for developers to leverage [[confidential_ai_and_its_applications | confidential AI]], offering security by design, without the need for extensive TEE expertise <a class="yt-timestamp" data-t="00:42:53">[00:42:53]</a>.