---
title: Solving data privacy issues in AI development
videoId: A0PxE39xaMc
---

From: [[aidotengineer]] <br/> 

AI is transforming various sectors, including healthcare, finance, automation, and digital marketing <a class="yt-timestamp" data-t="00:00:11">[00:00:11]</a>. However, a significant barrier to its widespread adoption is the lack of trust <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. Key concerns include running models on sensitive data without handing it over, deploying proprietary models without losing control, and collaborating in non-deterministic environments without relying solely on blind trust <a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a>. [[confidential_ai_and_its_impact | Confidential AI]] aims to solve these issues, with Super Protocol working to make it a reality <a class="yt-timestamp" data-t="00:00:36">[00:00:36]</a>.

## The Foundation: Confidential Computing

The core technology behind [[confidential_ai_and_its_impact | confidential AI]] is confidential computing <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a>. This addresses the often-overlooked problem that data and models are most vulnerable during processing (training, fine-tuning, or inference), not just when stored or in transit <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>.

### Trusted Execution Environments (TEEs)
Trusted Execution Environments (TEEs) are secure, isolated parts of a processor (like Intel TDX, AMD SEV-SMP, or Nvidia GPU TEs) that create a confidential environment where code and data are protected even during execution <a class="yt-timestamp" data-t="00:01:37">[00:01:37]</a>. The chip itself provides isolation using built-in instructions <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>. Once a workload enters this environment, it's protected in memory and is invisible to the host OS, hypervisor, or anyone with system access, including the hardware owner <a class="yt-timestamp" data-t="00:02:10">[00:02:10]</a>.

TEEs also generate a cryptographic attestation, which is a signed proof that the workload ran inside verified hardware using unmodified code <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>. This attestation provides strong assurances that the workload is protected by hardware and allows for statements about the workload's true nature <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>. It confirms what's in the TEE and that it's a real TEE in a properly manufactured, capable chip <a class="yt-timestamp" data-t="00:02:54">[00:02:54]</a>. In essence, TEEs enable sensitive computations to run securely and prove they ran as intended <a class="yt-timestamp" data-t="00:03:14">[00:03:14]</a>. This allows AI models to run on sensitive data without exposing either the model or the data <a class="yt-timestamp" data-t="00:03:24">[00:03:24]</a>.

## Real-World Problems Solved by Confidential AI

The shift to [[confidential_ai_and_its_impact | confidential AI]] is critical for addressing several practical problems developers face:

*   **[[Use cases of confidential_ai_in_healthcare_and_marketing | Healthcare]]**: Building or fine-tuning medical AI models is difficult due to the inability to access or get permission to use raw medical datasets <a class="yt-timestamp" data-t="00:03:51">[00:03:51]</a>. Hospitals and labs do not share raw data, and regulations often prevent bringing models to the data <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>. [[confidential_ai_and_its_impact | Confidential AI]] helps solve this by enabling secure processing of sensitive clinical data <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>.

*   **[[Ethics and adoption challenges of AI agents | Personal AI Agents]]**: Mass adoption of personal AI agents that manage inboxes, calendars, or documents is hindered by concerns about deep access to private, sensitive data <a class="yt-timestamp" data-t="00:04:50">[00:04:50]</a>. Users worry about data sharing, developers about storage and misuse, and enterprises/regulators about legal guarantees <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>. Confidentiality is the missing piece for real-world adoption of these technologies <a class="yt-timestamp" data-t="00:05:37">[00:05:37]</a>.

*   **[[Use cases of confidential_ai_in_healthcare_and_marketing | Digital Marketing]] and Custom Analytics**: Fine-tuning models on real user behavior data (tracking interactions with websites, content) often risks upsetting regulators and auditors due to privacy laws, internal security rules, and ethics <a class="yt-timestamp" data-t="00:05:47">[00:05:47]</a>. This creates a significant gap between what's technically possible and what's allowed <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>.

*   **[[Challenges in AI Development | AI Model Monetization]]**: Developers building domain-specific models (legal, medical, financial) want to monetize them without giving away the model or its weights <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a>. Simultaneously, customers are unwilling to expose their sensitive data for testing or production <a class="yt-timestamp" data-t="00:06:47">[00:06:47]</a>. [[confidential_ai_and_its_impact | Confidential AI]] allows both parties to benefit without relinquishing control <a class="yt-timestamp" data-t="00:06:59">[00:06:59]</a>.

*   **Model Training and Provenance**: Proving the provenance of a model trained or fine-tuned on sensitive data is crucial <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>. With attested execution, it becomes possible to guarantee that a model was trained where and how it was claimed, ensuring that inference outputs relate only to the original, specific datasets <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a>.

Traditional cloud setups fall short as they are built on trust and legal contracts rather than provable guarantees <a class="yt-timestamp" data-t="00:07:58">[00:07:58]</a>.

## Super Protocol: A Solution for Confidential AI

Super Protocol is a [[confidential_ai_and_its_impact | confidential AI]] cloud and marketplace designed for secure collaboration and monetization of AI models, data, and compute <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>.

### Key Features
*   **TE-Agnostic Infrastructure**: Super Protocol runs on Intel, Nvidia, and AMD TEEs, with plans to support future TE integrations from major chipmakers <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.
*   **Edge-Ready Architecture**: It supports ARM confidential computing, aiming to deliver end-to-end [[confidential_ai_and_its_impact | confidential AI]] from personal edge devices to the cloud <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>.
*   **Swarm Computing Principles**: It scales across distributed GPU nodes, offering no single point of failure and automatic workload redistribution <a class="yt-timestamp" data-t="00:09:27">[00:09:27]</a>.
*   **Decentralized**: Fully decentralized with no human intervention, orchestrated by smart contracts on the BNB chain <a class="yt-timestamp" data-t="00:09:40">[00:09:40]</a>.
*   **Zero Barrier to Entry**: Users don't need TEE expertise to run or attest workloads <a class="yt-timestamp" data-t="00:09:52">[00:09:52]</a>.
*   **Open Source Protocol**: All parts of Super Protocol will be open source, functioning as a protocol (like HTTPS) that protects data while AI is processing it <a class="yt-timestamp" data-t="00:10:03">[00:10:03]</a>.

### GPUless, Trustless, Limitless
Super Protocol enables AI workloads to be:
*   **GPUless**: It removes dependency on specific cloud vendors by allowing accelerated AI workloads across independent GPU nodes <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>. Users don't need to buy or rent GPUs for extended periods <a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>.
*   **Trustless**: Thanks to TEEs and open-source architecture, no unauthorized access is technically possible by the hardware provider, Super Protocol, or any third party <a class="yt-timestamp" data-t="00:10:59">[00:10:59]</a>. This makes confidential computing the foundation of trustless AI <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>.
*   **Limitless**: It removes legal, technical, and organizational barriers imposed by traditional cloud platforms <a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a>. With [[confidential_ai_and_its_impact | confidential AI]], users are not limited by policy, regulation, or infrastructure constraints <a class="yt-timestamp" data-t="00:11:29">[00:11:29]</a>. This enables training, deployment, and monetization of AI across organizations and jurisdictions with full confidentiality and ownership, even for agentic, non-deterministic AI <a class="yt-timestamp" data-t="00:12:18">[00:12:18]</a>.

## Impactful Case Studies

### [[Use cases of confidential_ai_in_healthcare_and_marketing | Digital Marketing]] (Realize and Mars)
Realize, an AI company measuring ad reactions by analyzing facial expressions, needed more biometric video data for accurate AI models <a class="yt-timestamp" data-t="00:13:05">[00:13:05]</a>. Privacy laws (like GDPR and CCPA) and data ownership concerns made providers reluctant to share sensitive footage <a class="yt-timestamp" data-t="00:13:32">[00:13:32]</a>.

By using Super Protocol's [[confidential_ai_and_its_impact | confidential AI]] cloud, AI training ran inside secure TEEs using powerful chips <a class="yt-timestamp" data-t="00:13:45">[00:13:45]</a>. Every step was automated by smart contracts and verified by hardware and Super Protocol's open-source certification, ensuring data and models remained completely secure and inaccessible even to the cloud provider, Super Protocol, or Realize <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a>.

As a result, providers shared four times more sensitive footage, growing the training set by 319% <a class="yt-timestamp" data-t="00:14:24">[00:14:24]</a>. Accuracy jumped to 75% (on par with human-level performance), leading to a 3-5% sales increase for Mars across 30 brands in 19 markets <a class="yt-timestamp" data-t="00:14:37">[00:14:37]</a>. This demonstrates that provable data privacy unlocks data, powering better models and real business impact <a class="yt-timestamp" data-t="00:14:53">[00:14:53]</a>.

### [[Use cases of confidential_ai_in_healthcare_and_marketing | Healthcare]] (BEAL and Titonix)
The Brain Electrophysiology Laboratory (BEAL) needed to submit perfect documentation for FDA approval of a new epilepsy diagnostic device <a class="yt-timestamp" data-t="00:15:19">[00:15:19]</a>. This process typically takes weeks of manual audits, multiple NDAs, and risks exposing trade secrets, with even small mistakes causing 120-day delays <a class="yt-timestamp" data-t="00:15:42">[00:15:42]</a>. BEAL wanted to use Titonix's AI-powered audit tool but had concerns about keeping their data and Titonix's model safe in traditional cloud environments <a class="yt-timestamp" data-t="00:16:01">[00:16:01]</a>.

Titonix used Super Protocol's [[confidential_ai_and_its_impact | confidential AI]] cloud <a class="yt-timestamp" data-t="00:16:15">[00:16:15]</a>. The audit ran inside secure hardware environments (TEEs) using Nvidia H100/H200 GPUs and Intel TDX CPUs <a class="yt-timestamp" data-t="00:16:22">[00:16:22]</a>. Every step was automated, orchestrated by smart contracts, and backed by cryptographic proof <a class="yt-timestamp" data-t="00:16:32">[00:16:32]</a>. All files and models remained encrypted, readable only inside the secure environment, and completely hidden from Super Protocol, BEAL, Titonix, or anyone else <a class="yt-timestamp" data-t="00:16:36">[00:16:36]</a>.

Audit time dropped from weeks to just one to two hours <a class="yt-timestamp" data-t="00:16:53">[00:16:53]</a>. There was zero risk of leaks, both BEAL's and Titonix's IP remained fully protected, and no re-review delays occurred <a class="yt-timestamp" data-t="00:17:00">[00:17:00]</a>. This proved that guaranteed confidentiality can transform even the most sensitive and high-stakes processes like FDA clearance audits <a class="yt-timestamp" data-t="00:17:20">[00:17:20]</a>.

## How it Works in Practice (Demos)

Super Protocol offers practical tools and features for secure AI development:

### Super AI Marketplace
The SuperAI marketplace is built on a confidential and decentralized architecture with no centralized components or data centers <a class="yt-timestamp" data-t="00:18:10">[00:18:10]</a>. A blockchain-based ecosystem manages relationships and financial settlements between AI model/dataset providers, confidential computing hardware providers, and clients <a class="yt-timestamp" data-t="00:18:19">[00:18:19]</a>.

Confidential computing ensures models remain private, and authors retain full control and ownership; models can be leased but not downloaded <a class="yt-timestamp" data-t="00:18:31">[00:18:31]</a>. Nobody has access to the TEE during processing, meaning models and user data are off-limits even to clients <a class="yt-timestamp" data-t="00:18:41">[00:18:41]</a>. Models deployed in the TEE are accessible via a link or API <a class="yt-timestamp" data-t="00:18:51">[00:18:51]</a>. The marketplace supports monetization for authors of closed-source models with various scenarios like per-hour, fixed, and revenue sharing <a class="yt-timestamp" data-t="00:18:57">[00:18:57]</a>.

Deployment involves selecting a model (e.g., DeepSeek) and GPU, assembling the order, and letting the system create the order on the blockchain <a class="yt-timestamp" data-t="00:19:40">[00:19:40]</a>. The engine and model are downloaded into the confidential computing environment for execution <a class="yt-timestamp" data-t="00:20:27">[00:20:27]</a>. Once deployed, the model is accessible via a link or API <a class="yt-timestamp" data-t="00:20:41">[00:20:41]</a>. Verification tools confirm the model is deployed in a confidential environment, the connection is encrypted, and the AI engine has not been tampered with <a class="yt-timestamp" data-t="00:21:10">[00:21:10]</a>.

### Agentic AI (N8N and Medical Data)
Super Protocol allows building secure automated AI workflows for processing sensitive medical data using N8N deployed on Super Protocol <a class="yt-timestamp" data-t="00:21:50">[00:21:50]</a>. By running everything inside TEEs (inaccessible even to server admins or Super Protocol) and combining low-code automation with a decentralized infrastructure, it delivers fully confidential, compliant, and verifiable medical AI <a class="yt-timestamp" data-t="00:22:01">[00:22:01]</a>.

**Use Case Example**: A doctor uploads an X-ray image and patient personal data via a protected web form <a class="yt-timestamp" data-t="00:22:17">[00:22:17]</a>. This data is passed to an automated workflow built with N8N, running inside a TEE <a class="yt-timestamp" data-t="00:22:25">[00:22:25]</a>. The workflow cleans input data, invokes an AI model to analyze the X-ray, generates a structured medical report, and securely emails it to the doctor <a class="yt-timestamp" data-t="00:22:33">[00:22:33]</a>.

In this workflow, personal data is separated from diagnostic input, so the AI model receives only the X-ray and symptom description <a class="yt-timestamp" data-t="00:24:15">[00:24:15]</a>. The result is combined with patient data for the report, which can be in text, HTML, or JSON, for integration with hospital systems or ERPs <a class="yt-timestamp" data-t="00:24:25">[00:24:25]</a>. All operations, including secure storage of API keys and login details, occur within the secure confidential environment <a class="yt-timestamp" data-t="00:25:50">[00:25:50]</a>. This solution can adapt to other medical imaging (CT, MRI, ECG) and lab tests quickly <a class="yt-timestamp" data-t="00:25:57">[00:25:57]</a>.

### Scaling (Distributed Inference with VLLM)
Super Protocol enables GPUless distributed inference using VLLM across multiple GPU servers without relying on a single provider <a class="yt-timestamp" data-t="00:26:19">[00:26:19]</a>. VLLM partitions a model by layers and assigns computation to different nodes, improving memory efficiency and throughput <a class="yt-timestamp" data-t="00:26:42">[00:26:42]</a>. While VLLM typically runs in unprotected environments, Super Protocol secures it by running every VLLM node inside a confidential VM powered by TEE hardware, all tied together over a private overlay network <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>. Data, model weights, and intermediate activations are decrypted and processed only within each confidential environment, with all inter-node communication encrypted <a class="yt-timestamp" data-t="00:27:12">[00:27:12]</a>.

This setup allows a single large LLM to run across multiple GPU nodes (e.g., four H100/H200 GPUs from different owners) in a fully confidential mode <a class="yt-timestamp" data-t="00:27:38">[00:27:38]</a>. The process involves building a Docker image, uploading it to decentralized storage, and launching master and worker nodes, with one node potentially hosting the model inference <a class="yt-timestamp" data-t="00:28:14">[00:28:14]</a>. On-chain reports can be downloaded and verified to confirm image and model hashes match expectations, ensuring integrity <a class="yt-timestamp" data-t="00:30:31">[00:30:31]</a>. Public endpoints can be tested, with parallel processing across machines leading to faster responses <a class="yt-timestamp" data-t="00:31:02">[00:31:02]</a>.

### Moving Beyond Trust (Verifiability)
Super Protocol replaces blind trust with built-in cryptographic proofs <a class="yt-timestamp" data-t="00:31:40">[00:31:40]</a>. Every run is independently and transparently verifiable down to the hardware level, meaning "trustless" signifies "verifiable by design" <a class="yt-timestamp" data-t="00:31:49">[00:31:49]</a>. Each workload produces a cryptographic proof showing what ran, where, and how, without exposing the actual workload data <a class="yt-timestamp" data-t="00:32:03">[00:32:03]</a>.

When a workload runs, it generates a cryptographic attestation – a signed proof from the hardware itself – building on the attestation capabilities of confidential computing <a class="yt-timestamp" data-t="00:32:20">[00:32:20]</a>. This attestation verifies that the model executed in a real TEE, using unmodified code, on verified hardware, inside a secure open-source runtime <a class="yt-timestamp" data-t="00:32:35">[00:32:35]</a>. Users don't have to trust the provider or platform because they can verify; if attempts are made to bypass the security, the protocol prevents the application and data from loading <a class="yt-timestamp" data-t="00:32:51">[00:32:51]</a>.

**Multi-Party Training Example**:
Consider three participants: Alice's lab and Bob's clinic (holding sensitive data), and Carol's research center (bringing a training engine) <a class="yt-timestamp" data-t="00:33:30">[00:33:30]</a>. The goal is to train a new model for early cancer detection on Alice's and Bob's data without exposing either the data or Carol's intellectual property <a class="yt-timestamp" data-t="00:33:42">[00:33:42]</a>. All three inputs run inside a TEE, making them inaccessible to the cloud host, Super Protocol, or even the participants <a class="yt-timestamp" data-t="00:33:51">[00:33:51]</a>. Outside the TEE, each party retains full custody of its assets <a class="yt-timestamp" data-t="00:34:07">[00:34:07]</a>.

Training is fully automated by the verified engine, the Super Protocol certification center, and smart contracts <a class="yt-timestamp" data-t="00:34:17">[00:34:17]</a>. A Confidential Virtual Machine (CVM) handles multiple jobs and, on boot, contacts the open-source certification authority (also in confidential mode) for a remote attestation <a class="yt-timestamp" data-t="00:34:49">[00:34:49]</a>. If the check passes, a certificate proves the CVM is genuine and running in an attested TEE <a class="yt-timestamp" data-t="00:35:08">[00:35:08]</a>. An open-source security mechanism (trusted loader) inside the CVM is also attested and then checks every component; if any check fails, the process stops to safeguard all parties <a class="yt-timestamp" data-t="00:35:18">[00:35:18]</a>.

Carol uploads her engine image to encrypted storage, providing its hash and source code for verification by Alice and Bob <a class="yt-timestamp" data-t="00:35:57">[00:35:57]</a>. Alice and Bob archive and upload their datasets, which are encrypted during upload <a class="yt-timestamp" data-t="00:36:39">[00:36:39]</a>. They grant the CVM access, specifying the verified engine's hash and the CVM's ID <a class="yt-timestamp" data-t="00:37:16">[00:37:16]</a>. Only the specified CVM with the private key can decrypt the data <a class="yt-timestamp" data-t="00:37:37">[00:37:37]</a>.

Carol places the main order to process the workload <a class="yt-timestamp" data-t="00:37:46">[00:37:46]</a>. When submitted, the trusted loader checks the CVM certificate, calculates hashes for the engine, datasets, and config, and compares them with an approved list, blocking the job if anything diverges <a class="yt-timestamp" data-t="00:37:56">[00:37:56]</a>. Only if every hash matches does training start inside the TEE <a class="yt-timestamp" data-t="00:38:08">[00:38:08]</a>. Data and the engine are only decrypted inside the TEE, protected from participants and even the system owner <a class="yt-timestamp" data-t="00:38:15">[00:38:15]</a>. Only Carol receives the encrypted output (the newly trained model and artifacts) <a class="yt-timestamp" data-t="00:38:27">[00:38:27]</a>. Encryption keys never leave the TEE <a class="yt-timestamp" data-t="00:38:35">[00:38:35]</a>.

After the job, raw inputs are wiped, and an order report is published on-chain, providing public, tamper-proof evidence that the job ran in a certified environment with approved inputs <a class="yt-timestamp" data-t="00:40:06">[00:40:06]</a>. This report includes certificates, processed inputs, and timing, with hashes matching the trusted engine and data <a class="yt-timestamp" data-t="00:40:23">[00:40:23]</a>. During runtime, an app inside a CVM can sign data with its private key, which can be verified on-chain, crucial for Web3 AI workflows <a class="yt-timestamp" data-t="00:41:21">[00:41:21]</a>.

This demonstrates how Super Protocol simplifies complex, multi-party, trust-heavy collaboration into a push-button workflow <a class="yt-timestamp" data-t="00:41:47">[00:41:47]</a>.

## Conclusion

Super Protocol offers a practical path forward for developers, providing a solution that is simple to use, transparent, verifiable, and secure by design <a class="yt-timestamp" data-t="00:42:53">[00:42:53]</a>. By enabling GPUless, trustless, and limitless operations <a class="yt-timestamp" data-t="00:42:59">[00:42:59]</a>, it allows for:
*   Running models on private data without exposure <a class="yt-timestamp" data-t="00:42:37">[00:42:37]</a>.
*   Deploying proprietary models without losing control <a class="yt-timestamp" data-t="00:42:40">[00:42:40]</a>.
*   Fine-tuning without compliance risk <a class="yt-timestamp" data-t="00:42:42">[00:42:42]</a>.
*   Verifying execution with cryptographic proof <a class="yt-timestamp" data-t="00:42:45">[00:42:45]</a>.