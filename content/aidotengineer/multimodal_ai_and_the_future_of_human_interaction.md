---
title: Multimodal AI and the Future of Human Interaction
videoId: HS5a8VIKsvA
---

From: [[aidotengineer]] <br/> 

The year 2025 marks a "perfect storm for [[voice_and_multimodal_ai_agents | AI agents]]" <a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>, driven by reasoning models outperforming human ability, increased test-time compute, advanced engineering, cheaper inference and hardware, and massive infrastructure investments globally <a class="yt-timestamp" data-t="00:04:48">[00:04:48]</a>. An [[voice_and_multimodal_ai_agents | AI agent]] is defined as a fully autonomous system where Large Language Models (LLMs) direct their own actions <a class="yt-timestamp" data-t="00:05:14">[00:05:14]</a>.

## Current State and Challenges
Despite the rapid [[advancements_in_ai_and_future_implications | advancements in AI]], [[voice_and_multimodal_ai_agents | AI agents]] are not yet fully functional as anticipated <a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a>. This is often due to "tiny cumulative errors" that accumulate, rather than outright hallucinations <a class="yt-timestamp" data-t="00:06:54">[00:06:54]</a>. These errors can include:
*   **Decision Errors:** Choosing the wrong fact, such as booking a flight to "San Francisco Peru" instead of "San Francisco California" <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>.
*   **Implementation Errors:** Incorrect access or integration, leading to issues like being locked out of a database <a class="yt-timestamp" data-t="00:07:26">[00:07:26]</a>.
*   **Heuristic Errors:** Applying the wrong criteria, such as failing to account for rush hour traffic when booking a flight <a class="yt-timestamp" data-t="00:07:44">[00:07:44]</a>.
*   **Taste Errors:** Misjudging personal preferences, like booking a flight on a specific aircraft type the user dislikes <a class="yt-timestamp" data-t="00:08:03">[00:08:03]</a>.

The "Perfection Paradox" arises when users get frustrated with [[voice_and_multimodal_ai_agents | AI agents]] that perform at human speed or are inconsistent, despite their magical capabilities <a class="yt-timestamp" data-t="00:08:22">[00:08:22]</a>. Even highly accurate agents can show significant performance disparities over many steps, making complex tasks unreliable <a class="yt-timestamp" data-t="00:09:00">[00:09:00]</a>.

## Strategies for Improving AI Interaction
To optimize [[voice_and_multimodal_ai_agents | AI agents]] and improve user interaction, several best practices are emerging:

### Data Curation
Ensuring [[voice_and_multimodal_ai_agents | AI agents]] have access to clean, structured data is crucial <a class="yt-timestamp" data-t="00:10:09">[00:10:09]</a>. This includes proprietary data, data generated by the agent itself, and data used for quality control in the model workflow <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>. Building an "agent data flywheel" ensures that every user interaction improves the product in real-time <a class="yt-timestamp" data-t="00:10:49">[00:10:49]</a>.

### Evaluations (Evals)
Measuring a model's response and determining the correct answer is critical <a class="yt-timestamp" data-t="00:11:22">[00:11:22]</a>. While straightforward in verifiable domains (like math), it's challenging for non-verifiable systems where human preferences and subjective signals need to be collected and understood <a class="yt-timestamp" data-t="00:11:47">[00:11:47]</a>.

### Scaffolding Systems
Implementing infrastructure logic to prevent cascading errors when an applied [[applications_and_future_of_ai_technology | AI feature]] fails is essential <a class="yt-timestamp" data-t="00:12:45">[00:12:45]</a>. This can involve building complex compound systems or bringing a human back into the loop for reasoning <a class="yt-timestamp" data-t="00:13:08">[00:13:08]</a>. The goal is to develop stronger agents that can self-heal, correct their own path, or break execution when unsure <a class="yt-timestamp" data-t="00:13:20">[00:13:20]</a>.

### [[building_user_experiences_with_ai | User Experience (UX)]]
UX is paramount in making [[voice_and_multimodal_ai_agents | AI agents]] better co-pilots <a class="yt-timestamp" data-t="00:13:47">[00:13:47]</a>. As foundation models become commodities, the ability to reimagine product experiences, deeply understand user workflows, and promote "beautiful elegant [[human_ai_collaboration_and_cocreation | human machine collaboration]]" <a class="yt-timestamp" data-t="00:14:07">[00:14:07]</a> differentiates companies <a class="yt-timestamp" data-t="00:14:47">[00:14:47]</a>. This includes features like asking clarifying questions, predicting next steps, and seamlessly integrating with legacy systems <a class="yt-timestamp" data-t="00:14:13">[00:14:13]</a>. The focus should be on leveraging proprietary data and deep user workflow knowledge in fields like robotics, hardware, defense, manufacturing, and life sciences to create magical end-user experiences <a class="yt-timestamp" data-t="00:14:55">[00:14:55]</a>.

### [[multimodal_interaction_in_apps | Building Multimodally]]
The future of [[the_evolution_of_ai_interfaces_and_user_interaction | AI interfaces and user interaction]] lies in "[[multimodal_interaction_in_apps | multimodal]]" experiences beyond just text-based chatbots <a class="yt-timestamp" data-t="00:15:26">[00:15:26]</a>. Incorporating new modalities can create a 10x more personalized user experience <a class="yt-timestamp" data-t="00:15:28">[00:15:28]</a>. This means making AI more human by adding "eyes and ears nose a voice" <a class="yt-timestamp" data-t="00:15:45">[00:15:45]</a>.

*   **Voice:** Significant improvements in voice technology are making it "pretty scary good" <a class="yt-timestamp" data-t="00:15:50">[00:15:50]</a>.
*   **Smell:** Companies are digitizing the sense of smell <a class="yt-timestamp" data-t="00:15:54">[00:15:54]</a>.
*   **Touch:** Instilling a more human feeling and sense of embodiment through robotics <a class="yt-timestamp" data-t="00:16:01">[00:16:01]</a>.
*   **Memories:** Enabling AI to become truly personal and know the user on a much deeper level <a class="yt-timestamp" data-t="00:16:07">[00:16:07]</a>.

By developing visionary products that exceed expectations through [[multimodal_interaction_in_apps | multimodal]] interaction, the perceived inconsistency of [[voice_and_multimodal_ai_agents | AI agents]] becomes less of a hindrance <a class="yt-timestamp" data-t="00:16:18">[00:16:18]</a>. The goal is to create seamless experiences where users might not even realize they are interacting with a large language model in the background <a class="yt-timestamp" data-t="00:16:40">[00:16:40]</a>.

Ultimately, the [[future_of_ai_in_improving_user_experience_and_integrations | future of AI in improving user experience and integrations]] depends on thinking bigger, leveraging [[multimodal_interaction_in_apps | multimodality]], and designing innovative product experiences that truly set the workflow and vision apart <a class="yt-timestamp" data-t="00:17:17">[00:17:17]</a>.