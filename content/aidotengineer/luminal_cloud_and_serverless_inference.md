---
title: Luminal cloud and serverless inference
videoId: 0uj9lMI-sIo
---

From: [[aidotengineer]] <br/> 

[[luminal_deep_learning_library | Luminal]] is developing a cloud offering designed to provide a simple, fast, and straightforward experience for machine learning inference <a class="yt-timestamp" data-t="00:23:36">[00:23:36]</a>. This platform leverages Luminal's ability to represent models as graphs <a class="yt-timestamp" data-t="00:23:11">[00:23:11]</a>.

## How it Works
Users can export their model graphs from [[luminal_deep_learning_library | Luminal]] into a file <a class="yt-timestamp" data-t="00:23:14">[00:23:14]</a>. This file can then be uploaded to the Luminal cloud to obtain a serverless inference endpoint <a class="yt-timestamp" data-t="00:23:18">[00:23:18]</a>.

The Luminal cloud handles various complexities:
*   **Optimization** <a class="yt-timestamp" data-t="00:23:24">[00:23:24]</a>
*   **Batching and queuing** <a class="yt-timestamp" data-t="00:23:25">[00:23:25]</a>
*   **Provisioning machines** <a class="yt-timestamp" data-t="00:23:28">[00:23:28]</a> (related to [[gpu_and_server_configurations_for_ai | GPU and server configurations for AI]])

## Serverless Benefits
The platform is entirely serverless <a class="yt-timestamp" data-t="00:23:30">[00:23:30]</a>, meaning users only pay for the time their graph is actively executing <a class="yt-timestamp" data-t="00:23:32">[00:23:32]</a>. This approach aims to deliver a highly efficient and cost-effective solution for [[full_stack_ai_engineering_in_serverless_environments | full stack AI engineering in serverless environments]] related to inference <a class="yt-timestamp" data-t="00:23:34">[00:23:34]</a>.

> [!INFO] Goal
> Luminal's objective is to build the "simplest, fastest ML cloud in the world" <a class="yt-timestamp" data-t="00:24:18">[00:24:18]</a>. This simplicity allows for faster innovation compared to more complex frameworks <a class="yt-timestamp" data-t="00:24:03">[00:24:03]</a>.