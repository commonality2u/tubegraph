---
title: Common pitfalls in AI strategy
videoId: 89aQ7T6cMwA
---

From: [[aidotengineer]] <br/> 

This article, drawn from an inverted presentation on how to "spectacularly mess up your AI strategy," highlights critical missteps to avoid when developing and deploying AI systems <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>. By understanding these "worse practices," organizations can navigate the complexities of AI development more effectively <a class="yt-timestamp" data-t="00:00:54">[00:00:54]</a>.

## Fostering Internal Division and Disconnect

A primary pitfall is the deliberate creation of internal silos and a disconnect within the company <a class="yt-timestamp" data-t="02:27:07">[02:27:07]</a>.

### Siloing Knowledge
*   **Lack of Communication** Attending AI industry conferences but never sharing learned insights with the team creates "impenetrable silos" and incentivizes secrecy <a class="yt-timestamp" data-t="02:53:05">[02:53:05]</a>. The goal is to divide and conquer one's own company <a class="yt-timestamp" data-t="02:27:07">[02:27:07]</a>.
*   **Embracing Disconnect** A key mistake is to disregard the relationship between willingness to pay, price, and cost, aiming for "unreasonable goals" that fail to create value <a class="yt-timestamp" data-t="02:35:08">[02:35:08]</a>. This is framed as adhering to an "anti-value stick," the opposite of strategic value creation <a class="yt-timestamp" data-t="03:18:05">[03:18:05]</a>.

### Mismanaging Value Perception
*   **Wishful Thinking Promises (WTP)** Making exaggerated promises to customers about AI's capabilities, such as solving climate change or achieving world peace, without worrying about the details <a class="yt-timestamp" data-t="03:32:05">[03:32:05]</a>.
*   **Particularly Ridiculous Infrastructure Costs (PRICE)** Buying the most expensive GPUs without cost-benefit analysis, maxing out company credit cards as a vague "investment" <a class="yt-timestamp" data-t="03:54:05">[03:54:05]</a>.
*   **Cascade of Spectacular Technical Debt (COST)** Building convoluted, intertwined systems that even executives barely understand, leading to guaranteed job security when they inevitably break <a class="yt-timestamp" data-t="04:16:05">[04:16:05]</a>.
*   **Why This System? (WTS)** Justifying AI projects solely with "because AI" without further explanation, treating it as "magic but much more expensive and less reliable" <a class="yt-timestamp" data-t="04:45:05">[04:45:05]</a>.

## Defining a Flawed AI Strategy

Poor strategy definition is a guaranteed path to failure <a class="yt-timestamp" data-t="05:04:05">[05:04:05]</a>.

### Vague and Unrealistic Objectives
*   **Fake Diagnosis** Grabbing random, poorly understood paragraphs from old reports and declaring them "must fix" issues without consulting those who do the actual work <a class="yt-timestamp" data-t="05:06:05">[05:06:05]</a>.
*   **Ambiguous Guiding Policy** Defining a strategy that is "incredibly ambiguous and vague," such as aiming to "become the global AI leader in everything" without defining what "everything" means <a class="yt-timestamp" data-t="05:27:05">[05:27:05]</a>.
*   **Absurd Action Plans** Including nonsensical action items like an "AI-powered SEO tool that guarantees top Google search results even if you sell garden gnomes," a generative art plug-in for NFTs of the CEO's cat, or an "AI drone lunch delivery service" <a class="yt-timestamp" data-t="05:41:05">[05:41:05]</a>.
*   **Ignoring Timelines** Embracing "Perpetual beta" and never intending to finish projects, instead creating massive backlogs with highlighted financial reports <a class="yt-timestamp" data-t="06:07:05">[06:07:05]</a>.
*   **Overwhelming Documentation** Creating overly long documents (e.g., 4,000 pages) and distributing them widely to "erode people's willpower to engage with the material" <a class="yt-timestamp" data-t="06:25:05">[06:25:05]</a>.

## Communication Breakdown and Jargon Abuse

One of the most effective ways to cause dysfunction is through pervasive and strategic use of jargon <a class="yt-timestamp" data-t="07:31:05">[07:31:05]</a>. This is a common [[avoiding_effective_communication_in_ai_deployment | communication challenge]] in AI deployment.

*   **Obfuscation** Using jargon to appear smart without being understood, making it impossible for others to engage or understand the true purpose <a class="yt-timestamp" data-t="06:46:05">[06:46:05]</a>. An example is "our multimodal agentic Transformer-based system leverages few-shot learning and Chain of Thought reasoning to optimize the synergistic potential of our Dynamic hyperparameter space" <a class="yt-timestamp" data-t="06:53:05">[06:53:05]</a>.
*   **Hiding "Jobs to Be Done"** Using technical terms like "building agents" instead of "writing a prompt" to exclude non-technical experts, such as mental health professionals, from understanding or participating in the process <a class="yt-timestamp" data-t="07:41:05">[07:41:05]</a>. This contributes to [[design_challenges_for_ai_agents | design challenges for AI agents]].
*   **Excluding Domain Experts** Using terms like "RAGs" instead of "making sure the AI has the right context" or "prompt injections" instead of "making sure users can't trick the AI into doing something bad" to alienate and exclude domain experts <a class="yt-timestamp" data-t="08:12:05">[08:12:05]</a>.
*   **Engineer-Centric Prompting** Encouraging engineers, rather than those who best understand customers, to write prompts <a class="yt-timestamp" data-t="08:24:05">[08:24:05]</a>.
*   **Making Everything Seem Technical** Deliberately making mundane tasks, like writing prompts, appear "super technical and out of reach for everyone" <a class="yt-timestamp" data-t="08:50:05">[08:50:05]</a>.

## Ineffective Mobilization of Teams

Mobilizing teams incorrectly is a significant pitfall that can lead to total collapse <a class="yt-timestamp" data-t="09:08:05">[09:08:05]</a>.

### Misallocating Resources
*   **Random Task Assignment** Randomly assigning AI tasks to individuals with "absolutely no relevant experience" <a class="yt-timestamp" data-t="09:24:05">[09:24:05]</a>. This is a clear case of [[mismanagement_of_ai_resources | mismanagement of AI resources]].
*   **Outsourcing Without Context** Outsourcing critical tasks like data review to offshore Q&A teams with "very little context about your business" <a class="yt-timestamp" data-t="09:32:05">[09:32:05]</a>.
*   **Premature Launching** Launching "completely untested bug-ridden AI chatbots directly to your customers" from an "incubation zone" without beta testing or quality assurance <a class="yt-timestamp" data-t="09:41:05">[09:41:05]</a>. This is a common [[challenges_with_current_ai_implementation | challenge with current AI implementation]].
*   **Disrupting Core Business** Yanking the best engineers from revenue-producing products to work on AI projects, leading to "total collapse" <a class="yt-timestamp" data-t="10:12:05">[10:12:05]</a>.

## Over-reliance on Tools and Data Avoidance

A critical mistake is to prioritize tools over processes and actively avoid looking at data <a class="yt-timestamp" data-t="10:39:05">[10:39:05]</a>.

### Tool-Centric Problem Solving
*   **Ignoring Process** Focusing on tools instead of processes to solve problems, throwing new tools at issues without analyzing or understanding them <a class="yt-timestamp" data-t="10:42:05">[10:42:05]</a>.
*   **Blindly Adopting Tools** For instance, if a RAG system fails, immediately buying a new, more expensive vector database rather than diagnosing the root cause <a class="yt-timestamp" data-t="10:51:05">[10:51:05]</a>.
*   **Uncritical Evaluation** Using every "off-the-shelf evaluation metric" without customizing them to business needs, blindly trusting numbers even if they make no sense <a class="yt-timestamp" data-t="11:01:05">[11:01:05]</a>. This contributes to [[challenges_in_building_reliable_ai_agents | challenges in building reliable AI agents]].
*   **Frequent Framework Changes** If AI agents aren't working, picking a new framework and vendor, or fine-tuning without any measurement or evaluation, assuming it will be better <a class="yt-timestamp" data-t="11:15:05">[11:15:05]</a>. This highlights common [[challenges in developing AI agents | development challenges for AI agents]].
*   **"Whack-a-Mole" Approach** Consistently hammering every problem with a new tool, even if the same problem recurs <a class="yt-timestamp" data-t="11:46:05">[11:46:05]</a>. This is the opposite of [[best_practices_for_building_ai_systems | best practices for building AI systems]].
*   **"Vendor Problem" Mindset** Believing that evaluations are solely a "vendor problem" and that a "one-size-fits-all solution" exists, allowing vendors to figure everything out <a class="yt-timestamp" data-t="12:09:05">[12:09:05]</a>. This also impacts [[costeffective_ai_strategies | cost-effective AI strategies]].

### Misleading Metrics and Data Avoidance
*   **Meaningless Dashboards** Creating dashboards filled with numerous off-the-shelf metrics that don't track with outcomes or real failure modes, making numbers unintelligible <a class="yt-timestamp" data-t="12:26:05">[12:26:05]</a>.
*   **Hoarding Random Metrics** Hoarding random metrics until one goes "up and to the right," then claiming success <a class="yt-timestamp" data-t="12:44:05">[12:44:05]</a>. This is a common pitfall in [[best_practices_and_lessons_learned_in_ai_agent_development | AI agent development]].
*   **Blindly Trusting Metrics** Adopting all metrics from eval frameworks blindly and never asking whether they actually measure success <a class="yt-timestamp" data-t="13:01:05">[13:01:05]</a>.
*   **Ignoring User Experience** Optimizing for metrics like cosine similarity, BLEU, and ROUGE while ignoring actual user experience <a class="yt-timestamp" data-t="13:17:05">[13:17:05]</a>.
*   **Avoiding Data** Actively avoiding looking at data, keeping a "blindfold" ready to avoid accidental data exposure <a class="yt-timestamp" data-t="13:42:05">[13:42:05]</a>.
*   **Implicit Trust in AI** Absolutely trusting AI output without ever looking at it, considering data analysis an "engineering problem" <a class="yt-timestamp" data-t="13:56:05">[13:56:05]</a>.
*   **Ignoring Customers** Believing developers have more domain expertise than business teams and treating customers as the "best Q&A" <a class="yt-timestamp" data-t="14:18:05">[14:18:05]</a>.
*   **Trusting Gut Over Data** Relying on gut feelings as a "reliable substitute for data" when making million-dollar decisions <a class="yt-timestamp" data-t="14:34:05">[14:34:05]</a>.
*   **Complex Data Storage** Storing data in complex systems accessible only to engineers, thereby preventing domain experts from accessing or understanding it <a class="yt-timestamp" data-t="15:20:05">[15:20:05]</a>. Insisting on expensive custom data analysis platforms requiring PhD teams to operate, taking months to load and prone to errors <a class="yt-timestamp" data-t="15:39:05">[15:39:05]</a>.

By consciously avoiding these "worst practices," organizations can prevent wasting time and resources, and foster better collaboration within their teams <a class="yt-timestamp" data-t="16:04:05">[16:04:05]</a>.