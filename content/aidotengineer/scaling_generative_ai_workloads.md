---
title: Scaling generative AI workloads
videoId: wHhlvcQgi9M
---

From: [[aidotengineer]] <br/> 

Justin Mohler, a principal applied AI architect at AWS, shares insights on [[Challenges in scaling AI products | scaling generative AI workloads]] based on his 15 years of experience in natural language processing and four years in generative AI at AWS <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a> <a class="yt-timestamp" data-t="00:00:20">[00:00:20]</a> <a class="yt-timestamp" data-t="00:00:23">[00:00:23]</a>. His small specialist team assists customers with [[Scaling AI agents in production | scaling GenAI workloads]] across various industries and customer sizes, including some of the largest in North America <a class="yt-timestamp" data-t="00:00:30">[00:00:30]</a> <a class="yt-timestamp" data-t="00:00:32">[00:00:32]</a> <a class="yt-timestamp" data-t="00:00:35">[00:00:35]</a> <a class="yt-timestamp" data-t="00:00:38">[00:00:38]</a> <a class="yt-timestamp" data-t="00:00:42">[00:00:42]</a>. Through this experience, he has observed common failure points and [[Best practices for building resilient AI workflows | best practices]] from successful projects, which he shares in talks <a class="yt-timestamp" data-t="00:00:47">[00:00:47]</a> <a class="yt-timestamp" data-t="00:00:50">[00:00:50]</a> <a class="yt-timestamp" data-t="00:00:52">[00:00:52]</a> <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>.

## The Biggest Challenge in Scaling Generative AI

According to Mohler, the biggest challenge in [[Scaling AI agents in production | scaling generative AI]] is evaluations <a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a> <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. While concerns like cost, hallucinations, accuracy, and capacity are often raised, a lack of evaluations is consistently the number one issue across all workloads <a class="yt-timestamp" data-t="00:01:29">[00:01:29]</a> <a class="yt-timestamp" data-t="00:01:33">[00:01:33]</a> <a class="yt-timestamp" data-t="00:01:35">[00:01:35]</a> <a class="yt-timestamp" data-t="00:01:37">[00:01:37]</a> <a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>. Evaluations are the "missing piece" that, when added, unlocks the ability to scale generative AI workloads <a class="yt-timestamp" data-t="00:01:47">[00:01:47]</a> <a class="yt-timestamp" data-t="00:02:07">[00:02:07]</a> <a class="yt-timestamp" data-t="00:02:14">[00:02:14]</a>.

### Customer Example: Document Processing Workload

In July 2024, Mohler was called in to assist a customer with a document processing workload that had been in development for six to twelve months with six to eight engineers <a class="yt-timestamp" data-t="00:02:20">[00:02:20]</a> <a class="yt-timestamp" data-t="00:02:26">[00:02:26]</a> <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a> <a class="yt-timestamp" data-t="00:02:34">[00:02:34]</a>. The project's accuracy was only 22%, leading the VP of technology to consider cutting it <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a> <a class="yt-timestamp" data-t="00:02:48">[00:02:48]</a> <a class="yt-timestamp" data-t="00:02:52">[00:02:52]</a>.

Upon discovery, Mohler found that the project had zero evaluations <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a> <a class="yt-timestamp" data-t="00:03:06">[00:03:06]</a>. While they had an end-to-end process, they only had a single accuracy number <a class="yt-timestamp" data-t="00:03:10">[00:03:10]</a> <a class="yt-timestamp" data-t="00:03:12">[00:03:12]</a>. Mohler designed an evaluation framework, which revealed the exact locations of the problems <a class="yt-timestamp" data-t="00:03:16">[00:03:16]</a> <a class="yt-timestamp" data-t="00:03:20">[00:03:20]</a>. Fixing these issues became trivial once identified <a class="yt-timestamp" data-t="00:03:25">[00:03:25]</a> <a class="yt-timestamp" data-t="00:03:29">[00:03:29]</a>. Over the next six months, the team built the framework and fixed the issues, achieving 92% accuracy by January, exceeding their 90% production launch threshold <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a> <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a> <a class="yt-timestamp" data-t="00:03:47">[00:03:47]</a>. This allowed them to launch and become the single largest document processing workload on AWS in North America at that time <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a> <a class="yt-timestamp" data-t="00:03:57">[00:03:57]</a>.

## What are Generative AI Evaluations?

While evaluations in traditional AI/ML often focus on measuring quality (e.g., F1 score, precision, recall) <a class="yt-timestamp" data-t="00:04:11">[00:04:11]</a> <a class="yt-timestamp" data-t="00:04:15">[00:04:15]</a> <a class="yt-timestamp" data-t="00:04:22">[00:04:22]</a>, the main goal with any generative AI evaluation framework should be to **discover problems** <a class="yt-timestamp" data-t="00:04:40">[00:04:40]</a> <a class="yt-timestamp" data-t="00:04:43">[00:04:43]</a>. Although generative AI evaluations produce a score, this is a secondary benefit <a class="yt-timestamp" data-t="00:04:31">[00:04:31]</a>. By identifying where problems are and potentially suggesting solutions through generative AI reasoning, workloads can be improved <a class="yt-timestamp" data-t="00:04:48">[00:04:48]</a> <a class="yt-timestamp" data-t="00:04:51">[00:04:51]</a> <a class="yt-timestamp" data-t="00:04:56">[00:04:56]</a>. Designing an evaluation framework with an error-finding mindset is crucial <a class="yt-timestamp" data-t="00:05:03">[00:05:03]</a> <a class="yt-timestamp" data-t="00:05:08">[00:05:08]</a>.

### Evaluations as a Filter for Project Success

Mohler's team uses evaluations as the number one filter to distinguish between a "science project" and a "successful project" <a class="yt-timestamp" data-t="00:05:35">[00:05:35]</a> <a class="yt-timestamp" data-t="00:05:42">[00:05:42]</a> <a class="yt-timestamp" data-t="00:05:44">[00:05:44]</a>. Teams willing to invest time in building a gold standard set for evaluations are typically successful, while those who just want "toys to play with" without focusing on evaluation often fail to scale <a class="yt-timestamp" data-t="00:05:57">[00:05:57]</a> <a class="yt-timestamp" data-t="00:06:06">[00:06:06]</a> <a class="yt-timestamp" data-t="00:06:09">[00:06:09]</a> <a class="yt-timestamp" data-t="00:06:12">[00:06:12]</a> <a class="yt-timestamp" data-t="00:06:19">[00:06:19]</a>. Wildly successful projects, often achieving 100x ROI or significant cost reductions, prioritize evaluation frameworks <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a> <a class="yt-timestamp" data-t="00:06:25">[00:06:25]</a> <a class="yt-timestamp" data-t="00:06:28">[00:06:28]</a> <a class="yt-timestamp" data-t="00:06:30">[00:06:30]</a>.

## Addressing Generative AI Evaluation Complexities

Evaluating generative AI outputs, often free-form text, can seem daunting, especially for those with a traditional AI/ML background accustomed to precise numeric scores <a class="yt-timestamp" data-t="00:06:54">[00:06:54]</a> <a class="yt-timestamp" data-t="00:06:59">[00:06:59]</a> <a class="yt-timestamp" data-t="00:07:02">[00:07:02]</a> <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>. However, humans have been grading free text for centuries (e.g., essays) <a class="yt-timestamp" data-t="00:07:14">[00:07:14]</a> <a class="yt-timestamp" data-t="00:07:22">[00:07:22]</a>. The key is to not just assign a score, but to **point out what went wrong and where to improve**, similar to a good professor providing feedback with a rubric <a class="yt-timestamp" data-t="00:08:01">[00:08:01]</a> <a class="yt-timestamp" data-t="00:08:16">[00:08:16]</a> <a class="yt-timestamp" data-t="00:20:48">[00:20:48]</a>.

### The Importance of Reasoning

Evaluating *how* a generative AI model arrived at an answer is as critical as evaluating the answer itself <a class="yt-timestamp" data-t="00:09:20">[00:09:20]</a> <a class="yt-timestamp" data-t="00:09:31">[00:09:31]</a>.

*   **2x4 Example**: If a 1-inch hole is drilled through a 2x4, the output appears correct <a class="yt-timestamp" data-t="00:08:42">[00:08:42]</a> <a class="yt-timestamp" data-t="00:08:45">[00:08:45]</a> <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>. However, if the methodology was dangerous (e.g., drilling with unsafe tools and posture), even a correct output indicates a flawed system that needs rethinking <a class="yt-timestamp" data-t="00:09:11">[00:09:11]</a> <a class="yt-timestamp" data-t="00:09:16">[00:09:16]</a> <a class="yt-timestamp" data-t="00:09:25">[00:09:25]</a>.
*   **Meteorology Company Example**: A meteorology company used generative AI to summarize local weather from sensor data <a class="yt-timestamp" data-t="00:09:42">[00:09:42]</a> <a class="yt-timestamp" data-t="00:09:44">[00:09:44]</a> <a class="yt-timestamp" data-t="00:09:47">[00:09:47]</a>.
    *   If the input indicates rain and 40Â° but the summary says "sunny and bright," the score is zero <a class="yt-timestamp" data-t="00:09:56">[00:09:56]</a> <a class="yt-timestamp" data-t="00:10:00">[00:10:00]</a> <a class="yt-timestamp" data-t="00:10:05">[00:10:05]</a> <a class="yt-timestamp" data-t="00:10:12">[00:10:12]</a>. However, simply knowing the score doesn't explain *why* it failed <a class="yt-timestamp" data-t="00:10:14">[00:10:14]</a>.
    *   If the model's reasoning is, "It's important to mental health to be happy, so I decided not to talk about the rain," this insight reveals the problem: the model is prioritizing a positive tone over factual accuracy <a class="yt-timestamp" data-t="00:10:16">[00:10:16]</a> <a class="yt-timestamp" data-t="00:10:20">[00:10:20]</a> <a class="yt-timestamp" data-t="00:10:22">[00:10:22]</a> <a class="yt-timestamp" data-t="00:10:23">[00:10:23]</a>. This allows for targeted fixes <a class="yt-timestamp" data-t="00:10:29">[00:10:29]</a>.
    *   Conversely, if the input is "sunny" and the response is "sunny" (score 10/10), it appears successful <a class="yt-timestamp" data-t="00:10:40">[00:10:40]</a> <a class="yt-timestamp" data-t="00:10:44">[00:10:44]</a>. But if the reasoning was equally flawed (e.g., "I decided not to talk about the rain"), this indicates the prompt isn't working correctly, and the success was coincidental <a class="yt-timestamp" data-t="00:10:54">[00:10:54]</a> <a class="yt-timestamp" data-t="00:10:57">[00:10:57]</a> <a class="yt-timestamp" data-t="00:11:00">[00:11:00]</a> <a class="yt-timestamp" data-t="00:11:03">[00:11:03]</a>.

## Prompt Decomposition

Prompt decomposition involves breaking a large, complex prompt into a series of chained, smaller prompts <a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a> <a class="yt-timestamp" data-t="00:11:59">[00:11:59]</a> <a class="yt-timestamp" data-t="00:13:02">[00:13:02]</a>. While not exclusive to evaluations, it greatly aids them because evaluations can then be attached to each section of the prompt <a class="yt-timestamp" data-t="00:11:28">[00:11:28]</a> <a class="yt-timestamp" data-t="00:11:30">[00:11:30]</a> <a class="yt-timestamp" data-t="00:13:07">[00:13:07]</a>. This allows identification of exactly which part of the prompt is failing, helping to focus improvement efforts <a class="yt-timestamp" data-t="00:11:56">[00:11:56]</a> <a class="yt-timestamp" data-t="00:11:59">[00:11:59]</a> <a class="yt-timestamp" data-t="00:13:11">[00:13:11]</a> <a class="yt-timestamp" data-t="00:13:15">[00:13:15]</a>.

It also helps determine if generative AI is the right tool for a specific part of the prompt <a class="yt-timestamp" data-t="00:13:18">[00:13:18]</a> <a class="yt-timestamp" data-t="00:13:21">[00:13:21]</a>. For the weather company, a section of their prompt handled wind speed classification (e.g., wind speed > 5 means windy) <a class="yt-timestamp" data-t="00:12:12">[00:12:12]</a> <a class="yt-timestamp" data-t="00:12:14">[00:12:14]</a> <a class="yt-timestamp" data-t="00:12:21">[00:12:21]</a>. While this worked in proof-of-concept, it sometimes failed at scale (e.g., Claude incorrectly stating "seven is less than five") <a class="yt-timestamp" data-t="00:12:35">[00:12:35]</a> <a class="yt-timestamp" data-t="00:12:38">[00:12:38]</a> <a class="yt-timestamp" data-t="00:12:41">[00:12:41]</a>. By decomposing the prompt, they replaced the mathematical comparison with a Python step, achieving 100% accuracy for that part <a class="yt-timestamp" data-t="00:12:51">[00:12:51]</a> <a class="yt-timestamp" data-t="00:13:28">[00:13:28]</a> <a class="yt-timestamp" data-t="00:13:30">[00:13:30]</a> <a class="yt-timestamp" data-t="00:13:33">[00:13:33]</a> <a class="yt-timestamp" data-t="00:13:38">[00:13:38]</a> <a class="yt-timestamp" data-t="00:13:42">[00:13:42]</a>.

### Semantic Routing

Semantic routing is a common pattern in [[Agentic architectures for generative AI | agentic architectures for generative AI]] <a class="yt-timestamp" data-t="00:14:02">[00:14:02]</a>. An incoming query is first routed to the appropriate model based on its task complexity (e.g., easy tasks to small models, hard tasks to large models) <a class="yt-timestamp" data-t="00:14:03">[00:14:03]</a> <a class="yt-timestamp" data-t="00:14:08">[00:14:08]</a> <a class="yt-timestamp" data-t="00:14:11">[00:14:11]</a>. This ensures the "right model for the job" is used <a class="yt-timestamp" data-t="00:14:18">[00:14:18]</a>.

Attaching evaluations to each step of semantic routing is crucial <a class="yt-timestamp" data-t="00:14:34">[00:14:34]</a> <a class="yt-timestamp" data-t="00:14:37">[00:14:37]</a>. For a semantic router, the evaluation input might be a query, and the output is a simple number indicating the chosen route <a class="yt-timestamp" data-t="00:14:39">[00:14:39]</a> <a class="yt-timestamp" data-t="00:14:41">[00:14:41]</a> <a class="yt-timestamp" data-t="00:14:43">[00:14:43]</a>. Breaking down prompts this way significantly increases accuracy by removing "dead space" or "dead tokens" (unnecessary instructions for a given task), which reduces cost and confusion for the model <a class="yt-timestamp" data-t="00:14:47">[00:14:47]</a> <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a> <a class="yt-timestamp" data-t="00:14:52">[00:14:52]</a> <a class="yt-timestamp" data-t="00:14:54">[00:14:54]</a> <a class="yt-timestamp" data-t="00:15:10">[00:15:10]</a> <a class="yt-timestamp" data-t="00:15:14">[00:15:14]</a> <a class="yt-timestamp" data-t="00:15:17">[00:15:17]</a>.

## Seven Habits of Highly Effective Generative AI Evaluations

Mohler identifies seven common trends among successful generative AI workloads that have scaled, all of which include robust evaluations <a class="yt-timestamp" data-t="00:15:35">[00:15:35]</a> <a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a> <a class="yt-timestamp" data-t="00:15:40">[00:15:40]</a> <a class="yt-timestamp" data-t="00:15:42">[00:15:42]</a>.

1.  **Fast**: Evaluations should run quickly, ideally within 30 seconds <a class="yt-timestamp" data-t="00:15:50">[00:15:50]</a> <a class="yt-timestamp" data-t="00:15:53">[00:15:53]</a> <a class="yt-timestamp" data-t="00:16:54">[00:16:54]</a>. This enables hundreds of changes and tests daily, accelerating the pace of innovation and accuracy improvements <a class="yt-timestamp" data-t="00:16:21">[00:16:21]</a> <a class="yt-timestamp" data-t="00:16:25">[00:16:25]</a> <a class="yt-timestamp" data-t="00:16:27">[00:16:27]</a>. A 30-second target allows for:
    *   10 seconds for parallel generation across 100 test cases <a class="yt-timestamp" data-t="00:17:15">[00:17:15]</a> <a class="yt-timestamp" data-t="00:17:18">[00:17:18]</a> <a class="yt-timestamp" data-t="00:17:25">[00:17:25]</a>.
    *   10 seconds for parallel judgment of these results by generative AI (or Python for numeric outputs) <a class="yt-timestamp" data-t="00:17:28">[00:17:28]</a> <a class="yt-timestamp" data-t="00:17:31">[00:17:31]</a> <a class="yt-timestamp" data-t="00:17:35">[00:17:35]</a> <a class="yt-timestamp" data-t="00:17:39">[00:17:39]</a>.
    *   10 seconds to summarize judge outputs by categories, highlighting right and wrong trends <a class="yt-timestamp" data-t="00:17:41">[00:17:41]</a> <a class="yt-timestamp" data-t="00:17:44">[00:17:44]</a> <a class="yt-timestamp" data-t="00:17:46">[00:17:46]</a> <a class="yt-timestamp" data-t="00:17:50">[00:17:50]</a>. This focuses on discovering errors and how to fix them <a class="yt-timestamp" data-t="00:18:09">[00:18:09]</a> <a class="yt-timestamp" data-t="00:18:12">[00:18:12]</a>.
2.  **Quantifiable**: Effective frameworks produce numbers, even if there's some jitter <a class="yt-timestamp" data-t="00:18:21">[00:18:21]</a> <a class="yt-timestamp" data-t="00:18:24">[00:18:24]</a> <a class="yt-timestamp" data-t="00:18:29">[00:18:29]</a>. This jitter is managed by using numerous test cases and averaging scores, similar to how grades are averaged in school <a class="yt-timestamp" data-t="00:18:51">[00:18:51]</a> <a class="yt-timestamp" data-t="00:18:54">[00:18:54]</a> <a class="yt-timestamp" data-t="00:19:00">[00:19:00]</a> <a class="yt-timestamp" data-t="00:19:03">[00:19:03]</a> <a class="yt-timestamp" data-t="00:19:07">[00:19:07]</a>.
3.  **Explainable**: Evaluations should provide insight into the model's reasoning during generation and scoring <a class="yt-timestamp" data-t="00:20:09">[00:20:09]</a> <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a> <a class="yt-timestamp" data-t="00:20:13">[00:20:13]</a> <a class="yt-timestamp" data-t="00:20:17">[00:20:17]</a>. Just as users' prompts need engineering, so do the judge's prompts, ensuring the judge scores correctly <a class="yt-timestamp" data-t="00:20:27">[00:20:27]</a> <a class="yt-timestamp" data-t="00:20:30">[00:20:30]</a> <a class="yt-timestamp" data-t="00:20:33">[00:20:33]</a>. Clear instructions and a rubric help the judge explain its reasoning <a class="yt-timestamp" data-t="00:20:49">[00:20:49]</a> <a class="yt-timestamp" data-t="00:21:09">[00:21:09]</a> <a class="yt-timestamp" data-t="00:21:13">[00:21:13]</a>.
4.  **Segmented**: Nearly all scaled workloads involve multiple steps, not a single prompt <a class="yt-timestamp" data-t="00:21:24">[00:21:24]</a> <a class="yt-timestamp" data-t="00:21:26">[00:21:26]</a> <a class="yt-timestamp" data-t="00:21:28">[00:21:28]</a> <a class="yt-timestamp" data-t="00:21:33">[00:21:33]</a>. Each step should be evaluated individually to determine the most appropriate model (e.g., Nova Micro for semantic routing) <a class="yt-timestamp" data-t="00:21:36">[00:21:36]</a> <a class="yt-timestamp" data-t="00:21:39">[00:21:39]</a> <a class="yt-timestamp" data-t="00:21:50">[00:21:50]</a> <a class="yt-timestamp" data-t="00:21:53">[00:21:53]</a> <a class="yt-timestamp" data-t="00:21:55">[00:21:55]</a>.
5.  **Diverse**: The test cases should cover all in-scope use cases, ideally around 100 cases <a class="yt-timestamp" data-t="00:22:10">[00:22:10]</a> <a class="yt-timestamp" data-t="00:22:12">[00:22:12]</a> <a class="yt-timestamp" data-t="00:22:18">[00:22:18]</a>. This ensures broad coverage and helps teams define the project's scope, including how to handle out-of-scope queries <a class="yt-timestamp" data-t="00:19:17">[00:19:17]</a> <a class="yt-timestamp" data-t="00:19:22">[00:19:22]</a> <a class="yt-timestamp" data-t="00:19:32">[00:19:32]</a> <a class="yt-timestamp" data-t="00:19:54">[00:19:54]</a> <a class="yt-timestamp" data-t="00:20:01">[00:20:01]</a>.
6.  **Traditional**: Do not abandon traditional AI/ML evaluation techniques <a class="yt-timestamp" data-t="00:22:30">[00:22:30]</a> <a class="yt-timestamp" data-t="00:22:32">[00:22:32]</a>. For numeric outputs, use numeric evaluations <a class="yt-timestamp" data-t="00:22:52">[00:22:52]</a> <a class="yt-timestamp" data-t="00:22:54">[00:22:54]</a>. For RAG architectures, traditional database accuracy, retrieval, precision, and F1 scores are still very powerful <a class="yt-timestamp" data-t="00:22:58">[00:22:58]</a> <a class="yt-timestamp" data-t="00:23:02">[00:23:02]</a> <a class="yt-timestamp" data-t="00:23:04">[00:23:04]</a>. Measuring cost and latency also relies on traditional tooling <a class="yt-timestamp" data-t="00:23:11">[00:23:11]</a> <a class="yt-timestamp" data-t="00:23:13">[00:23:13]</a>.
7.  **Good Gold Standard Set**: The most important investment of time is building a high-quality gold standard set <a class="yt-timestamp" data-t="00:23:33">[00:23:33]</a> <a class="yt-timestamp" data-t="00:23:36">[00:23:36]</a> <a class="yt-timestamp" data-t="00:23:52">[00:23:52]</a>. The entire system is designed around this set, so errors in the gold standard will propagate <a class="yt-timestamp" data-t="00:23:38">[00:23:38]</a> <a class="yt-timestamp" data-t="00:23:41">[00:23:41]</a>. Generative AI should not be used to create the gold standard set directly, as it can introduce the same errors <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a> <a class="yt-timestamp" data-t="00:24:03">[00:24:03]</a> <a class="yt-timestamp" data-t="00:24:07">[00:24:07]</a>. It can, however, generate a "silver standard set" which still requires human review for accuracy <a class="yt-timestamp" data-t="00:24:16">[00:24:16]</a> <a class="yt-timestamp" data-t="00:24:20">[00:24:20]</a> <a class="yt-timestamp" data-t="00:24:22">[00:24:22]</a>.

### Evaluation Framework Flow

An evaluation framework typically involves the following steps:
1.  **Input**: Select an input from the gold standard set <a class="yt-timestamp" data-t="00:24:26">[00:24:26]</a> <a class="yt-timestamp" data-t="00:24:28">[00:24:28]</a>.
2.  **Generation**: Pass the input through the prompt template and LLM to generate an output, including the answer and its reasoning <a class="yt-timestamp" data-t="00:24:30">[00:24:30]</a> <a class="yt-timestamp" data-t="00:24:33">[00:24:33]</a> <a class="yt-timestamp" data-t="00:24:36">[00:24:36]</a>.
3.  **Judgment**: Compare the generated output with the matching answer from the gold standard input using a "judge prompt." The judge then generates a score and the reasoning behind that number <a class="yt-timestamp" data-t="00:24:38">[00:24:38]</a> <a class="yt-timestamp" data-t="00:24:41">[00:24:41]</a> <a class="yt-timestamp" data-t="00:24:43">[00:24:43]</a> <a class="yt-timestamp" data-t="00:24:45">[00:24:45]</a> <a class="yt-timestamp" data-t="00:24:48">[00:24:48]</a>.
4.  **Categorization & Summary**: The output is categorized (often pre-defined in the gold standard set) to break down results by category and generate a summary of right and wrong answers for each <a class="yt-timestamp" data-t="00:24:54">[00:24:54]</a> <a class="yt-timestamp" data-t="00:24:57">[00:24:57]</a> <a class="yt-timestamp" data-t="00:25:02">[00:25:02]</a> <a class="yt-timestamp" data-t="00:25:09">[00:25:09]</a>.