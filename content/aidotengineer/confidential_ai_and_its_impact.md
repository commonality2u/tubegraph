---
title: Confidential AI and its impact
videoId: A0PxE39xaMc
---

From: [[aidotengineer]] <br/> 

[[The impact and future potential of AI and agents | AI]] is transforming industries such as [[use_cases_of_confidential_ai_in_healthcare_and_marketing | healthcare]], finance, automation, and [[use_cases_of_confidential_ai_in_healthcare_and_marketing | digital marketing]] <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>. However, a significant barrier to its widespread adoption is trust <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. Confidential AI addresses this by enabling models to run on sensitive data without exposure, deploying proprietary models without loss of control, and facilitating collaboration in non-deterministic environments without relying solely on blind trust <a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a>. This approach opens up new possibilities for developers working with sensitive data, proprietary models, or untrusted partners <a class="yt-timestamp" data-t="00:00:58">[00:00:58]</a>.

## Foundation: Confidential Computing

The core technology behind Confidential AI is confidential computing <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a>. It addresses the overlooked problem that data and models are most vulnerable during processing (training, fine-tuning, inference), not just when stored or in transit <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>.

### Trusted Execution Environments (TEEs)
Trusted Execution Environments (TEEs) are a key component, representing a secure and isolated part of the processor, such as Intel TDX, AMD SEV-SMP, or Nvidia GPU TEs <a class="yt-timestamp" data-t="00:01:37">[00:01:37]</a>. A TEE creates a confidential environment where code and data are protected during execution, isolated by instructions built into the chip during manufacturing <a class="yt-timestamp" data-t="00:01:53">[00:01:53]</a>. Workloads within this environment are protected in memory and invisible to the host OS, hypervisor, or even the hardware owner <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.

### Cryptographic Attestation
Beyond isolation, a TEE generates a cryptographic attestation â€“ a signed proof that the workload ran inside verified hardware using unmodified code <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>. This provides strong assurances that the workload is protected and verifies that what's inside the TEE is a real TEE in a properly manufactured, TEE-capable chip <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>. In essence, a TEE allows secure execution of sensitive computations and proof that they ran as intended, enabling [[solving_data_privacy_issues_in_ai_development | AI models to run on sensitive data without exposing either the model or the data]] <a class="yt-timestamp" data-t="00:03:14">[00:03:14]</a>.

## Why Confidential AI is Critical: Real-World Problems Solved

Confidential AI is critical because it addresses numerous real-world challenges faced by developers:

*   **[[use_cases_of_confidential_ai_in_healthcare_and_marketing | Healthcare]]**: Obtaining permission to use medical data for building or fine-tuning [[use_cases_of_confidential_ai_in_healthcare_and_marketing | medical AI models]] is exceptionally difficult due to strict regulations, data silos, and a reluctance of hospitals and labs to share raw datasets <a class="yt-timestamp" data-t="00:03:51">[00:03:51]</a>. Confidential AI helps overcome this by allowing models to be trained on sensitive data without exposure <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>.
*   **[[personal_local_and_private_ai_agents | Personal AI Agents]]**: For [[personal_local_and_private_ai_agents | personal AI agents]] that manage private data (inbox, calendar), mass adoption is hindered by user concerns about data sharing, developer concerns about storage security, and enterprise/regulator demands for strong guarantees <a class="yt-timestamp" data-t="00:04:50">[00:04:50]</a>. Confidentiality is the missing piece for their real-world adoption <a class="yt-timestamp" data-t="00:05:34">[00:05:34]</a>.
*   **[[use_cases_of_confidential_ai_in_healthcare_and_marketing | Digital Marketing]] and Custom Analytics**: Fine-tuning models on real user behavior data is desired, but privacy laws (GDPR, CCPA), internal security rules, and ethics often block or risk upsetting regulators <a class="yt-timestamp" data-t="00:05:47">[00:05:47]</a>. Confidential AI bridges the gap between technical possibility and what is legally and ethically allowed <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>.
*   **AI Model Monetization**: Developers of domain-specific models (legal, medical, financial) want to monetize their creations but risk losing control of their intellectual property (IP) if they allow others to run models without protection <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a>. Simultaneously, customers are unwilling to expose their sensitive data for testing or production <a class="yt-timestamp" data-t="00:06:47">[00:06:47]</a>. Confidential AI allows both parties to benefit without relinquishing control <a class="yt-timestamp" data-t="00:07:04">[00:07:04]</a>.
*   **Model Training and Provenance**: Even if a model is trained on sensitive data, proving its provenance (tracking back to initial datasets) is a challenge <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>. Attested execution makes it possible to guarantee that a model was trained as stated and that inference outputs relate only to the original data sets <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a>.

Traditional cloud setups, built on trust and legal contracts rather than provable guarantees, fall short in these scenarios <a class="yt-timestamp" data-t="00:07:58">[00:07:58]</a>.

## Super Protocol: Making Confidential AI Real

Super Protocol is a confidential AI cloud and marketplace designed for secure collaboration and monetization of AI models, data, and compute <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>.

### Key Features
*   **TE-Agnostic Infrastructure**: Super Protocol runs on Intel, Nvidia, and AMD TEEs and aims to support future platforms as major chip makers integrate TEEs <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.
*   **Edge-Ready Architecture**: It has validated ARM confidential computing compatibility, aiming to deliver end-to-end confidential AI from [[personal_local_and_private_ai_agents | personal edge devices]] to the cloud <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>.
*   **Swarm Computing Principles**: Scales across distributed GPU nodes with no single point of failure and automatic workload redistribution <a class="yt-timestamp" data-t="00:09:25">[00:09:25]</a>.
*   **Fully Decentralized**: Orchestrated entirely by smart contracts on BNB Chain, with no human intervention <a class="yt-timestamp" data-t="00:09:40">[00:09:40]</a>.
*   **Zero Barrier to Entry**: Users do not need TEE expertise to run or attest workloads <a class="yt-timestamp" data-t="00:09:52">[00:09:52]</a>.
*   **Open Source**: All parts of Super Protocol are open source, functioning as a protocol (like HTTPS for data in transit) to protect data while AI is working on it <a class="yt-timestamp" data-t="00:10:03">[00:10:03]</a>.

### GPUless, Trustless, Limitless
Super Protocol enables what it calls "GPUless, trustless, limitless" AI:

*   **GPUless**: This refers to removing dependency, not GPUs <a class="yt-timestamp" data-t="00:10:28">[00:10:28]</a>. It allows running accelerated AI workloads across independent GPU nodes without being locked into specific cloud vendors or centralized providers, and without needing to buy or rent GPUs for extended periods <a class="yt-timestamp" data-t="00:10:37">[00:10:37]</a>. Users maintain control, and unauthorized access is technically impossible due to TEEs and open-source architecture <a class="yt-timestamp" data-t="00:10:59">[00:10:59]</a>.
*   **Trustless**: Confidential computing is the foundation of trustless AI <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>. It replaces blind trust with built-in cryptographic proofs <a class="yt-timestamp" data-t="00:31:37">[00:31:37]</a>. Every workload produces a cryptographic proof showing what ran, where, and how, without exposing the actual workload data <a class="yt-timestamp" data-t="00:32:00">[00:32:00]</a>. This means users don't have to trust the provider or platform because they can verify the execution independently and transparently down to the hardware level <a class="yt-timestamp" data-t="00:32:51">[00:32:51]</a>.
*   **Limitless**: This involves removing legal, technical, and organizational barriers <a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a>. Traditional cloud platforms impose limits on data, geography, and control, hindering access to sensitive datasets, cross-border collaboration, and model monetization without relinquishing IP <a class="yt-timestamp" data-t="00:11:38">[00:11:38]</a>. They are also often unfit for agentic, non-deterministic [[the_impact_and_future_potential_of_ai_and_agents | AI where autonomous agents]] interact and evolve <a class="yt-timestamp" data-t="00:11:58">[00:11:58]</a>. Super Protocol removes these limits, allowing training, deployment, and monetization across organizations and jurisdictions with full confidentiality and ownership <a class="yt-timestamp" data-t="00:12:14">[00:12:14]</a>.

## Case Studies and Demos

Super Protocol demonstrates its capabilities through various real-world case studies and practical demonstrations.

### [[use_cases_of_confidential_ai_in_healthcare_and_marketing | Digital Marketing]] Case Study: Realize and Mars
Realize, a company using [[the_impact and_future_potential_of_ai_and_agents | AI]] to measure ad reactions through facial expressions, needed more biometric video data to improve its AI accuracy for brands like Mars <a class="yt-timestamp" data-t="00:13:05">[00:13:05]</a>. Privacy laws (GDPR, CCPA) and data ownership concerns made partners reluctant to share sensitive footage <a class="yt-timestamp" data-t="00:13:32">[00:13:32]</a>.

Realize used Super Protocol's confidential AI cloud, where AI training ran inside secure TEEs using powerful chips like Nvidia H100s/H200s and Intel Xeons <a class="yt-timestamp" data-t="00:13:45">[00:13:45]</a>. Smart contracts and open-source certification automated and verified every step <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a>. Data and models remained completely secure and inaccessible even to the cloud provider, Super Protocol, or Realize <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>. This verifiable confidentiality led providers to share four times more sensitive footage, boosting the training set by 319% <a class="yt-timestamp" data-t="00:14:24">[00:14:24]</a>. Accuracy jumped to 75%, on par with human performance, resulting in a 3-5% sales increase for Mars across 30 brands in 19 markets <a class="yt-timestamp" data-t="00:14:37">[00:14:37]</a>.

### [[use_cases_of_confidential_ai_in_healthcare_and_marketing | Healthcare]] Case Study: BEAL and Titonix
The Brain Electrophysiology Laboratory (BEAL) needed to submit perfect documentation for a new epilepsy diagnostic device to the FDA <a class="yt-timestamp" data-t="00:15:19">[00:15:19]</a>. This typically involved weeks of manual audits, NDAs, and risks of exposing trade secrets, with any mistake causing significant delays <a class="yt-timestamp" data-t="00:15:42">[00:15:42]</a>. BEAL wanted to use Titonix's AI-powered audit tool but worried about exposing their data and Titonix's model in traditional cloud environments <a class="yt-timestamp" data-t="00:16:01">[00:16:01]</a>.

Titonix used Super Protocol's confidential AI cloud <a class="yt-timestamp" data-t="00:16:17">[00:16:17]</a>. The audit ran inside secure TEEs (Nvidia H100/H200 GPUs and Intel TDX CPUs) <a class="yt-timestamp" data-t="00:16:22">[00:16:22]</a>. Automation by smart contracts and cryptographic proof ensured all files and models stayed encrypted and readable only within the secure environment, hidden from Super Protocol, BEAL, Titonix, or anyone else <a class="yt-timestamp" data-t="00:16:32">[00:16:32]</a>. This reduced audit time from weeks to 1-2 hours, eliminated leak risks, protected IP, and prevented 120-day re-review delays, allowing BEAL to deliver life-saving tools sooner <a class="yt-timestamp" data-t="00:16:53">[00:16:53]</a>.

### Super AI Marketplace Demo
The SuperAI marketplace, built on confidential and decentralized architecture, enables monetization for authors of closed-source models <a class="yt-timestamp" data-t="00:18:10">[00:18:10]</a>. Models are deployed in TEEs and accessible via link or API, remaining confidential and not downloadable <a class="yt-timestamp" data-t="00:18:31">[00:18:31]</a>. Users can deploy models in a few clicks, and a verification tool confirms deployment in a confidential environment, encrypted connection, and untampered AI engine <a class="yt-timestamp" data-t="00:18:00">[00:18:00]</a>.

### Agentic AI and Automated Workflows Demo
Super Protocol enables building secure automated AI workflows for processing sensitive data, like medical data using N8N <a class="yt-timestamp" data-t="00:21:39">[00:21:39]</a>. Running everything inside TEEs, inaccessible even to server admins, and combining low-code automation with decentralized infrastructure, delivers fully confidential, compliant, and verifiable medical AI <a class="yt-timestamp" data-t="00:21:58">[00:21:58]</a>. An example workflow demonstrates processing an X-ray image and patient data: the workflow cleans input, invokes an AI model for X-ray analysis, generates a structured medical report, and emails it securely to the doctor <a class="yt-timestamp" data-t="00:22:17">[00:22:17]</a>. All credentials (API keys, Gmail) are securely stored and isolated within the TEE <a class="yt-timestamp" data-t="00:23:36">[00:23:36]</a>.

### Scaling Distributed Inference Demo
Super Protocol enables distributed inference using VLLM across multiple GPU servers without reliance on a single provider, demonstrating its "GPUless" advantage <a class="yt-timestamp" data-t="00:26:16">[00:26:16]</a>. While VLLM partitions models across nodes for efficiency, traditional setups expose data and model code <a class="yt-timestamp" data-t="00:26:37">[00:26:37]</a>. Super Protocol secures this by running every VLLM node inside a confidential VM powered by TEE hardware, linked by a private overlay network <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>. Data, model weights, and intermediate activations are processed and decrypted only within each confidential environment, with all inter-node communication encrypted <a class="yt-timestamp" data-t="00:27:12">[00:27:12]</a>. This prevents sensitive material from leaving the secure boundary or being exposed to any host <a class="yt-timestamp" data-t="00:27:26">[00:27:26]</a>. The demo showed a single large LLM (Mistral 22B) running across four GPU nodes (H100/H200s) provided by different owners (Alice, Bob, Carol, David) in a fully confidential mode <a class="yt-timestamp" data-t="00:27:38">[00:27:38]</a>. On-chain reports verify that the image and model hashes match expectations for each participant, confirming integrity <a class="yt-timestamp" data-t="00:30:31">[00:30:31]</a>.

### Beyond Trust: Cryptographic Proofs and Verifiability Demo
Super Protocol replaces blind trust with built-in cryptographic proofs, making every run verifiable independently and transparently down to the hardware level <a class="yt-timestamp" data-t="00:31:35">[00:31:35]</a>. A cryptographic attestation, a signed proof from the hardware itself, verifies that a model executed in a real TEE using unmodified code on verified hardware inside a secure open-source runtime <a class="yt-timestamp" data-t="00:32:20">[00:32:20]</a>. If attempts are made to bypass the system, the protocol prevents the application and data from loading <a class="yt-timestamp" data-t="00:32:58">[00:32:58]</a>.

A multi-party training example demonstrates Alice's lab and Bob's clinic (sensitive data) collaborating with Carol's research center (training engine) to train a new model for early cancer detection <a class="yt-timestamp" data-t="00:33:13">[00:33:13]</a>. All three inputs run inside a TEE, inaccessible to the cloud host, Super Protocol, or even the participants <a class="yt-timestamp" data-t="00:33:50">[00:33:50]</a>. Data and source code remain private, with control remaining with each party <a class="yt-timestamp" data-t="00:34:07">[00:34:07]</a>. The training is fully automated and verified by a certification center and smart contracts on BNB Chain's Layer 2 <a class="yt-timestamp" data-t="00:34:15">[00:34:15]</a>.

Upon boot, a Confidential Virtual Machine (CVM) contacts an open-source certification authority for remote attestation, receiving a certificate if it's genuine and running in an attested TEE <a class="yt-timestamp" data-t="00:34:49">[00:34:49]</a>. Before data enters, an open-source trusted loader inside the CVM is attested, creates a signed key pair, and checks every component <a class="yt-timestamp" data-t="00:35:17">[00:35:17]</a>. If any check fails, the process stops to protect all parties <a class="yt-timestamp" data-t="00:35:33">[00:35:33]</a>. Data owners upload encrypted datasets, granting the CVM access, and the trusted loader verifies hashes before training begins <a class="yt-timestamp" data-t="00:36:39">[00:36:39]</a>. Data and the engine are only ever decrypted inside the TEE during training <a class="yt-timestamp" data-t="00:38:13">[00:38:13]</a>. Only Carol receives the encrypted output (the trained model and artifacts), while encryption keys never leave the TEE <a class="yt-timestamp" data-t="00:38:27">[00:38:27]</a>. An integrity report, signed inside the TEE, is published on OPBNB as part of the order report, providing public, tamper-proof evidence of the job's execution in a certified environment with approved inputs <a class="yt-timestamp" data-t="00:39:53">[00:39:53]</a>.

## Conclusion
Confidential AI offers a practical path forward for developers, addressing crucial privacy and trust issues in [[the_impact and_future_potential_of_ai_and_agents | AI development]] <a class="yt-timestamp" data-t="00:43:05">[00:43:05]</a>. With solutions like Super Protocol, developers can run models on private data without exposure, deploy proprietary models without losing control, fine-tune without compliance risk, and verify execution with cryptographic proof <a class="yt-timestamp" data-t="00:42:31">[00:42:31]</a>. It provides a simple, transparent, verifiable, and secure-by-design approach that is GPUless, trustless, and limitless <a class="yt-timestamp" data-t="00:42:53">[00:42:53]</a>.