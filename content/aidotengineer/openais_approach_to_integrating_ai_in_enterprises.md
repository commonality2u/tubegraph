---
title: OpenAIs approach to integrating AI in enterprises
videoId: joHR2pmxDQE
---

From: [[aidotengineer]] <br/> 

OpenAI details its strategy and best practices for integrating AI within enterprises, from empowering the workforce to deploying sophisticated agentic workflows. The approach emphasizes a clear strategic vision, iterative development, and close collaboration to ensure successful [[Impact of AI on organizational operations and efficiency | AI integration]] and scalability <a class="yt-timestamp" data-t="00:00:20">[00:00:20]</a>.

## OpenAI's Operational Structure and Enterprise Engagement

OpenAI operates with two core engineering teams:
*   **Research Team**: Composed of 1,200 researchers who invent and deploy foundational models <a class="yt-timestamp" data-t="00:00:48">[00:00:48]</a>. These models are described as "coming down from the heavens" <a class="yt-timestamp" data-t="00:00:57">[00:00:57]</a>.
*   **Apply Team**: Takes the foundational models and builds them into products like ChatGPT and the API <a class="yt-timestamp" data-t="00:01:00">[00:01:00]</a>.

The go-to-market team at OpenAI helps bring these products into the hands of an enterprise's workforce and products, automating internal operations <a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a>. This process involves an iterative loop where feedback from the field improves both products and core models through a research flywheel <a class="yt-timestamp" data-t="00:01:27">[00:01:27]</a>.

## The AI Customer Journey in Enterprise

OpenAI identifies three typical phases for enterprises integrating AI <a class="yt-timestamp" data-t="00:01:45">[00:01:45]</a>:

1.  **Building an AI-Enabled Workforce**: This initial phase focuses on getting AI into the hands of employees to foster [[Best practices for implementing AI in teams | AI literacy]] and daily use <a class="yt-timestamp" data-t="00:01:54">[00:01:54]</a>.
    *   **Product Use**: Typically starts with ChatGPT <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a>.
2.  **Automating AI Operations**: Involves building internal automation or co-pilot use cases within the workforce <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.
    *   **Product Use**: Can be partially done with ChatGPT, but more complex or customized cases leverage the API <a class="yt-timestamp" data-t="00:02:38">[00:02:38]</a>.
3.  **Infusing AI into End Product**: The final step, where AI is integrated into end-user facing products <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>.
    *   **Product Use**: Primarily uses the OpenAI API <a class="yt-timestamp" data-t="00:02:48">[00:02:48]</a>.

## Crafting an Enterprise AI Strategy

OpenAI recommends a multi-faceted approach to developing an [[Leadership and Organizational Strategies for AI Integration | AI strategy]] in practice <a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a>:

1.  **Top-Down Strategic Guidance**: The focus should not be on "what's your AI strategy," but rather "what's your broader business strategy," with AI serving as a technology to meet those objectives <a class="yt-timestamp" data-t="00:03:10">[00:03:10]</a>.
2.  **Identify High-Impact Use Cases**: Select one or two significant, high-impact use cases to scope out and deliver upon initially <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>.
3.  **Build Divisional Capability**: Enable teams and infuse AI throughout the organization through enablement, building centers of excellence, or establishing a centralized technological platform <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a>.

## The Use Case Journey Playbook

A typical use case journey, illustrated over approximately three months, follows these phases <a class="yt-timestamp" data-t="00:04:28">[00:04:28]</a>:

1.  **Ideation & Scoping**: Involves initial ideation, architecture review to fit AI into the existing stack, and defining success metrics/KPIs <a class="yt-timestamp" data-t="00:04:40">[00:04:40]</a>.
2.  **Development**: The bulk of the time, focused on iterating prompting strategies, RAG (Retrieval-Augmented Generation), and constantly improving the use case <a class="yt-timestamp" data-t="00:04:53">[00:04:53]</a>. OpenAI's team actively engages through workshops, office hours, and paired programming <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.
3.  **Testing & Evaluation**: Conducts A/B testing and beta rollouts based on predefined evaluation metrics <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>.
4.  **Production**: Includes launch rollout and scale optimization testing to ensure functionality for many end-users <a class="yt-timestamp" data-t="00:05:37">[00:05:37]</a>.
5.  **Maintenance**: Ongoing support after deployment <a class="yt-timestamp" data-t="00:05:45">[00:05:45]</a>.

> "The bulk of the time especially in partnership with Open AI will be around development." <a class="yt-timestamp" data-t="00:05:50">[00:05:50]</a>

## OpenAI Partnership and Support

OpenAI collaborates with enterprises by providing <a class="yt-timestamp" data-t="00:05:55">[00:05:55]</a>:
*   A dedicated team working alongside the client's dedicated team <a class="yt-timestamp" data-t="00:05:55">[00:05:55]</a>.
*   Early access to new models and features, offering a glimpse into future roadmaps to enable innovation <a class="yt-timestamp" data-t="00:06:05">[00:06:05]</a>.
*   Access to internal experts from research, engineering, and product teams <a class="yt-timestamp" data-t="00:06:35">[00:06:35]</a>.
*   Joint roadmap sessions to align on future developments <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>.

## Case Study: Morgan Stanley

OpenAI partnered with Morgan Stanley to build an internal knowledge assistant for their wealth managers <a class="yt-timestamp" data-t="00:06:54">[00:06:54]</a>. The goal was to provide highly accurate information from a large corpus of knowledge (research reports, stock data) to respond to clients <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>.

*   **Initial Accuracy**: 45% <a class="yt-timestamp" data-t="00:07:21">[00:07:21]</a>.
*   **Introduced Methods**: Hide retrieval, fine-tuning, embeddings, and different chunking strategies <a class="yt-timestamp" data-t="00:07:23">[00:07:23]</a>.
*   **Accuracy Improvement**:
    *   To 85% with reranking and classification <a class="yt-timestamp" data-t="00:07:36">[00:07:36]</a>.
    *   To 98% with prompt engineering and query expansion <a class="yt-timestamp" data-t="00:07:40">[00:07:40]</a>.

This example highlights how iterating and introducing various methods throughout the use case journey improved core metrics <a class="yt-timestamp" data-t="00:07:47">[00:07:47]</a>.

## The Rise of Agentic Workflows

OpenAI anticipates 2025 to be "the year of Agents," where Generative AI truly graduates from being an assistant to a co-bark (collaborative partner) <a class="yt-timestamp" data-t="00:08:02">[00:08:02]</a>.

An **agent** is defined as an [[Agentic Enterprise and AI | AI application]] consisting of <a class="yt-timestamp" data-t="00:09:02">[00:09:02]</a>:
*   A model with instructions (usually a prompt) <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>.
*   Access to tools for retrieving information and interacting with external systems <a class="yt-timestamp" data-t="00:09:11">[00:09:11]</a>.
*   An execution loop whose termination is controlled by the model itself <a class="yt-timestamp" data-t="00:09:16">[00:09:16]</a>.

In each execution cycle, the agent receives natural language instructions, determines whether to call tools, runs those tools, synthesizes a response with tool return values, and provides an answer to the user. It can also determine when its objective is met and terminate the loop <a class="yt-timestamp" data-t="00:09:24">[00:09:24]</a>.

## Lessons Learned in Building Agents

OpenAI has identified four key lessons or "best practices" for building agents <a class="yt-timestamp" data-t="00:09:50">[00:09:50]</a>:

### 1. Start with Primitives, Abstract Minimally

Rather than immediately using frameworks, start by building with raw API calls and logging <a class="yt-timestamp" data-t="00:10:07">[00:10:07]</a>. Frameworks can be enticing for quick proofs of concept, but they often obscure how the system behaves and its underlying primitives <a class="yt-timestamp" data-t="00:10:23">[00:10:23]</a>.

*   **Recommended Approach**: Build with primitives first to understand task decomposition, failure points, and what needs improvement <a class="yt-timestamp" data-t="00:10:53">[00:10:53]</a>.
*   **When to Abstract**: Introduce abstraction only when reinventing the wheel (e.g., re-implementing embedding strategies or model graders) <a class="yt-timestamp" data-t="00:11:05">[00:11:05]</a>.
*   **Key Idea**: Scalable agent development is more about understanding data, failure points, and constraints than choosing the "right framework" <a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a>.

### 2. Start Simple, Then Incrementally Improve

Avoid immediately jumping to complex multi-agent systems <a class="yt-timestamp" data-t="00:11:48">[00:11:48]</a>.

*   **Recommended Approach**: Start with a single agent purpose-built for a specific task, deploy it with a limited set of users, and observe its performance <a class="yt-timestamp" data-t="00:12:08">[00:12:08]</a>.
*   **Benefit**: This helps identify real bottlenecks (hallucinations, low adoption due to latency, inaccuracy due to poor retrieval) <a class="yt-timestamp" data-t="00:12:19">[00:12:19]</a>.
*   **Complexity**: Complexity should increase as more intense failure cases and constraints are discovered <a class="yt-timestamp" data-t="00:12:44">[00:12:44]</a>. The goal is to build a system that works, not necessarily a complicated one <a class="yt-timestamp" data-t="00:12:51">[00:12:51]</a>.

### 3. Network of Agents and Handoffs for Complexity

For more complex tasks, leverage a network of agents and the concept of handoffs <a class="yt-timestamp" data-t="00:13:03">[00:13:03]</a>.

*   **Network of Agents**: A collaborative system where multiple specialized agents work in concert to resolve complex requests or perform interrelated tasks, handling subflows within a larger [[Agentic Enterprise and AI | agentic workflow]] <a class="yt-timestamp" data-t="00:13:17">[00:13:17]</a>.
*   **Handoffs**: The process where one agent transfers control of an active conversation to another agent, preserving the entire conversation history and context <a class="yt-timestamp" data-t="00:13:38">[00:13:38]</a>.
*   **Example**: In a customer service flow, a GPT-4o mini call can perform triage, a GPT-4o agent manages the dispute conversation, and an O3 mini reasoning model performs accuracy-sensitive tasks like checking refund eligibility <a class="yt-timestamp" data-t="00:14:01">[00:14:01]</a>. This allows bringing "the right tools to the right job" <a class="yt-timestamp" data-t="00:14:12">[00:14:12]</a>.
*   **Benefit**: Handoffs effectively swap models, prompts, and tool definitions while maintaining conversation history, providing flexibility for diverse scenarios <a class="yt-timestamp" data-t="00:14:39">[00:14:39]</a>.

### 4. Guardrails for Safety, Security, and Reliability

Guardrails are mechanisms that enforce safety, security, and reliability within an application, preventing misuse and maintaining system integrity <a class="yt-timestamp" data-t="00:14:54">[00:14:54]</a>.

*   **Prompt Design**: Keep model instructions simple and focused on the target task to ensure maximum interoperability and predictable accuracy/performance <a class="yt-timestamp" data-t="00:15:10">[00:15:10]</a>.
*   **Implementation**: Guardrails should not be part of the main prompts but should instead be run in parallel <a class="yt-timestamp" data-t="00:15:25">[00:15:25]</a>.
*   **Efficiency**: The proliferation of faster and cheaper models like GPT-4o mini makes parallel guardrail execution more accessible <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>.
*   **High-Stakes Actions**: For high-stakes tool calls or user responses (e.g., issuing refunds, displaying personal account info), defer execution until all guardrails have returned a clear status <a class="yt-timestamp" data-t="00:15:42">[00:15:42]</a>.

These lessons emphasize a pragmatic, iterative approach to [[Strategies for effective AI implementation | AI implementation]], prioritizing understanding over premature complexity, and robust safeguards for production-ready systems <a class="yt-timestamp" data-t="00:16:08">[00:16:08]</a>.