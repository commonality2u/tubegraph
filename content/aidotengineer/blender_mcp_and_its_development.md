---
title: Blender MCP and its development
videoId: nnktgWtfJHE
---

From: [[aidotengineer]] <br/> 

The Blender Model Context Protocol (MCP) is a project aimed at making the complex 3D tool, Blender, easier to use by allowing Large Language Models (LLMs) to control it via prompting <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>.

## Speaker Background and Motivation
Sadhart, the developer of Blender [[Model Context Protocol MCP | MCP]], has 8 years of experience as a designer and engineer and enjoys tinkering <a class="yt-timestamp" data-t="00:00:22">[00:00:22]</a>. His motivation for building Blender [[Model Context Protocol MCP | MCP]] stemmed from his own struggle with Blender's complexity <a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a>. He observed that traditional Blender tasks, such as creating a simple donut, could take up to 5 hours for a beginner <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a>. The realization that [[Model Context Protocol MCP | MCP]] could enable an LLM to interact with any tool led him to question if it could simplify Blender <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>.

## What is Blender?
Blender is a versatile 3D tool used for importing assets, animating, exporting to game engines, and creating art <a class="yt-timestamp" data-t="00:00:40">[00:00:40]</a>. Its user interface is notably complex, featuring numerous tabs and sub-tabs, which historically makes it challenging for new users <a class="yt-timestamp" data-t="00:00:54">[00:00:54]</a>.

## The Concept Behind Blender MCP
The core idea of Blender [[Model Context Protocol MCP | MCP]] is to enable an LLM (like Claude or ChatGPT) to communicate with and control Blender <a class="yt-timestamp" data-t="00:02:02">[00:02:02]</a>. This allows users to generate 3D scenes by simply providing text prompts <a class="yt-timestamp" data-t="00:02:10">[00:02:10]</a>. For instance, a prompt like "make a dragon, have it guard a pot of gold" can generate a scene in approximately 5 minutes, a task that would otherwise take significantly longer <a class="yt-timestamp" data-t="00:02:18">[00:02:18]</a>.

## [[Technical structure and features of mCP | Technical Structure and Features of MCP]]
The operation of Blender [[Model Context Protocol MCP | MCP]] is designed to be straightforward <a class="yt-timestamp" data-t="00:03:27">[00:03:27]</a>:
*   **Client Connection**: An LLM client (e.g., Claude, Cursor) connects to Blender via the [[Model Context Protocol MCP | MCP]] protocol <a class="yt-timestamp" data-t="00:03:35">[00:03:35]</a>.
*   **Standardized Protocol**: The [[Model Context Protocol MCP | MCP]] serves as a standardized protocol, allowing Blender to expose its capabilities (tools) to the client <a class="yt-timestamp" data-t="00:03:48">[00:03:48]</a>.
*   **Blender Add-on**: A custom add-on within Blender executes the Python scripts generated by the LLM <a class="yt-timestamp" data-t="00:04:07">[00:04:07]</a>. When the LLM is prompted to create an object, it calls the appropriate tools to generate it in Blender <a class="yt-timestamp" data-t="00:04:13">[00:04:13]</a>.
*   **Asset Integration**: Industry-standard asset libraries like Rodin (AI-generated assets), Sketchfab, and Polyhaven are connected to the LLM, enabling seamless generation and import of assets directly into Blender based on prompts <a class="yt-timestamp" data-t="00:04:22">[00:04:22]</a>.
*   **Blender's Role**: Blender's inherent scripting capabilities (allowing code execution) and its flexibility in downloading and importing assets are crucial to Blender [[Model Context Protocol MCP | MCP]]'s functionality <a class="yt-timestamp" data-t="00:04:47">[00:04:47]</a>.

The client acts as the orchestrator, connecting to any API and allowing users to prompt for specific assets (e.g., "I want a zombie"), which can be AI-generated on the spot <a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a>. The system supports various clients and LLMs, including Claude, Cursor, ChatGPT, and Gemini <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>.

## Learnings from Development
During the development of Blender [[Model Context Protocol MCP | MCP]], several key insights were gained <a class="yt-timestamp" data-t="00:05:52">[00:05:52]</a>:
*   **Scripting Capabilities**: Tools with scripting abilities significantly reduce the heavy lifting, as LLMs excel at writing code that can be executed for modeling and asset retrieval <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>.
*   **Tool Management**: [[Model Context Protocol MCP | MCPs]] can become "confused" with too many tools <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>. The developer had to refactor Blender [[Model Context Protocol MCP | MCP]] multiple times due to 14-15 tools causing non-deterministic behavior <a class="yt-timestamp" data-t="00:06:20">[00:06:20]</a>. The solution was to keep the user experience lean and ensure each tool is distinct to help the LLM make accurate choices <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>.
*   **Avoiding UX Bloat**: It's important not to add features simply because they can be added <a class="yt-timestamp" data-t="00:06:58">[00:06:58]</a>. Blender [[Model Context Protocol MCP | MCP]]'s effectiveness comes from being lean and a generalist tool <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>.
*   **Improving Models**: Underlying LLM models are continuously improving, even with their current poor understanding of 3D <a class="yt-timestamp" data-t="00:07:17">[00:07:17]</a>. For example, Gemini 2.5 significantly enhanced Blender [[Model Context Protocol MCP | MCP]]'s performance by 3x upon its release <a class="yt-timestamp" data-t="00:07:30">[00:07:30]</a>.

## [[Integration and adoption of mCP in AI applications | Integration and Adoption]] and Impact on Creative Tools
Blender [[Model Context Protocol MCP | MCP]] launched with over 11,000 stars on GitHub and more than 160,000 downloads, indicating significant adoption <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>. Its introduction has drastically reduced the barrier to access for 3D tools <a class="yt-timestamp" data-t="00:08:00">[00:08:00]</a>.

Examples of its use include:
*   Creating a scene with AI-generated assets in two minutes <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a>.
*   Generating and animating a cat with AI-generated assets in under an hour <a class="yt-timestamp" data-t="00:08:31">[00:08:31]</a>.
*   Recreating a living room scene from a reference image, complete with appropriate assets, in minutes <a class="yt-timestamp" data-t="00:08:47">[00:08:47]</a>.
*   Generating game terrain from an image within Cursor, including complex textures and normal maps, by leveraging Blender's code execution capabilities <a class="yt-timestamp" data-t="00:09:07">[00:09:07]</a>.
*   Assisting in the creation of a high-fidelity game where players collect bone fragments inside lungs <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a>.
*   Producing glossy, iridescent materials and camera animations through AI prompting <a class="yt-timestamp" data-t="00:10:20">[00:10:20]</a>.
*   Generating racing tracks and animating cars, with camera angles for cinematic effects, which can then be converted into video clips using tools like Runway <a class="yt-timestamp" data-t="00:10:35">[00:10:35]</a>.
*   Creating the classic Blender donut in one minute with a simple prompt, a task that traditionally takes 5 hours <a class="yt-timestamp" data-t="00:11:28">[00:11:28]</a>.

This accessibility is "unlocking a whole new world of creators" by removing the high barrier to entry in 3D design <a class="yt-timestamp" data-t="00:11:47">[00:11:47]</a>.

## [[Future of creative tools with MCP and LLM | Future of Creative Tools with MCP and LLM]]
[[Model Context Protocol MCP | MCPs]] are broadly transforming how creative tools operate <a class="yt-timestamp" data-t="00:12:05">[00:12:05]</a>. The client acts as an orchestrator, communicating with external APIs and local tools like Blender <a class="yt-timestamp" data-t="00:12:16">[00:12:16]</a>.

The vision is for users to interface solely with an LLM to achieve their creative goals, without needing to learn the underlying software <a class="yt-timestamp" data-t="00:13:19">[00:13:19]</a>. For example, a user could prompt an LLM to "make a game," and the LLM, using [[Model Context Protocol MCP | MCPs]], could:
*   Call Blender to create assets <a class="yt-timestamp" data-t="00:13:25">[00:13:25]</a>.
*   Call Unity (a game engine) to build the game, add collisions, and logic <a class="yt-timestamp" data-t="00:13:29">[00:13:29]</a>.
*   Call external APIs for additional assets and animations <a class="yt-timestamp" data-t="00:13:38">[00:13:38]</a>.
*   Call Ableton (music creation software) to generate a soundtrack <a class="yt-timestamp" data-t="00:13:44">[00:13:44]</a>.

A demo combining Blender [[Model Context Protocol MCP | MCP]] with Ableton [[Model Context Protocol MCP | MCP]] showed the creation of a dragon with sinister lighting and a corresponding soundtrack, demonstrating the potential for stitching multiple creative outputs together <a class="yt-timestamp" data-t="00:14:11">[00:14:11]</a>.

This raises questions about the future of creativity:
*   Will tools primarily communicate with each other, with users interfacing only with LLMs, bypassing complex UIs <a class="yt-timestamp" data-t="00:15:20">[00:15:20]</a>?
*   Will creatives become more like "orchestra conductors," focusing on conceptualizing their vision and prompting the LLM to execute it, rather than mastering individual instruments <a class="yt-timestamp" data-t="00:15:43">[00:15:43]</a>?

[[Model Context Protocol MCP | MCPs]] are seen as the "fundamental glue" that will hold this future together, with LLMs at the intelligent core <a class="yt-timestamp" data-t="00:13:02">[00:13:02]</a>. Projects like Blender [[Model Context Protocol MCP | MCP]] and Ableton [[Model Context Protocol MCP | MCP]] are leading this shift, inspiring other [[Model Context Protocol MCP | MCPs]] for tools like PostGIS, Houdini, Unity, and Unreal Engine <a class="yt-timestamp" data-t="00:16:11">[00:16:11]</a>. This development could lead to a future where "everyone can become a creator" <a class="yt-timestamp" data-t="00:16:25">[00:16:25]</a>.