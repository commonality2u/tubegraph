---
title: Evolution and history of AI technology
videoId: 0vBKv9yAQi4
---

From: [[aidotengineer]] <br/> 

The field of artificial intelligence has seen rapid advancements, with many reflections on its history often focusing on recent years, sometimes as far back as 2019 or 2020 <a class="yt-timestamp" data-t="00:01:33">[00:01:33]</a>. Even these recent years are considered "ancient history" in the fast-moving AI landscape <a class="yt-timestamp" data-t="00:01:45">[00:01:45]</a>.

## Early AI "Caves"

While AI's roots stretch back to the 1970s <a class="yt-timestamp" data-t="00:01:57">[00:01:57]</a>, the period around 2012 and 2016 felt like the "AI caves" due to the nascent state of technology <a class="yt-timestamp" data-t="00:01:51">[00:01:51]</a>, <a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>, <a class="yt-timestamp" data-t="00:05:12">[00:05:12]</a>.

### 2012: Google Brain and Model Scale
Around 2012, a significant breakthrough occurred when Google Brain successfully identified cat videos on YouTube <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>. This model, with approximately one billion parameters, was considered a huge advancement at the time <a class="yt-timestamp" data-t="00:05:32">[00:05:32]</a>. For context, modern frontier models can have about a trillion parameters, making the 2012 model 1,000 times smaller <a class="yt-timestamp" data-t="00:05:36">[00:05:36]</a>. During this era, there was also a prevailing theory that computers would be limited in their achievements, a theory less popular today <a class="yt-timestamp" data-t="00:05:49">[00:05:49]</a>.

### 2016: The Infancy of Google Lens
In 2016, efforts in computer vision focused on helping computers differentiate between visually similar objects, such as Chihuahuas and blueberry muffins, dogs and bagels, or dogs and mops <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>. This work laid the foundation for the first version of Google Lens <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a>. In its early stages, one of the few consumer applications where computer vision models excelled was identifying plants <a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a>. However, early AI models were often unpredictable, feeling like a "slot machine" where results were inconsistent, highlighting [[challenges_in_ai_development | challenges in AI development]] related to the non-determinism of inputs or outputs <a class="yt-timestamp" data-t="00:03:48">[00:03:48]</a>.

## Present Day Advancements (2024)

Today, Google Lens has evolved significantly beyond its initial capabilities <a class="yt-timestamp" data-t="00:04:07">[00:04:07]</a>. Users can now search and shop based on what they see, use it on Google Images and YouTube, translate non-Latin character sets, and even solve math homework <a class="yt-timestamp" data-t="00:04:11">[00:04:11]</a>. Despite these advancements, it still retains its original ability to identify flowers <a class="yt-timestamp" data-t="00:04:36">[00:04:36]</a>. This extensive progress is attributed to consistent, step-by-step iteration over a decade <a class="yt-timestamp" data-t="00:04:43">[00:04:43]</a>.

## Software Development Life Cycle (SDLC) vs. Agent Development Life Cycle (ADLC)

The iterative improvement of AI, similar to general software, relies on a structured process <a class="yt-timestamp" data-t="00:04:52">[00:04:52]</a>. The traditional Software Development Life Cycle (SDLC) involves continuous improvement through implementation, testing, maintenance, analysis, and design <a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a>.

However, developing with large language models (LLMs) presents unique [[challenges_in_ai_development | challenges in AI development]], as they are often described as "building on top of a foundation of jello" <a class="yt-timestamp" data-t="00:11:34">[00:11:34]</a>.

**Traditional Software vs. Large Language Models:**
| Feature           | Traditional Software           | Large Language Models          |
| :---------------- | :----------------------------- | :----------------------------- |
| **Determinism**   | Deterministic <a class="yt-timestamp" data-t="00:11:43">[00:11:43]</a>          | Non-deterministic <a class="yt-timestamp" data-t="00:11:51">[00:11:51]</a>       |
| **Speed**         | Fast <a class="yt-timestamp" data-t="00:11:43">[00:11:43]</a>                   | Slow <a class="yt-timestamp" data-t="00:11:53">[00:11:53]</a>                    |
| **Cost**          | Cheap <a class="yt-timestamp" data-t="00:11:45">[00:11:45]</a>                  | Expensive to run <a class="yt-timestamp" data-t="00:11:53">[00:11:53]</a> |
| **Flexibility**   | Rigid (governed by if statements) <a class="yt-timestamp" data-t="00:11:45">[00:11:45]</a> | Very flexible <a class="yt-timestamp" data-t="00:11:55">[00:11:55]</a>         |
| **Capabilities**  | Follows logic <a class="yt-timestamp" data-t="00:11:48">[00:11:48]</a>      | Creative, can reason through problems <a class="yt-timestamp" data-t="00:11:57">[00:11:57]</a> |

To address these differences, Sierra developed the Agent Development Life Cycle (ADLC) <a class="yt-timestamp" data-t="00:12:12">[00:12:12]</a>. This methodology leverages the strengths of LLMs while integrating traditional software where beneficial <a class="yt-timestamp" data-t="00:12:02">[00:12:02]</a>. The ADLC applies AI to each part of the life cycle, speeding up improvements <a class="yt-timestamp" data-t="00:14:13">[00:14:13]</a>. Reasoning models, for example, act as a force multiplier, making AI more effective in development, testing, and QA <a class="yt-timestamp" data-t="00:15:06">[00:15:06]</a>.

### The Rise of [[development_and_challenges_of_ai_agents | AI Agents]]
As businesses recognize the necessity of [[the_impact_and_future_potential_of_ai_and_agents | AI agents]] to represent their operations and assist customers, companies like Chubbies have partnered with Sierra to deploy conversational AI platforms <a class="yt-timestamp" data-t="00:07:02">[00:07:02]</a>. These agents, like "Duncan Smothers," are designed to be highly capable, handling tasks such as sizing inquiries, inventory tracking, package tracking, and refunds <a class="yt-timestamp" data-t="00:07:42">[00:07:42]</a>. The goal is for these agents to perform autonomous actions, not just answer questions, leading to higher customer satisfaction <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>.

Every AI agent is treated as a product, requiring a fully featured developer and customer experience operations platform for optimal results <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>. Continuous iteration is key; even if an agent isn't perfect initially, it should consistently improve <a class="yt-timestamp" data-t="00:11:19">[00:11:19]</a>. This involves a rigorous quality assurance process where customer feedback leads to issue filing, test creation, and new releases, resulting in agents having thousands of tests over time <a class="yt-timestamp" data-t="00:12:45">[00:12:45]</a>.

## Voice Agents and Multimodality
The [[evolution_of_ai_models_and_their_application | evolution of AI models and their application]] also includes the development of voice agents, which launched in October 2023 <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>. The approach to voice agents is akin to responsive web design, where a single underlying platform and agent code can adapt to different channels and modalities <a class="yt-timestamp" data-t="00:16:13">[00:16:13]</a>. This allows for customization in phrasing and parallelized requests for lower latency <a class="yt-timestamp" data-t="00:16:27">[00:16:27]</a>.

The fascinating aspect of building with AI is that LLMs, despite being unpredictable, slow, and not great at math, allow designers to have empathy in a new way <a class="yt-timestamp" data-t="00:16:46">[00:16:46]</a>. This enables creators to better understand how to build robust and rich experiences for AI agents, even in challenging scenarios like real-time voice interactions with delays <a class="yt-timestamp" data-t="00:17:40">[00:17:40]</a>.