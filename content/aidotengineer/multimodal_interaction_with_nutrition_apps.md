---
title: Multimodal interaction with nutrition apps
videoId: Ghc-qalQFLw
---

From: [[aidotengineer]] <br/> 

Alma, a nutrition companion application, operates on the belief that "eating well shouldn't be hard" <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>. Good health is seen as starting with simple, [[personalized_nutrition_and_ai|personalized nutrition]] <a class="yt-timestamp" data-t="00:00:13">[00:00:13]</a>. The traditional challenge has been accurately understanding one's eating habits, with existing apps often demanding significant user input for minimal return <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>. Alma aims to solve this problem with AI, creating a unique nutrition companion <a class="yt-timestamp" data-t="00:00:44">[00:00:44]</a>.

## Simplifying Nutrition Tracking Through Multimodality

A core pillar of Alma's vision is to make [[nutrition_tracking_simplification|nutrition tracking]] simple, easy, and natural, akin to texting a friend <a class="yt-timestamp" data-t="00:01:04">[00:01:04]</a>. This approach avoids the need to search through endless product lists or rely on unreliable photo recognition <a class="yt-timestamp" data-t="00:01:13">[00:01:13]</a>.

The development process revealed that users value [[multimodal_interaction_in_apps|multimodality]] in how they interact with the app <a class="yt-timestamp" data-t="00:07:31">[00:07:31]</a>. While the speaker personally favors voice interaction, noting it allows them to track all meals in under 10 seconds, transforming a previously laborious exercise <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>, user feedback highlighted a preference for choice <a class="yt-timestamp" data-t="00:07:31">[00:07:31]</a>.

Users appreciate the flexibility Alma provides to:
*   **Talk** to the app <a class="yt-timestamp" data-t="00:07:35">[00:07:35]</a>
*   **Take a photo** <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a>
*   **Text** <a class="yt-timestamp" data-t="00:07:39">[00:07:39]</a>

This adaptability allows users to choose the most convenient method based on their context <a class="yt-timestamp" data-t="00:07:40">[00:07:40]</a>. The key lesson learned is to provide users with "as many different modalities that make sense for them" <a class="yt-timestamp" data-t="00:07:46">[00:07:46]</a>, rather than being overly committed to a single interaction method. This flexibility enhances the user experience, making [[voice_and_multimodal_ai_agents|AI agents]] more accessible and user-centric.