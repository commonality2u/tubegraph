---
title: Failure in AI project implementation
videoId: 89aQ7T6cMwA
---

From: [[aidotengineer]] <br/> 

The definitive guide to completely, utterly, and spectacularly messing up your AI strategy focuses on embracing "worse practices" to achieve "full-blown company crippling, career ending failure" <a class="yt-timestamp" data-t="00:00:43">[00:00:43]</a>. The goal is to torpedo projects and alienate colleagues <a class="yt-timestamp" data-t="00:00:57">[00:00:57]</a>.

## Presenters

*   **Greg**: An executive leader who has spent years crafting AI strategies in the C-Suite, including as Chief Product Officer at Pluralsight. He has witnessed how executive teams can turn "clear strategic opportunities into labyrinthine disasters" <a class="yt-timestamp" data-t="00:01:35">[00:01:35]</a>.
*   **Hamill**: A machine learning engineer and independent consultant who has worked with many companies on AI. He has seen "every conceivable way AI strategies can fail" <a class="yt-timestamp" data-t="00:01:50">[00:01:50]</a>.

Together, they refer to themselves as the "dream team of disaster" <a class="yt-timestamp" data-t="00:01:59">[00:01:59]</a>, advising on how to "invert always invert" based on Charlie Munger's wisdom <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>.

## Steps to Achieve AI Project Failure

### 1. Divide and Conquer Your Company

A key step to failure is to actively divide and conquer your own company <a class="yt-timestamp" data-t="00:02:27">[00:02:27]</a>.

*   **Embrace Disconnect**: Foster a disconnect between the willingness to pay (customer value) and the actual cost of implementation <a class="yt-timestamp" data-t="00:02:35">[00:02:35]</a>.
*   **Unreasonable Goals**: Contemplate unreasonable goals to create value <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>.
*   **Siloed Knowledge**: Attend every AI industry conference, but never discuss what was learned with your team <a class="yt-timestamp" data-t="00:02:50">[00:02:50]</a>. The objective is to create "impenetrable silos and incentivize secrecy between your teams" <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>.

### 2. Adhere to the Anti-Value Stick

Embrace the "anti-value stick," which is the opposite of good and useful principles in value creation and strategy <a class="yt-timestamp" data-t="00:03:18">[00:03:18]</a>.

*   **Wishful Thinking Promises (WTP)**: Tell customers that AI will do everything for them, like writing emails, blocking dogs, solving climate change, and achieving world peace, without worrying about details <a class="yt-timestamp" data-t="00:03:32">[00:03:32]</a>.
*   **Particularly Ridiculous Infrastructure Costs Everywhere (Price)**: Buy the most expensive GPUs and avoid cost-benefit analysis, maxing out the company credit card <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a>.
*   **Cascade of Spectacular Technical Debt (Cost)**: Build systems so convoluted and intertwined that even executives can barely understand them, ensuring job security when they inevitably break <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>.
*   **Why This System? (WTS)**: The answer to why a system is being built should always be "because AI," with no further explanation needed, treating it like "magic but much more expensive and less reliable" <a class="yt-timestamp" data-t="00:04:45">[00:04:45]</a>.

### 3. Define Your Strategy Poorly

This is a critical step in orchestrating [[common_pitfalls_in_ai_strategy | AI strategy pitfalls]].

*   **Fake Diagnosis**: Grab last year's annual report, highlight random, least-understood paragraphs, and declare them "must fix" items without consulting anyone who does the work <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.
*   **Ambiguous Guiding Policy**: Create an incredibly ambiguous and vague guiding policy, such as "become the global AI leader in everything," without defining what "everything" means <a class="yt-timestamp" data-t="00:05:27">[00:05:27]</a>.
*   **Unrealistic Action Plan**: Propose an AI-powered SEO tool guaranteeing top Google results (even for garden gnomes), a generative art plug-in for NFTs of the CEO's cat, and an AI drone lunch delivery service <a class="yt-timestamp" data-t="00:05:41">[00:05:41]</a>. Announce these at an All-Hands meeting, using buzzwords like "disruptive" <a class="yt-timestamp" data-t="00:05:54">[00:05:54]</a>.
*   **Embrace Perpetual Beta**: Disregard timelines, create a massive GitHub backlog, and stick all highlighted financial reports into it, eroding people's willpower to engage <a class="yt-timestamp" data-t="00:06:07">[00:06:07]</a>. A 4,000-page document posted in all Slack channels can also achieve this <a class="yt-timestamp" data-t="00:06:25">[00:06:25]</a>.

### 4. Communicate Through Jargon

To ensure [[avoiding_effective_communication_in_ai_deployment | ineffective communication in AI deployment]], drown everyone in a "tsunami of jargon" <a class="yt-timestamp" data-t="00:06:48">[00:06:48]</a>.

*   **Obfuscation**: Use complex phrases like "our multimodal agentic Transformer based system leverages F shot learning and Chain of Thought reasoning to optimize the synergistic potential of our Dynamic hyper parameter space" <a class="yt-timestamp" data-t="00:06:53">[00:06:53]</a>. The goal is to appear smart without anyone understanding <a class="yt-timestamp" data-t="00:07:08">[00:07:08]</a>.
*   **Hide "Jobs to Be Done"**: Use jargon strategically to hide the actual tasks, for example, calling prompt writing "building agents" to exclude mental health experts from participation <a class="yt-timestamp" data-t="00:07:38">[00:07:38]</a>.
*   **Misdirect Expertise**: Instead of saying "make sure the AI has the right context," say "Rags" <a class="yt-timestamp" data-t="00:08:12">[00:08:12]</a>. Instead of "make sure users can trick the AI into doing something bad," say "prompt injections" <a class="yt-timestamp" data-t="00:08:17">[00:08:17]</a>.
*   **Engineer-Centric Prompting**: Encourage engineers, rather than those who understand customers, to write prompts <a class="yt-timestamp" data-t="00:08:24">[00:08:24]</a>, contributing to [[challenges_in_building_reliable_ai_agents | challenges in building reliable AI agents]] and [[challenges_in_developing_ai_agents | developing AI agents]]. Making everything, including prompt writing, seem technical and out of reach for others is desired <a class="yt-timestamp" data-t="00:08:53">[00:08:53]</a>.

### 5. Mobilization - Zoning to Lose

Pioneer a "revolutionary framework" about "zoning to lose," designed specifically for failure <a class="yt-timestamp" data-t="00:09:19">[00:09:19]</a>.

*   **Random Task Assignment**: Randomly assign AI tasks to people with no relevant experience <a class="yt-timestamp" data-t="00:09:24">[00:09:24]</a>.
*   **Outsource Without Context**: Outsource data review to offshore Q&A teams with little business context <a class="yt-timestamp" data-t="00:09:32">[00:09:32]</a>.
*   **Launch Untested Products**: Launch completely untested, bug-ridden AI chatbots directly to customers from the incubation zone, disregarding quality assurance and beta testing <a class="yt-timestamp" data-t="00:09:45">[00:09:45]</a>.
*   **Organizational Collapse**: Yank best engineers from revenue-producing products, leading to total collapse <a class="yt-timestamp" data-t="00:10:12">[00:10:12]</a>.

### 6. Burn It All to the Ground - Focus on Tools, Not Processes

When your organization is in disarray, focus on tools, not processes, to burn it down <a class="yt-timestamp" data-t="00:10:30">[00:10:30]</a>. This is a common aspect of [[mismanagement_of_ai_resources | mismanagement of AI resources]].

*   **Throw Tools at Problems**: Don't analyze or understand problems; just throw tools at them <a class="yt-timestamp" data-t="00:10:44">[00:10:44]</a>. If a RAG system isn't retrieving documents, buy a new, more expensive vector database <a class="yt-timestamp" data-t="00:10:51">[00:10:51]</a>.
*   **Blindly Trust Metrics**: Use every off-the-shelf evaluation metric without customizing them to business needs, blindly trusting numbers even if they make no sense <a class="yt-timestamp" data-t="00:11:01">[00:11:01]</a>. This contributes to [[ensuring_ai_accuracy_and_reducing_errors | challenges in ensuring AI accuracy and reducing errors]].
*   **Framework Hopping**: If agents aren't working, pick a new framework and vendor. Fine-tune without measurement or evaluation, assuming it will be better "like Alchemy with a lot more electricity" <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>.
*   **Generic Metrics**: Adopt all evaluation metrics from frameworks, letting them guide blindly without questioning whether they measure success <a class="yt-timestamp" data-t="00:13:04">[00:13:04]</a>. Prioritize metrics like cosine similarity, BLEU, and ROUGE over actual user experience <a class="yt-timestamp" data-t="00:13:17">[00:13:17]</a>.
*   **No Cross-Checking**: Never cross-check with domain experts or users, as "if an LM says it's accurate, who are we to argue?" <a class="yt-timestamp" data-t="00:13:24">[00:13:24]</a>.

### 7. Avoid Looking at Data

This is the most potent technique for [[challenges_with_current_ai_implementation | challenges with current AI implementation]].

*   **Blindfold Approach**: Actively avoid looking at data <a class="yt-timestamp" data-t="00:13:42">[00:13:42]</a>. Trust the AI's output 100% without review <a class="yt-timestamp" data-t="00:13:58">[00:13:58]</a>.
*   **Delegate Data Responsibility**: Data analysis is an "engineering problem"; leaders have more important strategic tasks like meetings about meetings <a class="yt-timestamp" data-t="00:14:03">[00:14:03]</a>.
*   **Trust Gut Over Data**: Trust your gut feelings over data, especially for million-dollar decisions, as feelings are a reliable substitute <a class="yt-timestamp" data-t="00:14:34">[00:14:34]</a>.
*   **Engineer-Only Access**: Assume engineers are coding wizards with more domain expertise than business teams <a class="yt-timestamp" data-t="00:14:54">[00:14:54]</a>. Forget simpler options like spreadsheets for data annotation <a class="yt-timestamp" data-t="00:15:05">[00:15:05]</a>.
*   **Inaccessible Data Systems**: Put data in complex systems that only engineers can access, making it unavailable to domain experts <a class="yt-timestamp" data-t="00:15:26">[00:15:26]</a>. Insist on buying custom data analysis platforms requiring a team of PhDs to operate, especially if they take six months to load and have incessant errors <a class="yt-timestamp" data-t="00:15:39">[00:15:39]</a>.

## Conclusion

Following this advice meticulously guarantees wasted time and resources, and the alienation of colleagues, which is presented as the ultimate success in achieving total AI failure <a class="yt-timestamp" data-t="00:16:05">[00:16:05]</a>. For real advice on [[implementing_ai_in_enterprises | implementing AI in enterprises]], resources like ai-exec.com and an O'Reilly book are available <a class="yt-timestamp" data-t="00:16:20">[00:16:20]</a>.