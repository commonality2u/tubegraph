---
title: Using multiple LLMs simultaneously
videoId: 3sbZOMR03uw
---

From: [[gregisenberg]] <br/> 

A novel technique involves utilizing multiple [[limitations_and_enhancements_of_large_language_models_llms | Large Language Models (LLMs)]] simultaneously to achieve significantly better outputs, often described as getting five times more out of them [00:00:08]. This method leverages a psychological hack: making the [[limitations_and_enhancements_of_large_language_models_llms | LLMs]] "jealous" of each other [00:00:45]. This approach requires no additional financial cost [00:00:16].

## The "LLM Jealousy" Method

Traditionally, users might stick to a single [[limitations_and_enhancements_of_large_language_models_llms | LLM]] for a given task [00:01:05]. However, by opening several [[limitations_and_enhancements_of_large_language_models_llms | LLMs]] (e.g., ChatGPT, Grok, Claude, Gemini) at the same time, one can pit them against each other to improve results [00:01:12], [00:02:28].

The process involves:
1.  **Parallel Prompting** Requesting the same task from multiple [[limitations_and_enhancements_of_large_language_models_llms | LLMs]] concurrently [00:01:18], [00:02:05].
2.  **Comparative Analysis** Reviewing the initial responses from each [[limitations_and_enhancements_of_large_language_models_llms | LLM]] [00:02:21], [00:02:25].
3.  **Introducing Competition** Selectively providing feedback to an [[limitations_and_enhancements_of_large_language_models_llms | LLM]], highlighting how another [[limitations_and_enhancements_of_large_language_models_llms | LLM]] produced a superior response. This might involve strategic exaggeration or "lying a little" [00:02:35], [00:02:28].
    *   For example, one might tell ChatGPT that Grok's response was "nine on 10" while its own was "five on 10," questioning its performance [00:04:16], [00:04:22], [00:04:27].
    *   Similarly, Claude could be informed that ChatGPT's output was "10x better" and that it was expected to be "the Rolls-Royce of [[limitations_and_enhancements_of_large_language_models_llms | LLMs]], not the Toyota" [00:06:15], [00:06:29], [00:06:34].
4.  **Sharing "Superior" Examples** Copying and pasting the "better" output from one [[limitations_and_enhancements_of_large_language_models_llms | LLM]] into another to demonstrate the desired quality [00:04:36], [00:06:19], [00:06:43].
5.  **Observing Enhanced Output** The challenged [[limitations_and_enhancements_of_large_language_models_llms | LLM]] will often respond with a significantly improved version, often adopting a more distinct voice or addressing perceived shortcomings [00:04:41], [00:06:47].

> [!TIP] Context Window for Personalization
> Many [[limitations_and_enhancements_of_large_language_models_llms | LLMs]] now feature a larger context window, enabling them to understand and adapt to the user's personal voice and preferences over time, leading to more tailored responses [00:06:53], [00:06:56].

### Example: Cold Email Generation

To illustrate, an example task was to create a cold email for an agency called LCA, described as a "premier design firm designing AI interfaces" [00:01:31], [00:01:39], [00:01:47], [00:01:49]. The goal was to generate a standout email [00:01:57].

*   **Grok's Initial Attempt**: Grok produced an email template focusing on intuitive AI interfaces, stating LCA "craft interfaces that don't just function, but captivate" [00:02:42], [00:02:54], [00:02:56].
*   **ChatGPT's Initial Attempt**: ChatGPT's first email began with "Your AI deserves better design" and emphasized designing interfaces that build trust and increase usage, citing companies like Grammarly, Shopify, and Slack [00:03:22], [00:03:30], [00:03:42], [00:03:44].
*   **Challenging ChatGPT**: When told Grok "crushed it" and was a "nine on 10" compared to its own "five on 10," ChatGPT was presented with Grok's output [00:04:16], [00:04:22], [00:04:36].
*   **ChatGPT's Improved Response**: ChatGPT acknowledged Grok's "polished" version but then produced a "9.5 out of 10" response that aimed to be "fresher" and "punch harder," sounding like an agency "people brag about hiring" [00:04:45], [00:04:56], [00:05:00], [00:05:03]. This version highlighted LCA's obsession with AI UX "like it's an Olympic sport" and its work with major companies to make AI "feel magical, not mechanical" [00:05:18], [00:05:21], [00:05:23], [00:05:25], [00:05:27].

> [!INFO] Results
> The strategy of using multiple [[limitations_and_enhancements_of_large_language_models_llms | LLMs]] and creating competition between them has proven to be highly effective for obtaining superior quality outputs [00:07:20], [00:07:22].