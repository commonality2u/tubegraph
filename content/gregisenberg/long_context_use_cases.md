---
title: Long context use cases
videoId: 6h9y1rLem4c
---

From: [[gregisenberg]] <br/> 

One of the significant differentiated capabilities offered by Google's Gemini models within [[developing_and_customizing_aidriven_projects | AI Studio]] is their "long context" processing ability <a class="yt-timestamp" data-t="02:54:57">[02:54:57]</a>. This feature allows the models to process and understand very large inputs, which is particularly useful for extracting information from extensive media <a class="yt-timestamp" data-t="03:42:07">[03:42:07]</a> <a class="yt-timestamp" data-t="03:48:57">[03:48:57]</a>.

## Example: Analyzing a 30-Minute Video

A prime demonstration of long context processing involves analyzing a 30-minute video, such as a tour of the Natural History Museum <a class="yt-timestamp" data-t="04:00:00">[04:00:00]</a>.

Instead of manually breaking down the video into smaller segments or relying on extensive external processing steps, the Gemini models can directly ingest the entire video <a class="yt-timestamp" data-t="04:42:00">[04:42:00]</a>. For this specific 30-minute video, the model processed 531,000 tokens <a class="yt-timestamp" data-t="04:53:00">[04:53:00]</a>.

### Task and Output

Users can prompt the model with a request like "write me a list of all the museum exhibits throughout this video" <a class="yt-timestamp" data-t="04:07:00">[04:07:00]</a>. The model then generates a comprehensive list of exhibits by pulling context directly from the video <a class="yt-timestamp" data-t="05:55:00">[05:55:00]</a>.

> "A really good example of like something that would be if you think about like how would you do this in today's world without these models like it's basically impossible" <a class="yt-timestamp" data-t="04:27:00">[04:27:00]</a>

## Business Opportunities

This capability unlocks numerous business opportunities, particularly for extracting structured data from unstructured or semi-structured media <a class="yt-timestamp" data-t="05:24:00">[05:24:00]</a>.

### Directory Creation
The extracted data from long-form content, such as a list of museum exhibits from a video, can be used to create online directories <a class="yt-timestamp" data-t="05:11:00">[05:11:00]</a>. This taps into the vast amount of data "trapped" within media <a class="yt-timestamp" data-t="05:29:00">[05:29:00]</a>.

### Broader Applications
The long context ability is not limited to video; it can also be applied to lengthy audio files. For instance, [[developing_a_content_format | podcast platforms]] could use this to extract detailed intelligence and summaries from episodes <a class="yt-timestamp" data-t="06:01:00">[06:01:00]</a>.

This feature significantly reduces the "scaffolding work" traditionally required to process and extract information from long-form content <a class="yt-timestamp" data-t="05:35:00">[05:35:00]</a>. It enables [[ai_applications_in_daily_tasks_and_productivity | AI applications in daily tasks and productivity]] to tackle tasks that were previously time-consuming or impossible without significant human intervention.