---
title: Enhancing AI output with multiple LLMs
videoId: 3sbZOMR03uw
---

From: [[gregisenberg]] <br/> 

A method has been developed to significantly improve the output from Large Language Models (LLMs) such as Chat GPT, Groq, Claude, and Gemini, reportedly yielding five times better results, copy, and overall output without additional cost <a class="yt-timestamp" data-t="00:00:08">[00:00:08]</a>. This technique involves leveraging a form of "jealousy" or competition between different LLMs <a class="yt-timestamp" data-t="00:00:45">[00:00:45]</a>. This strategy is a key component of [[strategies_for_maximizing_the_potential_of_ai_tools | maximizing the potential of AI tools]] and [[enhancing_productivity_with_ai_agents | enhancing productivity with AI agents]].

## The Challenge with Single LLM Usage

Many users typically engage with AI by interacting with one LLM at a time, prompting it for a task and accepting its output [00:00:54]. However, this approach may not unlock the full potential of these AI tools.

## The Multi-LLM Competitive Strategy

The core of this method involves opening multiple LLMs simultaneously—two, three, or four at once—when a task needs to be completed <a class="yt-timestamp" data-t="00:01:12">[00:01:12]</a>. The process is as follows:

1.  **Initial Prompting:** Ask each open LLM the exact same prompt <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>.
    *   *Example:* Creating a cold email for an agency, LCA, a design firm specializing in AI interfaces, with the goal of making it stand out <a class="yt-timestamp" data-t="00:01:31">[00:01:31]</a>.
2.  **Evaluating Responses:** Review the initial outputs from each LLM <a class="yt-timestamp" data-t="00:02:21">[00:02:21]</a>.
3.  **Fostering Competition:** This is where the [[using_competitive_techniques_to_improve_ai_responses | competitive techniques to improve AI responses]] come into play. The key is to "pit each LLM against each other" <a class="yt-timestamp" data-t="00:02:28">[00:02:28]</a>. This often involves:
    *   **Praise one LLM to another:** Tell a less-performing LLM that another LLM (e.g., Groq) "crushed it" and was a "nine on 10," while the current LLM (e.g., Chat GPT) was "average" or a "five on 10" <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>.
    *   **Share the "superior" output:** Provide the better response from one LLM to another as an example, stating, "I thought you were the better LLM. What's going on?" <a class="yt-timestamp" data-t="00:04:27">[00:04:27]</a>. This forms a crucial part of [[using_feedback_to_refine_aigenerated_content | using feedback to refine AI-generated content]] and [[sequential_prompting_in_ai_workflows | sequential prompting in AI workflows]].
    *   **Exaggerate or "lie":** While it might seem unconventional, intentionally exaggerating the quality of one LLM's output to another can elicit better responses <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>.
4.  **Observe Improvement:** The LLM, seemingly motivated by this "competition," will often generate a significantly improved, more tailored, and higher-quality response <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>. This improvement often includes [[personalization_and_customization_of_ai_designs | personalization and customization of AI designs]], as many LLMs now understand the user's context and have a larger "context window" <a class="yt-timestamp" data-t="00:06:53">[00:06:53]</a>.

### Practical Example

When prompted to create a cold email:
*   **Groq's initial output** was deemed "not bad," described as polished and solid <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>.
*   **Chat GPT's initial output** was considered "not bad," but the user stated it "wasn't good" to the LLM, giving it a "five on 10" compared to Groq's "nine on 10" <a class="yt-timestamp" data-t="00:04:02">[00:04:02]</a>.
*   When challenged, Chat GPT produced a "9.5 out of 10" version, tailored to the user's voice and agency's specific branding, with an "edge Grock doesn't have" <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>.
*   The same technique was applied to Claude, falsely claiming Chat GPT's output was "10x better" and that Claude was a "Toyota" compared to Chat GPT's "Rolls Royce" <a class="yt-timestamp" data-t="00:06:12">[00:06:12]</a>. Claude then acknowledged the distinct voice of the example and produced an improved, more personalized email <a class="yt-timestamp" data-t="00:06:47">[00:06:47]</a>.

This method is presented as a "little hack" that can be incredibly helpful for maximizing the output of LLMs <a class="yt-timestamp" data-t="00:07:22">[00:07:22]</a>.