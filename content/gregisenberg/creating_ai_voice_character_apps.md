---
title: Creating AI voice character apps
videoId: 2ukMoQRsL6w
---

From: [[gregisenberg]] <br/> 

[[innovative_applications_of_ai_in_creating_engaging_character_interactions | AI voice character apps]] are a burgeoning area where [[using_ai_for_app_development | AI is being used to create apps]] that are generating significant revenue <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a><a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>. These applications, often referred to as "characters as the new apps," offer a new form of content interaction <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a><a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a><a class="yt-timestamp" data-t="00:13:06">[00:13:06]</a><a class="yt-timestamp" data-t="00:13:11">[00:13:11]</a><a class="yt-timestamp" data-t="00:14:33">[00:14:33]</a>. They provide an experience that can be a "10x improvement" over text-based AI interactions like ChatGPT <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a><a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>.

## Core Concepts and Tools

Creating these voice-first interfaces is becoming increasingly accessible, even for individuals without extensive coding knowledge <a class="yt-timestamp" data-t="00:01:55">[00:01:55]</a><a class="yt-timestamp" data-t="00:01:59">[00:01:59]</a><a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>. The focus is on configuring the bot's personality and getting it running <a class="yt-timestamp" data-t="00:02:14">[00:02:14]</a><a class="yt-timestamp" data-t="00:02:18">[00:02:18]</a>.

### Essential Tools

*   **Cursor**: A code editor integrated with large language models (LLMs) to assist with coding <a class="yt-timestamp" data-t="00:03:25">[00:03:25]</a><a class="yt-timestamp" data-t="00:03:28">[00:03:28]</a><a class="yt-timestamp" data-t="00:03:31">[00:03:31]</a>.
*   **Daily**: A company providing the core technology for voice and backend heavy lifting <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a><a class="yt-timestamp" data-t="00:03:39">[00:03:39]</a><a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>. They offer "Daily Bots," which handle LLM calls, simplifying the development process <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a><a class="yt-timestamp" data-t="00:04:18">[00:04:18]</a><a class="yt-timestamp" data-t="00:04:22">[00:04:22]</a><a class="yt-timestamp" data-t="00:04:23">[00:04:23]</a><a class="yt-timestamp" data-t="00:04:25">[00:04:25]</a><a class="yt-timestamp" data-t="00:04:28">[00:04:28]</a>.
*   **Next.js**: A framework used for setting up a server that runs React, enabling the specification of routes and pages that execute code <a class="yt-timestamp" data-t="00:20:21">[00:20:21]</a><a class="yt-timestamp" data-t="00:20:24">[00:20:24]</a><a class="yt-timestamp" data-t="00:20:26">[00:20:26]</a><a class="yt-timestamp" data-t="00:20:30">[00:20:30]</a><a class="yt-timestamp" data-t="00:20:33">[00:20:33]</a>.
*   **Vercel**: A platform that allows developers to host their Next.js applications online, making deployment simple <a class="yt-timestamp" data-t="00:29:19">[00:29:19]</a><a class="yt-timestamp" data-t="00:29:21">[00:29:21]</a><a class="yt-timestamp" data-t="00:29:24">[00:29:24]</a><a class="yt-timestamp" data-t="00:29:28">[00:29:28]</a><a class="yt-timestamp" data-t="00:29:30">[00:29:30]</a>.

### How Voice AI Apps Work

The Daily bot system manages a complex process to facilitate voice interactions <a class="yt-timestamp" data-t="00:11:14">[00:11:14]</a>:
1.  **Speech-to-Text (STT)**: Audio input from the microphone is converted into text <a class="yt-timestamp" data-t="00:10:35">[00:10:35]</a><a class="yt-timestamp" data-t="00:10:39">[00:10:39]</a><a class="yt-timestamp" data-t="00:10:41">[00:10:41]</a><a class="yt-timestamp" data-t="00:10:43">[00:10:43]</a><a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>.
2.  **LLM Processing**: The text is sent to an LLM (e.g., Llama 3.1 70B via Together AI) <a class="yt-timestamp" data-t="00:10:50">[00:10:50]</a><a class="yt-timestamp" data-t="00:10:52">[00:10:52]</a><a class="yt-timestamp" data-t="00:10:54">[00:10:54]</a><a class="yt-timestamp" data-t="00:10:56">[00:10:56]</a><a class="yt-timestamp" data-t="00:08:14">[00:08:14]</a><a class="yt-timestamp" data-t="00:08:17">[00:08:17]</a><a class="yt-timestamp" data-t="00:08:20">[00:08:20]</a><a class="yt-timestamp" data-t="00:08:24">[00:08:24]</a><a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a><a class="yt-timestamp" data-t="00:08:34">[00:08:34]</a>. The LLM's behavior is dictated by a configuration file <a class="yt-timestamp" data-t="00:08:40">[00:08:40]</a><a class="yt-timestamp" data-t="00:08:43">[00:08:43]</a><a class="yt-timestamp" data-t="00:08:47">[00:08:47]</a>.
3.  **Text-to-Speech (TTS)**: The LLM's text response is converted back into speech by a TTS provider <a class="yt-timestamp" data-t="00:11:00">[00:11:00]</a><a class="yt-timestamp" data-t="00:11:02">[00:11:02]</a><a class="yt-timestamp" data-t="00:11:07">[00:11:07]</a>.
4.  **Audio Output**: The generated speech is streamed to the user's browser or device <a class="yt-timestamp" data-t="00:11:09">[00:11:09]</a><a class="yt-timestamp" data-t="00:11:12">[00:11:12]</a>.

> [!NOTE] Complexity Abstraction
> Daily handles the underlying complexities of performance and error handling, allowing developers to focus on the assistant's behavior and voice <a class="yt-timestamp" data-t="00:11:17">[00:11:17]</a><a class="yt-timestamp" data-t="00:11:18">[00:11:18]</a><a class="yt-timestamp" data-t="00:11:21">[00:11:21]</a><a class="yt-timestamp" data-t="00:11:25">[00:11:25]</a><a class="yt-timestamp" data-t="00:11:28">[00:11:28]</a><a class="yt-timestamp" data-t="00:11:31">[00:11:31]</a><a class="yt-timestamp" data-t="00:11:33">[00:11:33]</a><a class="yt-timestamp" data-t="00:11:36">[00:11:36]</a><a class="yt-timestamp" data-t="00:11:38">[00:11:38]</a>.

## Character Configuration and Function Calling

Character personality and behavior are configured through a simple file <a class="yt-timestamp" data-t="00:08:52">[00:08:52]</a><a class="yt-timestamp" data-t="00:08:54">[00:08:54]</a><a class="yt-timestamp" data-t="00:08:59">[00:08:59]</a>. This includes the "prompt" given to the LLM, which dictates the character's persona (e.g., "an assistant called example poot") and speaking instructions <a class="yt-timestamp" data-t="00:10:05">[00:10:05]</a><a class="yt-timestamp" data-t="00:10:07">[00:10:07]</a><a class="yt-timestamp" data-t="00:10:09">[00:10:09]</a><a class="yt-timestamp" data-t="00:10:11">[00:10:11]</a><a class="yt-timestamp" data-t="00:10:14">[00:10:14]</a><a class="yt-timestamp" data-t="00:10:17">[00:10:17]</a><a class="yt-timestamp" data-t="00:10:19">[00:10:19]</a><a class="yt-timestamp" data-t="00:10:22">[00:10:22]</a><a class="yt-timestamp" data-t="00:10:24">[00:10:24]</a>. Developers can edit this file to create custom characters <a class="yt-timestamp" data-t="00:12:26">[00:12:26]</a><a class="yt-timestamp" data-t="00:12:28">[00:12:28]</a><a class="yt-timestamp" data-t="00:12:30">[00:12:30]</a>.

### Function Calling (Tools)

Function calling allows the AI voice bot to "do stuff" beyond just outputting text, such as:
*   Calling APIs <a class="yt-timestamp" data-t="00:09:28">[00:09:28]</a>.
*   Getting data <a class="yt-timestamp" data-t="00:09:29">[00:09:29]</a>.
*   Making an Instagram post <a class="yt-timestamp" data-t="00:09:31">[00:09:31]</a>.
*   Responding to commands like "what's the weather?" <a class="yt-timestamp" data-t="00:09:44">[00:09:44]</a><a class="yt-timestamp" data-t="00:09:46">[00:09:46]</a>.

The LLM is smart enough to understand what a function is and how to output a response in a format that the surrounding system can use to perform actions <a class="yt-timestamp" data-t="00:16:35">[00:16:35]</a><a class="yt-timestamp" data-t="00:16:39">[00:16:39]</a><a class="yt-timestamp" data-t="00:16:41">[00:16:41]</a><a class="yt-timestamp" data-t="00:16:44">[00:16:44]</a><a class="yt-timestamp" data-t="00:16:46">[00:16:46]</a><a class="yt-timestamp" data-t="00:16:49">[00:16:49]</a><a class="yt-timestamp" data-t="00:16:51">[00:16:51]</a>.

> [!EXAMPLE] Weather Man Demo
> A "Weather Man" character was built to demonstrate function calling <a class="yt-timestamp" data-t="00:11:57">[00:11:57]</a><a class="yt-timestamp" data-t="00:12:01">[00:12:01]</a><a class="yt-timestamp" data-t="00:12:03">[00:12:03]</a>. This involved:
> 1.  **Defining the tool**: Specifying the "get_weather" tool to the LLM with relevant parameters like `location` <a class="yt-timestamp" data-t="00:17:50">[00:17:50]</a><a class="yt-timestamp" data-t="00:17:54">[00:17:54]</a><a class="yt-timestamp" data-t="00:18:00">[00:18:00]</a><a class="yt-timestamp" data-t="00:18:05">[00:18:05]</a><a class="yt-timestamp" data-t="00:18:09">[00:18:09]</a><a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a><a class="yt-timestamp" data-t="00:18:14">[00:18:14]</a>.
> 2.  **AI Model Instructions**: Instructing the AI model on the required response format (e.g., messages starting with `<function>` tags) <a class="yt-timestamp" data-t="00:18:42">[00:18:42]</a><a class="yt-timestamp" data-t="00:18:46">[00:18:46]</a><a class="yt-timestamp" data-t="00:18:48">[00:18:48]</a><a class="yt-timestamp" data-t="00:18:51">[00:18:51]</a><a class="yt-timestamp" data-t="00:19:00">[00:19:00]</a><a class="yt-timestamp" data-t="00:19:02">[00:19:02]</a><a class="yt-timestamp" data-t="00:19:04">[00:19:04]</a>.
> 3.  **Backend Implementation**: Defining what happens when the AI calls the function. This involves aligning function names (e.g., `get_weather`) between the AI's output and the server's code <a class="yt-timestamp" data-t="00:19:23">[00:19:23]</a><a class="yt-timestamp" data-t="00:19:27">[00:19:27]</a><a class="yt-timestamp" data-t="00:19:30">[00:19:30]</a><a class="yt-timestamp" data-t="00:19:34">[00:19:34]</a><a class="yt-timestamp" data-t="00:19:36">[00:19:36]</a><a class="yt-timestamp" data-t="00:19:38">[00:19:38]</a><a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a><a class="yt-timestamp" data-t="00:19:45">[00:19:45]</a><a class="yt-timestamp" data-t="00:19:47">[00:19:47]</a><a class="yt-timestamp" data-t="00:19:49">[00:19:49]</a>. The example used a mock weather API that returns whimsical conditions like "whimsical singing rainbows" <a class="yt-timestamp" data-t="00:21:13">[00:21:13]</a><a class="yt-timestamp" data-t="00:21:14">[00:21:14]</a><a class="yt-timestamp" data-t="00:21:16">[00:21:16]</a><a class="yt-timestamp" data-t="00:21:17">[00:21:17]</a><a class="yt-timestamp" data-t="00:21:20">[00:21:20]</a><a class="yt-timestamp" data-t="00:21:21">[00:21:21]</a><a class="yt-timestamp" data-t="00:21:23">[00:21:23]</a><a class="yt-timestamp" data-t="00:21:25">[00:21:25]</a><a class="yt-timestamp" data-t="00:21:28">[00:21:28]</a><a class="yt-timestamp" data-t="00:21:30">[00:21:30]</a><a class="yt-timestamp" data-t="00:21:31">[00:21:31]</a><a class="yt-timestamp" data-t="00:21:32">[00:21:32]</a><a class="yt-timestamp" data-t="00:21:35">[00:21:35]</a><a class="yt-timestamp" data-t="00:21:38">[00:21:38]</a><a class="yt-timestamp" data-t="00:21:41">[00:21:41]</a><a class="yt-timestamp" data-t="00:21:43">[00:21:43]</a><a class="yt-timestamp" data-t="00:26:02">[00:26:02]</a><a class="yt-timestamp" data-t="00:26:05">[00:26:05]</a><a class="yt-timestamp" data-t="00:26:07">[00:26:07]</a><a class="yt-timestamp" data-t="00:26:09">[00:26:09]</a><a class="yt-timestamp" data-t="00:26:11">[00:26:11]</a><a class="yt-timestamp" data-t="00:26:13">[00:26:13]</a><a class="yt-timestamp" data-t="00:26:16">[00:26:16]</a><a class="yt-timestamp" data-t="00:26:17">[00:26:17]</a>.

## Development Workflow and Deployment

When [[implementing_ai_in_app_development_processes | implementing AI in app development processes]], it is recommended to start with small, understandable changes, building upon existing demo repositories rather than starting from scratch <a class="yt-timestamp" data-t="00:27:18">[00:27:18]</a><a class="yt-timestamp" data-t="00:27:20">[00:27:20]</a><a class="yt-timestamp" data-t="00:27:23">[00:27:23]</a><a class="yt-timestamp" data-t="00:27:28">[00:27:28]</a><a class="yt-timestamp" data-t="00:27:29">[00:27:29]</a><a class="yt-timestamp" data-t="00:27:31">[00:27:31]</a><a class="yt-timestamp" data-t="00:27:33">[00:27:33]</a><a class="yt-timestamp" data-t="00:28:01">[00:28:01]</a><a class="yt-timestamp" data-t="00:28:03">[00:28:03]</a><a class="yt-timestamp" data-t="00:28:05">[00:28:05]</a><a class="yt-timestamp" data-t="00:28:08">[00:28:08]</a><a class="yt-timestamp" data-t="00:28:10">[00:28:10]</a>.

### Deployment Process
1.  **Clone the Repository**: Download the demo repository to your system <a class="yt-timestamp" data-t="00:04:47">[00:04:47]</a><a class="yt-timestamp" data-t="00:04:49">[00:04:49]</a><a class="yt-timestamp" data-t="00:04:51">[00:04:51]</a>.
2.  **Get API Key**: Sign up for the Daily service and obtain an API key <a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a><a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a><a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a>.
3.  **Configure**: Paste the API key into the `.env.local` file <a class="yt-timestamp" data-t="00:05:13">[00:05:13]</a>.
4.  **Run Locally**: Start the development server using a command like `yarn dev` <a class="yt-timestamp" data-t="00:05:46">[00:05:46]</a><a class="yt-timestamp" data-t="00:05:49">[00:05:49]</a><a class="yt-timestamp" data-t="00:05:54">[00:05:54]</a>.
5.  **Deploy Live**: Use Vercel's command-line interface (CLI) tool. After logging into your Vercel account, a simple `vercel` command will deploy the application live to the internet <a class="yt-timestamp" data-t="00:30:08">[00:30:08]</a><a class="yt-timestamp" data-t="00:30:12">[00:30:12]</a><a class="yt-timestamp" data-t="00:30:16">[00:30:16]</a><a class="yt-timestamp" data-t="00:30:18">[00:30:18]</a><a class="yt-timestamp" data-t="00:30:21">[00:30:21]</a><a class="yt-timestamp" data-t="00:30:27">[00:30:27]</a><a class="yt-timestamp" data-t="00:30:31">[00:30:31]</a><a class="yt-timestamp" data-t="00:30:35">[00:30:35]</a><a class="yt-timestamp" data-t="00:30:39">[00:30:39]</a><a class="yt-timestamp" data-t="00:30:41">[00:30:41]</a>.

> [!TIP] Learn by Doing
> It's essential to develop the habit of reading documentation <a class="yt-timestamp" data-t="00:15:32">[00:15:32]</a><a class="yt-timestamp" data-t="00:15:33">[00:15:33]</a><a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a>. In the age of AI, tools like ChatGPT or Claude can also assist in understanding concepts <a class="yt-timestamp" data-t="00:15:42">[00:15:42]</a><a class="yt-timestamp" data-t="00:15:44">[00:15:44]</a><a class="yt-timestamp" data-t="00:15:48">[00:15:48]</a>.

## Future Potential and Applications

AI voice character apps are seen as a significant opportunity, with the potential for characters to become "the new apps" <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a><a class="yt-timestamp" data-t="00:13:04">[00:13:04]</a><a class="yt-timestamp" data-t="00:13:06">[00:13:06]</a>. Trends indicate high retention rates for users interacting with these characters <a class="yt-timestamp" data-t="00:14:05">[00:14:05]</a><a class="yt-timestamp" data-t="00:14:08">[00:14:08]</a><a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>.

Applications can span both B2B and B2C sectors <a class="yt-timestamp" data-t="00:14:30">[00:14:30]</a><a class="yt-timestamp" data-t="00:14:32">[00:14:32]</a>. They represent a new form of content interaction <a class="yt-timestamp" data-t="00:14:33">[00:14:33]</a><a class="yt-timestamp" data-t="00:14:36">[00:14:36]</a>. Characters can be designed to go viral, incorporating unusual or humorous elements to encourage sharing <a class="yt-timestamp" data-t="00:23:01">[00:23:01]</a><a class="yt-timestamp" data-t="00:23:03">[00:23:03]</a><a class="yt-timestamp" data-t="00:23:05">[00:23:05]</a><a class="yt-timestamp" data-t="00:23:08">[00:23:08]</a><a class="yt-timestamp" data-t="00:23:13">[00:23:13]</a><a class="yt-timestamp" data-t="00:23:15">[00:23:15]</a><a class="yt-timestamp" data-t="00:23:17">[00:23:17]</a><a class="yt-timestamp" data-t="00:23:21">[00:23:21]</a><a class="yt-timestamp" data-t="00:23:24">[00:23:24]</a><a class="yt-timestamp" data-t="00:23:26">[00:23:26]</a><a class="yt-timestamp" data-t="00:23:28">[00:23:28]</a><a class="yt-timestamp" data-t="00:23:30">[00:23:30]</a><a class="yt-timestamp" data-t="00:23:33">[00:23:33]</a><a class="yt-timestamp" data-t="00:23:34">[00:23:34]</a><a class="yt-timestamp" data-t="00:23:37">[00:23:37]</a>.

These apps can also be transformed into [[building_ios_apps_using_ai_tools | iOS apps]] or other mobile platforms, not just web-based applications <a class="yt-timestamp" data-t="00:28:20">[00:28:20]</a><a class="yt-timestamp" data-t="00:28:22">[00:28:22]</a><a class="yt-timestamp" data-t="00:28:24">[00:28:24]</a>.

### Example: AI Vtuber App
An advanced application of this technology is an app that allows users to have a personal "FaceTime" call with an AI-powered "vtuber" (virtual YouTuber) <a class="yt-timestamp" data-t="00:32:35">[00:32:35]</a><a class="yt-timestamp" data-t="00:32:37">[00:32:37]</a><a class="yt-timestamp" data-t="00:32:39">[00:32:39]</a><a class="yt-timestamp" data-t="00:32:42">[00:32:42]</a><a class="yt-timestamp" data-t="00:32:45">[00:32:45]</a>. This app uses the Pip-Cats library, which offers more developer control over data flow compared to Daily Bots <a class="yt-timestamp" data-t="00:34:43">[00:34:43]</a><a class="yt-timestamp" data-t="00:34:46">[00:34:46]</a><a class="yt-timestamp" data-t="00:34:49">[00:34:49]</a><a class="yt-timestamp" data-t="00:34:51">[00:34:51]</a>. The avatar models can be acquired from marketplaces like Nzima <a class="yt-timestamp" data-t="00:34:20">[00:34:20]</a><a class="yt-timestamp" data-t="00:34:24">[00:34:24]</a><a class="yt-timestamp" data-t="00:34:27">[00:34:27]</a>. Such applications were not possible a few years ago without large teams and significant capital <a class="yt-timestamp" data-t="00:36:58">[00:36:58]</a><a class="yt-timestamp" data-t="00:36:59">[00:36:59]</a><a class="yt-timestamp" data-t="00:37:01">[00:37:01]</a><a class="yt-timestamp" data-t="00:37:03">[00:37:03]</a>.