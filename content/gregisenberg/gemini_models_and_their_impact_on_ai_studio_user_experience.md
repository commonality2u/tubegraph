---
title: Gemini models and their impact on AI Studio user experience
videoId: 6h9y1rLem4c
---

From: [[gregisenberg]] <br/> 

Google AI Studio is a platform designed to showcase the full capabilities of Google's AI models, primarily the Gemini models, to developers and businesses looking to leverage advanced AI technology <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>, <a class="yt-timestamp" data-t="00:00:47">[00:00:47]</a>, <a class="yt-timestamp" data-t="00:01:04">[00:01:04]</a>, <a class="yt-timestamp" data-t="00:02:39">[00:02:39]</a>. The intent of [[introduction_to_google_ai_studio_and_its_capabilities | AI Studio]] is to demonstrate how these models can be used to [[building_apps_with_ai_tools | build applications]] and businesses <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>, <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>. There is no cost involved with using [[introduction_to_google_ai_studio_and_its_capabilities | AI Studio]] <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>, and [[introduction_to_google_ai_studio_and_its_capabilities | API keys]] for Gemini models are also free, offering up to 1.5 billion tokens across various models <a class="yt-timestamp" data-t="00:28:49">[00:28:49]</a>, <a class="yt-timestamp" data-t="00:29:02">[00:29:02]</a>. This approach aims to remove the economic burden for developers and startups wanting to [[business_opportunities_using_ai_studio_and_machine_learning_models | build AI products]] <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>.

## Core Capabilities and User Experience Enhancement

The Gemini models, along with Gemma (an open-source version), are the core power behind the [[introduction_to_google_ai_studio_and_its_capabilities | AI Studio]] experience <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>, <a class="yt-timestamp" data-t="00:07:20">[00:07:20]</a>. Different models like 2.0 Flash, Flashlight, and Pro offer various trade-offs in power, cost, and intelligence <a class="yt-timestamp" data-t="00:07:34">[00:07:34]</a>.

### Long Context Processing
One significant capability showcased in the [[demo_of_ai_studio_functionalities_and_its_applications | demo of AI Studio functionalities]] is the ability to handle "long context" <a class="yt-timestamp" data-t="00:02:54">[00:02:54]</a>. Gemini models can process extensive media, such as a 30-minute video, and extract specific information from it <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>. For example, a 30-minute video of a museum tour can be processed to list all museum exhibits, which would be "basically impossible" without these models <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>, <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>. This capability opens up [[business_opportunities_using_ai_studio_and_machine_learning_models | opportunities]] for extracting trapped data in media, such as creating online directories from video or audio content <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>, <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>.

### Reasoning Models
AI Studio provides access to reasoning models, which allow the AI to "really think" about tasks before generating an output <a class="yt-timestamp" data-t="00:07:54">[00:07:54]</a>, <a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a>. In the UI, this thinking process is visible in a "thoughts" category, simulating an outline or planning phase that a human engineer might undertake for a complex task <a class="yt-timestamp" data-t="00:10:16">[00:10:16]</a>, <a class="yt-timestamp" data-t="00:11:04">[00:11:04]</a>. For example, the model can take a basic code snippet and generate a full website, landing page, and SaaS app, outlining the desired outcomes, code structure, technology stack, and MVP functionality <a class="yt-timestamp" data-t="00:10:01">[00:10:01]</a>, <a class="yt-timestamp" data-t="00:11:04">[00:11:04]</a>. This capability significantly streamlines the [[building_apps_with_ai_tools | development process]] and allows for complex code generation <a class="yt-timestamp" data-t="00:12:38">[00:12:38]</a>. The reasoning model is available for free for developers via [[introduction_to_google_ai_studio_and_its_capabilities | AI Studio]] and its API <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>, <a class="yt-timestamp" data-t="00:12:50">[00:12:50]</a>.

### Multimodal Capabilities
Gemini models enable "multimodal capabilities," allowing them to deeply understand different objects and their visual representation in images <a class="yt-timestamp" data-t="00:14:26">[00:14:26]</a>.
*   **Spatial Understanding**: The "spatial understanding" feature dynamically overlays 2D bounding boxes on images to identify the position of items <a class="yt-timestamp" data-t="00:13:42">[00:13:42]</a>, <a class="yt-timestamp" data-t="00:14:14">[00:14:14]</a>. This unlocks new [[business_opportunities_using_ai_studio_and_machine_learning_models | business ideas]] like furniture shopping sites that can identify items in a room from a picture, inventory management by snapping pictures, or real-time utilization monitoring for parking garages <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>.
*   **Function Calling**: Gemini models can integrate with existing products through "native function calling capabilities" <a class="yt-timestamp" data-t="00:18:18">[00:18:18]</a>. An example is linking [[introduction_to_google_ai_studio_and_its_capabilities | AI Studio]] to the Google Maps API to create a "geoguesser" experience that takes users to historical locations based on a prompt <a class="yt-timestamp" data-t="00:18:25">[00:18:25]</a>. This allows for a "combinatorial explosion" of new product experiences by bringing disparate products together with AI <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>. The code for these starter apps is available on GitHub for free use and modification <a class="yt-timestamp" data-t="00:19:38">[00:19:38]</a>.

### Real-time Streaming and AI Co-Presence
The multimodal live API, powered by Gemini, allows for real-time streaming experiences <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>. This enables "AI co-presence," where the AI can see what the user sees and hear what they say, providing real-time contextual help <a class="yt-timestamp" data-t="00:20:22">[00:20:22]</a>, <a class="yt-timestamp" data-t="00:20:40">[00:20:40]</a>.
*   **Dynamic Assistance**: A [[demo_of_ai_studio_functionalities_and_its_applications | demo]] showed the AI guiding a user through debugging code in a live environment, understanding screen content and command line output <a class="yt-timestamp" data-t="00:20:52">[00:20:52]</a>, <a class="yt-timestamp" data-t="00:21:42">[00:21:42]</a>.
*   **Future of Work**: This is seen as the "future of work," where an AI partner provides real-time value and intelligence, accelerating task completion <a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>, <a class="yt-timestamp" data-t="00:25:17">[00:25:17]</a>.
*   **Democratization of Access**: This capability can democratize access to learning and assistance, enabling people to learn complex skills like coding or video editing with AI guidance, even without a human tutor <a class="yt-timestamp" data-t="00:27:33">[00:27:33]</a>, <a class="yt-timestamp" data-t="00:27:56">[00:27:56]</a>.
*   **Tool Integration**: The real-time experience also supports native tool integration, allowing for pseudo-function calls, code execution in a virtual environment, and grounding (browsing the internet) to find solutions without leaving the product experience <a class="yt-timestamp" data-t="00:25:32">[00:25:32]</a>, <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>.

Despite some early rough edges in conversation flow, the "raw capabilities" showcased are highly promising for [[user_experience_design_for_ai_applications | future AI applications]] <a class="yt-timestamp" data-t="00:22:40">[00:22:40]</a>, <a class="yt-timestamp" data-t="00:26:33">[00:26:33]</a>. Google encourages user feedback to continuously improve the [[introduction_to_google_ai_studio_and_its_capabilities | AI Studio]] and API experiences <a class="yt-timestamp" data-t="00:28:14">[00:28:14]</a>, <a class="yt-timestamp" data-t="00:29:26">[00:29:26]</a>.