---
title: AI copresence and API integration
videoId: 6h9y1rLem4c
---

From: [[gregisenberg]] <br/> 

[[ai_studio_capabilities_and_demo | Google's AI Studio]] is designed to showcase the full capabilities of its AI models, particularly the Gemini models, offering developers a free platform to explore and build new applications leveraging Google's technology [00:00:07](<a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>, [00:02:45](<a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>).

## Integrating APIs with AI Applications

[[incorporating_ai_features_in_applications | Incorporating AI features in applications]] through API integration is a core strength highlighted by Google's AI Studio. The platform demonstrates how AI models can be connected with existing products and services to create new, differentiated experiences [00:19:04](<a class="yt-timestamp" data-t="00:19:04">[00:19:04]</a>).

### Examples of API Integration
*   **Google Maps API:** A thin "geoguesser" experience was built by hooking up [[ai_studio_capabilities_and_demo | AI Studio]] and Gemini to the Google Maps API, allowing the model to take users to historical locations based on a prompt [00:18:18](<a class="yt-timestamp" data-t="00:18:18">[00:18:18]</a>). This showcases how combining previously separate products with AI can lead to a "combinatorial explosion" of new business opportunities [00:19:09](<a class="yt-timestamp" data-t="00:19:09">[00:19:09]</a>).
*   **Code Editors (e.g., Cursor):** Developers can use their free [[integrating_apis_with_ai_applications | API keys]] from [[ai_studio_capabilities_and_demo | AI Studio]] to power experiences in other applications like Cursor, leveraging Gemini models for coding assistance [00:12:50](<a class="yt-timestamp" data-t="00:12:50">[00:12:50]</a>, [00:13:15](<a class="yt-timestamp" data-t="00:13:15">[00:13:15]</a>).

### Benefits for Developers
[[integrating_apis_with_ai_applications | API keys]] for Gemini models are free by default, offering up to 1.5 billion tokens across various models [00:28:49](<a class="yt-timestamp" data-t="00:28:49">[00:28:49]</a>). This aims to reduce the "economic burden" for developers and startups wanting to build AI products, with a clear path for scaling to production [00:29:07](<a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>).

## AI Copresence

[[ai_agents_and_their_applications | AI copresence]] refers to the concept of an AI being able to "see" and understand the context of a user's environment in real-time, providing assistance and intelligence accordingly [00:01:52](<a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>, [00:20:22](<a class="yt-timestamp" data-t="00:20:22">[00:20:22]</a>). This capability is powered by the multimodal live API [00:20:11](<a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>).

### Real-Time Interaction
A demonstration showed a model listening and responding to a user in real-time while viewing a code editor on a shared screen. The AI could identify the file type, note placeholder text for an [[integrating_apis_with_ai_applications | API key]], and suggest solutions for errors, similar to a pair programmer [00:20:35](<a class="yt-timestamp" data-t="00:20:35">[00:20:35]</a>, [00:23:29](<a class="yt-timestamp" data-t="00:23:29">[00:23:29]</a>).

### Future of Work and Applications
[[ai_agents_and_their_applications | AI copresence]] is seen as the future of work, allowing an AI partner to provide value and intelligence to any task [00:24:52](<a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>).
Potential applications include:
*   **Enhanced IDEs:** Moving beyond code autocompletion to having a "senior developer" AI in the IDE, understanding the entire screen, including browsers, in real-time [00:23:29](<a class="yt-timestamp" data-t="00:23:29">[00:23:29]</a>, [00:23:40](<a class="yt-timestamp" data-t="00:23:40">[00:23:40]</a>).
*   **Democratizing Learning:** Providing real-time assistance for learning new skills like coding or video editing, especially for those who don't have a tutor or support system [00:24:09](<a class="yt-timestamp" data-t="00:24:09">[00:24:09]</a>, [00:27:33](<a class="yt-timestamp" data-t="00:27:33">[00:27:33]</a>).
*   **Bridging External Information:** The model can integrate with native tools for code execution, and enable grounding to browse the internet for relevant information without leaving the product experience [00:25:32](<a class="yt-timestamp" data-t="00:25:32">[00:25:32]</a>, [00:25:51](<a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>).

While the current technology is an early look, it demonstrates the raw capabilities and hints at a future where AI is seamlessly integrated into user experiences [00:22:35](<a class="yt-timestamp" data-t="00:22:35">[00:22:35]</a>, [00:23:08](<a class="yt-timestamp" data-t="00:23:08">[00:23:08]</a>). Developers are encouraged to experiment with the multimodal live API at audio.google.com [00:28:01](<a class="yt-timestamp" data-t="00:28:01">[00:28:01]</a>).