---
title: Introduction to Google AI Studio and its capabilities
videoId: 6h9y1rLem4c
---

From: [[gregisenberg]] <br/> 

Google AI Studio is a platform designed to showcase the full capabilities of Google's AI technology, particularly its Gemini models <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>, <a class="yt-timestamp" data-t="00:02:39">[00:02:39]</a>. It is intended for anyone looking to [[building_a_startup_using_ai_tools | build a business using AI]] or leverage Google's multi-trillion dollar technology <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>.

## Core Features and User Experience

Accessing AI Studio is free and requires only a Google account <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>, <a class="yt-timestamp" data-t="00:02:34">[00:02:34]</a>. The platform aims to highlight the differentiated features and capabilities of Gemini models that may not be possible with other AI services <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>, <a class="yt-timestamp" data-t="00:01:30">[00:01:30]</a>.

### Prompt Gallery
AI Studio includes a prompt gallery that offers a wide range of examples, from simple queries to complex tasks like optimizing code or extracting information from images <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>, <a class="yt-timestamp" data-t="00:03:16">[00:03:16]</a>. This gallery is designed to demonstrate the full potential of the models <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a>.

### Long Context Understanding
One of the significant capabilities of AI Studio, powered by Gemini models, is its ability to handle "long context" information <a class="yt-timestamp" data-t="00:02:52">[00:02:52]</a>, <a class="yt-timestamp" data-t="00:03:49">[00:03:49]</a>. This allows the models to process extensive media, such as a 30-minute video or long audio files (e.g., podcasts), and extract detailed information, performing tasks that would otherwise be very difficult or impossible <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>, <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>, <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a>. For example, it can analyze a video of a museum tour and list all the exhibits shown <a class="yt-timestamp" data-t="00:04:07">[00:04:07]</a>.

## Gemini Models

The [[gemini_models_and_their_impact_on_ai_studio_user_experience | Gemini models]] are the core technology behind the AI Studio experience <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a>, <a class="yt-timestamp" data-t="00:07:12">[00:07:12]</a>. Users can experiment with various Gemini models, each with different trade-offs in terms of power, cost, and rate limits <a class="yt-timestamp" data-t="00:07:30">[00:07:30]</a>, <a class="yt-timestamp" data-t="00:07:34">[00:07:34]</a>.

*   **2.0 Flash Model**: More powerful and slightly more expensive <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a>.
*   **Flashlight Model**: Has higher rate limits and is a bit less intelligent but capable of many core tasks <a class="yt-timestamp" data-t="00:07:43">[00:07:43]</a>.
*   **Pro Model**: An experimental variant and the most intelligent model available <a class="yt-timestamp" data-t="00:07:49">[00:07:49]</a>.
*   **Reasoning Model**: Represents the "New Frontier capabilities" <a class="yt-timestamp" data-t="00:07:59">[00:07:59]</a>.

### Reasoning Models
The reasoning model allows the AI to "think" about different things before generating a final output <a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a>, <a class="yt-timestamp" data-t="00:08:39">[00:08:39]</a>. This thinking process, visible as "thoughts" in the UI (though abstracted in the API), mimics human outlining or planning, such as breaking down a software engineering task into desired outcomes, code, structure, and technology stack <a class="yt-timestamp" data-t="00:10:16">[00:10:16]</a>, <a class="yt-timestamp" data-t="00:10:52">[00:10:52]</a>.

For example, a user can provide a basic code snippet and prompt the reasoning model to transform it into a fully-fledged website, landing page, and SaaS application <a class="yt-timestamp" data-t="00:09:05">[00:09:05]</a>, <a class="yt-timestamp" data-t="00:10:07">[00:10:07]</a>. The model will then outline the necessary components, such as user authentication, a dashboard, and image generation tools, before generating the code <a class="yt-timestamp" data-t="00:11:12">[00:11:12]</a>. The reasoning model is available for free to developers in AI Studio and via an API key, which can also be used with tools like Cursor <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>, <a class="yt-timestamp" data-t="00:12:50">[00:12:50]</a>.

## Starter Apps and Advanced Capabilities

AI Studio offers "starter apps" to demonstrate the "art of the possible" with different model capabilities <a class="yt-timestamp" data-t="00:13:32">[00:13:32]</a>. The code for these starter apps is openly available on GitHub for users to download, modify, and use with a free API key <a class="yt-timestamp" data-t="00:19:38">[00:19:38]</a>, <a class="yt-timestamp" data-t="00:19:52">[00:19:52]</a>.

### Spatial Understanding
This capability allows the model to deeply understand and visually represent objects within images <a class="yt-timestamp" data-t="00:13:50">[00:13:50]</a>, <a class="yt-timestamp" data-t="00:13:54">[00:13:54]</a>. It can generate 2D bounding boxes, providing coordinates for objects in an image <a class="yt-timestamp" data-t="00:14:14">[00:14:14]</a>, <a class="yt-timestamp" data-t="00:14:59">[00:14:59]</a>. This multimodal capability enables generic object detection, useful for applications like furniture shopping (identifying items in a room image) or inventory management (tracking stock via pictures) <a class="yt-timestamp" data-t="00:14:34">[00:14:34]</a>, <a class="yt-timestamp" data-t="00:15:31">[00:15:31]</a>, <a class="yt-timestamp" data-t="00:16:00">[00:16:00]</a>. It can automate painful service-based tasks that agencies and consulting firms previously handled manually <a class="yt-timestamp" data-t="00:16:52">[00:16:52]</a>.

### Function Calling
AI Studio supports native function calling, allowing Gemini to connect with existing products and APIs <a class="yt-timestamp" data-t="00:18:18">[00:18:18]</a>. An example is integrating with the Google Maps API to create a "geoguesser" experience that takes users to historical or interesting locations based on prompts <a class="yt-timestamp" data-t="00:18:25">[00:18:25]</a>, <a class="yt-timestamp" data-t="00:18:41">[00:18:41]</a>. This capability creates a "combinatorial explosion" of potential new businesses by combining previously separate products with AI in the middle <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>. The amount of work required to build such solutions is relatively small compared to historical SaaS product development <a class="yt-timestamp" data-t="00:19:25">[00:19:25]</a>.

### Real-time Streaming (Multimodal Live API)
The Multimodal Live API powers real-time streaming experiences, enabling AI to be "co-present" with the user <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>, <a class="yt-timestamp" data-t="00:20:22">[00:20:22]</a>. This means the AI can see and hear what the user sees and says, providing real-time context and assistance <a class="yt-timestamp" data-t="00:20:22">[00:20:22]</a>, <a class="yt-timestamp" data-t="00:20:29">[00:20:29]</a>.

<div class="callout is-box">
<div class="callout-title">
<div class="callout-icon"></div>
AI Co-presence Example
</div>
<div class="callout-content">
A [[demo_of_ai_studio_functionalities_and_its_applications | demo]] showcased the AI assisting a developer in debugging Python code in a real-time console <a class="yt-timestamp" data-t="00:20:35">[00:20:35]</a>. The AI listened to the user's voice, saw the code editor, identified file and API key errors, and provided suggestions for resolution <a class="yt-timestamp" data-t="00:20:52">[00:20:52]</a>, <a class="yt-timestamp" data-t="00:21:42">[00:21:42]</a>.
</div>
</div>

This capability is seen as the future of work and [[building_apps_with_ai_tools | building apps with AI tools]], enabling an AI partner to provide value and intelligence to any task <a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>. It can act as a senior developer pair-programming in an IDE, seeing the user's entire screen (including browser content) and providing real-time assistance <a class="yt-timestamp" data-t="00:23:29">[00:23:29]</a>, <a class="yt-timestamp" data-t="00:23:40">[00:23:40]</a>, <a class="yt-timestamp" data-t="00:23:45">[00:23:45]</a>. The Multimodal Live API supports native tool integrations, including code execution in a Python virtual environment and "grounding" to browse the internet for information, all within the product experience <a class="yt-timestamp" data-t="00:25:32">[00:25:32]</a>, <a class="yt-timestamp" data-t="00:25:46">[00:25:46]</a>, <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>.

This technology helps democratize access to expertise, assisting users across various skill levels, from learning to code to editing videos <a class="yt-timestamp" data-t="00:24:03">[00:24:03]</a>, <a class="yt-timestamp" data-t="00:24:25">[00:24:25]</a>, <a class="yt-timestamp" data-t="00:27:56">[00:27:56]</a>. The Multimodal Live API is free to use and prototype with an API key, offering 1.5 billion tokens across various Gemini models <a class="yt-timestamp" data-t="00:28:01">[00:28:01]</a>, <a class="yt-timestamp" data-t="00:28:49">[00:28:49]</a>, <a class="yt-timestamp" data-t="00:28:57">[00:28:57]</a>.

Google's goal with AI Studio and its free API access is to "remove the economic burden for developers for startups to start [[building_apps_with_ai_tools | building really cool AI products]]" <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>, <a class="yt-timestamp" data-t="00:29:12">[00:29:12]</a>.