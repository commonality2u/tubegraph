---
title: Security and privacy concerns with AI applications
videoId: HVhXwBYenC8
---

From: [[gregisenberg]] <br/> 

The rapid emergence of AI tools like Manis AI brings significant discussions around data security and user privacy, especially concerning the origin and operational transparency of these applications <a class="yt-timestamp" data-t="00:26:59">[00:26:59]</a>.

## Data Handling by Chinese AI Companies

A primary concern stems from the fact that Manis AI is a Chinese company <a class="yt-timestamp" data-t="00:27:07">[00:27:07]</a>. There is a valid concern that Chinese companies are obligated to provide government access to data <a class="yt-timestamp" data-t="00:27:30">[00:27:30]</a>. This raises reluctance among users to provide personal or sensitive information to such tools <a class="yt-timestamp" data-t="00:27:49">[00:27:49]</a>.

> "If you are a Chinese company, I think you're obligated to give access to the government so because of that reason and I know people are very reluctant to use this..." <a class="yt-timestamp" data-t="00:27:38">[00:27:38]</a>

Concerns also extend to financial interactions, where users might worry about data being compromised if they were to integrate services like Stripe accounts, potentially handing over sensitive financial information <a class="yt-timestamp" data-t="00:33:34">[00:33:34]</a>.

## Mitigating Risks and Best Practices

When using AI tools, particularly those with opaque data handling policies, caution is advised:
*   **Be Mindful of Shared Data** Users should be very careful and mindful of the data they share <a class="yt-timestamp" data-t="00:29:21">[00:29:21]</a>.
*   **Avoid Personal Information** It is recommended not to throw any personal information into these tools <a class="yt-timestamp" data-t="00:28:04">[00:28:04]</a>.
*   **Keep Requests General** Keep requests vague and do simple tests, such as cloning a website, to understand how the tool works without exposing sensitive data <a class="yt-timestamp" data-t="00:29:33">[00:29:33]</a>.
*   **Scan Generated Code** If an AI tool generates code for local deployment, it is crucial to scan through the code to ensure its safety before running it on a local computer <a class="yt-timestamp" data-t="00:55:14">[00:55:14]</a>.
*   **Utilize Virtual Sandboxes** Running generated code in a virtual sandbox in the cloud rather than directly on a local machine can add an extra layer of security <a class="yt-timestamp" data-t="00:55:46">[00:55:46]</a>.

## Competitive Landscape and Open-Source Alternatives

Despite the [[competitive_approach_to_ai_usage | challenges and limitations of AI tools]] posed by Manis AI's origin, it highlights the importance for US companies and developers to understand the competition <a class="yt-timestamp" data-t="00:28:14">[00:28:14]</a>. Manis AI's approach of integrating multiple AI capabilities and tools into one framework has been noted as a "second deep seek moment for China" <a class="yt-timestamp" data-t="00:28:23">[00:28:23]</a>.

This development is expected to spur [[startup_ideas_using_ai_technology | US companies]] to build similar, potentially more secure, tools <a class="yt-timestamp" data-t="00:28:47">[00:28:47]</a>. The emergence of several open-source projects mirroring Manis AI's functionality also provides alternatives for users who prefer transparency and control over their data <a class="yt-timestamp" data-t="00:29:02">[00:29:02]</a>.

Ultimately, while [[opportunities_for_ai_applications_in_career_advancement | AI tools]] like Manis AI offer impressive capabilities for automating business and product development <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>, users should prioritize [[human_versus_ai_services | data safety and privacy]] by being informed and cautious about the information they share <a class="yt-timestamp" data-t="00:27:56">[00:27:56]</a>.