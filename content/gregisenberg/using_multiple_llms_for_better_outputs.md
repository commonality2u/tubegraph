---
title: Using multiple LLMs for better outputs
videoId: 3sbZOMR03uw
---

From: [[gregisenberg]] <br/> 

A method has been developed to achieve significantly better results, including improved copy and overall output, from large language models (LLMs) such as ChatGPT, Grok, Claude, and Gemini, often yielding five times more effectiveness without additional cost <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.

## The "Jealousy" Method: Pitting LLMs Against Each Other

The core idea behind this method is to make LLMs "jealous" of each other to encourage them to provide better output <a class="yt-timestamp" data-t="00:00:45">[00:00:45]</a>. This approach involves opening multiple LLMs simultaneously (e.g., two, three, or four at a time) for a single task <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a>.

The process involves:
1.  **Initial Prompting**: Provide the same prompt to each open LLM <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>.
2.  **Competitive Feedback**: After receiving responses from all LLMs, begin the "jealousy" phase <a class="yt-timestamp" data-t="00:02:25">[00:02:25]</a>. This involves critiquing one LLM's response by comparing it to another's, sometimes even fabricating or exaggerating the quality of another LLM's output <a class="yt-timestamp" data-t="00:02:33">[00:02:33]</a>.
3.  **Sharing "Better" Examples**: Share the output from an LLM that performed well with another LLM, indicating that the first LLM "crushed it" or was significantly better <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>. This prompts the challenged LLM to improve its subsequent response.

This strategy capitalizes on a competitive dynamic, leading to [[enhancing_ai_effectiveness_through_competition | enhanced AI effectiveness]] <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>.

### Practical Example: Cold Email Generation

To illustrate, consider creating a cold email for a design firm named LCA, which specializes in designing AI interfaces <a class="yt-timestamp" data-t="00:01:31">[00:01:31]</a>.

1.  **Grok's Initial Attempt**: Grok produced an email template focusing on intuitive AI interfaces, stating LCA crafts interfaces that captivate <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>. It included elements like specialized expertise and a call to action for a 15-minute call <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>. This was considered "not bad" <a class="yt-timestamp" data-t="00:03:18">[00:03:18]</a>.

2.  **ChatGPT's Initial Attempt**: ChatGPT's subject line was "Your AI deserves better design" <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a>. Its email highlighted LCA's focus on designing interfaces that build trust in AI, mentioning companies like Grammarly, Shopify, and Slack <a class="yt-timestamp" data-t="00:03:30">[00:03:30]</a>. It offered a "quick tear down" with ideas to improve conversion and UX <a class="yt-timestamp" data-t="00:03:53">[00:03:53]</a>. This was deemed "not bad," but the user decided to rate it poorly to instigate competition <a class="yt-timestamp" data-t="00:04:02">[00:04:02]</a>.

3.  **Challenging ChatGPT**: ChatGPT was told that Grok "crushed it" with a "nine on 10," while ChatGPT was "average" at "five on 10," questioning why it wasn't the "better LLM" <a class="yt-timestamp" data-t="00:04:12">[00:04:12]</a>. Grok's output was then shared with ChatGPT <a class="yt-timestamp" data-t="00:04:36">[00:04:36]</a>.
    *   **ChatGPT's Improved Response**: ChatGPT acknowledged Grok's polished version but then generated a "9.5 out of 10" email with more punch and a fresher, more brag-worthy tone that captured the user's specific voice <a class="yt-timestamp" data-t="00:04:45">[00:04:45]</a>. This revised email focused on making AI feel "magical, not mechanical," and directly addressed activation and retention, offering a personalized "tear down" <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>. This output was considered a "standing ovation" <a class="yt-timestamp" data-t="00:05:54">[00:05:54]</a>.

4.  **Challenging Claude**: The same competitive tactic was applied to Claude, implying that ChatGPT's output was "10x better" and suggesting Claude was a "Toyota" compared to a "Rolls-Royce" <a class="yt-timestamp" data-t="00:06:12">[00:06:12]</a>. Claude's subsequent response also showed an improved understanding of the user's voice and context <a class="yt-timestamp" data-t="00:06:47">[00:06:47]</a>.

## Benefits and Observations

This approach leads to significantly better outputs from LLMs <a class="yt-timestamp" data-t="00:07:20">[00:07:20]</a>. An interesting observation is that LLMs, particularly those with larger context windows, seem to understand the user's personal context and identity better through this iterative, competitive process <a class="yt-timestamp" data-t="00:06:53">[00:06:53]</a>. This "hack" has proven to be very helpful for generating high-quality content <a class="yt-timestamp" data-t="00:07:25">[00:07:25]</a>.