---
title: Personalization and style referencing in Midjourney
videoId: h5nxat56wKI
---

From: [[gregisenberg]] <br/> 

Midjourney is considered an entirely [[Midjourney as a new medium for art creation | new medium]] for art creation, acting as a different type of canvas and a different way of problem-solving in design <a class="yt-timestamp" data-t="00:00:01">[00:00:01]</a>. Unlike traditional paint, it offers entire [[exploring_aesthetics_and_style_references_in_midjourney | Aesthetics]] with layers and complexity that can be blended and balanced to achieve desired harmony <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>.

## Why Use Midjourney?

Professionally, Midjourney serves as a significant inspiration tool, allowing users to rapidly develop ideas and create mood boards in a more controlled manner than traditional image searches <a class="yt-timestamp" data-t="00:11:16">[00:11:16]</a>. It's also effective for production, especially with new features like the editor for outpainting and adding elements <a class="yt-timestamp" data-t="00:11:52">[00:11:52]</a>. Beyond professional use, many find it enjoyable, akin to art therapy, as it allows users to get lost in creative exploration <a class="yt-timestamp" data-t="00:12:14">[00:12:14]</a>.

The tool acts as a "discovery engine," enabling users to explore [[exploring_aesthetics_and_style_references_in_midjourney | Aesthetics]] and embark on creative "rabbit holes" <a class="yt-timestamp" data-t="00:12:27">[00:12:27]</a>. High-level Midjourney users can create art so refined that it is indistinguishable from traditional art, potentially appearing in galleries or on websites as impactful design assets <a class="yt-timestamp" data-t="00:12:51">[00:12:51]</a>.

## Midjourney Web App vs. Discord

For optimal experience, users should transition from Discord to the Midjourney web app (midjourney.com), which is now open to everyone <a class="yt-timestamp" data-t="00:06:36">[00:06:36]</a>.

### Explore Tab
The web app's "Explore" tab showcases all publicly available generations, serving as a vast library of inspiration <a class="yt-timestamp" data-t="00:07:05">[00:07:05]</a>. Users can search for specific themes (e.g., "vintage poster") <a class="yt-timestamp" data-t="00:07:31">[00:07:31]</a>. Clicking a search icon on a generated image provides similar results based on subject matter and style <a class="yt-timestamp" data-t="00:07:46">[00:07:46]</a>.

### Privacy Considerations
By default, generations on Standard Plan accounts and below are public <a class="yt-timestamp" data-t="00:07:19">[00:07:19]</a>. For client work or proprietary imagery, a Pro Plan or higher is required to enable "stealth mode" via the settings in the prompt bar, preventing assets from showing up in the public database <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>.

### Organization
Users are advised to "like" their favorite generations by clicking the heart icon or right-clicking and selecting "like" <a class="yt-timestamp" data-t="00:27:19">[00:27:19]</a>. This allows for easy filtering in the "Organize" tab, making it simpler to locate preferred images among hundreds of generations <a class="yt-timestamp" data-t="00:27:50">[00:27:50]</a>.

## Style References

Style references are images used to influence the aesthetic of new generations without necessarily pulling in the subject matter of the reference image itself <a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a>.

### Image Prompt vs. Style Reference
When uploading an image in Midjourney, it defaults to an "image prompt" (represented by a pict icon) <a class="yt-timestamp" data-t="00:14:27">[00:14:27]</a>. An image prompt attempts to pull in the subject matter and actual pixels of the reference image, which can lead to unexpected results if the goal is only to transfer style <a class="yt-timestamp" data-t="00:20:13">[00:20:13]</a>.

To use an image as a style reference, click the "paperclip" icon after uploading <a class="yt-timestamp" data-t="00:14:35">[00:14:35]</a>. Midjourney then analyzes the image's style elements (color, composition, lighting, texture, pattern) and applies them to the new generation, decoupling them from the original subject matter <a class="yt-timestamp" data-t="00:19:49">[00:19:49]</a>, <a class="yt-timestamp" data-t="00:40:19">[00:40:19]</a>.

### Style Weight Parameter (`--sw`)
The `--sw` parameter (style weight) controls how much influence a style reference has over the generation <a class="yt-timestamp" data-t="00:17:18">[00:17:18]</a>. The default value is 100, but it can be increased up to 1000 for stronger influence <a class="yt-timestamp" data-t="00:17:36">[00:17:36]</a>. Initially, it's recommended to start with a basic text prompt and style reference to observe Midjourney's interpretation, then adjust the style weight and add more descriptive text if needed <a class="yt-timestamp" data-t="00:16:12">[00:16:12]</a>.

### Blending Multiple Styles
Multiple style references can be used simultaneously, blending their unique flares into the mix <a class="yt-timestamp" data-t="00:28:42">[00:28:42]</a>. Weights can be assigned to individual style references using the double colon syntax (`::`) followed by a number to control their relative influence (e.g., `sref1::2 sref2::1`) <a class="yt-timestamp" data-t="00:44:34">[00:44:34]</a>.

### Style Reference Codes (SRF Codes)
Beyond image-based style references, Midjourney also uses "style reference codes" (SRF codes) <a class="yt-timestamp" data-t="00:37:16">[00:37:16]</a>. These codes are like coordinates in a multi-dimensional [[exploring_aesthetics_and_style_references_in_midjourney | Style Space]], directing the AI to a specific aesthetic location <a class="yt-timestamp" data-t="00:37:34">[00:37:34]</a>. There are billions of possible SRF codes, representing vast aesthetic possibilities <a class="yt-timestamp" data-t="00:38:01">[00:38:01]</a>.

Users can "mine" these codes from Midjourney, curate them into lists, and combine them with personalization and text prompts to build unique "aesthetic recipes" <a class="yt-timestamp" data-t="00:38:08">[00:38:08]</a>. Tools like a "Style Reference Explorer" (containing thousands of images with associated SRF codes) allow for visual exploration of these codes <a class="yt-timestamp" data-t="00:36:53">[00:36:53]</a>.

## Personalization

Personalization allows Midjourney to learn a user's specific [[exploring_aesthetics_and_style_references_in_midjourney | aesthetic]] preferences, fine-tuning the model to their taste <a class="yt-timestamp" data-t="00:32:31">[00:32:31]</a>.

### Training Personalization
To activate personalization, go to the "Personalize" tab and start teaching the AI by rating images <a class="yt-timestamp" data-t="00:29:37">[00:29:37]</a>. Users simply select their favorite image from a pair or skip if neither appeals <a class="yt-timestamp" data-t="00:29:51">[00:29:51]</a>. The more images rated (e.g., a thousand), the more Midjourney learns about preferences like preferred colors, lighting, general style (photographic vs. illustrative), and even subject matter <a class="yt-timestamp" data-t="00:30:13">[00:30:13]</a>.

### Stylize Parameter (`--s`)
The `--s` parameter (stylize) determines how much of Midjourney's default, community-curated aesthetic is applied to a text prompt <a class="yt-timestamp" data-t="00:31:20">[00:31:20]</a>. High stylize values (e.g., 1000) result in images that distinctly "scream AI" or look very much like the default Midjourney style <a class="yt-timestamp" data-t="00:32:15">[00:32:15]</a>. The default stylize value is 100 <a class="yt-timestamp" data-t="00:32:00">[00:32:00]</a>.

When personalization is turned on, the `--s` parameter controls the influence of the user's fine-tuned aesthetic <a class="yt-timestamp" data-t="00:32:45">[00:32:45]</a>. Increasing the stylize value with personalization active increases the "heavy-handedness" of the user's preferences in the generation <a class="yt-timestamp" data-t="00:48:32">[00:48:32]</a>.

## Combining Levers for Aesthetic Control

Midjourney offers various "aesthetic levers" that users can pull to guide and push aesthetics in desired directions <a class="yt-timestamp" data-t="00:29:03">[00:29:03]</a>. The key is to learn how to balance and find harmony between them <a class="yt-timestamp" data-t="00:18:29">[00:18:29]</a>.

These levers include:
*   **Text Prompt:** The primary description of the desired image, which can include details about subject, medium (e.g., "paper cutout illustration"), and more <a class="yt-timestamp" data-t="00:18:05">[00:18:05]</a>.
*   **Style References (Images or SRF Codes):** Guides the overall aesthetic <a class="yt-timestamp" data-t="00:15:06">[00:15:06]</a>, <a class="yt-timestamp" data-t="00:38:45">[00:38:45]</a>.
*   **Parameters:**
    *   `--sw` (Style Weight): Controls style reference influence <a class="yt-timestamp" data-t="00:17:18">[00:17:18]</a>.
    *   `--ar` (Aspect Ratio): Defines the image dimensions (e.g., `2:3` for a poster print) <a class="yt-timestamp" data-t="00:19:03">[00:19:03]</a>.
    *   `--no`: Excludes elements from the generation (e.g., `--no text`) <a class="yt-timestamp" data-t="00:26:52">[00:26:52]</a>.
    *   `--s` (Stylize): Controls personalization influence or default model aesthetic <a class="yt-timestamp" data-t="00:31:17">[00:31:17]</a>.
    *   `--raw`: Leans towards a more photorealistic output <a class="yt-timestamp" data-t="00:52:08">[00:52:08]</a>.
*   **Personalization:** The user's fine-tuned aesthetic preferences <a class="yt-timestamp" data-t="00:30:29">[00:30:29]</a>.

### Iterative Process
The creation process in Midjourney is iterative <a class="yt-timestamp" data-t="00:42:02">[00:42:02]</a>:
1.  Start simple with a subject and possibly a medium <a class="yt-timestamp" data-t="00:04:31">[00:04:31]</a>.
2.  Add a style reference and observe the initial interpretation <a class="yt-timestamp" data-t="00:16:12">[00:16:12]</a>.
3.  Adjust parameters like `--sw` and refine the text prompt for better support <a class="yt-timestamp" data-t="00:17:14">[00:17:14]</a>, <a class="yt-timestamp" data-t="00:18:05">[00:18:05]</a>.
4.  Experiment with different style references or SRF codes, blending them and adjusting their weights <a class="yt-timestamp" data-t="00:39:59">[00:39:59]</a>.
5.  Incorporate personalization and adjust the stylize parameter <a class="yt-timestamp" data-t="00:47:57">[00:47:57]</a>.
6.  Use "permutation prompts" (e.g., `{100, 200, 500}`) to run multiple values of a parameter at once, quickly visualizing the outcomes <a class="yt-timestamp" data-t="00:49:17">[00:49:17]</a>.
7.  Analyze visual results and decide what further adjustments are needed to achieve the desired outcome <a class="yt-timestamp" data-t="00:42:06">[00:42:06]</a>.

### Editor Feature
The editor feature allows users to directly modify existing generations, such as painting out unwanted elements (e.g., text) or adjusting compositions <a class="yt-timestamp" data-t="00:26:29">[00:26:29]</a>.

## Midjourney as a New Medium
The combination of style references, personalization, and various parameters transforms Midjourney into a new medium for art, offering a complex yet controllable way to blend [[exploring_aesthetics_and_style_references_in_midjourney | Aesthetics]] <a class="yt-timestamp" data-t="00:46:09">[00:46:09]</a>. It allows artists to go beyond the semantic limitations of text prompting, leveraging the complexity and depth of visuals to create unique "style potions" <a class="yt-timestamp" data-t="00:47:02">[00:47:02]</a>, <a class="yt-timestamp" data-t="00:42:42">[00:42:42]</a>. This deep control over aesthetic direction allows for building a personalized creative world <a class="yt-timestamp" data-t="00:46:44">[00:46:44]</a>.

There is also an initiative to physically manifest latent space, building a lab with equipment like robots for painting and music, 3D printers, and editing stations to bring digital creations to life <a class="yt-timestamp" data-t="00:59:47">[00:59:47]</a>.