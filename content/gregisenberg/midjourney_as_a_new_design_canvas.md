---
title: MidJourney as a new design canvas
videoId: h5nxat56wKI
---

From: [[gregisenberg]] <br/> 

[[ai_design_tools_like_runway_and_midjourney | MidJourney]] is envisioned as an entirely new medium, a different type of canvas for problem-solving <a class="yt-timestamp" data-t="00:00:01">[00:00:01]</a>. Unlike traditional paint, it allows users to work with "entire Aesthetics" that possess layers and complexity <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>. The process involves blending and balancing these elements to achieve a desired harmony <a class="yt-timestamp" data-t="00:00:15">[00:00:15]</a>. Once a "recipe" is discovered, it can be infinitely prompted into <a class="yt-timestamp" data-t="00:00:24">[00:00:24]</a>.

## Moving Beyond Text Prompts
Initially, [[ai_design_tools_like_runway_and_midjourney | MidJourney]] primarily relied on word prompts and parameters <a class="yt-timestamp" data-t="00:01:55">[00:01:55]</a>. While words are still useful, they are only the "tip of the iceberg" <a class="yt-timestamp" data-t="00:01:07">[00:01:07]</a>. The real power comes from [[visual_versus_text_prompts_in_midjourney | using visuals to drive visuals]], which allows for an explosion of aesthetics and style space into infinite directions <a class="yt-timestamp" data-t="00:01:12">[00:01:12]</a>. This approach reduces reliance on the base model's interpretation of style tokens, allowing users to "pave their own lane" <a class="yt-timestamp" data-t="00:01:29">[00:01:29]</a>. Text prompting is described as "super limiting" because it's confined by the model's semantic interpretation of words <a class="yt-timestamp" data-t="00:46:58">[00:46:58]</a>, whereas visuals are more complex and cannot be put into a semantic box <a class="yt-timestamp" data-t="00:47:08">[00:47:08]</a>.

## Core Concepts of the New Canvas
### Style References
Images can be used as [[exploring_aesthetics_with_style_space_in_midjourney | style references]] to influence generations <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>. When an image is set as a style reference (indicated by a paperclip icon), [[ai_design_tools_like_runway_and_midjourney | MidJourney]] attempts to understand and integrate its aesthetic elements, decoupling aesthetics from subject matter <a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a>. This differs significantly from an "image prompt" (indicated by a pict icon), which pulls in subject matter and actual pixels from the source image, potentially leading to unintended or "wonky" results if only the style is desired <a class="yt-timestamp" data-t="00:20:00">[00:20:00]</a>.

### Style Weight
The `--sw` (style weight) parameter determines the influence of a style reference over the generation <a class="yt-timestamp" data-t="00:17:21">[00:17:21]</a>. The default is 100, but it can be increased up to 1000 to lean more heavily into the style reference's aesthetic <a class="yt-timestamp" data-t="00:17:40">[00:17:40]</a>.

### Aesthetic Levers
[[ai_design_tools_like_runway_and_midjourney | MidJourney]] provides various "aesthetic levers" for control:
*   **Style References**: Images that guide the aesthetic <a class="yt-timestamp" data-t="00:29:09">[00:29:09]</a>.
*   **Text Prompt**: Descriptive text that influences the subject matter and general direction <a class="yt-timestamp" data-t="00:29:11">[00:29:11]</a>.
*   **Parameters**: Values like `--sw` (style weight) and `--ar` (aspect ratio) to fine-tune outputs <a class="yt-timestamp" data-t="00:17:18">[00:17:18]</a>.
*   **Personalization**: [[personalization_and_style_reference_codes_in_midjourney | MidJourney]] learns a user's aesthetic preferences through image ratings, allowing for a fine-tuned model that reflects individual taste (e.g., color, lighting, style, subject matter) <a class="yt-timestamp" data-t="00:29:36">[00:29:36]</a>. This can be enabled or disabled, and its influence can be adjusted with the `stylize` parameter <a class="yt-timestamp" data-t="00:31:17">[00:31:17]</a>. A higher `stylize` value means more of the model's curated aesthetics (or your personalized aesthetics, if enabled) are applied <a class="yt-timestamp" data-t="00:31:40">[00:31:40]</a>.
*   **Style Reference Codes (SRF codes)**: These are unique codes that act as "coordinates in a multi-dimensional Style Space," directing the model to a specific aesthetic universe. Prompting into an SRF code influences anything generated by the aesthetics of that universe <a class="yt-timestamp" data-t="00:37:31">[00:37:31]</a>. These codes represent aspects like color, composition, lighting, texture, and pattern <a class="yt-timestamp" data-t="00:40:19">[00:40:19]</a>. Users can blend multiple SRF codes to create unique aesthetic combinations <a class="yt-timestamp" data-t="00:41:39">[00:41:39]</a>.

### Workflow and Exploration
The ideal workflow involves starting simply and iteratively refining the prompt:
1.  **Initial Prompt**: Start with a basic subject and perhaps a medium (e.g., painting, illustration, photograph) <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>.
2.  **Analyze Interpretation**: Observe how [[ai_design_tools_like_runway_and_midjourney | MidJourney]] interprets the initial prompt and style references <a class="yt-timestamp" data-t="00:16:28">[00:16:28]</a>.
3.  **Refine with Parameters**: Adjust parameters like style weight and aspect ratio to guide the aesthetics <a class="yt-timestamp" data-t="00:17:18">[00:17:18]</a>.
4.  **Assist with Text**: Add more specific descriptive words to the text prompt to support the desired look <a class="yt-timestamp" data-t="00:18:05">[00:18:05]</a>.
5.  **Explore Variations**: Use "subtle" or "strong" variations to explore different compositions while maintaining the general vibe <a class="yt-timestamp" data-t="00:25:35">[00:25:35]</a>.
6.  **Editor Feature**: The new editor allows for outpainting and adding new elements, or removing unwanted ones (e.g., text) <a class="yt-timestamp" data-t="00:26:28">[00:26:28]</a>.

The overarching goal is to find "balance and harmony" between these aesthetic levers <a class="yt-timestamp" data-t="00:28:29">[00:28:29]</a>. This process is less like a "slot machine game" and more about making guided decisions to understand why things are happening <a class="yt-timestamp" data-t="00:45:22">[00:45:22]</a>.

## Benefits of the New Canvas
*   **Inspiration Tool**: [[midjourney_for_inspiration_and_creative_exploration | MidJourney]] is a powerful tool for ideation, concept generation, and discovery <a class="yt-timestamp" data-t="00:11:16">[00:11:16]</a>. It functions similarly to mood boards built from Pinterest or Dribbble, but with more control <a class="yt-timestamp" data-t="00:11:36">[00:11:36]</a>.
*   **Creative Control**: Users have significant creative control over the aesthetic direction <a class="yt-timestamp" data-t="00:36:09">[00:36:09]</a>.
*   **Production Utility**: It can be used in production workflows, especially with the editor feature for manipulating existing assets <a class="yt-timestamp" data-t="00:11:52">[00:11:52]</a>.
*   **"Art Therapy"**: Many find it a fun and engaging tool to get lost in <a class="yt-timestamp" data-t="00:12:14">[00:12:14]</a>.
*   **Asset Creation**: [[ai_design_tools_like_runway_and_midjourney | MidJourney]] helps transform ideas into "living breathing assets" for websites, landing pages, or social media <a class="yt-timestamp" data-t="00:13:23">[00:13:23]</a>.

## Future Developments
There's potential for a marketplace where users could sell their "personalizations" or curated style reference books <a class="yt-timestamp" data-t="00:36:30">[00:36:30]</a>. A lab is being built in Red Hook, in partnership with Pioneer Works, to teach users how to use these tools deeply and bring digital creations to life through equipment like robots, 3D printers, and plotter printers <a class="yt-timestamp" data-t="00:59:51">[00:59:51]</a>. The goal is to physically manifest latent space, bridging the gap between digital art and physical exhibition <a class="yt-timestamp" data-t="00:59:51">[00:59:51]</a>.