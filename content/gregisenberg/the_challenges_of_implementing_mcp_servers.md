---
title: The Challenges of Implementing MCP Servers
videoId: 7j_NE6Pjv-E
---

From: [[gregisenberg]] <br/> 

While [[understanding_mcps_and_their_importance | MCPs]] (Modular Common Protocols) are gaining significant attention and aim to make [[mcps_and_their_role_in_making_llms_more_capable | LLMs more capable]], their implementation is not without hurdles. Currently, the process of setting up and managing [[understanding_mcps_and_their_importance | MCP]] servers presents several technical challenges <a class="yt-timestamp" data-t="00:13:50">[00:13:50]</a>.

## Current Implementation Difficulties

Setting up an [[understanding_mcps_and_their_importance | MCP]] server on various [[understanding_mcps_and_their_importance | MCP]] clients is described as "annoying" <a class="yt-timestamp" data-t="00:13:53">[00:13:53]</a>. This difficulty stems from several practical issues:
*   **Manual Processes** There's a significant amount of manual work involved, requiring "a lot of downloading," moving files, copying data, and other setup steps <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a>. Much of this setup is localized, focusing on "local stuff" <a class="yt-timestamp" data-t="00:14:05">[00:14:05]</a>.
*   **Unresolved Issues** There are still "kinks that have to be figured out" within the [[understanding_mcps_and_their_importance | MCP]] standard and its implementation <a class="yt-timestamp" data-t="00:14:08">[00:14:08]</a>.
*   **Cohesion Challenges** Even without [[understanding_mcps_and_their_importance | MCPs]], integrating multiple tools with [[mcps_and_their_role_in_making_llms_more_capable | LLMs]] can be "a nightmare" <a class="yt-timestamp" data-t="00:05:43">[00:05:43]</a>, requiring substantial engineering hours. For example, the significant effort invested by AI startups like Tempo or in projects like [[challenges_and_limitations_of_manis_ai | Manis AI]] to make tools work cohesively highlights the complexity involved in such integrations <a class="yt-timestamp" data-t="00:14:41">[00:14:41]</a>. While [[understanding_mcps_and_their_importance | MCPs]] aim to simplify this, the current early stage still presents integration challenges <a class="yt-timestamp" data-t="00:18:07">[00:18:07]</a>.

## The Evolving Standard

The standard for [[understanding_mcps_and_their_importance | MCPs]] is still in its nascent stages <a class="yt-timestamp" data-t="00:17:43">[00:17:43]</a>. The current challenges are expected to lessen as the standard becomes "figured out or finalized polished," or if "someone comes up with a better one" <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>.

The ecosystem currently consists of [[understanding_mcps_and_their_importance | MCP]] clients (like Tempo, Wind Surf, Cursor), the protocol itself, [[understanding_mcps_and_their_importance | MCP]] servers, and the external services they connect to <a class="yt-timestamp" data-t="00:11:07">[00:11:07]</a>. The responsibility for building these [[understanding_mcps_and_their_importance | MCP]] servers currently falls on service providers <a class="yt-timestamp" data-t="00:12:18">[00:12:18]</a>.

Until the [[comparison_of_mcps_with_existing_standards | MCP standard]] is finalized and adopted across the board by service providers, integrating services seamlessly remains a challenge <a class="yt-timestamp" data-t="00:17:52">[00:17:52]</a>. The possibility of new standards emerging, such as one from OpenAI, further underscores the early and fluid state of the technology <a class="yt-timestamp" data-t="00:19:27">[00:19:27]</a>.

Therefore, while the potential for [[mcps_and_their_role_in_making_llms_more_capable | making LLMs more capable]] is significant, those looking to engage with [[understanding_mcps_and_their_importance | MCPs]]—whether from a technical or business perspective—should closely observe the evolving landscape and the solidification of the standard before making major strategic moves <a class="yt-timestamp" data-t="00:19:03">[00:19:03]</a>.