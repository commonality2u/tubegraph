---
title: Google AI Studio demonstration and features
videoId: 6h9y1rLem4c
---

From: [[gregisenberg]] <br/> 

[[Google AI Studio demonstration and features | Google AI Studio]], led by Logan Kilpatrick, Google's Product Lead for AI Studio, is a platform designed to showcase the full capabilities of its underlying AI models <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>, <a class="yt-timestamp" data-t="00:00:48">[00:00:48]</a>, <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>. It is particularly relevant for those interested in [[using_ai_to_build_software_applications | building businesses using AI]] and leveraging Google's technology <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>, <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>. The platform is free to use <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>, allowing users to explore and identify differentiated features <a class="yt-timestamp" data-t="00:02:52">[00:02:52]</a>.

## Core Features and Capabilities

### Basic Prompting and Gallery
[[Google AI Studio demonstration and features | AI Studio]] offers a basic left-hand navigation for direct prompting, where users can interact with the models and receive responses <a class="yt-timestamp" data-t="00:02:59">[00:02:59]</a>, <a class="yt-timestamp" data-t="00:03:03">[00:03:03]</a>. It also includes a "Prompt Gallery" that provides a wide range of examples, from light-hearted tasks like generating trip ideas to more complex functions such as optimizing code <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>, <a class="yt-timestamp" data-t="00:03:16">[00:03:16]</a>. This gallery aims to demonstrate the extensive capabilities of the models <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a>.

### Long Context Processing
One of the most significant differentiated features of [[Google AI Studio demonstration and features | AI Studio]] and the [[Gemini models in AI Studio | Gemini models]] is their ability to handle long contexts <a class="yt-timestamp" data-t="00:02:54">[00:02:54]</a>, <a class="yt-timestamp" data-t="00:03:42">[00:03:42]</a>, <a class="yt-timestamp" data-t="00:04:46">[00:04:46]</a>. This includes processing lengthy videos and extracting information <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>.

For instance, a 30-minute video tour of the Natural History Museum can be uploaded, and the model can be prompted to list all museum exhibits found in the video <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>. This process leverages 531,000 tokens for the video <a class="yt-timestamp" data-t="00:04:53">[00:04:53]</a>. This capability makes it possible to extract data that would otherwise be extremely difficult or impossible to obtain without such models, potentially enabling the creation of online directories or other data-rich applications <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>, <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>, <a class="yt-timestamp" data-t="00:05:35">[00:05:35]</a>. The model is highly effective at extracting context from various media, including long audio files like podcasts <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a>, <a class="yt-timestamp" data-t="00:06:07">[00:06:07]</a>.

### Diverse Models and Capabilities
[[Google AI Studio demonstration and features | AI Studio]] provides access to various [[Gemini models in AI Studio | Gemini models]], including <a class="yt-timestamp" data-t="00:07:12">[00:07:12]</a>, <a class="yt-timestamp" data-t="00:07:17">[00:07:17]</a>:
*   **Gemma**: An open-source version for developers needing open-source models <a class="yt-timestamp" data-t="00:07:21">[00:07:21]</a>, <a class="yt-timestamp" data-t="00:07:25">[00:07:25]</a>.
*   **2.0 Flash Model**: More powerful but slightly more expensive <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a>.
*   **Flashlight Model**: Higher rate limits, slightly less intelligent, but capable of core tasks <a class="yt-timestamp" data-t="00:07:39">[00:07:39]</a>, <a class="yt-timestamp" data-t="00:07:43">[00:07:43]</a>.
*   **Pro Model**: An experimental variant and the most intelligent model available <a class="yt-timestamp" data-t="00:07:49">[00:07:49]</a>, <a class="yt-timestamp" data-t="00:07:54">[00:07:54]</a>.
*   **Reasoning Model**: Represents the New Frontier capabilities <a class="yt-timestamp" data-t="00:07:59">[00:07:59]</a>, <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>. This model is available for free for developers and can be accessed via an API key <a class="yt-timestamp" data-t="00:08:08">[00:08:08]</a>, <a class="yt-timestamp" data-t="00:08:10">[00:08:10]</a>.

The reasoning model is designed to "think" about tasks more deeply, going beyond a first answer <a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a>, <a class="yt-timestamp" data-t="00:08:39">[00:08:39]</a>. This is demonstrated by providing a code snippet and asking the model to turn it into a fully-fledged website, landing page, and SaaS application <a class="yt-timestamp" data-t="00:10:02">[00:10:02]</a>, <a class="yt-timestamp" data-t="00:10:07">[00:10:07]</a>. The model's "thoughts" category in the UI shows its internal planning process, akin to outlining an essay or code structure <a class="yt-timestamp" data-t="00:10:16">[00:10:16]</a>, <a class="yt-timestamp" data-t="00:10:23">[00:10:23]</a>, <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>, <a class="yt-timestamp" data-t="00:11:30">[00:11:30]</a>. This thinking process outlines desired outcomes, code usage, structure, technology stack, landing page optimization, and MVP functionality, including user authentication and dashboards <a class="yt-timestamp" data-t="00:10:52">[00:10:52]</a>, <a class="yt-timestamp" data-t="00:11:04">[00:11:04]</a>, <a class="yt-timestamp" data-t="00:11:12">[00:11:12]</a>. The final output includes extensive content and code, with the total runtime for this complex task being 23 seconds <a class="yt-timestamp" data-t="00:11:55">[00:11:55]</a>, <a class="yt-timestamp" data-t="00:12:15">[00:12:15]</a>. This highlights the potential for developers to quickly prototype or generate complete applications <a class="yt-timestamp" data-t="00:12:34">[00:12:34]</a>, <a class="yt-timestamp" data-t="00:12:38">[00:12:38]</a>, <a class="yt-timestamp" data-t="00:12:44">[00:12:44]</a>.

### Starter Apps for Practical Application
[[Google AI Studio demonstration and features | AI Studio]] provides "starter apps" to illustrate what can be built with the models <a class="yt-timestamp" data-t="00:13:26">[00:13:26]</a>, <a class="yt-timestamp" data-t="00:13:31">[00:13:31]</a>, <a class="yt-timestamp" data-t="00:13:36">[00:13:36]</a>:

*   **Spatial Understanding**: This capability allows the model to deeply understand objects and their visual representation in images <a class="yt-timestamp" data-t="00:13:50">[00:13:50]</a>, <a class="yt-timestamp" data-t="00:13:54">[00:13:54]</a>.
    *   **Demonstration**: An image is analyzed to identify the position of items and dynamically overlay 2D bounding boxes <a class="yt-timestamp" data-t="00:14:09">[00:14:09]</a>, <a class="yt-timestamp" data-t="00:14:14">[00:14:14]</a>, <a class="yt-timestamp" data-t="00:14:20">[00:14:20]</a>.
    *   **Business Ideas**: This [[understanding_ai_tools_and_models_for_development | multimodal capability]] enables applications such as:
        *   Identifying furniture in a room for an online furniture website <a class="yt-timestamp" data-t="00:14:39">[00:14:39]</a>, <a class="yt-timestamp" data-t="00:15:35">[00:15:35]</a>.
        *   Inventory management by snapping pictures or using real-time video feeds to assess utilization <a class="yt-timestamp" data-t="00:15:52">[00:15:52]</a>, <a class="yt-timestamp" data-t="00:16:00">[00:16:00]</a>.
        *   Real-time monitoring of parking garage utilization <a class="yt-timestamp" data-t="00:16:16">[00:16:16]</a>.
        *   Satellite analysis to explicitly bound areas based on criteria, e.g., identifying corn fields <a class="yt-timestamp" data-t="00:16:28">[00:16:28]</a>.
    *   This technology has the potential to automate service-based businesses or painful tasks historically performed by humans <a class="yt-timestamp" data-t="00:16:52">[00:16:52]</a>, <a class="yt-timestamp" data-t="00:17:00">[00:17:00]</a>, transforming them into high-revenue opportunities <a class="yt-timestamp" data-t="00:17:14">[00:17:14]</a>.

*   **Function Calling**: Demonstrates the ability to connect [[Google AI Studio demonstration and features | AI Studio]] and [[Gemini models in AI Studio | Gemini]] with existing products like the Google Maps API <a class="yt-timestamp" data-t="00:18:18">[00:18:18]</a>, <a class="yt-timestamp" data-t="00:18:25">[00:18:25]</a>.
    *   **Demonstration**: A thin "geoguesser" experience where a prompt like "take me somewhere in ancient history" uses the Maps API to show a location and provide details <a class="yt-timestamp" data-t="00:18:33">[00:18:33]</a>, <a class="yt-timestamp" data-t="00:18:41">[00:18:41]</a>.
    *   **Business Impact**: This combinatorial explosion of connecting multiple products with AI can form entirely new businesses with relatively low development effort compared to historical SaaS solutions <a class="yt-timestamp" data-t="00:19:04">[00:19:04]</a>, <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>, <a class="yt-timestamp" data-t="00:19:25">[00:19:25]</a>.

All starter app code is available on GitHub for download and free use, along with a free API key to power the experience <a class="yt-timestamp" data-t="00:19:38">[00:19:38]</a>, <a class="yt-timestamp" data-t="00:19:42">[00:19:42]</a>, <a class="yt-timestamp" data-t="00:19:52">[00:19:52]</a>, <a class="yt-timestamp" data-t="00:19:58">[00:19:58]</a>.

### Real-time Streaming (Multimodal Live API)
The multimodal live API powers a real-time streaming experience, enabling "AI co-presence" where AI can see and understand what the user sees to provide context-aware assistance <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>, <a class="yt-timestamp" data-t="00:20:16">[00:20:16]</a>, <a class="yt-timestamp" data-t="00:20:22">[00:20:22]</a>, <a class="yt-timestamp" data-t="00:20:29">[00:20:29]</a>.

*   **Demonstration**: The model listens to the user's speech and analyzes their screen <a class="yt-timestamp" data-t="00:20:35">[00:20:35]</a>, <a class="yt-timestamp" data-t="00:20:40">[00:20:40]</a>. In a coding scenario, the model identifies a Python file, understands its context, and provides real-time debugging suggestions, distinguishing between file not found errors and API key issues <a class="yt-timestamp" data-t="00:20:52">[00:20:52]</a>, <a class="yt-timestamp" data-t="00:20:58">[00:20:58]</a>, <a class="yt-timestamp" data-t="00:21:13">[00:21:13]</a>, <a class="yt-timestamp" data-t="00:21:42">[00:21:42]</a>, <a class="yt-timestamp" data-t="00:21:59">[00:21:59]</a>.
*   **Implications**: This is an early look at the future of work <a class="yt-timestamp" data-t="00:24:43">[00:24:43]</a>, where AI acts as a "senior developer" or "AI partner" in an IDE, pair programming, understanding the entire screen, and even browsing the internet for solutions within the product experience <a class="yt-timestamp" data-t="00:23:29">[00:23:29]</a>, <a class="yt-timestamp" data-t="00:23:35">[00:23:35]</a>, <a class="yt-timestamp" data-t="00:23:40">[00:23:40]</a>, <a class="yt-timestamp" data-t="00:25:00">[00:25:00]</a>, <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>. This capability significantly reduces the steep learning curve in technology and software, enabling users at various skill levels to perform complex tasks like coding or video editing <a class="yt-timestamp" data-t="00:24:03">[00:24:03]</a>, <a class="yt-timestamp" data-t="00:24:09">[00:24:09]</a>, <a class="yt-timestamp" data-t="00:24:25">[00:24:25]</a>. It "democratizes access" to expertise by providing constant assistance <a class="yt-timestamp" data-t="00:27:33">[00:27:33]</a>, <a class="yt-timestamp" data-t="00:27:56">[00:27:56]</a>.
*   The Multimodal Live API also supports native tool integrations, pseudo-function calls, and code execution within a virtual Python environment, showing outputs <a class="yt-timestamp" data-t="00:25:32">[00:25:32]</a>, <a class="yt-timestamp" data-t="00:25:39">[00:25:39]</a>, <a class="yt-timestamp" data-t="00:25:46">[00:25:46]</a>.

Logan Kilpatrick encourages users to try the real-time streaming experience at `audio.Google.com` (specifically the "stream real time" section) and provide feedback, as it is free to use <a class="yt-timestamp" data-t="00:28:01">[00:28:01]</a>, <a class="yt-timestamp" data-t="00:28:08">[00:28:08]</a>. Free API keys for the [[Gemini models in AI Studio | Gemini models]] offer up to 1.5 billion tokens, with the entire multimodal live experience prototype available for free <a class="yt-timestamp" data-t="00:28:42">[00:28:42]</a>, <a class="yt-timestamp" data-t="00:28:49">[00:28:49]</a>, <a class="yt-timestamp" data-t="00:28:57">[00:28:57]</a>. This approach aims to remove economic barriers for developers and startups to build AI products <a class="yt-timestamp" data-t="00:29:07">[00:29:07]</a>, <a class="yt-timestamp" data-t="00:29:12">[00:29:12]</a>.