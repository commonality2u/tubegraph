---
title: Long context use cases in AI
videoId: 6h9y1rLem4c
---

From: [[gregisenberg]] <br/> 

Long context refers to the ability of AI models to process and understand very large amounts of information, such as long videos, extensive documents, or continuous audio streams, as a single input <a class="yt-timestamp" data-t="02:54:57">[02:54:57]</a>. This capability is considered a significant advancement in AI, opening up new possibilities for building businesses and applications <a class="yt-timestamp" data-t="01:25:39">[01:25:39]</a>.

## Leveraging Google's AI Studio and Gemini Models

Google's AI Studio and the underlying Gemini models are designed to showcase and facilitate these long context capabilities <a class="yt-timestamp" data-t="01:04:18">[01:04:18]</a>. AI Studio allows users to experiment with various Gemini models, including:
*   **Flash Models (2.0 Flash, Flashlight)**: Offer different trade-offs between power, cost, and rate limits <a class="yt-timestamp" data-t="07:34:04">[07:34:04]</a>.
*   **Pro Model**: An experimental and highly intelligent model <a class="yt-timestamp" data-t="07:49:00">[07:49:00]</a>.
*   **Reasoning Model**: Available for free to developers, enabling advanced cognitive processes within the AI <a class="yt-timestamp" data-t="08:04:13">[08:04:13]</a>.

AI Studio is free to use and provides access to differentiated features, making it easier for developers and startups to build AI products <a class="yt-timestamp" data-t="02:45:00">[02:45:00]</a> <a class="yt-timestamp" data-t="02:52:00">[02:52:00]</a>.

### Processing Long-form Media

One of the most impactful long context applications is the ability to process lengthy media files:
*   **Video Analysis**: Gemini models can ingest a 30-minute video, such as a tour of a museum, and extract specific information like a list of all exhibits <a class="yt-timestamp" data-t="03:54:33">[03:54:33]</a> <a class="yt-timestamp" data-t="04:07:07">[04:07:07]</a>. This processing involves handling hundreds of thousands of tokens (e.g., 531,000 tokens for a 30-minute video) <a class="yt-timestamp" data-t="04:53:07">[04:53:07]</a>. This capability makes tasks that were previously "basically impossible" or required extensive manual work, simple and automated <a class="yt-timestamp" data-t="04:32:04">[04:32:04]</a>.
*   **Audio Intelligence**: Similarly, long audio files, like podcasts, can be analyzed to extract intelligence and insights <a class="yt-timestamp" data-t="06:01:00">[06:01:00]</a>.
*   **Image Understanding (Spatial)**: The models possess "spatial understanding," allowing them to deeply understand objects and their visual representation in images <a class="yt-timestamp" data-t="13:50:00">[13:50:00]</a>. This includes dynamically overlaying 2D bounding boxes and providing coordinates of objects, which can be applied to [[potential_applications_of_ai_in_business_automation | inventory management]], parking garage utilization, or satellite analysis <a class="yt-timestamp" data-t="14:14:00">[14:14:00]</a> <a class="yt-timestamp" data-t="15:52:00">[15:52:00]</a>.

### Advanced Reasoning Capabilities

Reasoning models allow the AI to "think" about different aspects of a problem before generating a final output <a class="yt-timestamp" data-t="08:32:00">[08:32:00]</a>.
*   **Code Generation and Development**: When asked to transform a simple code snippet into a full website and SaaS application, the reasoning model outlines the desired outcomes, necessary code, technology stack, landing page optimization, and MVP for SaaS functionality <a class="yt-timestamp" data-t="10:07:00">[10:07:00]</a> <a class="yt-timestamp" data-t="10:48:00">[10:48:00]</a>. This internal "thought process" is visible in the UI, similar to outlining an essay or code structure <a class="yt-timestamp" data-t="10:16:38">[10:16:38]</a> <a class="yt-timestamp" data-t="11:30:00">[11:30:00]</a>. This capability aids [[leveraging_ai_for_code_explanation_and_learning | code explanation]] and generation.
*   **Function Calling**: AI Studio and Gemini can connect to external APIs, like Google Maps, to create interactive experiences <a class="yt-timestamp" data-t="18:18:00">[18:18:00]</a>. This [[incorporating_ai_features_in_applications | incorporation of AI features]] allows for a "combinatorial explosion" of different product experiences by linking historically separate products through AI <a class="yt-timestamp" data-t="19:15:00">[19:15:00]</a>.

### Real-Time AI Co-Presence

The Multimodal Live API enables real-time streaming experiences, allowing the AI to be "co-present" with the user <a class="yt-timestamp" data-t="20:10:39">[20:10:39]</a> <a class="yt-timestamp" data-t="23:14:00">[23:14:00]</a>.
*   **Interactive Assistance**: The AI can listen to spoken commands and see the user's screen (e.g., a code editor), providing real-time guidance, debugging assistance, and suggestions <a class="yt-timestamp" data-t="20:35:00">[20:35:00]</a> <a class="yt-timestamp" data-t="21:09:15">[21:09:15]</a>.
*   **Democratizing Access**: This live assistance can help individuals who are new to technology or learning complex skills, like coding or video editing, by acting as a virtual senior developer or tutor <a class="yt-timestamp" data-t="24:03:00">[24:03:00]</a> <a class="yt-timestamp" data-t="27:23:00">[27:23:00]</a>.
*   **Tool Integration**: The API supports native tool integrations, including pseudo-function calls, code execution environments (like Python virtual environments), and grounding for internet browsing, allowing the AI to access external information relevant to the user's context <a class="yt-timestamp" data-t="25:32:00">[25:32:00]</a> <a class="yt-timestamp" data-t="25:51:00">[25:51:00]</a>. This creates a unified experience that bridges the outside world into the application <a class="yt-timestamp" data-t="26:16:00">[26:16:00]</a>. This is a powerful example of [[voicedriven_ai_applications | voice-driven AI applications]] and [[implementing_ai_assistants_in_different_business_functions | AI assistants]].

## Business Opportunities and Accessibility

The powerful long context capabilities of Gemini models present a vast landscape of business opportunities:
*   **Data Extraction for Directories**: Extracting structured data from unstructured media, such as creating online directories from video content <a class="yt-timestamp" data-t="05:11:00">[05:11:00]</a>.
*   **Automation of Services**: Businesses can leverage these tools to [[utilizing_ai_for_automation_and_scalability | automate]] previously human-intensive service-based tasks, transforming agencies and consulting firms into scalable technology solutions <a class="yt-timestamp" data-t="16:52:00">[16:52:00]</a> <a class="yt-timestamp" data-t="17:08:00">[17:08:00]</a>.
*   **New Product Experiences**: The combination of AI with existing products creates unique business opportunities, allowing for the rapid prototyping and deployment of new SaaS solutions with relatively little work compared to historical methods <a class="yt-timestamp" data-t="19:21:00">[19:21:00]</a>.

Google aims to remove the economic burden for developers and startups by offering free access to AI Studio and generous free tiers for API keys (e.g., 1.5 billion tokens for Gemini models) <a class="yt-timestamp" data-t="28:42:00">[28:42:00]</a>. Starter apps with full codebases are available on GitHub, allowing developers to immediately begin experimenting and building <a class="yt-timestamp" data-t="19:38:00">[19:38:00]</a>.