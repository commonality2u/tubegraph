---
title: Human intelligence vs neural network intelligence
videoId: a42key59cZQ
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The relationship, similarities, and differences between human intelligence and artificial neural network (NN) intelligence are complex and represent a significant area of ongoing thought for researcher Gwern Branwen. He views them as deeply intertwined, though the exact nature of their connection remains an open question [[artificial_intelligence_vs_human_intelligence | [00:30:54]]].

## Gwern's Parsimonious Theory of Intelligence

Gwern posits that a high-level view of intelligence, supported by the success of scaling in AI, is that "all intelligence is search over Turing machines" [[ai_trajectory_and_scaling_hypothesis | [00:07:06]]]. Processes like "learning" or "scaling" involve searching over more numerous and longer Turing machines and applying them to specific cases [[challenges_and_advancements_in_ai_training_techniques | [00:07:19]]]. He suggests there is no "general master algorithm" or "special intelligence fluid," but rather a vast number of special cases learned and encoded [[theories_of_intelligence_and_cognition | [00:07:32]]].

### Application to Human Intelligence Variation

When questioned about how this model accounts for variations in human intelligence, where some individuals appear to have more "general horsepower," Gwern explains that more intelligent individuals simply possess more "compute" to search over more Turing machines for longer periods [[role_of_compute_in_ai_development | [00:08:12]]]. The brain learns numerous individual, specialized problems, and these learned solutions are then recombined to manifest as fluid intelligence [[neuroscience_and_ai_understanding_intelligence | [00:08:52]]]. This is why there's no identifiable "IQ gland"; intelligence is distributed and learned [[limits_and_potential_of_human_and_ai_knowledge | [00:08:37]]]. This is analogous to how large neural networks can be seen as ensembles of smaller models tailored to specific problems [[machine_learning_hardware_and_tpus | [00:09:03]]].

### Evolutionary Rarity of Human-Level Intelligence

This "search over Turing machines" model also helps explain why human-level intelligence is evolutionarily rare [[ai_scalability_and_breakthroughs | [00:09:33]]]. For many organisms, genetically hard-coding solutions to specific environmental challenges (akin to small, efficient Turing machines) is far more adaptive than developing a "colossally expensive, unreliable, glitchy search process" like human general intelligence [[biological_and_cultural_evolution | [00:09:39]]]. In static environments or for short-lived organisms, tailored, evolved solutions are superior to general-purpose learning mechanisms [[evolutionary_biology_and_ai_parallels | [00:10:22]]].

## The Central Tension and Interconnectedness

Gwern describes the relationship between human and neural network intelligence as the "biggest unresolved tension" in his worldview [[challenges_in_ai_alignment_and_potential_risks | [00:30:51]]]. He oscillates on whether they are two sides of the same coin, if one is an inferior version of the other, or if both are "awesome" in different ways [[comparisons_between_atomic_bomb_development_and_modern_ai_advancements | [00:31:03]]]. Puzzles include GPT-4's memorization capabilities versus its perceived lack of creativity, and how humans, who remember little, can still be so smart [[large_language_models_and_transfer_learning | [00:31:21]]]. He also debates the relative sample efficiency of language models versus humans [[limitations_of_large_language_models_llms_in_solving_novel_tasks | [00:31:33]]].

Despite these unresolved aspects, Gwern firmly believes that human and AI intelligence cannot be "totally unrelated" [[neuroscience_and_ai_understanding_intelligence | [00:33:07]]]. He argues that if the scaling hypothesis (which underpins much of current AI progress) is true, it *must* also illuminate aspects of human, primate, and other biological intelligences [[impact_of_ai_on_economic_and_societal_structures | [00:32:56]]]. The idea of two completely separate paths to intelligence emerging simultaneously is "absurd" to him, much like humans and aliens independently arriving on Mars for the first time at the exact same moment [[ai_safety_and_existential_risks | [00:33:37]]]. They could be "two sides of the same coin" or have "obscure connections" [[mechanistic_interpretability_in_ai | [00:33:25]]].

## Cognitive Diversity in AI Models

Gwern contends that, excluding raw capability, AI models are *already* more cognitively diverse than the human population [[future_of_ai_challenges_and_opportunities | [01:25:13]]]. Different types of models (e.g., LLMs, GANs, VAEs) operate in fundamentally distinct ways, with different latent spaces and characteristic errors, especially noticeable in smaller or less optimized models [[ai_developments_in_hardware_and_software_advancements | [01:25:25]]]. He describes the outputs of some different models as being as dissimilar as "ants do to beavers" [[innovations_and_challenges_in_ai_hardware | [01:26:23]]].

While acknowledging that current top-tier LLMs (like those in Chatbot Arena) can seem very similar, he attributes this to heavy tuning, shared training data, and convergent evolution in a narrow spaceâ€”akin to "identical twins" [[large_language_models_and_transfer_learning | [01:26:03]]]. He notes a "massive loss of diversity" *within* LLMs recently, but across the broader field of deep learning, a wide range of "minds and ways to think" exist that are not captured in traditional philosophy of mind [[philosophical_perspectives_on_consciousness_and_free_will | [01:26:34]]]. As an example of cognitive difference, he contrasts GAN models, which have incentives to "hide things" due to their adversarial training (e.g., being 'scared' to render hands), with diffusion models, which attempt to render hands but may do so in "gigantic, monstrous, Cthulhu-esque abortions" [[artificial_intelligence_vs_human_intelligence | [01:26:53]]].

## Lingering Questions

Among the significant questions Gwern hopes will be answered by 2050 are several directly related to the comparison between human and artificial intelligence:
*   Why do humans differ so much from each other and from day to day? [[impact_of_culture_and_environment_on_intelligence | [01:35:34]]]
*   Why are human brains so oversized compared to artificial neural networks? [[largescale_brain_and_model_parameters | [01:36:19]]]
