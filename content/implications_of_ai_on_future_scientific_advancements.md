---
title: Implications of AI on future scientific advancements
videoId: XhB3qH_TFds
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The rapid development of Artificial Intelligence (AI), particularly Large Language Models (LLMs), presents profound implications for the future of scientific discovery. Adam Brown, founder of the Blueshift team at Google DeepMind and a theoretical physicist, discussed the current capabilities, future potential, and inherent challenges of AI in science <a class="yt-timestamp" data-t="00:00:48">[00:00:48]</a>.

## The Einstein Test: AI and Foundational Reasoning

A significant benchmark for AI's reasoning capabilities is its potential to replicate monumental scientific breakthroughs. Brown suggests that perhaps the "very last thing" LLMs might achieve is to, given the laws of physics understood at the turn of the 20th century, independently invent general relativity <a class="yt-timestamp" data-t="00:40:22">[00:40:22]</a>, <a class="yt-timestamp" data-t="00:40:32">[00:40:32]</a>. He posits that if AI can accomplish such a feat, it would signify a near-complete encompassment of human intelligence, potentially within a decade <a class="yt-timestamp" data-t="00:41:57">[00:41:57]</a>.

Currently, LLMs are seen in some sense as "interpolators," but the level of abstraction at which they interpolate is continuously increasing <a class="yt-timestamp" data-t="00:41:10">[00:41:10]</a>. From a sufficiently elevated viewpoint, even the invention of general relativity could be considered an interpolation at a grandiose level of abstraction <a class="yt-timestamp" data-t="00:41:24">[00:41:24]</a>. While current systems primarily handle more elementary, undergraduate-level material <a class="yt-timestamp" data-t="00:42:42">[00:42:42]</a>, the ability to recognize analogies, combine concepts, and transform scientific problems into solvable mathematical ones demonstrates a form of creativity or advanced interpolation [[ai_scalability_and_breakthroughs]].

## Current Applications: AI as a Scientific Assistant

Physicists are beginning to use LLMs significantly, primarily as assistants rather than autonomous agents capable of grand discoveries like quantizing gravity <a class="yt-timestamp" data-t="00:46:51">[00:46:51]</a>.

### Literature Search and Tutoring
Three years ago, LLMs were considered "totally useless" for scientific tasks, but their utility has grown remarkably <a class="yt-timestamp" data-t="00:47:04">[00:47:04]</a>.
*   **Literature Search:** LLMs excel at semantic searches for relevant papers based on an idea <a class="yt-timestamp" data-t="00:47:22">[00:47:22]</a>.
*   **Personal Tutors:** They serve as effective, non-judgmental tutors for physicists needing to understand established concepts, debug their own understanding, or explore advanced topics not always well-documented [[the_significance_of_good_explanations_in_learning_complex_subjects]]. Brown notes that this is analogous to how chess players improve by training with chess machines <a class="yt-timestamp" data-t="00:48:57">[00:48:57]</a>.

### Educational Benchmarks and Debugging
*   **Academic Performance:** LLMs have shown impressive progress in academic settings. For instance, Brown mentioned that models now "essentially ace" his graduate general relativity exam at Stanford, a significant leap from zero performance three years ago and weak student performance a year ago [[challenges_in_ai_alignment_and_potential_risks]]. Scott Aaronson's intro to quantum computing class saw GPT-4 achieving a B or A- <a class="yt-timestamp" data-t="00:52:56">[00:52:56]</a>.
*   **Understanding and Debugging:** LLMs can explain complex topics and even debug a user's incorrect understanding. Brown shared an experience where an LLM explained the use of squeezed light at LIGO and pinpointed flaws in his own thinking [[artificial_intelligence_vs_human_intelligence]]. This ability to debug, similar to debugging code, suggests a level of understanding beyond simple pattern matching [[mechanistic_interpretability_in_ai]].

## AI-Driven Discoveries: The Path Forward

While AI has different strengths and weaknesses compared to humans—possessing vast knowledge but not yet translating it into novel discoveries at the same rate a human might [[ai_for_science_and_societal_challenges]]—several avenues for AI-driven breakthroughs are emerging.

### New Representations and Notations
A significant aspect of scientific progress involves developing new ways to think about problems, often through new representations or notations [[open_source_ai_models_and_their_implications]].
*   Einstein's summation convention and Penrose's diagrams are historical examples of notations that greatly advanced physics [[historical_influences_on_leadership_and_innovation]].
*   As LLMs improve, they might develop their own superior representations, which could be a pivotal sign of progress, e.g., an AI like Gemini proposing a new notation to better analyze a question [[large_language_models_and_transfer_learning]].
*   While AI sees more examples than any human, it's not clear they "natively" think in higher dimensions more than humans who use notations as tools. However, extensive exposure could lead to sophisticated representations <a class="yt-timestamp" data-t="00:44:52">[00:44:52]</a>.

### Analyzing Large Datasets
Astronomy has collected exabytes of data from various observatories <a class="yt-timestamp" data-t="00:56:19">[00:56:19]</a>.
*   Efforts are underway (e.g., Shirley Ho at Flatiron) to feed this astronomical data directly into transformer models to see if they can uncover hidden patterns or insights that humans might miss [[forecasting_ai_progress_and_the_intelligence_explosion]]. This could revolutionize the utility of expensive observatories <a class="yt-timestamp" data-t="00:57:22">[00:57:22]</a>.

## Challenges in AI-Led Science

### The Evaluation Problem
A significant hurdle in AI generating new scientific theories is evaluation [[the_geopolitical_stakes_of_agi_development]].
*   Unlike problems with clear right/wrong answers (like those in NP), it's hard for a computer to inherently know if a generated theory like special relativity is a "winner" <a class="yt-timestamp" data-t="00:59:06">[00:59:06]</a>.
*   Revolutionary theories are not always adopted solely based on better data fit; "beauty" and conceptual elegance play a crucial role, as seen in the shift from geocentric to heliocentric models. Optimizing only for data consistency might lead to "epicycles" rather than profound conceptual shifts [[forecasting_ai_progress_and_the_intelligence_explosion]]. Teaching LLMs a sense of "beauty" would be necessary [[ai_alignment_and_safety_concerns]].
*   This mirrors challenges in human science, where consensus on new theories can take a long time and lacks a simple verifier <a class="yt-timestamp" data-t="01:01:22">[01:01:22]</a>.

### Generalization and Difficulty of Evaluation
As LLMs become more powerful, evaluating their performance becomes increasingly difficult, requiring PhD-level experts to create challenging problems. However, there's generally positive transfer between domains: making models better at one task tends to improve performance in others <a class="yt-timestamp" data-t="00:55:50">[00:55:50]</a>.

## The Future of Scientific Fields and Timelines

AI could revitalize fields where progress has slowed. For example, particle physics saw immense success with the Standard Model in the 1970s, which was "too good" and predicted outcomes from particle accelerators so well that it became hard to find new directions [[progress_towards_artificial_general_intelligence_agi]]. While new, more powerful particle accelerators are desired, their cost is a major factor. Brown speculates that once AGI makes society vastly richer, building such facilities might become feasible <a class="yt-timestamp" data-t="01:07:04">[01:07:04]</a>.

There is still room for completely new conceptualizations and ways of thinking in physics, not just incremental progress <a class="yt-timestamp" data-t="01:03:13">[01:03:13]</a>.

Regarding the timeline for AI to automate the role of a physicist, Brown acknowledges it's close to "ASI complete." He stated he could "certainly imagine a scenario in which it's five years" [[the_timeline_and_technological_progress_towards_agi_by_2027]].

The rapid progress in AI, contrasted with the often slower pace of traditional physics research, underscores the transformative potential AI holds for accelerating scientific discovery across various domains [[impact_of_ai_on_future_technology_and_society]].