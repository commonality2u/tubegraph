---
title: Prompt engineering and its impact on accuracy
videoId: lR9isPmwZ3s
---

From: [[hu-po]] <br/> 

## What is Prompt Engineering?
Prompt engineering refers to the process of manually crafting specific instructions or additional text to guide large language models (LLMs) to achieve desired outputs and maximize task accuracy <a class="yt-timestamp" data-t="09:55:07">[09:55:07]</a>. It has become a significant factor in influencing LLM performance, with even small changes in prompt wording leading to drastically different results <a class="yt-timestamp" data-t="25:44:06">[25:44:06]</a>. This phenomenon highlights the "black box" nature of LLMs, where the exact reasons for performance improvements due to specific prompts are often unknown <a class="yt-timestamp" data-t="20:26:07">[20:26:07]</a>.

## The Impact of Prompt Design on LLM Accuracy
LLMs are highly sensitive to prompt format; semantically similar prompts can yield vastly different performance levels <a class="yt-timestamp" data-t="25:42:01">[25:42:01]</a>. An example is the significant increase in accuracy on mathematical word problems by simply adding phrases like "let's think step by step" or "take a deep breath and work on this problem step by step" <a class="yt-timestamp" data-t="10:30:30">[10:30:30]</a>, <a class="yt-timestamp" data-t="10:55:07">[10:55:07]</a>. Adding "take a deep breath and work on this problem step by step" can increase accuracy by 10% on grade school math word problems compared to an empty string <a class="yt-timestamp" data-t="10:55:07">[10:55:07]</a>, <a class="yt-timestamp" data-t="13:53:07">[13:53:07]</a>. This sensitivity suggests that LLMs respond to psychological-like cues, much like how a coach might encourage athletes for better performance <a class="yt-timestamp" data-t="14:24:25">[14:24:25]</a>.

Optimal prompt formats can be model-specific and task-specific, meaning a prompt that works well for one LLM or task might not work for another <a class="yt-timestamp" data-t="26:17:09">[26:17:09]</a>, <a class="yt-timestamp" data-t="26:19:09">[26:19:09]</a>.

## [[optimization_by_prompting_opro | Optimization by Prompting (OpRo)]]
The paper "Large Language Models as Optimizers" introduces [[optimization_by_prompting_opro | Optimization by Prompting (OpRo)]], a method that leverages LLMs as optimizers where the optimization task is described in natural language <a class="yt-timestamp" data-t="05:52:02">[05:52:02]</a>, <a class="yt-timestamp" data-t="22:27:08">[22:27:08]</a>. This approach bypasses the need for derivative-based algorithms, which are often challenging in real-world applications where gradients are absent <a class="yt-timestamp" data-t="03:17:00">[03:17:00]</a>, <a class="yt-timestamp" data-t="03:26:07">[03:26:07]</a>, <a class="yt-timestamp" data-t="05:12:00">[05:12:00]</a>.

### How OpRo Works
In each optimization step, the LLM generates new solutions (prompts) from a metaprompt that includes previously generated solutions and their corresponding performance values (scores) <a class="yt-timestamp" data-t="06:10:00">[06:10:00]</a>, <a class="yt-timestamp" data-t="06:13:00">[06:13:00]</a>. This is an iterative process, where the LLM continuously refines prompts based on past performance, akin to an in-context learning approach <a class="yt-timestamp" data-t="06:19:00">[06:19:00]</a>, <a class="yt-timestamp" data-t="33:02:00">[33:02:00]</a>.

The metaprompt for [[optimization_by_prompting_opro | OpRo]] contains two core pieces <a class="yt-timestamp" data-t="32:46:00">[32:46:00]</a>:
1.  **Previously generated prompts with their training accuracies:** These act as examples, showing the LLM which prompt variations have performed well <a class="yt-timestamp" data-t="32:47:00">[32:47:00]</a>, <a class="yt-timestamp" data-t="34:51:00">[34:51:00]</a>. The paper's default setting sorts these in ascending order of score <a class="yt-timestamp" data-t="22:27:00">[22:27:00]</a>, <a class="yt-timestamp" data-t="01:17:22">[01:17:22]</a>.
2.  **Optimization problem description:** This includes several exemplars (randomly selected training examples) to illustrate the task of interest <a class="yt-timestamp" data-t="32:52:00">[32:52:00]</a>, <a class="yt-timestamp" data-t="01:16:37">[01:16:37]</a>. These exemplars help the optimizer LLM understand the task and phrase new instructions <a class="yt-timestamp" data-t="01:29:41">[01:29:41]</a>.

### Role of Different LLMs
In the [[optimization_by_prompting_opro | OpRo]] framework, two distinct LLMs are involved <a class="yt-timestamp" data-t="01:14:03">[01:14:03]</a>:
*   **Optimizer LLM:** This LLM is responsible for generating new prompts. It receives the metaprompt and aims to increase the task accuracy <a class="yt-timestamp" data-t="01:14:03">[01:14:03]</a>. For experiments, the optimizer LLM (e.g., Palm 2L instruction tuned) typically has a temperature set to 1.0 to encourage exploration and randomness in its generated prompts <a class="yt-timestamp" data-t="01:21:18">[01:21:18]</a>, <a class="yt-timestamp" data-t="01:21:20">[01:21:20]</a>.
*   **Score LLM:** This LLM evaluates the performance of the generated prompts by applying them to the task and computing an accuracy score <a class="yt-timestamp" data-t="01:13:57">[01:13:57]</a>. The score LLM (e.g., Palm 2L) has its temperature set to 0 to ensure deterministic decoding and consistent scoring <a class="yt-timestamp" data-t="01:20:43">[01:20:43]</a>, <a class="yt-timestamp" data-t="01:21:12">[01:21:12]</a>.

### Parameters Affecting OpRo Performance
Various hyperparameters influence [[optimization_by_prompting_opro | OpRo]]'s effectiveness:
*   **Order of Previous Instructions:** Sorting past instructions in ascending order (lowest to highest score) generally yields better final accuracies compared to descending or random orders <a class="yt-timestamp" data-t="01:24:52">[01:24:52]</a>, <a class="yt-timestamp" data-t="01:25:30">[01:25:30]</a>. This suggests a "recency bias" where LLMs are more influenced by instructions closer to the end of the metaprompt <a class="yt-timestamp" data-t="01:24:18">[01:24:18]</a>.
*   **Instruction Scores Presentation:** Presenting accuracy scores to the optimizer LLM is crucial <a class="yt-timestamp" data-t="01:26:04">[01:26:04]</a>. However, the granularity matters; rounding accuracies to 20 buckets can sometimes outperform 100 buckets or no scores, depending on the task <a class="yt-timestamp" data-t="01:26:53">[01:26:53]</a>, <a class="yt-timestamp" data-t="01:27:33">[01:27:33]</a>.
*   **Number of Exemplars:** Providing a few examples (e.g., 3-10) from the training set is critical as it helps the optimizer LLM understand the task <a class="yt-timestamp" data-t="01:29:41">[01:29:41]</a>. More exemplars do not necessarily improve performance and might even distract the optimizer if the metaprompt becomes too long <a class="yt-timestamp" data-t="01:29:50">[01:29:50]</a>, <a class="yt-timestamp" data-t="01:30:27">[01:30:27]</a>.
*   **Number of Generated Instructions per Step:** Generating multiple new solutions (e.g., eight) at each optimization step improves stability and allows for faster exploration of promising directions <a class="yt-timestamp" data-t="01:48:06">[01:48:06]</a>, <a class="yt-timestamp" data-t="01:32:02">[01:32:02]</a>, <a class="yt-timestamp" data-t="01:32:37">[01:32:37]</a>.

## Benchmarks and Results
[[optimization_by_prompting_opro | OpRo]] was evaluated on various benchmarks, primarily focusing on natural language tasks.

### GSM8K
GSM8K is a dataset of 8.5K high-quality, linguistically diverse grade school math word problems <a class="yt-timestamp" data-t="01:11:57">[01:11:57]</a>, <a class="yt-timestamp" data-t="01:12:00">[01:12:00]</a>. On GSM8K, the best prompts optimized by [[optimization_by_prompting_opro | OpRo]] outperformed human-designed prompts by up to 8% <a class="yt-timestamp" data-t="01:11:21">[01:11:21]</a>, <a class="yt-timestamp" data-t="01:11:23">[01:11:23]</a>. For example, a prompt like "I'm always down for solving a math problem together. Just give me a moment to read and understand the problem. Then I'll create an equation that models the problem, which I'll solve for the unknown variable. I also may or may not use some helpful diagrams or visuals. Lastly, be sure to allow me some time to carefully check my work before submitting any responses" achieved 70% accuracy <a class="yt-timestamp" data-t="01:36:20">[01:36:20]</a>, <a class="yt-timestamp" data-t="01:36:40">[01:36:40]</a>.

### Big Bench Hard (BBH)
BBH is a benchmark created by Google, designed to go "beyond the imitation game" (Turing test) <a class="yt-timestamp" data-t="01:15:12">[01:15:12]</a>, <a class="yt-timestamp" data-t="01:15:15">[01:15:15]</a>. It comprises about 200 diverse tasks, including abstract reasoning, arithmetic operations, ASCII art recognition, and sarcasm detection <a class="yt-timestamp" data-t="01:16:40">[01:16:40]</a>, <a class="yt-timestamp" data-t="01:16:42">[01:16:42]</a>, <a class="yt-timestamp" data-t="01:16:51">[01:16:51]</a>, <a class="yt-timestamp" data-t="01:16:54">[01:16:54]</a>, <a class="yt-timestamp" data-t="01:16:57">[01:16:57]</a>.

Optimized prompts for BBH tasks can also be quite specific and even seemingly unusual:
*   For Boolean expressions, an optimal instruction is "group sub-expressions with parentheses to accurately evaluate logical Expressions. Determine the resulting is either true or false" <a class="yt-timestamp" data-t="01:27:23">[01:27:23]</a>, <a class="yt-timestamp" data-t="01:27:30">[01:27:30]</a>.
*   For sarcasm detection (Snarks task), the optimal prompt is "choose the option that wickedly embodies a sarcasm" <a class="yt-timestamp" data-t="01:28:22">[01:28:22]</a>. The choice of words like "wickedly" and "embodies" is curious and highlights the LLM's unpredictable nature <a class="yt-timestamp" data-t="01:28:29">[01:28:29]</a>.
*   For "dick languages" (parentheses completion tasks), the optimal instruction is "add the missing closed parentheses" <a class="yt-timestamp" data-t="01:28:47">[01:28:47]</a>, <a class="yt-timestamp" data-t="01:29:02">[01:29:02]</a>.
*   For object counting, the optimal prompt is "determine the total count of mentioned vegetables accurately and state the final count as the answer" <a class="yt-timestamp" data-t="01:44:19">[01:44:19]</a>, <a class="yt-timestamp" data-t="01:44:26">[01:44:26]</a>.

### Comparative Performance and Optimal Prompts
While human-designed prompts have achieved some success (e.g., "let's think step by step" improving accuracy to 71% on GSM8K from 34% with an empty string <a class="yt-timestamp" data-t="01:14:56">[01:14:56]</a>), [[optimization_by_prompting_opro | OpRo]] can find even better ones. For instance, the prompt "take a deep breath and work on this problem step by step" achieved 80% accuracy on the same task <a class="yt-timestamp" data-t="01:14:56">[01:14:56]</a>.

Interestingly, the style of instructions found by different optimizer LLMs can vary. Palm 2 Lite and Text Bison (Google's LLMs) tend to generate concise prompts, while GPT models generate longer, more detailed ones <a class="yt-timestamp" data-t="01:40:30">[01:40:30]</a>, <a class="yt-timestamp" data-t="01:40:32">[01:40:32]</a>, <a class="yt-timestamp" data-t="01:40:37">[01:40:37]</a>. This challenges the intuition that more context always leads to better performance <a class="yt-timestamp" data-t="01:40:51">[01:40:51]</a>.

## Limitations and Challenges
Despite its successes, [[optimization_by_prompting_opro | OpRo]] faces several limitations:
*   **Context Window Length:** The limited context window of current LLMs restricts the amount of information that can be included in the metaprompt, making it challenging for large-scale optimization problems <a class="yt-timestamp" data-t="01:09:37">[01:09:37]</a>.
*   **Sensitivity to Initialization:** The optimization process is sensitive to initial conditions; the starting prompts heavily influence the subsequent generations <a class="yt-timestamp" data-t="01:33:46">[01:33:46]</a>. If initial prompts share a commonality (e.g., starting with "let's"), the LLM tends to generate similar variations, potentially missing globally optimal but structurally different prompts <a class="yt-timestamp" data-t="01:34:17">[01:34:17]</a>.
*   **Optimization Landscape Complexity:** For objective functions with "bumpy" landscapes (i.e., highly non-linear or complex), LLMs may struggle to propose a correct descending direction, leading to optimization getting stuck at local optima <a class="yt-timestamp" data-t="01:10:11">[01:10:11]</a>, <a class="yt-timestamp" data-t="01:10:13">[01:10:13]</a>, <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a>.
*   **Lack of Error Case Utilization:** The optimizer LLM does not effectively utilize specific error cases in the training set to infer promising directions for improvement <a class="yt-timestamp" data-t="01:46:09">[01:46:09]</a>, <a class="yt-timestamp" data-t="01:46:13">[01:46:13]</a>.
*   **Reliability:** Optimizer LLMs do not always reliably follow instructions, sometimes generating solutions that have already appeared or are self-contradictory <a class="yt-timestamp" data-t="01:48:38">[01:48:38]</a>, <a class="yt-timestamp" data-t="01:49:02">[01:49:02]</a>.

## Future Implications and Discussion
The paper demonstrates that LLMs can function as general optimizers across different kinds of objective functions, simply through prompting <a class="yt-timestamp" data-t="01:44:45">[01:44:45]</a>, <a class="yt-timestamp" data-t="01:44:47">[01:44:47]</a>. This concept extends beyond prompt optimization to include mathematical optimization problems like linear regression (continuous) and the traveling salesman problem (discrete) <a class="yt-timestamp" data-t="01:52:50">[01:52:50]</a>, <a class="yt-timestamp" data-t="01:53:00">[01:53:00]</a>, <a class="yt-timestamp" data-t="01:53:02">[01:53:02]</a>, <a class="yt-timestamp" data-t="01:53:04">[01:53:04]</a>, <a class="yt-timestamp" data-t="01:53:06">[01:53:06]</a>.

This work suggests that LLMs might be able to solve optimization problems without explicitly calculating gradients, potentially through some internal "slope-based" or pattern-matching capability <a class="yt-timestamp" data-t="01:57:02">[01:57:02]</a>. The ability of LLMs to recognize patterns from in-context demonstrations supports this idea <a class="yt-timestamp" data-t="02:25:00">[02:25:00]</a>.

The broader implication is a future where LLMs could potentially replace traditional optimization algorithms, even for complex tasks like tuning the weights of neural networks directly <a class="yt-timestamp" data-t="00:38:28">[00:38:28]</a>. This development could lead to a world where interactions with computers are primarily in natural language, and LLMs automatically solve any optimization problem that can be described textually <a class="yt-timestamp" data-t="00:39:39">[00:39:39]</a>, <a class="yt-timestamp" data-t="00:39:40">[00:39:40]</a>, <a class="yt-timestamp" data-t="00:39:46">[00:39:46]</a>.

The trend of LLMs optimizing other LLMs, and even potentially optimizing the "meta instructions" themselves, points towards increasingly complex self-improving AI systems <a class="yt-timestamp" data-t="01:17:55">[01:17:55]</a>, <a class="yt-timestamp" data-t="01:18:00">[01:18:00]</a>. This raises questions about the future [[role_of_product_managers_architects_and_engineers_in_software_development | roles of prompt engineers]] and other human specialists as AI systems become more autonomous in their development and optimization <a class="yt-timestamp" data-t="01:11:09">[01:11:09]</a>. This also highlights [[considerations_in_optimizing_software_engineering_processes | considerations in optimizing software engineering processes]] and the [[evaluation_of_software_design_and_development_benchmarks | evaluation of software design and development benchmarks]] moving forward.