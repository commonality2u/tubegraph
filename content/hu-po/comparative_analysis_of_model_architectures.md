---
title: Comparative analysis of model architectures
videoId: eTBG17LANcI
---

From: [[hu-po]] <br/> 

A recent paper introduces a new class of [[latent_diffusion_models_and_architectures | diffusion models]] called Diffusion Transformers (DiTs), which replace the commonly used U-Net backbone with a [[transformerbased_model_architectures | Transformer]] architecture operating on latent patches <a class="yt-timestamp" data-t="00:05:08">[00:05:08]</a>. This approach aims to leverage the remarkable scaling properties of [[transformerbased_model_architectures | Transformers]] observed in other domains like Natural Language Processing (NLP) <a class="yt-timestamp" data-t="00:14:51">[00:14:51]</a>.

## Background on Diffusion Models

Traditionally, [[latent_diffusion_models_and_architectures | diffusion models]] have adopted the U-Net architecture as their de facto choice <a class="yt-timestamp" data-t="00:07:31">[00:07:31]</a>. U-Nets are convolutional networks that start "wide," narrow down to a "choke point," and then expand back out, forming a U-shape <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a>. This paper demonstrates that the U-Net bias is not crucial for the performance of [[latent_diffusion_models_and_architectures | diffusion models]] and can be replaced with standard designs like [[transformerbased_model_architectures | Transformers]] <a class="yt-timestamp" data-t="00:09:09">[00:09:09]</a>.

[[latent_diffusion_models_and_links | Diffusion models]] are trained to learn a reverse process that removes noise from data, inverting a forward noising process <a class="yt-timestamp" data-t="00:20:52">[00:20:52]</a>. The training often involves optimizing a variational lower bound of the log likelihood, typically simplified to a mean squared error between predicted noise and ground truth noise <a class="yt-timestamp" data-t="00:22:03">[00:22:03]</a>. Key improvements in [[latent_diffusion_models_and_architectures | diffusion models]] have included classifier-free guidance, predicting noise instead of pixels, and using cascaded DDPPM pipelines <a class="yt-timestamp" data-t="00:15:50">[00:15:50]</a>.

## Diffusion Transformers (DiTs) Architecture

DiTs adhere to the best practices of [[transformerbased_model_architectures | Vision Transformers (ViTs)]] <a class="yt-timestamp" data-t="00:09:48">[00:09:48]</a>. Instead of convolving across an image like a U-Net, [[transformerbased_model_architectures | ViTs]] cut the image into small patches and feed each patch as a token into the [[transformerbased_model_architectures | Transformer]] <a class="yt-timestamp" data-t="00:10:08">[00:10:08]</a>. The diffusion process in DiTs occurs in a [[latent_diffusion_models_and_architectures | latent space]], rather than directly in pixel space, to improve computational efficiency <a class="yt-timestamp" data-t="00:05:14">[00:05:14]</a> <a class="yt-timestamp" data-t="00:27:28">[00:27:28]</a>.

The input to a DiT is a spatial latent representation (e.g., 32x32x4 for a 256x256x3 image input) <a class="yt-timestamp" data-t="00:29:10">[00:29:10]</a> <a class="yt-timestamp" data-t="00:29:17">[00:29:17]</a>. This latent representation is then "patchified" into smaller pieces, with patch sizes (P) of 2, 4, or 8 being explored <a class="yt-timestamp" data-t="00:31:52">[00:31:52]</a>. Positional embeddings are added to each patch to indicate its original location in the image <a class="yt-timestamp" data-t="00:29:48">[00:29:48]</a>.

### Conditioning and Normalization
DiT models can be conditioned on additional information such as noise time step, class labels (C), or natural language prompts <a class="yt-timestamp" data-t="00:32:24">[00:32:24]</a>. This conditioning is handled by adding specific tokens for time and class labels, which are processed via a cross-attention layer within the [[transformerbased_model_architectures | Transformer]] blocks <a class="yt-timestamp" data-t="00:33:14">[00:33:14]</a> <a class="yt-timestamp" data-t="00:33:41">[00:33:41]</a>.

The architecture also incorporates adaptive normalization layers, like `AdaLN-Zero`, which adjust scale and shift parameters to maintain stable numerical distributions within the network during training <a class="yt-timestamp" data-t="00:34:09">[00:34:09]</a> <a class="yt-timestamp" data-t="00:34:20">[00:34:22]</a>. This helps gradients flow better and improves learning <a class="yt-timestamp" data-t="00:35:32">[00:35:32]</a>.

## Scaling Properties and Performance
The paper analyzes the scalability of DiTs through the lens of GFLOPs (Giga Floating Point Operations) <a class="yt-timestamp" data-t="00:05:29">[00:05:29]</a>. They find that DiTs with higher GFLOPs—achieved by increased [[transformerbased_model_architectures | Transformer]] depth, width, or number of input tokens—consistently result in lower FID (Fréchet Inception Distance) scores, indicating better image quality <a class="yt-timestamp" data-t="00:05:39">[00:05:39]</a>.

DiT models vary in size, from "Small" (12 [[transformerbased_model_architectures | Transformer]] layers, 6 attention heads, hidden dimension 384) to "XL2" (28 [[transformerbased_model_architectures | Transformer]] layers, 16 attention heads, hidden dimension 1152) <a class="yt-timestamp" data-t="00:41:51">[00:41:51]</a>. The largest model, DiT-XL2, achieved a state-of-the-art FID score of 2.27 on the 256x256 ImageNet generation benchmark <a class="yt-timestamp" data-t="00:11:36">[00:11:36]</a>, outperforming all prior diffusion models <a class="yt-timestamp" data-t="01:02:05">[01:02:05]</a>.

> [!NOTE] Model Complexity Measurement
> The researchers emphasize using GFLOPs to measure model complexity rather than just parameter counts, as GFLOPs better account for image resolution and actual compute requirements <a class="yt-timestamp" data-t="00:17:10">[00:17:10]</a> <a class="yt-timestamp" data-t="00:17:27">[00:17:27]</a>.

A key finding is that performance steadily improves with increased model size (GFLOPs) <a class="yt-timestamp" data-t="01:00:22">[01:00:22]</a>. Moreover, larger DiT models are more compute-efficient <a class="yt-timestamp" data-t="01:00:31">[01:00:31]</a>. The selection of patch size also significantly impacts performance; smaller patches (e.g., P=2, meaning 2x2 patches resulting in 4 total patches if image dimension is 512x512 with a 8x downsample factor) allow for finer detail generation, leading to crispier images <a class="yt-timestamp" data-t="00:56:01">[00:56:01]</a>.

## Training Details and Costs
The DiT models were implemented in JAX and trained on Google's TPU v3 pods <a class="yt-timestamp" data-t="00:51:15">[00:51:15]</a> <a class="yt-timestamp" data-t="00:51:19">[00:51:19]</a>. The largest model, DiT-XL2, trained at 5.7 iterations per second on a TPU v3-256 pod <a class="yt-timestamp" data-t="00:52:46">[00:52:46]</a>. Training for 400,000 steps on such a pod is estimated to cost around $10,000 per model <a class="yt-timestamp" data-t="00:54:57">[00:54:57]</a> <a class="yt-timestamp" data-t="00:55:14">[00:55:14]</a>. Despite the high cost, the models achieved state-of-the-art results without extensive hyperparameter tuning for learning rates, decay, or warm-up schedules <a class="yt-timestamp" data-t="00:45:05">[00:45:05]</a> <a class="yt-timestamp" data-t="00:48:18">[00:48:18]</a>. They primarily used a constant learning rate of 1e-4 and maintained an exponential moving average of DiT weights <a class="yt-timestamp" data-t="00:45:05">[00:45:05]</a> <a class="yt-timestamp" data-t="00:47:26">[00:47:26]</a>. An off-the-shelf, pre-trained VAE model from Stable Diffusion was used for the [[latent_diffusion_models_and_architectures | latent space]] operations <a class="yt-timestamp" data-t="00:49:03">[00:49:03]</a>.

## Conclusion and Future Outlook
This research demonstrates that [[transformerbased_model_architectures | Transformers]] can effectively serve as backbones for [[latent_diffusion_models_and_architectures | diffusion models]], achieving state-of-the-art image quality <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>. The scalability of [[transformerbased_model_architectures | Transformers]] allows for continuous performance improvement with increased model size <a class="yt-timestamp" data-t="00:05:57">[00:05:57]</a>. The impressive crispness and semantic correctness of generated images (e.g., fine details like a dog's wrist) highlight the model's capabilities <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a>.

While the models excel at high-frequency details and texture, some low-frequency semantic inconsistencies can still appear (e.g., illogical boat structures or slight anatomical distortions in animals) <a class="yt-timestamp" data-t="01:10:40">[01:10:40]</a> <a class="yt-timestamp" data-t="01:12:31">[01:12:31]</a>. Future work is expected to further scale DiT models to even larger sizes and token counts <a class="yt-timestamp" data-t="01:05:13">[01:05:13]</a>. The rapid advancements in [[latent_diffusion_models_and_architectures | diffusion models]], outpacing the progress seen in earlier generative models like GANs, suggest the potential for generating high-resolution video from text prompts in the near future <a class="yt-timestamp" data-t="01:14:19">[01:14:19]</a> <a class="yt-timestamp" data-t="01:15:02">[01:15:02]</a>.