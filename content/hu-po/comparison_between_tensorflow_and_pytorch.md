---
title: Comparison between TensorFlow and PyTorch
videoId: t21REMsFJ_4
---

From: [[hu-po]] <br/> 

Over the last decade, the landscape of machine learning software development has seen significant changes, with many frameworks emerging and fading <a class="yt-timestamp" data-t="00:02:04">[00:02:04]</a>. Historically, most have relied heavily on leveraging Nvidia's CUDA and performed best on Nvidia GPUs <a class="yt-timestamp" data-t="00:02:11">[00:02:11]</a>. However, with the arrival of [[pytorch_20_and_openai_triton | PyTorch 2.0]] and [[pytorch_20_and_openai_triton | OpenAI's Triton]], Nvidia's dominant position, mainly due to its software, is being disrupted <a class="yt-timestamp" data-t="00:02:32">[00:02:32]</a>.

## The Rise and Fall of TensorFlow

A handful of years ago, the framework ecosystem was fragmented, but TensorFlow was a front-runner, potentially even larger than PyTorch <a class="yt-timestamp" data-t="00:05:55">[00:05:55]</a>. Google appeared poised to control the machine learning industry, possessing a first-mover advantage, the most commonly used framework (TensorFlow), and successful AI application-specific accelerators like the TPU <a class="yt-timestamp" data-t="00:06:10">[00:06:10]</a>.

However, data from conferences like ICLR, CVPR, and NeurIPS show that PyTorch, which was relatively uncommon (10% mentions) in 2017, grew to almost 70-80% mentions by 2020, while TensorFlow's market share decreased <a class="yt-timestamp" data-t="00:06:26">[00:06:26]</a>. This indicates that PyTorch largely won the framework race <a class="yt-timestamp" data-t="00:07:05">[00:07:05]</a>.

### TensorFlow's Approach and Challenges
TensorFlow was written with the mindset of a compiled code language, requiring users to create a graph and then compile it for execution, similar to a C-based workflow <a class="yt-timestamp" data-t="00:08:42">[00:08:42]</a>. This graph-based approach made debugging and understanding code more challenging, as visibility into execution only came after compilation <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>. Although TensorFlow later introduced an eager mode by default, the research community and most large tech firms had already settled on PyTorch <a class="yt-timestamp" data-t="00:09:59">[00:09:59]</a>. Google also developed a second framework, Jax, which competes directly with TensorFlow <a class="yt-timestamp" data-t="00:07:41">[00:07:41]</a>.

## The Ascent of PyTorch

PyTorch's victory was primarily due to its increased flexibility and usability <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>. It offers a very Python-like workflow, allowing users to write code line by line and execute it line by line, similar to a scripting framework <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>. This ease of use made PyTorch more popular <a class="yt-timestamp" data-t="00:09:14">[00:09:14]</a>. Nearly every generative AI model that has made news is based on PyTorch <a class="yt-timestamp" data-t="01:00:07">[01:00:07]</a>.

When executing in eager mode, each operation is read from memory, computed, and then sent back to memory before the next operation is handled <a class="yt-timestamp" data-t="00:35:48">[00:35:48]</a>. This means the CPU acts as a commander, constantly loading and unloading data from GPU RAM, making memory bandwidth a limiting factor <a class="yt-timestamp" data-t="00:35:57">[00:35:57]</a>. To optimize this, a method called operator fusion was developed, where multiple functions are computed in one pass to minimize memory reads and writes <a class="yt-timestamp" data-t="00:37:06">[00:37:06]</a>. This reduces the back-and-forth communication with memory <a class="yt-timestamp" data-t="00:40:05">[00:40:05]</a>. PyTorch steadily implemented more fused operators natively over time, which increased its performance in eager mode <a class="yt-timestamp" data-t="00:41:07">[00:41:07]</a>. However, this also led to PyTorch ballooning to over 2,000 operators <a class="yt-timestamp" data-t="00:41:29">[00:41:29]</a>.

### PyTorch 2.0: Bridging the Gap
[[pytorch_20_and_openai_triton | PyTorch 2.0]], released for early testing with full availability in March, brings significant changes, most notably adding a compiled solution that supports graph execution <a class="yt-timestamp" data-t="00:48:09">[00:48:09]</a>. This shift is designed to make proper utilization of various hardware resources much easier <a class="yt-timestamp" data-t="00:48:35">[00:48:35]</a>.

PyTorch 2.0 offers substantial performance improvements, with an 86% gain for training on Nvidia's A100 and a 26% gain on CPUs for inference <a class="yt-timestamp" data-t="00:48:48">[00:48:48]</a>. These benefits could extend to other GPUs and accelerators from various companies, fostering competition <a class="yt-timestamp" data-t="00:49:04">[00:49:04]</a>.

Key components of [[pytorch_20_and_openai_triton | PyTorch 2.0]] include:
*   **PrimTorch**: Reduces the number of operators from over 2,000 down to 250, making implementation of different non-Nvidia backends simpler and more accessible <a class="yt-timestamp" data-t="00:54:49">[00:54:49]</a>.
*   **Torch Dynamo**: Ingests any PyTorch user script and generates a computational graph <a class="yt-timestamp" data-t="00:55:38">[00:55:38]</a>. It supports partial graph capture, guarded graph capture (checks validity and avoids recompilation), and just-in-time recapture (recompiles if the graph becomes invalid) <a class="yt-timestamp" data-t="00:59:19">[00:59:19]</a>. This dramatically reduces overhead and is seamless for the user, working for over 99% of 7,000 tested PyTorch models <a class="yt-timestamp" data-t="00:56:40">[00:56:40]</a>.
*   **Torch Inductor**: A Python-native learning compiler that generates fast code for multiple accelerator backends <a class="yt-timestamp" data-t="01:02:14">[01:02:14]</a>. It takes the FX graph, further lowers it to a core set of around 50 operators, and then enters a scheduling phase to fuse operators and determine memory planning <a class="yt-timestamp" data-t="01:03:08">[01:03:08]</a>. Inductor's backend code generation leverages [[pytorch_20_and_openai_triton | OpenAI Triton]] for GPUs, outputting PTX code and thereby skipping Nvidia's closed-source CUDA libraries like cuBLAS in favor of open-source alternatives like Cutlass <a class="yt-timestamp" data-t="01:05:01">[01:05:01]</a>. This significantly reduces the work required for compiler teams to support new AI accelerators <a class="yt-timestamp" data-t="01:08:40">[01:08:40]</a>.

PyTorch 2.0 also brings advancements in distributed training with better API support for data parallelism, sharding, pipeline parallelism, and tensor parallelism <a class="yt-timestamp" data-t="00:50:46">[00:50:46]</a>. It supports dynamic shapes natively, making it easier to handle varying sequence lengths for Large Language Models (LLMs) <a class="yt-timestamp" data-t="00:52:00">[00:52:00]</a>. This mirrors capabilities seen in Jax, which is good at parallelism and differential computing <a class="yt-timestamp" data-t="00:52:15">[00:52:15]</a>.

### The Impact on Hardware
The industry is moving towards a model where software allows hardware to change more easily <a class="yt-timestamp" data-t="00:47:38">[00:47:38]</a>. PyTorch is transitioning from being almost exclusively run on Nvidia GPUs to supporting TPUs and other hardware startups like Cerebras <a class="yt-timestamp" data-t="00:47:48">[00:47:48]</a>. The ability to swap out hardware while maintaining the same framework is becoming increasingly important <a class="yt-timestamp" data-t="00:47:58">[00:47:58]</a>.

While Nvidia's CUDA expertise has historically given them an advantage, allowing Cuda experts to re-implement and significantly speed up models like [[compatibility_of_nerf_studio_with_pytorch_and_cuda | Nerf]] <a class="yt-timestamp" data-t="01:07:01">[01:07:01]</a>, [[pytorch_20_and_openai_triton | Triton]] aims to bridge this gap <a class="yt-timestamp" data-t="01:07:52">[01:07:52]</a>. [[pytorch_20_and_openai_triton | Triton]] enables higher-level languages to achieve performance comparable to lower-level ones, and its kernels are more legible to typical ML researchers <a class="yt-timestamp" data-t="01:07:54">[01:07:54]</a>. This approach makes it easier for other hardware accelerators to integrate, opening up the market for AI hardware and custom ASICs <a class="yt-timestamp" data-t="01:08:39">[01:08:39]</a>.

The shift in the market means that the architecture and economics of the chip solution are becoming the biggest drivers of purchase decisions, rather than the ease of use previously afforded by Nvidia's superior software <a class="yt-timestamp" data-t="00:46:46">[00:46:46]</a>. This also means that companies like Meta, who are heavily invested in PyTorch, are motivated to make their software stack more portable to introduce competition into the hardware space <a class="yt-timestamp" data-t="00:49:51">[00:49:51]</a>.

In conclusion, the evolution of frameworks like PyTorch 2.0 and tools like [[pytorch_20_and_openai_triton | OpenAI Triton]] represent a convergence towards a hybrid approach that blends the usability of eager execution with the performance benefits of graph compilation <a class="yt-timestamp" data-t="00:58:49">[00:58:49]</a>. This trend is expected to increase variety and competition in the hardware market for machine learning <a class="yt-timestamp" data-t="01:11:15">[01:11:15]</a>. While model architectures may continue to evolve (e.g., beyond Transformers), the underlying frameworks are adapting to allow more flexible hardware choices <a class="yt-timestamp" data-t="00:47:01">[00:47:01]</a>.