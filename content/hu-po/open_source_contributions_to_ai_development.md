---
title: Open source contributions to AI development
videoId: pov3pLFMOPY
---

From: [[hu-po]] <br/> 

The development of [[open_source_artificial_intelligence | open-source artificial intelligence]] (AI) is significantly influenced by innovations that make large models more accessible for fine-tuning and research. One such advancement is QLoRA, an efficient fine-tuning approach that dramatically reduces memory usage, enabling the fine-tuning of multi-billion parameter models on consumer-grade hardware <a class="yt-timestamp" data-t="00:00:29">[00:00:29]</a>.

## QLoRA: A Game Changer for Accessibility

QLoRA, developed by lead author Tim Detmers and co-author Artidoro, focuses on quantization techniques to make large language models (LLMs) more manageable <a class="yt-timestamp" data-t="01:53:51">[01:53:51]</a>. Detmers is recognized for his contributions to quantization research and is the author of the `bitsandbytes` library, a popular GitHub repository for generic PyTorch quantization <a class="yt-timestamp" data-t="02:46:00">[02:46:00]</a> <a class="yt-timestamp" data-t="02:53:05">[02:53:05]</a>. While `bitsandbytes` offers general quantization, the `artidoro/qlora` repository specifically provides the code used for the QLoRA paper, targeting LLMs like Llama <a class="yt-timestamp" data-t="03:28:00">[03:28:00]</a> <a class="yt-timestamp" data-t="03:31:00">[03:31:00]</a>.

The core innovation of QLoRA is its ability to fine-tune a 65-billion parameter model on a single 48-gigabyte GPU, while preserving the full 16-bit fine-tuning task performance <a class="yt-timestamp" data-t="04:26:00">[04:26:00]</a> <a class="yt-timestamp" data-t="05:29:00">[05:29:00]</a>. This is a significant shift, as regular 16-bit fine-tuning of the Llama 65B model would typically require over 780 gigabytes of GPU memory, necessitating multiple server racks with dozens of GPUs <a class="yt-timestamp" data-t="17:13:00">[17:13:00]</a> <a class="yt-timestamp" data-t="17:44:00">[17:44:00]</a> <a class="yt-timestamp" data-t="18:02:00">[18:02:00]</a>.

### Key Innovations of QLoRA

QLoRA introduces several innovations to achieve memory efficiency without sacrificing performance:
1.  **4-bit NormalFloat (NF4)**: A new data type considered information-theoretically optimal for normally distributed weights in a neural network <a class="yt-timestamp" data-t="10:31:00">[10:31:00]</a> <a class="yt-timestamp" data-t="10:40:00">[10:40:00]</a>. This data type is designed to efficiently store numbers between -1.0 and 1.0, leveraging the common practice of normalizing weights in neural networks <a class="yt-timestamp" data-t="01:10:55">[01:10:55]</a> <a class="yt-timestamp" data-t="01:18:00">[01:18:00]</a>. NF4 outperforms 4-bit integers and 4-bit floats in empirical results <a class="yt-timestamp" data-t="01:12:00">[01:12:00]</a> <a class="yt-timestamp" data-t="01:14:00">[01:14:00]</a>.
2.  **Double Quantization (DQ)**: This technique reduces the memory footprint by quantizing the quantization constants themselves <a class="yt-timestamp" data-t="12:15:00">[12:15:00]</a> <a class="yt-timestamp" data-t="12:20:00">[12:20:00]</a>. For example, quantization constants stored as 32-bit floats are further quantized to 8-bit floats, saving an average of 0.37 bits per parameter <a class="yt-timestamp" data-t="24:40:00">[24:40:00]</a> <a class="yt-timestamp" data-t="25:57:00">[25:57:00]</a>. This approach is reminiscent of residual quantization found in other papers <a class="yt-timestamp" data-t="12:27:00">[12:27:00]</a>.
3.  **Paged Optimizers**: These manage memory spikes that occur during gradient checkpointing, preventing "out of memory" (OOM) errors that traditionally hinder fine-tuning of large models <a class="yt-timestamp" data-t="13:34:00">[13:34:00]</a> <a class="yt-timestamp" data-t="28:05:00">[28:05:00]</a>. By utilizing NVIDIA's unified memory feature, optimizer states can be automatically "evicted" to CPU RAM when GPU memory is full, and then "paged" back when needed <a class="yt-timestamp" data-t="28:06:00">[28:06:00]</a> <a class="yt-timestamp" data-t="31:34:00">[31:34:00]</a>. This ensures stable training, especially for mini-batches with long sequence lengths that consume significant memory <a class="yt-timestamp" data-t="48:52:00">[48:52:00]</a> <a class="yt-timestamp" data-t="49:09:00">[49:09:00]</a>.

QLoRA back-propagates gradients through a frozen, 4-bit quantized base model, but only updates a small set of learnable low-rank adapter (LoRA) weights <a class="yt-timestamp" data-t="06:21:00">[06:21:00]</a> <a class="yt-timestamp" data-t="06:40:00">[06:40:00]</a> <a class="yt-timestamp" data-t="19:31:00">[19:31:00]</a>. This means the vast majority of the model's parameters remain unchanged, dramatically reducing the computational burden <a class="yt-timestamp" data-t="07:09:00">[07:09:00]</a>. The LoRA parameters themselves are stored in 16-bit precision during training <a class="yt-timestamp" data-t="01:37:05">[01:37:05]</a>.

The most critical LoRA hyperparameter for achieving performance equivalent to full 16-bit fine-tuning is the use of LoRA adapters on *all* linear Transformer block layers <a class="yt-timestamp" data-t="01:58:51">[01:58:51]</a> <a class="yt-timestamp" data-t="01:59:59">[01:59:59]</a>. The projection dimension (rank `R`) of the LoRA matrices, which determines their size, appears to have little impact on performance <a class="yt-timestamp" data-t="01:59:41">[01:59:41]</a> <a class="yt-timestamp" data-t="02:02:23">[02:02:23]</a>.

### Impact on the [[open_source_artificial_intelligence | Open Source AI]] Community

The accessibility provided by QLoRA is crucial for the [[opensource_ai_and_its_implications | open-source AI and its implications]] <a class="yt-timestamp" data-t="02:08:00">[02:08:00]</a> <a class="yt-timestamp" data-t="02:09:00">[02:09:00]</a>. It means that individual researchers and small teams can fine-tune large, publicly available models on a single consumer GPU, eliminating the prohibitive cost of compute previously required <a class="yt-timestamp" data-t="09:11:00">[09:11:00]</a> <a class="yt-timestamp" data-t="09:59:00">[09:59:00]</a>. This democratizes AI research, allowing for rapid experimentation and innovation outside of large industry labs <a class="yt-timestamp" data-t="10:02:00">[10:02:00]</a> <a class="yt-timestamp" data-t="02:13:00">[02:13:00]</a> <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>.

The paper highlights that data quality is more important than dataset size for fine-tuning <a class="yt-timestamp" data-t="01:44:39">[01:44:39]</a> <a class="yt-timestamp" data-t="01:45:00">[01:45:00]</a>. For instance, a 9,000-example dataset (OASST1) outperformed a 450,000-example dataset (Flan V2) for instruction-following generalization <a class="yt-timestamp" data-t="01:45:00">[01:45:00]</a> <a class="yt-timestamp" data-t="01:47:00">[01:47:00]</a>. This finding, consistent with other research like the Lima paper, encourages a focus on high-quality, curated data <a class="yt-timestamp" data-t="01:34:00">[01:34:00]</a> <a class="yt-timestamp" data-t="01:41:00">[01:41:00]</a>.

QLoRA has been used to train the Guanaco model family, with the best model achieving 99.3% of ChatGPT's performance level on the Vicuna Benchmark, requiring only 24 hours of fine-tuning on a single professional GPU <a class="yt-timestamp" data-t="08:08:00">[08:08:00]</a> <a class="yt-timestamp" data-t="08:35:00">[08:35:00]</a>. The smallest Guanaco model (7B) requires just 5 GB of memory and outperforms larger Alpaca models <a class="yt-timestamp" data-t="02:17:00">[02:17:00]</a>. All QLoRA models and code, including CUDA kernels for 4-bit training, are open-sourced and integrated into the Hugging Face Transformer stack, making them widely accessible <a class="yt-timestamp" data-t="01:16:00">[01:16:00]</a> <a class="yt-timestamp" data-t="03:57:00">[03:57:00]</a>.

### Challenges and Future Directions

While QLoRA significantly advances [[open_source_artificial_intelligence | open-source AI]], certain challenges remain:
*   **Benchmarking Limitations**: Current chatbot benchmarks are not entirely trustworthy for accurate evaluation <a class="yt-timestamp" data-t="01:15:16">[01:15:16]</a>. Models like Guanaco perform well on the Vicuna benchmark, but issues like GPT-4's bias towards its own answers or towards the first option in a prompt introduce uncertainty <a class="yt-timestamp" data-t="02:22:00">[02:22:00]</a> <a class="yt-timestamp" data-t="02:41:50">[02:41:50]</a>. Human and GPT-4 evaluations largely agree on model rankings but also show strong disagreements <a class="yt-timestamp" data-t="02:26:00">[02:26:00]</a>. There is a need for better and more comprehensive benchmarks beyond single quantifiable scores <a class="yt-timestamp" data-t="03:16:00">[03:16:00]</a> <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>.
*   **Outliers and Intelligence**: Research suggests a weird relationship between model scale and the prevalence of outliers in weights. As models grow larger, the percentage of layers containing outliers increases, and these outliers are believed to be crucial for the neural network's "intelligence" <a class="yt-timestamp" data-t="01:09:55">[01:09:55]</a> <a class="yt-timestamp" data-t="01:11:00">[01:11:00]</a>. This area requires further understanding, as it impacts optimal quantization strategies.
*   **Hardware and Software Co-design**: The trend of vertical integration in deep learning, where models and training processes are increasingly tailored to specific hardware (e.g., Google's TPUs, Tesla's Dojo chip), could pose challenges for broader [[open_source_artificial_intelligence | open-source AI]] development that aims for hardware agnosticism <a class="yt-timestamp" data-t="01:57:00">[01:57:00]</a> <a class="yt-timestamp" data-t="01:59:00">[01:59:00]</a>.

Despite these challenges, QLoRA represents a significant step towards enabling broader participation in AI research and development. The ability to fine-tune large models with limited resources means that innovation can flourish beyond the confines of well-funded corporate labs, leading to a more diverse and vibrant [[open_source_artificial_intelligence | open-source AI]] ecosystem.