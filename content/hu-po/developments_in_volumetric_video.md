---
title: Developments in Volumetric Video
videoId: _jqhy-dr7Q4
---

From: [[hu-po]] <br/> 

Volumetric video, a form of 3D video, is undergoing rapid advancements, with Gaussian Splats emerging as a key primitive for capturing and rendering dynamic scenes. These developments are paving the way for applications in fields like robotics and virtual reality (VR) <a class="yt-timestamp" data-t="03:22:00">[03:22:00]</a>.

## Understanding Gaussian Splats

A Gaussian Splat is a method for rendering a 3D model into 2D images given a specific camera pose <a class="yt-timestamp" data-t="00:26:30">[00:26:30]</a>. In a 3D Gaussian model, a scene is represented by a collection of Gaussian points, each parameterized by its covariance, center position, color, and opacity <a class="yt-timestamp" data-t="00:26:42">[00:26:42]</a>. The rendering pipeline for Gaussian Splats is fully differentiable, allowing for optimization using image similarity and reconstruction losses <a class="yt-timestamp" data-t="00:27:04">[00:27:04]</a>.

### Advantages Over Traditional 3D Representations

Compared to traditional mesh representations used in video games, Gaussian Splats offer significant benefits:
*   **Ease of Creation**: Meshes require extensive manual labor to create, especially for high-quality volumetric videos <a class="yt-timestamp" data-t="00:15:27">[00:15:27]</a>. Gaussian Splats, conversely, can be generated by simply filming a scene with a device like an iPhone and feeding the images into a Gaussian Splatting process <a class="yt-timestamp" data-t="00:16:07">[00:16:07]</a>.
*   **Photorealism**: Gaussian Splats can produce much more photorealistic simulations than manually created meshes <a class="yt-timestamp" data-t="00:16:16">[00:16:16]</a>.
*   **Fast Rendering**: Gaussian Splats enable very fast rendering speeds, largely due to tile-based rendering that can be done in parallel <a class="yt-timestamp" data-t="00:29:45">[00:29:45]</a>.
*   **Explicit Representation**: Unlike NeRFs, which implicitly store scene information within a multi-layer perceptron, Gaussian Splats explicitly store each Gaussian, making it easier to segment and manipulate different parts of a scene <a class="yt-timestamp" data-t="00:31:16">[00:31:16]</a>. This explicitness is beneficial for applications like robotics, where specific objects within a scene might need to be isolated or moved <a class="yt-timestamp" data-t="00:31:28">[00:31:28]</a>.

## Volumetric Video in Robotics

Gaussian Splats are being explored for various robotics applications, particularly in creating photorealistic simulations for training and navigation.

### Sim-to-Real Transfer

One key application is enhancing sim-to-real transfer, the process of training a robot in simulation and deploying it in a real environment.
*   **SplatSim**: A paper from Carnegie Mellon University called "SplatSim" uses Gaussian Splats to replace traditional mesh representations in simulators <a class="yt-timestamp" data-t="00:06:31">[00:06:31]</a>. This allows for the generation of highly photorealistic synthetic data, bridging the "domain shift" between synthetic and real-world visual data <a class="yt-timestamp" data-t="00:08:34">[00:08:34]</a>. The approach achieved an 86% task success rate in simulation, compared to 97% when trained on real-world data, demonstrating its effectiveness in closing the sim-to-real gap <a class="yt-timestamp" data-t="00:24:29">[00:24:29]</a>.
*   **DeepMind's Approach**: Similar to SplatSim, DeepMind's OP3 robotics paper used a NeRF (Neural Radiance Field) to render the background of a simulated environment, keeping the robot and objects as meshes for physics interactions <a class="yt-timestamp" data-t="00:13:57">[00:13:57]</a>. This hybrid approach allowed for a more photorealistic background without the manual effort of creating detailed meshes <a class="yt-timestamp" data-t="00:16:35">[00:16:35]</a>.

### Image-Goal Navigation

Gaussian Splats also facilitate image-goal navigation for robots.
*   **Beijian Embodied Image-Goal Navigation**: This paper describes a robot blimp navigating a room by using visual perception to reach a target location defined by an image <a class="yt-timestamp" data-t="00:17:37">[00:17:37]</a>. The entire room scene was captured and converted into a Gaussian Splat using 534 RGB images with known camera positions <a class="yt-timestamp" data-t="00:18:40">[00:18:40]</a>. The robot uses a model predictive control approach, querying the Gaussian Splat to predict what an image would look like at various future positions, and comparing these to the goal image <a class="yt-timestamp" data-t="00:21:48">[00:21:48]</a>.

## Advancing Dynamic Scenes and Streaming

A significant challenge for Gaussian Splats is handling dynamic scenes, as early implementations were primarily for static environments <a class="yt-timestamp" data-t="00:20:21">[00:20:21]</a>. Recent research focuses on enabling motion and streaming.

### Sliding Window Gaussian Splatting (SwinGS)

SwinGS addresses the streaming of volumetric video, which is crucial for applications like VR headsets and robots with limited on-device compute <a class="yt-timestamp" data-t="00:32:46">[00:32:46]</a>.
*   **Efficient Memory Management**: SwinGS manages Gaussian Splats by efficiently taking out old Gaussians and bringing in new ones relevant to the current view or time slice <a class="yt-timestamp" data-t="00:34:36">[00:34:36]</a>. This allows for continuous streaming of volumetric data, maximizing the use of limited GPU memory on edge devices <a class="yt-timestamp" data-t="00:35:09">[00:35:09]</a>.

### Markov Chain Monte Carlo (MCMC) for Gaussian Management

A novel approach reinterprets Gaussian Splat management using Markov Chain Monte Carlo (MCMC) techniques, specifically Stochastic Gradient Langevin Dynamics (SGLD) <a class="yt-timestamp" data-t="00:43:52">[00:43:52]</a>.
*   **Addressing Hyperparameter Issues**: Traditional Gaussian Splatting relies on heuristic-based densification (splitting Gaussians) and pruning (removing "dead" Gaussians), which require careful tuning of multiple hyperparameters <a class="yt-timestamp" data-t="00:53:04">[00:53:04]</a>. This can lead to arbitrary choices and inconsistent performance <a class="yt-timestamp" data-t="00:53:21">[00:53:21]</a>.
*   **Relocating Dead Gaussians**: The MCMC approach rethinks the set of 3D Gaussians as random samples drawn from an underlying probability distribution <a class="yt-timestamp" data-t="00:54:34">[00:54:34]</a>. Instead of splitting or removing Gaussians, "dead" Gaussians (those with low opacity or presence) are relocated to positions where more Gaussians are needed (areas of high image reconstruction error) <a class="yt-timestamp" data-t="00:55:55">[00:55:55]</a>.
*   **Uniform Data Volume**: This relocation strategy maintains a uniform data volume (i.e., a consistent number of Gaussians) across time, which is crucial for streamable content and efficient GPU memory usage on client devices <a class="yt-timestamp" data-t="00:56:19">[00:56:19]</a>.
*   **Connection to Molecular Dynamics**: This reinterpretation draws from molecular dynamics, specifically the Langevin equation, which describes the random movement of particles (like pollen grains in Brownian motion) <a class="yt-timestamp" data-t="00:58:21">[00:58:21]</a>. Researchers noted a "striking similarity" between the Gaussian update equations and the Langevin equation, allowing them to apply established principles of molecular dynamics to optimize Gaussian Splats <a class="yt-timestamp" data-t="01:01:15">[01:01:15]</a>. This means a similar mathematical framework used to describe the movement of tiny balls in physical space can be used to manage the movement and distribution of Gaussian Splats in 3D scene representation <a class="yt-timestamp" data-t="01:00:00">[01:00:00]</a>.

## Towards Interactive Volumetric Video

While significant progress has been made in photorealism and dynamic rendering, a missing piece for fully interactive volumetric video is the integration of physics.

*   **Current Limitations**: Existing Gaussian Splat demos, such as those of a musician playing guitar, are purely visual; users cannot interact with or manipulate objects within the scene <a class="yt-timestamp" data-t="01:10:39">[01:10:39]</a>. Traditional physics engines in video games rely on meshes for collision detection and force calculation <a class="yt-timestamp" data-t="01:09:40">[01:09:40]</a>.
*   **Gaussian Garments**: Research like "Gaussian Garments" is moving towards incorporating physics properties into Gaussians <a class="yt-timestamp" data-t="01:11:01">[01:11:01]</a>. This involves assigning physics-based properties (like bending energy) to Gaussians based on the object they represent, enabling realistic deformation of clothing <a class="yt-timestamp" data-t="01:11:56">[01:11:56]</a>. This is a step towards enabling full Gaussian-based scenes where all physics interactions are also handled by the Gaussians themselves <a class="yt-timestamp" data-t="01:13:27">[01:13:27]</a>.

## Rendering on Edge Devices

Efficient rendering on devices with limited compute is crucial for the widespread adoption of volumetric video.

*   **WebGPU/WebGL**: Initiatives are underway to standardize the rendering of Gaussian Splats on any device with a browser, leveraging the GPU. WebGPU (Web Graphics Processing Unit) and WebGL (Web Graphics Library) aim to enable fast rendering and even machine learning inference directly within web browsers <a class="yt-timestamp" data-t="01:06:45">[01:06:45]</a>. This means VR headsets and phones could access GPU capabilities via a browser to render complex volumetric scenes <a class="yt-timestamp" data-t="01:07:01">[01:07:01]</a>.
*   **Open-Source Implementations**: The release of open-source libraries like "GSplat," developed by institutions including UC Berkeley, Amazon, and Luma AI, provides a clean, fast, and openly licensed implementation of Gaussian Splatting, including CUDA kernels <a class="yt-timestamp" data-t="00:45:05">[00:45:05]</a>. This greatly facilitates research and development in the field, allowing more people to use and modify Gaussian Splats <a class="yt-timestamp" data-t="00:47:48">[00:47:48]</a>.

### Future Outlook for Volumetric Video

The future of volumetric video, particularly in VR and robotics, looks promising with Gaussian Splats at its core.
*   **Simplified Asset Creation**: The goal is to move towards creating physics-enabled Gaussian Splat assets from common devices like a single monocular iPhone camera, rather than expensive multi-camera setups <a class="yt-timestamp" data-t="01:17:19">[01:17:19]</a>.
*   **Foundation Models**: [[video_diffusion_models_in_generative_3d | Video diffusion models in generative 3D]] and pre-trained image encoders are expected to play a role in reducing the number of images required for Gaussian Splat creation and improving initialization <a class="yt-timestamp" data-t="01:44:46">[01:44:46]</a>.
*   **Specialized Hardware**: While current GPUs are already efficient for Gaussian Splats, future VR headsets might integrate application-specific integrated circuits (ASICs) specifically optimized for Gaussian Splatting as the representation becomes ubiquitous <a class="yt-timestamp" data-t="01:54:52">[01:54:52]</a>.
*   **Enhanced Capabilities**: Challenges remain in rendering complex materials like see-through glass, smoke, and hair, but the fundamental nature of Gaussians as point-based primitives may make them inherently better suited for these elements than meshes <a class="yt-timestamp" data-t="01:49:43">[01:49:43]</a>.
*   **Semantic Integration**: Augmenting Gaussians with semantic properties (e.g., categorizing objects like "chopsticks") will allow for open-vocabulary 3D querying and detailed object segmentation, crucial for advanced robotic interaction <a class="yt-timestamp" data-t="01:47:44">[01:47:44]</a>.

Ultimately, the shift towards a 3D representation like Gaussian Splats, rather than purely 2D image sequences, is seen as fundamental for developing true robotic world models that accurately reflect the 3D nature of reality <a class="yt-timestamp" data-t="01:58:36">[01:58:36]</a>. This shift is set to enable more immersive and interactive experiences in virtual worlds and more capable robots in the real world <a class="yt-timestamp" data-t="01:26:20">[01:26:20]</a>.