---
title: Structured chain of thought in AI models
videoId: 5qkjxDzEaaw
---

From: [[hu-po]] <br/> 

Structured Chain of Thought refers to an approach where a model is forced to think step-by-step through a problem, rather than immediately providing a direct answer <a class="yt-timestamp" data-t="00:39:15">[00:39:15]</a>. This method is often described as a "hardcoded [[Chain of Thought in AI Reasoning | Chain of Thought]]" or a "structured approach" <a class="yt-timestamp" data-t="00:38:06">[00:38:06]</a>.

## Purpose and Mechanism
The core idea is to improve the reasoning abilities of [[foundation_models_in_ai | language models]] and [[visual_reasoning | Vision Language Models]] (VLMs) <a class="yt-timestamp" data-t="00:39:04">[00:39:04]</a>. By breaking down a complex problem into a sequence of predefined steps, the model is guided to produce a more accurate and well-reasoned output <a class="yt-timestamp" data-t="00:39:09">[00:39:09]</a>.

A typical structured approach, as demonstrated by the Lava 01 paper, might involve the following stages for a question posed about an image:
*   **Question**: The initial query <a class="yt-timestamp" data-t="00:38:24">[00:38:24]</a>.
*   **Summary**: What is the problem and what should be done? <a class="yt-timestamp" data-t="00:39:24">[00:39:24]</a>
*   **Caption**: What information can be gathered from the image? <a class="yt-timestamp" data-t="00:38:25">[00:38:25]</a>
*   **Reasoning**: How to solve the problem step by step <a class="yt-timestamp" data-t="00:39:28">[00:39:28]</a>.
*   **Answer**: The final response, formulated after building a comprehensive context from the preceding steps <a class="yt-timestamp" data-t="00:39:31">[00:39:31]</a>.

If a [[visual_reasoning | Vision Language Model]] were to be directly fed a complex question (e.g., "subtract all the shiny balls, subtract all the purple objects, how many of the objects left?"), it would likely struggle to provide the correct answer immediately <a class="yt-timestamp" data-t="00:38:49">[00:38:49]</a>. By imposing these intermediate "thinking" steps, the model's performance on such tasks significantly improves <a class="yt-timestamp" data-t="00:39:08">[00:39:08]</a>.

## Enhancements and Applications
### Beam Search
Further enhancing this structured approach, techniques like "inference time stage level beam search" can be applied <a class="yt-timestamp" data-t="00:39:45">[00:39:45]</a>. While greedy decoding picks the most likely next token at each step, beam search explores multiple possible paths, looking ahead to identify token sequences with higher overall probabilities <a class="yt-timestamp" data-t="00:40:56">[00:40:56]</a>. When applied at each stage of the structured reasoning process, this allows for more robust token generation within each step <a class="yt-timestamp" data-t="00:41:48">[00:41:48]</a>.

### Self-Improvement
Structured [[Chain of Thought in AI Reasoning | Chain of Thought]] can be leveraged for [[SelfImprovement in AI Models | self-improvement]] in AI models. Traditionally, reasoning traces might be generated by human experts <a class="yt-timestamp" data-t="00:44:43">[00:44:43]</a>. However, models can also automatically generate these traces <a class="yt-timestamp" data-t="00:46:22">[00:46:22]</a>. For example, by sampling multiple outputs and assessing their consistency using metrics like sentence embedding similarity, a model can identify and prioritize more consistent (and likely correct) reasoning paths <a class="yt-timestamp" data-t="00:49:35">[00:49:35]</a>. This process allows for the creation of high-quality training data from the model's own outputs, which can then be used for fine-tuning, leading to improved performance <a class="yt-timestamp" data-t="00:48:03">[00:48:03]</a>.

### GUI Agents and Future Imagination
The concept of structured reasoning is particularly relevant for [[chain_of_thought_prompting_in_robotics | GUI agents]], which interact with digital screens <a class="yt-timestamp" data-t="01:00:35">[01:00:35]</a>. These agents need to interpret visual information (e.g., screenshots) and decide on actions (e.g., mouse clicks, keyboard inputs) <a class="yt-timestamp" data-t="00:27:00">[00:27:00]</a>.

Beyond merely organizing existing knowledge, advanced forms of structured reasoning can involve generative capabilities:
*   **Imagining Future Observations**: Agents can be given the compute budget to predict what future screens might look like after performing a hypothetical action <a class="yt-timestamp" data-t="00:54:55">[00:54:55]</a>. This "generative world exploration" allows the agent to evaluate potential outcomes before committing to an action, improving decision-making <a class="yt-timestamp" data-t="00:54:59">[00:54:59]</a>.

## Trade-offs and Future Outlook
While structured reasoning improves accuracy, it introduces latency due to the increased number of tokens that need to be processed <a class="yt-timestamp" data-t="01:05:16">[01:05:16]</a>. There is an ongoing "arms race" between hardware developers trying to increase "tokens per second" processing speed and AI researchers continually adding more complex reasoning steps (and thus more tokens) to improve model performance <a class="yt-timestamp" data-t="01:05:50">[01:05:50]</a>.

Despite the computational overhead, the overall trend suggests that future AI agents, particularly [[chain_of_thought_prompting_in_robotics | GUI agents]], will extensively use visual reasoning with highly complex, multi-stage thought processes <a class="yt-timestamp" data-t="01:06:45">[01:06:45]</a>. The ability of models to self-improve and even generate imagined future states will further enhance their capabilities <a class="yt-timestamp" data-t="01:25:25">[01:25:25]</a>. This is seen as strong evidence for [[SelfImprovement in AI Models | self-improving AI]] <a class="yt-timestamp" data-t="01:25:43">[01:25:43]</a>.