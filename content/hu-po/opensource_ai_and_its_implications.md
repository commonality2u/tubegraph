---
title: Opensource AI and its implications
videoId: 1ZwXkw9_Xq8
---

From: [[hu-po]] <br/> 

[[open_source_artificial_intelligence | Open source artificial intelligence]] has emerged as a significant development in the field of large language models (LLMs), with models like Meta's Llama 2 leading the way. Unlike its predecessor, Llama 1, which was leaked, Llama 2 is the first "open source big competitive LLM" intentionally released for public use [00:00:55](<a class="yt-timestamp" data-t="00:00:55">[00:00:55]</a>. This openness carries several implications for development, safety, and accessibility.

## Llama 2: An Open Foundation
Llama 2 is a collection of pre-trained and fine-tuned LLMs, available in sizes ranging from 7 billion to 70 billion parameters [00:03:41](<a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>, [00:03:55](<a class="yt-timestamp" data-t="00:03:55">[00:03:55]</a>. The fine-tuned versions, known as Llama 2 Chat, are optimized for dialogue use cases [00:03:59](<a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>. These models can be downloaded and run locally [00:01:11](<a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a>.

### Technical Details
*   **Architecture**: Llama 2 uses a standard Transformer architecture with pre-normalization (RMS Norm), Swiglu activation, and Rotary Positional Embeddings (RoPE) [02:26:22](<a class="yt-timestamp" data-t="02:26:22">[02:26:22]</a>. Key differences from Llama 1 include an increased context length from 2048 to 4096 tokens and the adoption of Grouped Query Attention (GQA) for efficiency [01:18:20](<a class="yt-timestamp" data-t="01:18:20">[01:18:20]</a>, [00:29:04](<a class="yt-timestamp" data-t="00:29:04">[00:29:04]</a>.
*   **Training Data**: The models were pre-trained on two trillion tokens of a new mix of publicly available data, specifically excluding data from Meta's own products or services [00:22:52](<a class="yt-timestamp" data-t="00:22:52">[00:22:52]</a>, [00:23:45](<a class="yt-timestamp" data-t="00:23:45">[00:23:45]</a>, [00:23:55](<a class="yt-timestamp" data-t="00:23:55">[00:23:55]</a>. Efforts were made to remove data from sites known to contain high volumes of personal information [00:23:35](<a class="yt-timestamp" data-t="00:23:35">[00:23:35]</a>. Factual resources were "upsampled" to increase knowledge and reduce hallucinations [00:23:59](<a class="yt-timestamp" data-t="00:23:59">[00:23:59]</a>.
*   **Fine-tuning**: Llama 2 Chat models undergo supervised fine-tuning (SFT) and iterative reinforcement learning with human feedback (RLHF), primarily using the PPO algorithm [01:03:18](<a class="yt-timestamp" data-t="01:03:18">[01:03:18]</a>, [01:29:11](<a class="yt-timestamp" data-t="01:29:11">[01:29:11]</a>, [01:30:16](<a class="yt-timestamp" data-t="01:30:16">[01:30:16]</a>. This process involves two separate reward models: one for helpfulness and another for safety [00:20:38](<a class="yt-timestamp" data-t="00:20:38">[00:20:38]</a>, [01:17:35](<a class="yt-timestamp" data-t="01:17:35">[01:17:35]</a>.
*   **Ghost Attention (GAt)**: A technique called "Ghost Attention" was introduced to maintain multi-turn consistency by synthetically concatenating system prompts (e.g., "always answer in emojis") to all user messages during conversation, ensuring the model remembers initial instructions [01:43:33](<a class="yt-timestamp" data-t="01:43:33">[01:43:33]</a>, [01:44:00](<a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>, [01:49:35](<a class="yt-timestamp" data-t="01:49:35">[01:49:35]</a>.

### Performance
Llama 2 models outperform other [[open_source_contributions_to_ai_development | open source chat models]] on most benchmarks and are deemed "suitable substitutes for closed-source models" like ChatGPT, Claude, and Bard, based on human evaluations for helpfulness and safety [00:04:04](<a class="yt-timestamp" data-t="00:04:04">[00:04:04]</a>, [00:04:14](<a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a>. The 13B model is often highlighted as a "sweet spot" for performance relative to size, offering significantly better performance than the 7B model [01:02:40](<a class="yt-timestamp" data-t="01:02:40">[01:02:40]</a>, [02:42:41](<a class="yt-timestamp" data-t="02:42:41">[02:42:41]</a>.

## Implications of Open Sourcing LLMs

### Advantages of Openness
*   **Transparency and Collaboration**: Meta explicitly states that opening Llama 2 "encourages responsible AI Innovation" and "draws upon the collective wisdom, diversity, and ingenuity of the AI practitioner community" [02:34:27](<a class="yt-timestamp" data-t="02:34:27">[02:34:27]</a>, [02:34:31](<a class="yt-timestamp" data-t="02:34:31">[02:34:31]</a>. This contrasts with secretive "closed product LLMs" that offer little transparency [00:03:01](<a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>, [01:00:00](<a class="yt-timestamp" data-t="01:00:00">[01:00:00]</a>.
*   **Democratization and Innovation**: Open access to foundational models "democratizes access" and "stimulates Innovation and accelerates progress" [02:35:11](<a class="yt-timestamp" data-t="02:35:11">[02:35:11]</a>, [02:35:23](<a class="yt-timestamp" data-t="02:35:23">[02:35:23]</a>. It removes barriers to entry, allowing small businesses to leverage these technologies without incurring the immense training costs associated with developing LLMs from scratch [02:35:31](<a class="yt-timestamp" data-t="02:35:31">[02:35:31]</a>, [02:36:02](<a class="yt-timestamp" data-t="02:36:02">[02:36:02]</a>.
*   **Ease of Commercial Use**: Llama 2 is available for both research and commercial use, which provides an "ease of mind" for startups and businesses compared to models like Llama 1, which was leaked and not officially sanctioned for commercial purposes [02:34:04](<a class="yt-timestamp" data-t="02:34:04">[02:34:04]</a>, [02:52:23](<a class="yt-timestamp" data-t="02:52:23">[02:52:23]</a>.

### Challenges and Concerns
*   **[[challenges_and_implications_for_ai_safety | AI Safety]] and Control**: While Meta emphasizes safety measures like "red teaming" (internal teams trying to make the model misbehave) [02:12:07](<a class="yt-timestamp" data-t="02:12:07">[02:12:07]</a>, some suggest safety concerns might be a "red herring" for control [01:13:15](<a class="yt-timestamp" data-t="01:13:15">[01:13:15]</a>. There's a tension between making an LLM maximally helpful and maximally safe, as increased safety can lead to "false refusals" (incorrectly refusing legitimate prompts) [02:07:29](<a class="yt-timestamp" data-t="02:07:29">[02:07:29]</a>, [02:09:08](<a class="yt-timestamp" data-t="02:09:08">[02:09:08]</a>.
*   **Bias in Data**: [[ethical_considerations_and_societal_impacts_of_ai_simulations | Ethical considerations and societal impacts of AI simulations]] are complex, particularly concerning biases present in pre-training data [01:58:12](<a class="yt-timestamp" data-t="01:58:12">[01:58:12]</a>. LLMs reflect real-world biases from their training data (e.g., pronoun biases) [01:59:50](<a class="yt-timestamp" data-t="01:59:50">[01:59:50]</a>. This raises a [[philosophical_implications_of_ai_development | philosophical implication of AI development]]: should models reflect existing societal biases accurately, or should synthetic data be injected to balance them and reduce bias, even if it deviates from real-world accuracy [02:01:25](<a class="yt-timestamp" data-t="02:01:25">[02:01:25]</a>, [02:01:32](<a class="yt-timestamp" data-t="02:01:32">[02:01:32]</a>? This contentious issue could lead to more control from companies seeking to avoid backlash [02:03:04](<a class="yt-timestamp" data-t="02:03:04">[02:03:04]</a>.
*   **Proprietary Cleaning**: Even when using publicly available datasets, companies apply their own cleaning processes, meaning the "effective data set" can diverge significantly between models, making direct comparisons difficult [02:45:07](<a class="yt-timestamp" data-t="02:45:07">[02:45:07]</a>.
*   **[[impacts_of_ai_on_human_roles_in_scientific_research | Impacts of AI on human roles in scientific research]] and Annotation**: Human annotators play a crucial role in fine-tuning, with their preferences shaping model behavior [01:04:46](<a class="yt-timestamp" data-t="01:04:46">[01:04:46]</a>. The term "collecting" data for fine-tuning is noted as misleading, as much of it is actively "created" by paid annotators [01:06:08](<a class="yt-timestamp" data-t="01:06:08">[01:06:08]</a>. The quality of human annotation significantly impacts model performance [01:07:32](<a class="yt-timestamp" data-t="01:07:32">[01:07:32]</a>.
*   **Tool Use Emergence**: Despite not being explicitly annotated for tool usage, Llama 2 demonstrates an emergent capability to understand and utilize tools (APIs) through semantics in a zero-shot context [02:33:38](<a class="yt-timestamp" data-t="02:33:38">[02:33:38]</a>, [02:33:47](<a class="yt-timestamp" data-t="02:33:47">[02:33:47]</a>. This is a key [[applications_in_machine_learning_and_ai | application in Machine Learning and AI]] and points to [[the_potential_future_and_challenges_of_ai_agents | the potential future and challenges of AI agents]].

## Future Outlook
Meta plans to make further improvements to Llama 2 Chat [02:38:13](<a class="yt-timestamp" data-t="02:38:13">[02:38:13]</a>. Potential avenues for future development include training for longer periods (as Llama 2 did not show signs of saturation) [02:45:47](<a class="yt-timestamp" data-t="02:45:47">[02:45:47]</a>, utilizing Meta's vast internal proprietary datasets, and adopting more modern tokenizers or fine-tuning techniques (e.g., LoRA) [02:46:16](<a class="yt-timestamp" data-t="02:46:16">[02:46:16]</a>, [02:50:30](<a class="yt-timestamp" data-t="02:50:30">[02:50:30]</a>. The open release of Llama 2 is seen as a significant step for [[open_source_artificial_intelligence | open source artificial intelligence]], encouraging collaboration and transparency in AI development [02:56:52](<a class="yt-timestamp" data-t="02:56:52">[02:56:52]</a>.