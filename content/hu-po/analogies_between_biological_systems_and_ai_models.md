---
title: Analogies between Biological Systems and AI Models
videoId: 3nrvy0FuLWM
---

From: [[hu-po]] <br/> 

This article explores the striking analogies between biological systems and artificial intelligence (AI) models, drawing insights from Michael Levin's paper on [[collective_intelligence_in_biology_and_ai | collective intelligence]]. The discussion highlights how both domains exhibit hierarchical structures, emergent intelligence, and problem-solving capabilities across various scales and substrates.

## Multiscale Architecture and Hierarchical Organization

A defining feature of biology is its multiscale architecture, ranging from molecular networks to cells, tissues, organs, whole bodies, and swarms [00:06:12]. This progression represents a hierarchy of organization, from microscopic units like cells to macroscopic units like swarms of humans or birds [00:06:24].

A similar hierarchical, multiscale architecture is observed in modern deep learning [00:06:46]. For instance, convolutional neural networks (ConvNets), which process images for tasks like classification, create a hierarchy of concepts where different levels pay attention to distinct features [00:06:58]. Low-level blocks in a Vision Transformer (ViT) might identify textures, while higher levels progressively extract more abstract features like shapes and patterns [00:23:35]. The highest levels, near the classification head, recognize complex features corresponding to specific classes, such as the white rim of a cup for "espresso" or bottles for "bottle" [00:24:08].

Crucially, biology is nested not only structurally but also functionally [00:07:42]. Each level can solve problems in distinct "problem spaces," such as physiological, morphological, and behavioral state spaces [00:07:48]. This concept of "spaces" is analogous to "latent spaces" or "embedding spaces" in AI, where high-dimensional data is projected into lower-dimensional representations [00:08:02].

## Defining Intelligence and Problem Solving

Michael Levin defines intelligence as the "degree of ability to reach the same goal by different means," or problem-solving in changing or novel circumstances [00:18:37]. This definition applies across scales in both biological and AI systems.

In biology, the development from an embryo to a full human can be viewed as traversing a "morphological space" (the space of all body types) towards a final "attractor state" [00:10:31]. Even if disrupted, like a tadpole with incorrectly arranged cranial facial organs, the biological system can still become a normal frog by finding novel movements to reach the target morphology [00:25:21]. This process is akin to reducing "distance error," similar to reconstruction losses used in training image encoders or 3D generative models in AI [00:25:35]. High-level errors (e.g., misclassifying a banana as a basset hound) can propagate down to the lowest levels of a neural network, subtly changing individual neurons [00:26:07].

In [[selfimprovement_in_ai_models | AI models]], individual neurons act as agents, receiving signals and deciding whether and how strongly to fire [00:15:19]. Collections of neurons form neural networks with their own agency, and multiple neural networks can operate together to solve problems, such as multiple language models collaborating in a [[structured_chain_of_thought_in_ai_models | structured chain of thought]] [00:15:52]. This indicates that there is no inherent limit to creating higher levels of agency by bundling lower-level agents [00:16:16].

## The Cognitive Light Cone and Perceptual Field

A key concept is the "cognitive light cone," which defines the limited amount of space and time an individual agent can perceive and interact with [00:32:31]. This is an extension of the physics concept of a "light cone," which delineates the causal influences based on the speed of light [00:30:14].

When individual agents form a collective, their [[collective_intelligence_in_biology_and_ai | collective intelligence]] expands their perceptual field and cognitive light cone [00:28:53]. This allows collectives to survey larger spatial areas and incorporate information from a broader spatio-temporal horizon, enabling greater computational capacity and actuation [00:29:49]. For example, the receptive field in convolutional neural networks acts similarly, where different feature levels have varying perceptual fields of the input image [00:32:02].

Evolution, driven by competition and survival, facilitates the increase of complexity [00:14:42]. To better survive and perform actions in an environment, entities need to be aware of and act upon a greater part of that environment [00:33:31]. This pressure drives the formation of collectives with larger cognitive light cones, which in turn enhances their survival chances [00:33:47].

## Implications for Consciousness and Agency

The paper challenges the notion that intelligence and consciousness are exclusive to "brainy animals" [00:44:00]. Levin argues that if humans, as collections of chemistry and neurons, possess consciousness, then neural networks—as collections of "little tiny things" making a [[collective_intelligence_in_biology_and_ai | collective intelligence]]—should also be considered to have some form of consciousness [00:45:00].

> "Thus there is simply no special human category which one can correctly anthropomorphize as somehow being beyond the laws of physics at its base claims of intelligence and other cognitive terms like all others must be based on rigorous experiment." [00:45:27]

Consciousness and agency are not unique human properties but emergent phenomena that can be found at every level of the hierarchy, from individual cells to communities and even the universe [00:46:06]. This perspective suggests that a group of cells (an organoid) can be conscious in some way, just as a community or tribe of humans can exhibit intelligence and consciousness [00:46:12].

## Analogies in Dysfunction: Cancer and Social Isolation

Levin draws a parallel between cancer and individual cells becoming isolated from the information structure of their tissue, reverting to a more ancient, individualistic behavior focused solely on survival and growth [00:48:18]. This is analogous to individual humans becoming isolated from their community or nation-state, reverting to more primal behaviors [00:49:08]. Just as a tumor might act as its own [[collective_intelligence_in_biology_and_ai | collective intelligence]], individual humans can also prioritize self-interest over the collective [00:49:33].

However, the collective often exerts influence to "shut down" such deviations, forcing individuals to conform for the greater good of the "hive mind" [01:03:56]. This pressure is seen in human societies where individuals are expected to contribute to the community's purpose [01:04:26].

## Emergent Intelligence and Biological Mechanisms

The intelligence of a collective system is not simply hardcoded at the lowest level, such as DNA in biology [00:57:03]. Rather, it emerges from the substrate itself. For instance, in biology, collective behavior is governed by bioelectricity, where electrical potentials direct cells' paths in morphological space [00:57:34].

The "hive knows things that the ant does not" [01:04:05]. Similarly, if multiple language models operate as a collective, a new level of emergent intelligence arises [00:58:10]. This aligns with the "connectivist" idea that deeply networked individual units, though simple on their own, can collectively create something "more than the sum of their parts" [00:58:22].

An example of emergent intelligence in simple biological systems is seen in bacterial communities, which use electrical signaling to coordinate and adjust individual physiologies for optimal collective behavior [01:09:46]. Similarly, experiments with mycelium (fungal networks) show their ability to form complex connections resembling the Tokyo rail system when seeking food, demonstrating that the [[collective_intelligence_in_biology_and_ai | collective intelligence]] of simple biological units can converge on solutions similar to those developed by humans [01:10:48].

## Future Implications for AI

The paper suggests that both biology and AI are subfields of a greater discipline focused on [[collective_intelligence_in_biology_and_ai | collective intelligences]] and the creation of hierarchies of competence and knowledge [01:34:49]. As AI models become increasingly complex, with [[foundation_models_in_ai | foundation models]] composed of stacked transformers, and ensembles of language models acting as agents within larger AI systems, this pattern of forming higher-level [[collective_intelligence_in_biology_and_ai | collective intelligences]] will continue [01:15:42].

This continuous layering of agents and emergent intelligence points towards concepts like the [[philosophical_aspects_of_ai_and_reality | Singularity]] or a "teological attractor" at the end of time, as described by Terrence McKenna [00:40:32]. The accelerating speed of human innovation, especially with the internet and AI, is increasing the size of humanity's [[collective_intelligence_in_biology_and_ai | collective light cone]], propelling it towards a point of infinite complexity where the entire universe might become connected into a larger [[collective_intelligence_in_biology_and_ai | collective intelligence]] [01:28:10].

The current advancements in AI, such as language models demonstrating "general intelligence" across diverse tasks, fulfill the definition of [[collective_intelligence_in_biology_and_ai | AGI]] for some [01:18:18]. The next step involves wrapping these models in control loops (sense, plan, act) to create agents [01:19:19]. Ultimately, [[implications_of_ai_model_scaling_and_convergence | Artificial Super Intelligence (ASI)]] could manifest as a complex [[convergence_of_ai_models_across_modalities | collective intelligence]] [01:19:54], with humans themselves being a [[collective_intelligence_in_biology_and_ai | collective intelligence]] of firing neurons creating an "illusion of agency and consciousness" [01:20:10]. This interdisciplinary understanding of intelligence across scales offers profound implications for bioengineering and the future development of AI systems [01:13:50].