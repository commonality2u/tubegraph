---
title: Residual Vector Quantization
videoId: SodPUNBFeMY
---

From: [[hu-po]] <br/> 

[[quantization_and_optimization_in_machine_learning | Quantization]] is a process of reducing the precision of data to fit into a smaller space <a class="yt-timestamp" data-t="00:30:58">[00:30:58]</a>. This approximation is often used when representing a pure, continuous signal, such as an audio waveform, would be impossible or computationally expensive <a class="yt-timestamp" data-t="00:31:23">[00:31:23]</a>, <a class="yt-timestamp" data-t="00:31:25">[00:31:25]</a>, <a class="yt-timestamp" data-t="00:31:27">[00:31:27]</a>.

## How it Works
[[residual_vector_quantization | Residual Vector Quantization]] (RVQ) is a technique that involves quantizing a signal and then iteratively quantizing the *residual* (the difference or error) between the quantized signal and the original <a class="yt-timestamp" data-t="00:26:12">[00:26:12]</a>, <a class="yt-timestamp" data-t="00:26:18">[00:26:18]</a>, <a class="yt-timestamp" data-t="00:26:20">[00:26:20]</a>, <a class="yt-timestamp" data-t="00:31:47">[00:31:47]</a>, <a class="yt-timestamp" data-t="00:31:50">[00:31:50]</a>. This creates increasingly higher resolution quantizations, but the most significant information is typically captured in the first [[quantization_for_large_language_models | quantization]] level <a class="yt-timestamp" data-t="00:26:37">[00:26:37]</a>, <a class="yt-timestamp" data-t="00:26:40">[00:26:40]</a>, <a class="yt-timestamp" data-t="00:26:45">[00:26:45]</a>, <a class="yt-timestamp" data-t="00:36:43">[00:36:43]</a>, <a class="yt-timestamp" data-t="00:36:45">[00:36:45]</a>, <a class="yt-timestamp" data-t="02:13:16">[02:13:16]</a>, <a class="yt-timestamp" data-t="02:23:56">[02:23:56]</a>.

In the context of audio, RVQ allows for taking a high-resolution audio waveform and transforming it into multiple sequences of discrete tokens (a "code book") <a class="yt-timestamp" data-t="00:27:03">[00:27:03]</a>, <a class="yt-timestamp" data-t="00:27:06">[00:27:06]</a>, <a class="yt-timestamp" data-t="00:27:08">[00:27:08]</a>, <a class="yt-timestamp" data-t="00:27:11">[00:27:11]</a>, <a class="yt-timestamp" data-t="00:35:36">[00:35:36]</a>, <a class="yt-timestamp" data-t="00:35:39">[00:35:39]</a>. These tokens are then used by models like [[quantization_in_large_language_models | Transformers]] for efficient processing <a class="yt-timestamp" data-t="00:35:51">[00:35:51]</a>, <a class="yt-timestamp" data-t="00:35:53">[00:35:53]</a>.

### Code Books
RVQ results in *K* parallel discrete token sequences, one for each code book <a class="yt-timestamp" data-t="00:35:08">[00:35:08]</a>, <a class="yt-timestamp" data-t="00:35:12">[00:35:12]</a>.
*   **Code Book:** A discrete set of vectors or embeddings that can be passed between an encoder and decoder, representing a limited set of discrete tokens <a class="yt-timestamp" data-t="00:17:23">[00:17:23]</a>, <a class="yt-timestamp" data-t="00:17:25">[00:17:25]</a>, <a class="yt-timestamp" data-t="00:17:28">[00:17:28]</a>, <a class="yt-timestamp" data-t="00:18:06">[00:18:06]</a>, <a class="yt-timestamp" data-t="00:18:09">[00:18:09]</a>, <a class="yt-timestamp" data-t="00:18:13">[00:18:13]</a>, <a class="yt-timestamp" data-t="00:18:15">[00:18:15]</a>. The "size" of a code book refers to the number of possible values it contains <a class="yt-timestamp" data-t="00:34:44">[00:34:44]</a>, <a class="yt-timestamp" data-t="00:34:56">[00:34:56]</a>.
*   **Quantization Levels:** Each quantizer in RVQ encodes the residual error from the previous [[quantization_techniques_for_transformers | quantization]] step, leading to multiple levels of refinement <a class="yt-timestamp" data-t="00:26:12">[00:26:12]</a>, <a class="yt-timestamp" data-t="00:26:16">[00:26:16]</a>, <a class="yt-timestamp" data-t="00:26:20">[00:26:20]</a>, <a class="yt-timestamp" data-t="00:36:01">[00:36:01]</a>, <a class="yt-timestamp" data-t="00:36:02">[00:36:02]</a>.
*   **Dependencies:** Quantized values from different code books are generally not independent because each subsequent level quantizes the residual of the previous one <a class="yt-timestamp" data-t="00:26:12">[00:26:12]</a>, <a class="yt-timestamp" data-t="00:26:16">[00:26:16]</a>, <a class="yt-timestamp" data-t="00:26:20">[00:26:20]</a>, <a class="yt-timestamp" data-t="00:32:00">[00:32:00]</a>, <a class="yt-timestamp" data-t="00:32:01">[00:32:01]</a>, <a class="yt-timestamp" data-t="00:36:32">[00:36:32]</a>, <a class="yt-timestamp" data-t="00:52:03">[00:52:03]</a>, <a class="yt-timestamp" data-t="00:52:05">[00:52:05]</a>, <a class="yt-timestamp" data-t="00:52:07">[00:52:07]</a>, <a class="yt-timestamp" data-t="00:52:19">[00:52:19]</a>, <a class="yt-timestamp" data-t="00:52:21">[00:52:21]</a>, <a class="yt-timestamp" data-t="00:52:25">[00:52:25]</a>. This dependency can affect how models process these tokens, as errors can compound if not handled carefully <a class="yt-timestamp" data-t="00:52:34">[00:52:34]</a>, <a class="yt-timestamp" data-t="00:52:36">[00:52:36]</a>.

## Applications
RVQ is commonly used in audio generation models like EnCodec and SoundStorm.
*   **EnCodec Audio Tokenizer:** This convolutional autoencoder uses RVQ to quantize its latent space <a class="yt-timestamp" data-t="02:50:54">[02:50:54]</a>, <a class="yt-timestamp" data-t="00:29:46">[00:29:46]</a>, <a class="yt-timestamp" data-t="00:29:50">[00:29:50]</a>, <a class="yt-timestamp" data-t="00:29:54">[00:29:54]</a>. It converts raw audio (e.g., 32 kHz samples) into a sequence of discrete tokens at a much lower frame rate (e.g., 50 Hz), making audio modeling more tractable for [[Quantization for large language models | Transformers]] <a class="yt-timestamp" data-t="00:33:55">[00:33:55]</a>, <a class="yt-timestamp" data-t="00:33:57">[00:33:57]</a>, <a class="yt-timestamp" data-t="00:34:01">[00:34:01]</a>, <a class="yt-timestamp" data-t="00:34:07">[00:34:07]</a>, <a class="yt-timestamp" data-t="00:35:27">[00:35:27]</a>, <a class="yt-timestamp" data-t="00:35:30">[00:35:30]</a>, <a class="yt-timestamp" data-t="00:35:33">[00:35:33]</a>, <a class="yt-timestamp" data-t="02:21:56">[02:21:56]</a>, <a class="yt-timestamp" data-t="02:22:01">[02:22:01]</a>, <a class="yt-timestamp" data-t="02:22:02">[02:22:02]</a>.
*   **Music Generation:** Models like MusicGen use RVQ with multiple code books to represent music <a class="yt-timestamp" data-t="00:25:25">[00:25:25]</a>, <a class="yt-timestamp" data-t="00:25:27">[00:25:27]</a>, <a class="yt-timestamp" data-t="00:25:28">[00:25:28]</a>, <a class="yt-timestamp" data-t="00:25:30">[00:25:30]</a>, <a class="yt-timestamp" data-t="00:33:43">[00:33:43]</a>. The generation process then operates in this tokenized space <a class="yt-timestamp" data-t="00:23:18">[00:23:18]</a>, <a class="yt-timestamp" data-t="00:23:23">[00:23:23]</a>, <a class="yt-timestamp" data-t="00:23:25">[00:23:25]</a>, <a class="yt-timestamp" data-t="02:21:11">[02:21:11]</a>, <a class="yt-timestamp" data-t="02:21:15">[02:21:15]</a>.
*   **Speech Generation:** Similarly, RVQ is utilized in speech generation models <a class="yt-timestamp" data-t="00:11:10">[00:11:10]</a>.

## Optimizing RVQ for Transformers
The inherent dependencies between different quantization levels in RVQ pose a challenge for efficient [[Advancements in model efficiency through quantization | Transformer]] processing <a class="yt-timestamp" data-t="00:53:15">[00:53:15]</a>. If each level is predicted sequentially, it increases computational cost <a class="yt-timestamp" data-t="00:46:22">[00:46:22]</a>, <a class="yt-timestamp" data-t="00:46:26">[00:46:26]</a>. Various strategies are explored to balance quality and performance:

*   **Flattening:** This approach concatenates all code books into one giant vector, simplifying the prediction to a single step <a class="yt-timestamp" data-t="00:49:50">[00:49:50]</a>, <a class="yt-timestamp" data-t="00:50:06">[00:50:06]</a>, <a class="yt-timestamp" data-t="00:50:08">[00:50:08]</a>, <a class="yt-timestamp" data-t="00:50:10">[00:50:10]</a>, <a class="yt-timestamp" data-t="02:00:07">[02:00:07]</a>, <a class="yt-timestamp" data-t="02:00:08">[02:00:08]</a>, <a class="yt-timestamp" data-t="02:04:03">[02:04:03]</a>, <a class="yt-timestamp" data-t="02:04:05">[02:04:05]</a>, <a class="yt-timestamp" data-t="02:04:07">[02:04:07]</a>. While it can improve generation quality, it comes at a high computational cost due to the increased number of autoregressive steps <a class="yt-timestamp" data-t="00:46:06">[00:46:06]</a>, <a class="yt-timestamp" data-t="00:47:41">[00:47:41]</a>, <a class="yt-timestamp" data-t="02:00:40">[02:00:40]</a>, <a class="yt-timestamp" data-t="02:04:10">[02:04:10]</a>, <a class="yt-timestamp" data-t="02:04:11">[02:04:11]</a>, <a class="yt-timestamp" data-t="02:22:45">[02:22:45]</a>.
*   **Delayed/Interleaving Patterns:** These strategies introduce delays or offsets between the processing of different code books <a class="yt-timestamp" data-t="00:31:30">[00:31:30]</a>, <a class="yt-timestamp" data-t="00:32:01">[00:32:01]</a>, <a class="yt-timestamp" data-t="00:32:03">[00:32:03]</a>, <a class="yt-timestamp" data-t="00:33:05">[00:33:05]</a>, <a class="yt-timestamp" data-t="00:37:43">[00:37:43]</a>, <a class="yt-timestamp" data-t="00:52:21">[00:52:21]</a>, <a class="yt-timestamp" data-t="00:52:22">[00:52:22]</a>, <a class="yt-timestamp" data-t="00:52:25">[00:52:25]</a>, <a class="yt-timestamp" data-t="01:02:21">[01:02:21]</a>, <a class="yt-timestamp" data-t="01:03:13">[01:03:13]</a>, <a class="yt-timestamp" data-t="01:03:16">[01:03:16]</a>, <a class="yt-timestamp" data-t="02:00:00">[02:00:00]</a>, <a class="yt-timestamp" data-t="02:10:35">[02:10:35]</a>, <a class="yt-timestamp" data-t="02:13:03">[02:13:03]</a>, <a class="yt-timestamp" data-t="02:13:05">[02:13:05]</a>, <a class="yt-timestamp" data-t="02:13:39">[02:13:39]</a>, <a class="yt-timestamp" data-t="02:13:46">[02:13:46]</a>, <a class="yt-timestamp" data-t="02:13:49">[02:13:49]</a>, <a class="yt-timestamp" data-t="02:23:46">[02:23:46]</a>, <a class="yt-timestamp" data-t="02:23:48">[02:23:48]</a>. This allows for some parallel processing while still acknowledging the dependencies, leading to faster inference with comparable quality <a class="yt-timestamp" data-t="00:53:39">[00:53:39]</a>, <a class="yt-timestamp" data-t="00:53:42">[00:53:42]</a>, <a class="yt-timestamp" data-t="01:00:33">[01:00:33]</a>, <a class="yt-timestamp" data-t="01:03:59">[01:03:59]</a>, <a class="yt-timestamp" data-t="01:04:00">[01:04:00]</a>, <a class="yt-timestamp" data-t="02:00:29">[02:00:29]</a>, <a class="yt-timestamp" data-t="02:00:30">[02:00:30]</a>, <a class="yt-timestamp" data-t="02:04:11">[02:04:11]</a>, <a class="yt-timestamp" data-t="02:04:13">[02:04:13]</a>, <a class="yt-timestamp" data-t="02:10:37">[02:10:37]</a>, <a class="yt-timestamp" data-t="02:10:38">[02:10:38]</a>, <a class="yt-timestamp" data-t="02:23:51">[02:23:51]</a>, <a class="yt-timestamp" data-t="02:24:14">[02:24:14]</a>, <a class="yt-timestamp" data-t="02:26:26">[02:26:26]</a>.
*   **Partial Delay:** Delays specific code books (e.g., 2, 3, and 4) while potentially processing the most important one (code book 1) first <a class="yt-timestamp" data-t="02:02:29">[02:02:29]</a>, <a class="yt-timestamp" data-t="02:02:31">[02:02:31]</a>, <a class="yt-timestamp" data-t="02:02:32">[02:02:32]</a>, <a class="yt-timestamp" data-t="02:02:52">[02:02:52]</a>, <a class="yt-timestamp" data-t="02:02:54">[02:02:54]</a>, <a class="yt-timestamp" data-t="02:02:56">[02:02:56]</a>, <a class="yt-timestamp" data-t="02:13:46">[02:13:46]</a>, <a class="yt-timestamp" data-t="02:13:49">[02:13:49]</a>.
*   **Valley Pattern:** Predicts the first code book for all time steps sequentially, then predicts the remaining code books (e.g., 2, 3, and 4) in parallel <a class="yt-timestamp" data-t="00:52:54">[00:52:54]</a>, <a class="yt-timestamp" data-t="00:52:57">[00:52:57]</a>, <a class="yt-timestamp" data-t="00:53:00">[00:53:00]</a>, <a class="yt-timestamp" data-t="00:53:01">[00:53:01]</a>, <a class="yt-timestamp" data-t="00:53:03">[00:53:03]</a>, <a class="yt-timestamp" data-t="02:03:39">[02:03:39]</a>, <a class="yt-timestamp" data-t="02:03:41">[02:03:41]</a>, <a class="yt-timestamp" data-t="02:03:42">[02:03:42]</a>. This pattern has twice the number of steps as a purely parallel approach <a class="yt-timestamp" data-t="02:03:54">[02:03:54]</a>, <a class="yt-timestamp" data-t="02:03:55">[02:03:55]</a>.
*   **Partial Flattening:** Similar to the valley pattern but interleaves the first code book with the parallel sampling of the others <a class="yt-timestamp" data-t="02:03:57">[02:03:57]</a>, <a class="yt-timestamp" data-t="02:03:58">[02:03:58]</a>, <a class="yt-timestamp" data-t="02:04:00">[02:04:00]</a>, <a class="yt-timestamp" data-t="02:04:01">[02:04:01]</a>. This also results in double the number of interleaved sequence steps <a class="yt-timestamp" data-t="02:14:21">[02:14:21]</a>, <a class="yt-timestamp" data-t="02:14:23">[02:14:23]</a>, <a class="yt-timestamp" data-t="02:14:25">[02:14:25]</a>, <a class="yt-timestamp" data-t="02:14:27">[02:14:27]</a>.

The choice of these patterns reflects a trade-off between the exactness of the distribution modeling and computational efficiency <a class="yt-timestamp" data-t="00:52:39">[00:52:39]</a>, <a class="yt-timestamp" data-t="00:52:41">[00:52:41]</a>, <a class="yt-timestamp" data-t="00:52:42">[00:52:42]</a>, <a class="yt-timestamp" data-t="00:53:15">[00:53:15]</a>, <a class="yt-timestamp" data-t="00:53:17">[00:53:17]</a>, <a class="yt-timestamp" data-t="00:53:20">[00:53:20]</a>, <a class="yt-timestamp" data-t="00:53:23">[00:53:23]</a>, <a class="yt-timestamp" data-t="00:53:24">[00:53:24]</a>, <a class="yt-timestamp" data-t="02:24:15">[02:24:15]</a>, <a class="yt-timestamp" data-t="02:24:16">[02:24:16]</a>. While flattening can achieve the best scores, the delay and partial flattening patterns offer similar performance at a fraction of the computational cost <a class="yt-timestamp" data-t="01:59:56">[01:59:56]</a>, <a class="yt-timestamp" data-t="01:59:58">[01:59:58]</a>, <a class="yt-timestamp" data-t="02:00:00">[02:00:00]</a>, <a class="yt-timestamp" data-t="02:04:10">[02:04:10]</a>, <a class="yt-timestamp" data-t="02:04:11">[02:04:11]</a>, <a class="yt-timestamp" data-t="02:04:13">[02:04:13]</a>, <a class="yt-timestamp" data-t="02:04:14">[02:04:14]</a>, <a class="yt-timestamp" data-t="02:24:23">[02:24:23]</a>, <a class="yt-timestamp" data-t="02:24:26">[02:24:26]</a>.