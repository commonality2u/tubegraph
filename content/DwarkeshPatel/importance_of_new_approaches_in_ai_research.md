---
title: Importance of new approaches in AI research
videoId: UakqL6Pj9xo
---

From: [[DwarkeshPatel]] <br/> 
The discussion between François Chollet, an AI researcher and creator of Keras, along with Mike Knoop, co-founder of Zapier, highlights the critical need for innovation and the exploration of new methodologies in AI research. In the context of large language models (LLMs) and their limitations, Chollet emphasizes the necessity to develop novel techniques beyond current models to push the boundaries of artificial intelligence.

## The Limitations of Current AI Models

One of the pressing issues in AI research is the over-reliance on existing models, particularly LLMs, which biases the research community towards familiar solutions rather than seeking truly novel ideas. Chollet points out that current LLMs essentially operate as vast interpolative memories, incapable of genuine program synthesis or adaption to unseen situations:

> "The way LLMs work is that they’re basically this big interpolative memory... by contrast, ARC does not require a lot of knowledge at all. It’s designed to only require what’s known as core knowledge" <a class="yt-timestamp" data-t="00:01:18">[00:01:18]</a>.

The widespread adoption of these models has led to a stifling effect on research diversity and innovation [[limitations_of_large_language_models_in_solving_novel_tasks | limitations of large language models in solving novel tasks]]:

> "Now LLMs have essentially sucked the oxygen out of the room, like everyone is doing LLMs" <a class="yt-timestamp" data-t="00:00:38">[00:00:38]</a>.

## The ARC Benchmark as a Catalyst for Innovation

Chollet's introduction of the ARC (Abstraction and Reasoning Corpus) benchmark serves as a significant motivation for researchers to diverge from traditional methods. The benchmark is specifically designed to resist memorization, pushing for the development of systems capable of genuine reasoning and adaptation [[understanding_arc_benchmarks_and_its_significance | understanding ARC benchmarks and its significance]]:

> "ARC requires you to try new ideas. That's very much the point... existing technology has reached a plateau" <a class="yt-timestamp" data-t="01:04:31">[01:04:31]</a>.

This benchmark is intended not only to measure progress towards AGI but also to inspire researchers to explore uncharted territories in AI development [[challenges_in_achieving_artificial_general_intelligence | challenges in achieving artificial general intelligence]]:

> "If there's an easy way to hack the benchmark, that reveals that the benchmark is flawed" <a class="yt-timestamp" data-t="01:25:06">[01:25:06]</a>.

## The Threat of Homogenized Research Paths

Knoop and Chollet express concerns about the trend of closed frontier research, which limits the flow of innovation. This trend, they argue, was exacerbated by companies like OpenAI, that have moved away from open research publication [[opensource_versus_closedsource_ai_models | open-source versus closed-source AI models]]:

> "OpenAI basically set back progress towards AGI by quite a few years... by causing this complete closing down of frontier research publishing" <a class="yt-timestamp" data-t="01:07:14">[01:07:14]</a>.

This situation calls for a return to a more open and experimental approach that previously characterized the AI field [[technological_and_social_innovation | technological and social innovation]]:

> "The internet and open source has shown that it's the most powerful innovation ecosystem that's ever existed" <a class="yt-timestamp" data-t="01:07:43">[01:07:43]</a>.

## The Need for Diverse Research Approaches

The dialogue underscores the necessity for incorporating varied methodologies, including discrete program synthesis and hybrid systems that combine multiple types of reasoning [[comparison_between_human_intelligence_and_ai_learning_techniques | comparison between human intelligence and AI learning techniques]]:

> "The way forward is to create a hybrid system... mostly System 2. You're going to fix the fundamental limitation of discrete program search, which is combinatorial explosion, with deep learning" <a class="yt-timestamp" data-t="01:29:43">[01:29:43]</a>.

By merging System 1 and System 2 thinking, as described by Chollet, AI can potentially overcome its current limitations and address more complex, novel tasks [[the_future_of_ai_research_and_potential_societal_impacts | the future of AI research and potential societal impacts]]:

> "Humans are never doing pure System 1 or pure System 2. They're always mixing and matching both" <a class="yt-timestamp" data-t="01:28:18">[01:28:18]</a>.

## Conclusion

The evolution of AI technology relies heavily on the willingness of the research community to explore novel approaches and challenge the current paradigms. The drive towards AGI demands systems that can not only leverage existing knowledge but also reason and adapt in unfamiliar scenarios. Encouraging a diverse range of research methodologies is essential for true innovation in the field of AI [[challenges_and_considerations_for_achieving_agi | challenges and considerations for achieving AGI]].

> [!info] The ARC Prize
>
> A $1 million prize has been announced for breakthroughs on the ARC benchmark. It aims to attract diverse talent and encourage novel solutions, helping further the path towards AGI by rewarding innovative research <a class="yt-timestamp" data-t="01:09:09">[01:09:09]</a>.