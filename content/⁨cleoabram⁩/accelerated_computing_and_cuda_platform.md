---
title: Accelerated computing and CUDA platform
videoId: 7ARBJQn6QkM
---

From: [[⁨cleoabram⁩]] <br/> 

NVIDIA, led by CEO Jensen Huang, has significantly influenced modern computing and the future of technology by pioneering [[Impact of GPUs on computing and AI | accelerated computing]] with the [[evolution_of_nvidia_technology | Graphics Processing Unit (GPU)]] and its [[evolution_of_nvidia_technology | CUDA]] platform <a class="yt-timestamp" data-t="00:00:28">[00:00:28]</a>. The company's work has driven a fundamental shift in how computers operate, leading to an "explosion of what's possible with technology" <a class="yt-timestamp" data-t="00:00:41">[00:00:41]</a>. NVIDIA's innovations underpin much of today's futuristic technology, including AI, robotics, gaming, self-driving cars, and breakthrough medical research <a class="yt-timestamp" data-t="00:00:56">[00:00:56]</a>.

## The Dawn of Parallel Processing

In the early 1990s, when NVIDIA was founded, a critical observation about software programs was made: approximately 10% of code performed 99% of the processing, and this intensive processing could be done in parallel <a class="yt-timestamp" data-t="00:04:20">[00:04:20]</a>. The remaining 90% of the code, however, required sequential processing <a class="yt-timestamp" data-t="00:04:33">[00:04:33]</a>. This insight led to the belief that the ideal computer should handle both sequential and parallel processing effectively, rather than just one <a class="yt-timestamp" data-t="00:04:40">[00:04:40]</a>.

### CPU vs. GPU: Sequential vs. Parallel

Traditional Central Processing Units (CPUs) excel at sequential processing, tackling problems one at a time <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>. In contrast, GPUs were designed to perform many smaller problems simultaneously through parallel processing <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>.

NVIDIA initially focused on video games because they required significant parallel processing for 3D graphics <a class="yt-timestamp" data-t="00:05:41">[00:05:41]</a>. This market allowed NVIDIA to invest heavily in research and development, creating a "flywheel" between technology and market growth that propelled the company forward <a class="yt-timestamp" data-t="00:06:04">[00:06:04]</a>.

Jensen Huang describes the GPU as a "time machine" because it accelerates work, allowing people to achieve their life's work within their lifetime <a class="yt-timestamp" data-t="00:06:31">[00:06:31]</a>. This acceleration applies to various fields, such as quantum chemistry research, weather prediction, and self-driving car simulations <a class="yt-timestamp" data-t="00:06:37">[00:06:37]</a>.

## The [[evolution_of_nvidia_technology | CUDA]] Platform: Democratizing Parallel Computing

While GPUs initially revolutionized gaming, researchers discovered that NVIDIA's GPUs could be "tricked" into solving general-purpose problems, not just graphics issues <a class="yt-timestamp" data-t="00:08:14">[00:08:14]</a>. This led NVIDIA to create [[evolution_of_nvidia_technology | CUDA]] (Compute Unified Device Architecture) in the mid-2000s <a class="yt-timestamp" data-t="00:08:29">[00:08:29]</a>. [[evolution_of_nvidia_technology | CUDA]] is a platform that allows programmers to instruct GPUs using familiar languages like C, making parallel computing power accessible to a much wider audience <a class="yt-timestamp" data-t="00:08:34">[00:08:34]</a>.

The vision behind [[evolution_of_nvidia_technology | CUDA]] was multi-faceted, stemming from researchers' innovative uses of GPUs for tasks like medical imaging (e.g., CT reconstruction) <a class="yt-timestamp" data-t="00:09:13">[00:09:13]</a>, as well as internal needs to create more dynamic virtual worlds for games, requiring particle physics and fluid dynamics simulations <a class="yt-timestamp" data-t="00:09:41">[00:09:41]</a>. NVIDIA committed to [[evolution_of_nvidia_technology | CUDA]] because the large video game market ensured their GPU architecture would become the highest-volume parallel processor in the world, reaching many people <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>.

## The AI Revolution: Fueled by GPUs and [[evolution_of_nvidia_technology | CUDA]]

A pivotal moment occurred in 2012 when researchers Ilya Sutskever, Alex Krizhevsky, and Geoff Hinton used NVIDIA GPUs with [[evolution_of_nvidia_technology | CUDA]] to train AlexNet, a neural network that dramatically outperformed competitors in an image recognition challenge <a class="yt-timestamp" data-t="00:11:04">[00:11:04]</a>. This demonstrated that GPUs could be the "engines of a whole new way of computing," shifting from step-by-step instructions to training computers with vast numbers of examples <a class="yt-timestamp" data-t="00:11:35">[00:11:35]</a>.

This breakthrough marked a "truly seismic shift" towards the current [[technological_advances_enabling_ai_capabilities | AI explosion]] <a class="yt-timestamp" data-t="00:11:51">[00:11:51]</a>. NVIDIA's leadership realized that if deep learning architectures could scale, they had the potential to solve a vast majority of machine learning problems and reshape the entire computer industry <a class="yt-timestamp" data-t="00:14:16">[00:14:16]</a>. This led them to re-engineer the entire computing stack, giving rise to systems like DGX <a class="yt-timestamp" data-t="00:14:42">[00:14:42]</a>.

### Core Beliefs and Long-Term Vision

NVIDIA's long-term commitment, despite a decade between the AlexNet breakthrough and widespread AI adoption <a class="yt-timestamp" data-t="00:16:30">[00:16:30]</a>, is rooted in fundamental beliefs:
*   **Accelerated Computing**: The continued belief that combining sequential and parallel processing offers the most effective computing <a class="yt-timestamp" data-t="00:19:50">[00:19:50]</a>.
*   **Scalability of Deep Learning**: Deep neural networks can learn increasingly nuanced features by becoming larger and processing more data, with no apparent physical, architectural, or mathematical limits found yet <a class="yt-timestamp" data-t="00:20:06">[00:20:06]</a>.
*   **Learning from Data**: AI's ability to learn from diverse data modalities (images, sound, text, amino acid sequences) and translate between them, opening up a universe of problem-solving opportunities <a class="yt-timestamp" data-t="00:21:05">[00:21:05]</a>.

NVIDIA invested "tens of billions of dollars" before the full impact of AI became widely apparent, driven by an unwavering belief in their future <a class="yt-timestamp" data-t="00:19:17">[00:19:17]</a>.

## Future Applications of Accelerated Computing

The next decade will focus on the "application science of AI," exploring how AI can be applied across various fields <a class="yt-timestamp" data-t="00:23:18">[00:23:18]</a>.

### Physical AI and Robotics
Everything that moves will someday be robotic <a class="yt-timestamp" data-t="00:30:22">[00:30:22]</a>. NVIDIA is building tools like **Omniverse** and **Cosmos** to train robotic systems in digital worlds <a class="yt-timestamp" data-t="00:25:11">[00:25:11]</a>. This allows robots to learn from massive repetitions and varied conditions without physical wear and tear <a class="yt-timestamp" data-t="00:24:56">[00:24:56]</a>.

*   **Cosmos**: A "world language model" that provides AI with "world common sense," encoding fundamental physical laws like gravity, friction, inertia, and object permanence <a class="yt-timestamp" data-t="00:28:16">[00:28:16]</a>.
*   **Omniverse**: A simulation platform grounded in Newtonian physics, used to condition Cosmos and generate an infinite number of physically plausible future scenarios for robots to learn from <a class="yt-timestamp" data-t="00:28:42">[00:28:42]</a>.

This combination enables robots to learn much faster and more comprehensively, leading to a future "surrounded by robots," including personal R2-D2-like companions in various forms <a class="yt-timestamp" data-t="00:31:11">[00:31:11]</a>.

### Digital Biology and Climate Science
NVIDIA is also making significant bets on [[potential_applications_of_quantum_computing | digital biology]], aiming to understand and predict the language of molecules, cells, and the human body to enable digital twins of humans <a class="yt-timestamp" data-t="00:45:28">[00:45:28]</a>. Similarly, in [[commercial_applications_and_future_of_nuclear_fusion | climate science]], they are working on high-resolution regional climate and weather predictions to help create the best possible future <a class="yt-timestamp" data-t="00:45:56">[00:45:56]</a>.

## Challenges and Limitations

Despite the immense potential, NVIDIA acknowledges challenges in the [[technological_advances_enabling_ai_capabilities | AI advancements and applications]]:
*   **AI Safety**: Addressing issues like bias, toxicity, hallucination (generating plausible but untruthful information), and impersonation <a class="yt-timestamp" data-t="00:32:24">[00:32:24]</a>. This requires deep engineering to ensure products function properly and don't harm people <a class="yt-timestamp" data-t="00:33:41">[00:33:41]</a>.
*   **Energy Efficiency**: The primary physical limit in computing is the energy required to transport and flip bits <a class="yt-timestamp" data-t="00:35:47">[00:35:47]</a>. NVIDIA's focus is on building more energy-efficient computers, having increased AI computing energy efficiency by 10,000 times since 2016 <a class="yt-timestamp" data-t="00:37:09">[00:37:09]</a>.

### Hardware Design Philosophy: General vs. Specific

NVIDIA prioritizes creating flexible architectures rather than highly specialized chips for specific AI models like transformers <a class="yt-timestamp" data-t="00:40:48">[00:40:48]</a>. This is based on the belief that innovation in algorithms and software will continue to evolve, requiring adaptable hardware that can support new ideas and inventions <a class="yt-timestamp" data-t="00:40:08">[00:40:08]</a>.

## Preparing for an AI-Powered Future

Huang advises everyone, especially students, to learn how to interact with AI models like ChatGPT, Gemini Pro, and Grok <a class="yt-timestamp" data-t="00:55:48">[00:55:48]</a>. This skill, akin to being good at asking questions, will be crucial for leveraging AI as a personal tutor, programmer, writer, or analyst <a class="yt-timestamp" data-t="00:56:10">[00:56:10]</a>. Just as past generations learned to use computers, the current generation must learn to use AI to enhance their jobs and lives <a class="yt-timestamp" data-t="00:57:02">[00:57:02]</a>. This will empower individuals, making them "superhumans" because they are augmented by "super AIs" <a class="yt-timestamp" data-t="00:52:16">[00:52:16]</a>.

NVIDIA's impact, spanning from gaming technology to the [[how_dalle_2_functions_and_its_technology | transformation of digital biology]], [[advancements_and_applications_from_cern_research | material sciences]], robotics, and transportation, places it at the epicenter of many [[technological_advancements_and_future_potential | future technological advancements]] <a class="yt-timestamp" data-t="01:01:59">[01:01:59]</a>.