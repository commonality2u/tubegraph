---
title: Open source in AI development and safety
videoId: oX7OduG1YmI
---

From: [[⁨cleoabram⁩]] <br/> 

Open source in the context of [[advantages_and_risks_of_ai_technology | AI]] development means that people can take and modify a model and build applications on top of it [00:41:05]. This approach contrasts with closed and centralized models developed by companies like OpenAI or Google, which aim to be the singular [[advantages_and_risks_of_ai_technology | AI]] for all interactions [00:39:52].

## A Vision for Diverse AI Systems
Meta CEO Mark Zuckerberg believes that the future will see a multitude of different [[advantages_and_risks_of_ai_technology | AI]] systems, akin to the current diversity of apps and websites [00:40:11]. He envisions a future where every business will have its own [[advantages_and_risks_of_ai_technology | AI]] to interact with customers for sales or support [00:40:22], and many creators will also have their personalized AIs [00:40:34]. This model promotes a richer world with a diversity of different systems [00:41:00], empowering people to build their own [[advantages_and_risks_of_ai_technology | AI]] solutions [00:41:05].

## The Safety Debate in AI
The debate surrounding open source [[advantages_and_risks_of_ai_technology | AI]] often centers on safety.
<a class="yt-timestamp" data-t="00:41:26">[00:41:26]</a> In a world where [[advantages_and_risks_of_ai_technology | AI]] continues to get smarter, the key question is how to ensure a positive future and mitigate safety concerns.

### Argument for Closed Models
Some argue that keeping models closed and not distributing them to many developers would make them safer, preventing malicious actors from misusing the [[advantages_and_risks_of_ai_technology | AI]] [00:41:40].

### Argument for Open Source
Historically, the software industry has seen open source software become safer and more secure [00:42:05]. This is because when software is open source, more people can scrutinize all parts of the system [00:42:14]. Inevitable issues, such as bugs or security vulnerabilities, become apparent quicker and are subsequently fixed [00:42:41]. Developers then roll out new versions, similar to how Meta releases new Llama models (e.g., Llama 3, Llama 3.1, Llama 3.2) [00:42:52].

<a class="yt-timestamp" data-t="00:43:04">[00:43:04]</a> Zuckerberg posits that despite concerns about potential misuse, open source leads to a "smarter and safer model for everyone" [00:43:12], as feedback from widespread use helps to make the model safer [00:43:23]. The history of open source in software suggests it will lead to a more prosperous and safer future for [[ethical_considerations_in_robotics_and_ai | AI]] as well [00:43:33].

## Future Scaling of AI Models
A significant open question in the [[technological_advancements_and_global_competition_in_ai | AI]] field is how far the current transformer-based architectures can scale [00:44:17]. Unlike past [[advantages_and_risks_of_ai_technology | AI]] architectures that hit plateaus, these newer systems, developed over the last 5 to 10 years, "haven't found the end yet" [00:44:44].

<a class="yt-timestamp" data-t="00:44:44">[00:44:44]</a> This continuous scalability is a high-stakes question for companies like Meta, which are investing hundreds of billions of dollars in infrastructure to build out future [[advantages_and_risks_of_ai_technology | AI]] capabilities [00:45:42]. While it's possible that a limit will eventually be reached, there's also the possibility that [[technological_advancements_and_global_competition_in_ai | AI]] will continue advancing significantly for decades to come, leading to compelling new products and a dynamic technological landscape [00:46:26].