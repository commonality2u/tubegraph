---
title: Impact of AI on the music industry
videoId: Ey75Xw_ikqs
---

From: [[⁨cleoabram⁩]] <br/> 

[[machine_learning_and_its_impact_on_ai_development | AI]] is rapidly transforming the music industry, enabling new forms of creation and raising complex questions about authorship, compensation, and the future of human artistic expression <a class="yt-timestamp" data-t="00:00:29">[00:00:29]</a>. This shift is considered a significant turning point in music history <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>.

## What is AI Music?
[[machine_learning_and_its_impact_on_ai_development | AI]] music involves using [[machine_learning_and_its_impact_on_ai_development | AI]] to create new songs, generate lyrics, or produce melodies <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>. These creations can include:
*   **Voice Clones:** Replicating the voice of an artist to sing new material <a class="yt-timestamp" data-t="00:00:24">[00:00:24]</a>. Examples include Frank Sinatra singing "Get Low" or Johnny Cash singing "Barbie Girl," none of which were actually performed by the original artists <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a><a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a><a class="yt-timestamp" data-t="00:00:24">[00:00:24]</a>.
*   **Fake Collaborations:** Creating songs that sound like collaborations between artists who have not actually worked together <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>.
*   **Automated Generation:** Producing entire songs or melodies simply by typing in a few words <a class="yt-timestamp" data-t="00:00:43">[00:00:43]</a>.

## Bridging "The Gap" in Creativity
[[potential_risks_and_benefits_of_ai | AI]] offers a potential benefit by helping to shrink "the gap," which is the difference between an ideal musical idea in an artist's head and what they can realistically create with their existing tools and technical skills <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a><a class="yt-timestamp" data-t="00:02:43">[00:02:43]</a>. While creativity and technical skill are often confused, lowering the requirement for technical skill can lead to more great music being created <a class="yt-timestamp" data-t="00:02:58">[00:02:58]</a><a class="yt-timestamp" data-t="00:03:08">[00:03:08]</a>. Historically, creating compositions required being a musical genius like Mozart or Beethoven, who had to test ideas internally due to the high cost of gathering an orchestra <a class="yt-timestamp" data-t="00:03:12">[00:03:12]</a><a class="yt-timestamp" data-t="00:03:23">[00:03:23]</a>. Modern artists like Avicii used tools like computers as their main instrument <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a><a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a>.

## [[Role of AI in shaping social media and content creation | AI as a Tool for Artists]]
[[machine_learning_and_its_impact_on_ai_development | AI]] is emerging as a powerful new tool for artists <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a><a class="yt-timestamp" data-t="00:03:47">[00:03:47]</a>. Artists can use technologies like ChatGPT to generate lyrics or Google's MusicLM to create new melodies <a class="yt-timestamp" data-t="00:03:47">[00:03:47]</a><a class="yt-timestamp" data-t="00:03:50">[00:03:50]</a>. Songs made with [[machine_learning_and_its_impact_on_ai_development | AI]] may already be present on platforms like Spotify without listeners' knowledge <a class="yt-timestamp" data-t="00:03:55">[00:03:55]</a>.

However, musicians hold differing views on the appropriate use of [[machine_learning_and_its_impact_on_ai_development | AI]]:
*   Some artists express concern about [[machine_learning_and_its_impact_on_ai_development | AI]] writing lyrics or automatically generating music, believing it may not be beneficial for the human mind <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a><a class="yt-timestamp" data-t="00:04:07">[00:04:07]</a>.
*   Others, like Grimes, are early adopters, particularly of [[machine_learning_and_its_impact_on_ai_development | AI]] voice cloning <a class="yt-timestamp" data-t="00:04:11">[00:04:11]</a><a class="yt-timestamp" data-t="00:04:13">[00:04:13]</a><a class="yt-timestamp" data-t="00:04:17">[00:04:17]</a>. Grimes released a tool called Elf Tech, which allows anyone to change their voice into hers <a class="yt-timestamp" data-t="00:04:26">[00:04:26]</a><a class="yt-timestamp" data-t="00:04:30">[00:04:30]</a>. Users of her voice on Spotify appear as a "collaborator" under a verified artist profile, and Grimes plans to feature the best of these [[machine_learning_and_its_impact_on_ai_development | AI]]-generated songs on her own album, creating a "competitive [[machine_learning_and_its_impact_on_ai_development | AI]] album" to see which performs better <a class="yt-timestamp" data-t="00:04:54">[00:04:54]</a><a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a><a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a><a class="yt-timestamp" data-t="00:05:08">[00:05:08]</a>. While Grimes is enthusiastic, many other artists are opposed to their voices being used in this manner without consent <a class="yt-timestamp" data-t="00:05:15">[00:05:15]</a><a class="yt-timestamp" data-t="00:05:20">[00:05:20]</a>.

## [[Legal and copyright issues in AI music | Legal and Copyright Challenges]]
A major question facing the industry is when artists should get paid in a world with [[machine_learning_and_its_impact_on_ai_development | AI]] music <a class="yt-timestamp" data-t="00:03:30">[00:03:30]</a><a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>. The music industry already has rules based on distinguishing between "inspiration" and "copying" <a class="yt-timestamp" data-t="00:05:41">[00:05:41]</a><a class="yt-timestamp" data-t="00:05:52">[00:05:52]</a>.

Existing frameworks for payment include:
*   **Inspiration:** Most music falls into this category, where artists are inspired by others without direct copying or payment <a class="yt-timestamp" data-t="00:05:57">[00:05:57]</a>.
*   **Sampling:** Directly copying a portion of an original recording or composition requires payment to the copyright holders <a class="yt-timestamp" data-t="00:06:34">[00:06:34]</a><a class="yt-timestamp" data-t="00:06:37">[00:06:37]</a>. Doja Cat's "Paint The Town Red" samples Dionne Warwick's "Walk On By" <a class="yt-timestamp" data-t="00:06:17">[00:06:17]</a>.
*   **Interpolation:** Re-recording a line or melody from someone else's song requires payment to the original composer, but not for the original recording <a class="yt-timestamp" data-t="00:06:41">[00:06:41]</a><a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>. Ariana Grande's "7 Rings" interpolates "My Favorite Things" from *The Sound of Music* <a class="yt-timestamp" data-t="00:06:46">[00:06:46]</a>.
*   **Covering:** Re-recording an entire song requires paying the owner of the original composition <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a><a class="yt-timestamp" data-t="00:07:15">[00:07:15]</a>.
*   **Grimes's Model:** People using Grimes's voice via Elf Tech are creating new songs and recordings, but because they use her voice and likeness, they agree to pay her <a class="yt-timestamp" data-t="00:07:19">[00:07:19]</a><a class="yt-timestamp" data-t="00:07:25">[00:07:25]</a>.

Regardless of whether [[machine_learning_and_its_impact_on_ai_development | AI]] is used, if a track utilizes existing copyrighted material through sampling, interpolation, or covering, the original owner must be paid <a class="yt-timestamp" data-t="00:07:29">[00:07:29]</a><a class="yt-timestamp" data-t="00:07:34">[00:07:34]</a>.

### Copyright System
Copyright law protects two distinct elements: the original song recording (the master) and the composition of the original song itself <a class="yt-timestamp" data-t="00:07:46">[00:07:46]</a><a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a>. This system is complex and often resolved through lawsuits <a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a><a class="yt-timestamp" data-t="00:07:57">[00:07:57]</a>.

Notable lawsuits include:
*   **"Blurred Lines" (2015):** Pharrell Williams and Robin Thicke were ordered to pay $5 million for copying the composition of Marvin Gaye's "Got to Give It Up" <a class="yt-timestamp" data-t="00:07:57">[00:07:57]</a><a class="yt-timestamp" data-t="00:08:02">[00:08:02]</a>.
*   **Ed Sheeran's "Thinking Out Loud":** Sheeran won a lawsuit claiming his chord progression copied "Let's Get It On" <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a><a class="yt-timestamp" data-t="00:08:15">[00:08:15]</a>.
*   **Olivia Rodrigo:** Retroactively gave Taylor Swift songwriting credits and royalties due to accusations of her songs being too similar <a class="yt-timestamp" data-t="00:08:22">[00:08:22]</a><a class="yt-timestamp" data-t="00:08:25">[00:08:25]</a>.

### The "Vibe" and [[the_ethical_and_economic_implications_of_aigenerated_art | AI Training Data]] Debate
The major specific question for [[machine_learning_and_its_impact_on_ai_development | AI]] is whether artists should be paid if an [[machine_learning_and_its_impact_on_ai_development | AI]] trains on their music <a class="yt-timestamp" data-t="00:09:16">[00:09:16]</a><a class="yt-timestamp" data-t="00:09:21">[00:09:21]</a>.
*   [[machine_learning_and_its_impact_on_ai_development | AI]] tools require thousands of songs for training data <a class="yt-timestamp" data-t="00:09:27">[00:09:27]</a>. These companies are not always transparent about the data used <a class="yt-timestamp" data-t="00:09:32">[00:09:32]</a>.
*   [[machine_learning_and_its_impact_on_ai_development | AI]] tools do not sample, interpolate, or cover in the traditional sense; instead, they analyze patterns and create entirely new works <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a><a class="yt-timestamp" data-t="00:09:47">[00:09:47]</a>.
*   Currently, the industry decides compensation based on the **output** (how the finished product sounds), not the **input** (what music was used for inspiration or training) <a class="yt-timestamp" data-t="00:09:52">[00:09:52]</a><a class="yt-timestamp" data-t="00:09:57">[00:09:57]</a>. This means artists are paid if the end result is similar enough, regardless of whether their music was directly used to make it <a class="yt-timestamp" data-t="00:10:03">[00:10:03]</a>.
*   Changing this would require paying artists for "inspiration," a concept not currently part of the compensation model <a class="yt-timestamp" data-t="00:10:13">[00:10:13]</a>.

The CEO of Spotify, Daniel Ek, states that Spotify receives audio files and wouldn't know what tools were used to create them <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a><a class="yt-timestamp" data-t="00:10:33">[00:10:33]</a>. He emphasizes that the output of [[machine_learning_and_its_impact_on_ai_development | AI]] training is most important, prioritizing new IP that does not "draft off someone else's name and likeness" <a class="yt-timestamp" data-t="00:10:50">[00:10:50]</a><a class="yt-timestamp" data-t="00:10:57">[00:10:57]</a>.

## [[The future advancements in AI beyond art generation | Autonomous AI Agents]] and the Future
If [[machine_learning_and_its_impact_on_ai_development | AI]] begins to make music more autonomously, it moves beyond being just a tool for artists and becomes more akin to an artist itself <a class="yt-timestamp" data-t="00:11:05">[00:11:05]</a><a class="yt-timestamp" data-t="00:11:09">[00:11:09]</a>. This raises existential questions about ownership and creation <a class="yt-timestamp" data-t="00:11:36">[00:11:36]</a>.
*   **Scalability:** Autonomous [[machine_learning_and_its_impact_on_ai_development | AI]] agents could generate millions or even billions of songs, testing what works <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a><a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a><a class="yt-timestamp" data-t="00:11:29">[00:11:29]</a>.
*   **Creator Status:** It's unclear who owns the intellectual property (IP) when [[machine_learning_and_its_impact_on_ai_development | AI]] acts as a creator <a class="yt-timestamp" data-t="00:11:36">[00:11:36]</a>. While the [[machine_learning_and_its_impact_on_ai_development | AI]] itself wouldn't be treated as a creator, the person behind the [[machine_learning_and_its_impact_on_ai_development | AI]] would <a class="yt-timestamp" data-t="00:11:41">[00:11:41]</a><a class="yt-timestamp" data-t="00:11:47">[00:11:47]</a>.

## [[The ethical and economic implications of AIgenerated art | Implications for Human Expression]]
From an existential perspective, one might question if it matters whether an [[machine_learning_and_its_impact_on_ai_development | AI]] created music if it evokes an emotional response like dancing, singing, or crying <a class="yt-timestamp" data-t="00:11:54">[00:11:54]</a><a class="yt-timestamp" data-t="00:11:58">[00:11:58]</a>. However, music is fundamentally human expression—a way to communicate emotions and experiences <a class="yt-timestamp" data-t="00:12:04">[00:12:04]</a><a class="yt-timestamp" data-t="00:12:12">[00:12:12]</a>.

If [[machine_learning_and_its_impact_on_ai_development | AI]] serves as a tool to enhance human expression, it is seen as beneficial <a class="yt-timestamp" data-t="00:12:23">[00:12:23]</a>. It has the potential to help people who may not have believed they had musical talent discover their abilities, leading to more connections through music <a class="yt-timestamp" data-t="00:12:31">[00:12:31]</a><a class="yt-timestamp" data-t="00:12:36">[00:12:36]</a>. The future could see an unlocking of immense human musical expression currently "locked inside people's minds" <a class="yt-timestamp" data-t="00:12:56">[00:12:56]</a><a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>. There is still much to figure out to ensure musicians are compensated fairly <a class="yt-timestamp" data-t="00:12:29">[00:12:29]</a>.

Despite the complexities and controversies, there's optimism that [[machine_learning_and_its_impact_on_ai_development | AI]] can empower more individuals to express themselves musically <a class="yt-timestamp" data-t="00:12:44">[00:12:44]</a>.