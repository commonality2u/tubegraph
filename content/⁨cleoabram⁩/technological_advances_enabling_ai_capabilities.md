---
title: Technological advances enabling AI capabilities
videoId: MWHN6ojlVXI
---

From: [[⁨cleoabram⁩]] <br/> 

The current surge in [[the_future_advancements_in_ai_beyond_art_generation | AI]] tools is rooted in fundamental shifts in how these systems operate and the computing power available to them <a class="yt-timestamp" data-t="00:01:13">[00:01:13]</a>.

## The Rise of Machine Learning

Prior to recent advancements, game-playing [[the_future_advancements_in_ai_beyond_art_generation | AI]] systems were programmed with insanely complex rules for how to play <a class="yt-timestamp" data-t="00:01:27">[00:01:27]</a>. This algorithmic approach required humans to define every possible move and outcome <a class="yt-timestamp" data-t="00:02:04">[00:02:04]</a>.

A significant breakthrough occurred with AlphaZero, a system developed by Google's parent company, Alphabet <a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>, which learned the game of chess without any pre-programmed rules <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a>. Instead, AlphaZero observed enough games to recognize winning patterns <a class="yt-timestamp" data-t="00:01:45">[00:01:45]</a>. This marked a shift from human-given rules to observation-based learning <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>.

This ability to learn fundamentally changed [[the_future_advancements_in_ai_beyond_art_generation | AI]] development <a class="yt-timestamp" data-t="00:02:29">[00:02:29]</a> and is what makes powerful [[the_creative_potential_unlocked_by_ai_tools | AI tools]] like ChatGPT possible today <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a>. The technique is known as [[machine_learning_and_its_impact_on_ai_development | machine learning]] <a class="yt-timestamp" data-t="00:02:36">[00:02:36]</a>.

### How Machine Learning Works

At its core, [[machine_learning_and_its_impact_on_ai_development | machine learning]] involves providing a computer with a set of inputs and desired outputs, then allowing it to create the rules that transform one into the other <a class="yt-timestamp" data-t="00:02:46">[00:02:46]</a>. This process can result in the [[the_future_advancements_in_ai_beyond_art_generation | AI]] developing rules that humans might not have conceived of or fully understand <a class="yt-timestamp" data-t="00:02:59">[00:02:59]</a>.

[[machine_learning_and_its_impact_on_ai_development | Machine learning]] systems excel at pattern matching <a class="yt-timestamp" data-t="00:08:27">[00:08:27]</a>, which enables them to produce verifiable correct results even if the exact method of arrival isn't fully transparent <a class="yt-timestamp" data-t="00:08:29">[00:08:29]</a>.

## Hardware Advancements

The capacity to create the advanced [[the_future_advancements_in_ai_beyond_art_generation | AI]] models seen today only recently became possible due to a dramatic increase in the power of the computers used to train them <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>.

Around 2009, the computing power supporting [[the_future_advancements_in_ai_beyond_art_generation | AI]] models began to escalate rapidly <a class="yt-timestamp" data-t="00:03:13">[00:03:13]</a>. This surge is largely attributed to a shift from Central Processing Units (CPUs) to Graphics Processing Units (GPUs) for training <a class="yt-timestamp" data-t="00:03:19">[00:03:19]</a>. While CPUs process tasks sequentially, GPUs can process many tasks in parallel <a class="yt-timestamp" data-t="00:03:30">[00:03:30]</a>.

[[technological_advancements_and_future_potential | Technological advancements]] in hardware mean the physical tools behind [[the_future_advancements_in_ai_beyond_art_generation | AI]] are now extremely powerful and are continuing to improve rapidly <a class="yt-timestamp" data-t="00:03:48">[00:03:48]</a>. According to OpenAI, the computing power used in the largest [[the_future_advancements_in_ai_beyond_art_generation | AI]] models has been doubling approximately every three months <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>.

This increased power is directly responsible for current [[the_future_advancements_in_ai_beyond_art_generation | AI]] capabilities, such as passing the bar exam, generating more realistic images, and answering complex questions <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>.

### Real-World Impact: AlphaFold

A significant demonstration of these [[technological_advancements_and_future_potential | technological advancements]] was seen in 2021, when researchers used [[machine_learning_and_its_impact_on_ai_development | machine learning]] to solve the protein folding problem <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>. Previously considered "one of the most important yet unresolved issues of modern science" <a class="yt-timestamp" data-t="00:08:50">[00:08:50]</a>, understanding protein structures is crucial for developing medicines <a class="yt-timestamp" data-t="00:09:12">[00:09:12]</a>.

By feeding existing sequences and 3D structures into a [[machine_learning_and_its_impact_on_ai_development | machine learning]] system, it learned the patterns between them <a class="yt-timestamp" data-t="00:09:22">[00:09:22]</a>. This led to predicted 3D structures for over 200 million proteins, encompassing nearly all proteins known to science <a class="yt-timestamp" data-t="00:09:33">[00:09:33]</a>. This achievement, exemplified by DeepMind's AlphaFold, dramatically accelerated a process that previously took years <a class="yt-timestamp" data-t="00:09:41">[00:09:41]</a>.

As [[machine_learning_and_its_impact_on_ai_development | machine learning]] systems continue to improve, there are high hopes for their application in solving global challenges like climate change <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>, and for transforming various sectors such as music, news, [[future_of_robotics_and_ai_applications | robotics]], and sports <a class="yt-timestamp" data-t="00:10:58">[00:10:58]</a>.