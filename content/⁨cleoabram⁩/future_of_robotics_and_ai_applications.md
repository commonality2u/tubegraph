---
title: Future of robotics and AI applications
videoId: 7ARBJQn6QkM
---

From: [[⁨cleoabram⁩]] <br/> 

Jensen Huang, CEO of NVIDIA, plays a pivotal role in shaping the [[technological_advances_enabling_ai_capabilities | future of technology]], particularly in the realms of AI and robotics <a class="yt-timestamp" data-t="00:36:00">[00:36:00]</a>. NVIDIA has been instrumental in a fundamental shift in computing, unleashing the current explosion of technological possibilities <a class="yt-timestamp" data-t="00:41:00">[00:41:00]</a>. The company's innovations underpin futuristic technology in AI, robotics, gaming, self-driving cars, and breakthrough medical research <a class="yt-timestamp" data-t="00:56:00">[00:56:00]</a>.

## The Genesis of Modern Computing and AI

The foundation for these advancements lies in NVIDIA's early insights into parallel processing:
*   **The GPU's Inception**: In the early 1990s, NVIDIA observed that a small percentage (around 10%) of code in software programs accounts for 99% of processing, which can be done in parallel <a class="yt-timestamp" data-t="04:20:00">[04:20:00]</a>. The company set out to build a computer that could efficiently handle both sequential and parallel processing <a class="yt-timestamp" data-t="04:40:00">[04:40:00]</a>. This led to the creation of the Graphics Processing Unit (GPU), which became a "time machine" enabling faster simulations and accelerating research, allowing scientists to complete their life's work within their lifetime <a class="yt-timestamp" data-t="06:25:00">[06:25:00]</a>. Gaming was chosen as the initial focus due to its demand for parallel processing and its potential as a large market, which in turn funded significant R&D for further [[technological_advances_enabling_ai_capabilities | technological advancements and future potential]] <a class="yt-timestamp" data-t="05:30:00">[05:30:00]</a>.
*   **The CUDA Platform**: Recognizing the broader applicability of parallel processing beyond graphics, NVIDIA developed CUDA <a class="yt-timestamp" data-t="08:29:00">[08:29:00]</a>. This platform made GPUs accessible to a wider range of programmers using standard languages like C, democratizing access to immense computing power <a class="yt-timestamp" data-t="08:29:00">[08:29:00]</a>. CUDA's vision was to enable many more people to create incredible things with increased computing power <a class="yt-timestamp" data-t="10:43:00">[10:43:00]</a>.
*   **AlexNet and the AI Revolution**: In 2012, researchers leveraged NVIDIA GPUs and CUDA to train AlexNet, a neural network that dramatically outperformed competitors in an image recognition challenge <a class="yt-timestamp" data-t="11:04:00">[11:04:00]</a>. This moment marked a seismic shift from step-by-step programming to training computers to learn from vast amounts of data, fundamentally altering how we compute <a class="yt-timestamp" data-t="11:35:00">[11:35:00]</a>. NVIDIA, seeing the potential for [[machine_learning_and_its_impact_on_ai_development | deep learning]] architectures to scale and solve a vast array of problems, decided to re-engineer the entire computing stack, leading to products like DGX <a class="yt-timestamp" data-t="14:16:00">[14:16:00]</a>. This commitment, despite taking a decade to fully materialize for the public, was based on core beliefs about the scalability and broad applicability of deep learning <a class="yt-timestamp" data-t="16:22:00">[16:22:00]</a>.

## Core Beliefs Driving the [[Future of AI development and opensource considerations | Future of AI]]

Huang's vision for the future is rooted in several core beliefs:
1.  **Accelerated Computing**: The continued belief in combining parallel and general-purpose processors for accelerated computing <a class="yt-timestamp" data-t="19:50:00">[19:50:00]</a>.
2.  **Scalability of Deep Learning**: Deep neural networks can learn increasingly nuanced features by becoming larger and larger, a principle empirically proven through advancements in model and data size <a class="yt-timestamp" data-t="20:06:00">[20:06:00]</a>.
3.  **Omni-modal Learning**: AI's ability to learn and translate between almost any modality of data, from text to images, sound, and even molecular structures <a class="yt-timestamp" data-t="21:27:00">[21:27:00]</a>.

## [[The future advancements in AI beyond art generation | The Future Advancements in AI Beyond Art Generation]]

The next decade will shift from the fundamental science of AI to the "application science of AI" <a class="yt-timestamp" data-t="23:12:00">[23:12:00]</a>. This involves applying AI across diverse fields:
*   **Digital Biology**: Understanding the language of molecules and cells to create digital twins of the human body <a class="yt-timestamp" data-t="23:24:00">[23:24:00]</a>.
*   **Climate Technology**: Improving weather predictions and understanding high-resolution regional climates <a class="yt-timestamp" data-t="23:31:00">[23:31:00]</a>.
*   **Industry and Society**: Applying AI to agriculture, fishery, transportation, optimizing logistics, teaching, and even podcasting <a class="yt-timestamp" data-t="23:31:00">[23:31:00]</a>.
*   **Multimodal Translation**: Capabilities include summarizing text, translating languages, generating images from text, captioning images, predicting protein structures from amino acid sequences, and eventually inferring protein functions from their structures <a class="yt-timestamp" data-t="21:42:00">[21:42:00]</a>.

## Robotics: A "Big Bang" Moment

A significant leap is expected in physical AI, encompassing humanoid robots, self-driving cars, smart buildings, autonomous warehouses, and lawnmowers <a class="yt-timestamp" data-t="24:07:00">[24:07:00]</a>. This advancement is driven by a new training paradigm:
*   **Digital Training Environments**: Instead of training robots solely in the real world (which risks damage and is slow), robots are now trained in digital worlds <a class="yt-timestamp" data-t="24:56:00">[24:56:00]</a>. NVIDIA's Omniverse and Cosmos create these realistic 3D environments, allowing for immense repetitions, varied conditions, and much faster learning <a class="yt-timestamp" data-t="25:11:00">[25:11:00]</a>.
*   **World Foundation Model**: Cosmos acts as a "world language model," imbuing AI with "world common sense" by encoding physical principles like gravity, friction, inertia, geometric and spatial awareness, object permanence, and cause and effect <a class="yt-timestamp" data-t="28:08:00">[28:08:00]</a>. Omniverse, based on Newtonian physics, provides the "ground truth" through physical simulations, allowing the generation of infinite, physically plausible future scenarios for robots to learn from <a class="yt-timestamp" data-t="28:42:00">[28:42:00]</a>.
*   **Ubiquitous Robotics**: This approach will lead to a future where "everything that moves will be robotic, and it will be soon" <a class="yt-timestamp" data-t="30:17:00">[30:17:00]</a>. This includes self-driving cars, autonomous lawnmowers, and the widespread emergence of [[the_future_impact_of_humanoid_robots_on_human_society | humanoid robots]] <a class="yt-timestamp" data-t="30:35:00">[30:35:00]</a>. People will have personal "R2-D2s" integrated into their smart glasses, phones, PCs, and cars, becoming constant companions that grow with them <a class="yt-timestamp" data-t="31:32:00">[31:32:00]</a>.

## [[Potential risks and benefits of AI | Potential Risks and Benefits of AI]]

While the future holds immense promise, [[potential_risks_and_benefits_of_ai | potential risks of AI]] are also being addressed:
*   **Common Concerns**: These include bias, toxicity, hallucination (AI confidently generating plausible but untrue information), and the creation of fake information (news, images, impersonations) <a class="yt-timestamp" data-t="32:24:00">[32:24:00]</a>.
*   **Engineering and Safety**: AI safety requires deep research and engineering to prevent systems from performing incorrectly and causing harm (e.g., a self-driving car making an aggressive turn) <a class="yt-timestamp" data-t="33:11:00">[33:11:00]</a>. It also involves ensuring system robustness, like incorporating triple redundancy in critical systems, similar to flight computers in planes, along with layers of human oversight <a class="yt-timestamp" data-t="33:54:00">[33:54:00]</a>. The goal is to architect AI safety systems as a community, ensuring proper function, preventing harm, and maintaining sufficient security <a class="yt-timestamp" data-t="34:31:00">[34:31:00]</a>.

## Overcoming Limitations and Empowering Humanity

The primary technological limitation now is the energy required to transport and process information <a class="yt-timestamp" data-t="35:47:00">[35:47:00]</a>. However, significant progress has been made in energy efficiency; an AI supercomputer delivered in 2016 costing $250,000 required 10,000 times more energy than a current version with six times the performance <a class="yt-timestamp" data-t="36:38:00">[36:38:00]</a>. Continued focus on energy efficiency is crucial for the advancement of more intelligent systems <a class="yt-timestamp" data-t="37:56:00">[37:56:00]</a>.

NVIDIA's strategy is to prioritize flexibility and general-purpose design over highly specialized hardware, anticipating continuous innovation in AI algorithms beyond current architectures like transformers <a class="yt-timestamp" data-t="39:15:00">[39:15:00]</a>. This approach fosters an environment where researchers can continue to invent and refine ideas <a class="yt-timestamp" data-t="40:54:00">[40:54:00]</a>.

Looking ahead, the [[educational_and_societal_implications_of_ai_advancements | impact of AI on society]] is profound. AI will eliminate drudgery, making tasks almost instantaneous <a class="yt-timestamp" data-t="48:04:00">[48:04:00]</a>. Just as highways and video conferencing created new economies and ways of living, AI will usher in new opportunities <a class="yt-timestamp" data-t="48:23:00">[48:23:00]</a>. Having "superhuman" AIs as personal assistants will empower individuals, increase confidence, and lower barriers to understanding any field of knowledge <a class="yt-timestamp" data-t="50:46:00">[50:46:00]</a>.

AI is already transforming computing by enhancing graphics cards like the GeForce RTX 50 Series. AI can predict up to 8 million pixels on a 4K display from just 500,000 computed pixels, creating perfect images with greater efficiency <a class="yt-timestamp" data-t="53:16:00">[53:16:00]</a>. Furthermore, AI supercomputers, once costly and exclusive to researchers, are becoming more accessible (e.g., $3,000 versions) for students and engineers, enabling more people to develop their own AIs <a class="yt-timestamp" data-t="54:52:00">[54:52:00]</a>.

A key recommendation for the future is to learn how to interact with AI models like ChatGPT, Gemini Pro, and Grok <a class="yt-timestamp" data-t="55:48:00">[55:48:00]</a>. Prompting AI is an art form, and mastering it will enable individuals, regardless of their profession, to leverage AI to do their jobs better, similar to how previous generations learned to use computers <a class="yt-timestamp" data-t="56:10:00">[56:10:00]</a>. The ultimate outcome is for humans to become "superhumans" by collaborating with these advanced AIs <a class="yt-timestamp" data-t="52:16:00">[52:16:00]</a>.