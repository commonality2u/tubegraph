---
title: Augmented reality and virtual presence
videoId: oX7OduG1YmI
---

From: [[⁨cleoabram⁩]] <br/> 

Meta is actively developing [[augmented_and_virtual_reality_technology | augmented reality]] (AR) and mixed reality technologies, aiming to create a future where digital and physical worlds seamlessly merge <a class="yt-timestamp" data-t="00:00:52">[00:00:52]</a>. The core vision behind these advancements is to deliver a profound sense of "presence" – the feeling of being physically present with another person through technology, a capability not currently achievable with existing communication methods <a class="yt-timestamp" data-t="00:11:34">[00:11:34]</a>.

## Holographic Augmented Reality Glasses

Meta has developed prototype holographic [[augmented_and_virtual_reality_technology | augmented reality]] glasses, representing a decade of research and development <a class="yt-timestamp" data-t="00:02:09">[00:02:09]</a>. These are described as the first full holographic AR glasses in the world <a class="yt-timestamp" data-t="00:02:20">[00:02:20]</a>.

### Capabilities and Applications
The glasses are designed to miniaturize all necessary computing to fit into a normal pair of glasses, capable of projecting full holograms into the real world with a wide field of view <a class="yt-timestamp" data-t="00:02:43">[00:02:43]</a>. This technology envisions scenarios where people can interact with full-body holograms of others, playing games like ping pong or poker, working together, and even engaging in activities like chess <a class="yt-timestamp" data-t="00:03:00">[00:03:00]</a>. This capability is expected to transform fields such as work, productivity, science, education, entertainment, and gaming <a class="yt-timestamp" data-t="00:03:29">[00:03:29]</a>.

### Technical Components
The prototype glasses incorporate a complex array of components:
*   **Micro Projectors:** These shoot light into waveguides <a class="yt-timestamp" data-t="00:04:58">[00:04:58]</a>.
*   **Waveguide System:** A specialized display system with nano-etchings that catch light and create holograms <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.
*   **Eye Tracking:** Synchronizes hologram placement with the user's gaze <a class="yt-timestamp" data-t="00:05:23">[00:05:23]</a>.
*   **Cameras and Sensors:** Illuminate eyes and see the surrounding world to correctly place holograms and understand user location <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>.
*   **Computing and Batteries:** Power the entire system <a class="yt-timestamp" data-t="00:05:35">[00:05:35]</a>.
*   **Microphones and Speakers:** Enable audio interaction and communication <a class="yt-timestamp" data-t="00:05:41">[00:05:41]</a>.
*   **Radio:** Communicates with other computing devices for heavier processing <a class="yt-timestamp" data-t="00:06:15">[00:06:15]</a>.
*   **Wrist-based Neural Interface:** Allows for advanced interaction <a class="yt-timestamp" data-t="00:06:21">[00:06:21]</a>.

The goal is to make future versions of these glasses cheaper, higher quality, smaller, and more stylish <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>.

## Evolution of Computing Platforms

Meta believes [[augmented_and_virtual_reality_technology | augmented reality]] glasses will be the next major computing platform, following the progression from mainframes to desktop computers to phones <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>. This trend is driven by a desire for computing to become more ubiquitous, natural, and social, allowing users to interact with the world around them without being taken away from it, unlike phones <a class="yt-timestamp" data-t="00:04:21">[00:04:21]</a>.

## Landscape of Immersive Technologies

The field of immersive technologies includes various approaches to integrating digital objects into physical space:
*   **Heads-up Displays:** Glasses with headlocked displays that move with the user's eyes <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>.
*   **Snapchat Spectacles:** Another example of glasses with digital object capabilities <a class="yt-timestamp" data-t="00:07:14">[00:07:14]</a>.
*   **Headsets (e.g., Quest, [[apple_vision_pro_and_its_potential | Apple Vision Pro]]):** Full headsets that offer mixed reality experiences <a class="yt-timestamp" data-t="00:07:19">[00:07:19]</a>.

Meta's strategy involves developing several distinct product lines:
*   **Display-less Glasses (Ray Ban Meta glasses):** Stylish glasses primarily focused on AI interaction without a display, serving as an affordable product line <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a>. These are great for AI, allowing users to talk to it and receive voice responses <a class="yt-timestamp" data-t="00:08:45">[00:08:45]</a>.
*   **Heads-up Display Glasses:** An intermediate option with a smaller field of view (20-30 degrees) for tasks like seeing AI responses, texting with a wrist-based neural interface, getting directions, or searching for information <a class="yt-timestamp" data-t="00:08:51">[00:08:51]</a>.
*   **Full Holographic AR Glasses:** The most premium and expensive option, designed for full holographic interaction <a class="yt-timestamp" data-t="00:09:38">[00:09:38]</a>.
*   **Full Headsets (Quest series):** Devices like Quest 3 and Quest 3S provide high-quality mixed reality at accessible price points, capable of fitting more compute than glasses <a class="yt-timestamp" data-t="00:09:55">[00:10:01]</a>. Meta aims to deliver high-quality mixed reality for lower costs, exemplified by Quest 3S at $299 <a class="yt-timestamp" data-t="00:10:22">[00:10:22]</a>.

## The Value of Presence and Personalized AI

Meta's core values driving these developments are "presence" and "personalized AI" <a class="yt-timestamp" data-t="00:11:28">[00:11:28]</a>.
*   **Presence:** The main goal on the AR and mixed reality side is to recreate the deep feeling of being physically present with another person, which existing technologies like video calls cannot fully achieve <a class="yt-timestamp" data-t="00:11:34">[00:11:34]</a>. This sense of presence evokes a visceral reaction in users experiencing virtual or mixed reality <a class="yt-timestamp" data-t="00:11:45">[00:11:45]</a>.
*   **Personalized AI:** This involves making AI models smarter and more compelling by personalizing them with context about the user's life and physical surroundings <a class="yt-timestamp" data-t="00:12:15">[00:12:15]</a>. Glasses are considered the ideal form factor for this, as they are positioned to see what the user sees and hear what they hear, capturing essential contextual information <a class="yt-timestamp" data-t="00:12:44">[00:12:44]</a>.

### The Nuances of Presence
While technologies like video calls allow for online connection, the ability to create a sense of being "right there in front of me" is a significant leap forward, offering optimism for future interactions <a class="yt-timestamp" data-t="00:13:31">[00:13:31]</a>. However, the emotional impact of physical presence, such as hugging, remains a challenge <a class="yt-timestamp" data-t="00:14:01">[00:14:01]</a>.

### Challenges with Haptics and Touch
Replicating physical touch (haptics) is complex <a class="yt-timestamp" data-t="00:14:09">[00:14:09]</a>. While progress is being made with controllers for hands (e.g., feeling a digital ping pong ball hit a paddle), replicating force feedback for activities like Jiu-Jitsu is significantly harder <a class="yt-timestamp" data-t="00:14:47">[00:14:47]</a>. Smell is another crucial sense for memories that is not expected to be replicated in these devices in the near future <a class="yt-timestamp" data-t="00:16:33">[00:16:33]</a>.

### The Illusion of Presence
Achieving a sense of presence is about creating a convincing illusion <a class="yt-timestamp" data-t="00:17:12">[00:17:12]</a>. More often than one specific element creating presence, it's any "wrong" element that breaks it <a class="yt-timestamp" data-t="00:17:20">[00:17:20]</a>. Factors that can break presence include a field of view that is too low, latency, or physics that don't behave realistically <a class="yt-timestamp" data-t="00:18:01">[00:18:01]</a>.

Surprisingly, people can accept some discrepancies, such as mixing photorealistic avatars with cartoon worlds, or cartoon avatars in photorealistic worlds, as long as the avatars' movements feel authentic to the person they represent <a class="yt-timestamp" data-t="00:18:19">[00:18:19]</a>. This indicates that authentic mannerisms are critical for convincing interaction, even if the visual fidelity isn't fully photorealistic across the board <a class="yt-timestamp" data-t="00:19:06">[00:19:06]</a>.

## Impact on Human Connection and Social Interactions

Concerns exist regarding whether increased digital connection might replace physical interaction, especially given data showing a decline in the number of friends Americans have and a decrease in in-person socializing <a class="yt-timestamp" data-t="00:20:17">[00:20:17]</a>. However, it's argued that digital presence doesn't necessarily replace physical connection, but rather augments it for those who already lack sufficient social interaction <a class="yt-timestamp" data-t="00:22:16">[00:22:16]</a>. The argument is that people generally desire more socialization than their current circumstances allow, and AR can unlock more connection by enabling presence with people in other locations <a class="yt-timestamp" data-t="00:22:45">[00:22:45]</a>. For example, it might lead to more time spent with a sister living across the country rather than less time with a spouse in the same household <a class="yt-timestamp" data-t="00:22:56">[00:22:56]</a>. The loss of social capital and connections predates much of modern technology <a class="yt-timestamp" data-t="00:23:54">[00:23:54]</a>.

## AI and its Intersection with Social Media

The integration of AI, particularly generative AI, is expected to deeply change how social media feels <a class="yt-timestamp" data-t="00:32:03">[00:32:03]</a>.
*   **Enhanced Content Creation:** AI will provide tools for individuals and creators to produce funnier memes, more interesting content, and edited footage from daily life captured via glasses <a class="yt-timestamp" data-t="00:32:42">[00:32:42]</a>.
*   **AI-Generated Content:** Future social media could feature content purely generated by AI, personalized for the user, summarizing information, or producing humorous material <a class="yt-timestamp" data-t="00:33:27">[00:33:27]</a>.
*   **AI Creators and Digital Artifacts:** There will be AI creators, and human creators will build AI versions of themselves to interact with their communities <a class="yt-timestamp" data-t="00:33:49">[00:33:49]</a>. These AI artifacts are interactive sculptures, trained by creators to communicate on specific topics and provide community engagement when the human creator is unavailable <a class="yt-timestamp" data-t="00:34:32">[00:34:32]</a>.

AI is anticipated to change almost every field and feature of every application over the next 5 to 10 years, leading to significant innovation <a class="yt-timestamp" data-t="00:35:04">[00:35:04]</a>.

## Concerns and Preparation for the Future

The rapid pace of technological change, especially with AI, brings uncertainty and anxiety <a class="yt-timestamp" data-t="00:36:21">[00:36:21]</a>. While new tools will improve lives and work, individuals will need to adapt and keep up with trends to remain competitive <a class="yt-timestamp" data-t="00:36:44">[00:36:44]</a>.

### Balancing Struggle and Assistance
The question arises whether AI assistance removes valuable "struggle" necessary for human development <a class="yt-timestamp" data-t="00:25:23">[00:25:23]</a>. Examples include:
*   **Universal Translators:** While potentially reducing the need to learn languages, similar to how calculators didn't eliminate math, they remove communication barriers <a class="yt-timestamp" data-t="00:24:42">[00:24:42]</a>. Ray Ban Metas already offer real-time translation for a few languages <a class="yt-timestamp" data-t="00:31:23">[00:31:23]</a>.
*   **Emotional Articulation:** AI could help individuals articulate emotions, but the process of struggling to communicate is also seen as crucial for personal growth <a class="yt-timestamp" data-t="00:25:41">[00:25:41]</a>.
*   **Coding:** AI will allow users to describe desired software, which the AI will then build. However, learning to code is still valuable for developing rigorous thinking, even if AI handles much of the production <a class="yt-timestamp" data-t="00:29:35">[00:29:35]</a>.

The belief is that humans will always find new things to strive for, and tools will simply help them achieve more complex goals <a class="yt-timestamp" data-t="00:26:42">[00:26:42]</a>. To prepare for this future, maintaining curiosity and embracing technological evolution rather than fighting it is advised <a class="yt-timestamp" data-t="00:39:01">[00:39:01]</a>.

## The Role of Open Source AI

Open source in AI means that developers can take and modify models to build a diverse range of AI systems, contrasting with a centralized, closed approach where a few companies build a single dominant AI <a class="yt-timestamp" data-t="00:40:07">[00:40:07]</a>. This approach supports a future with many different AI systems, similar to the variety of apps and websites available today <a class="yt-timestamp" data-t="00:40:11">[00:40:11]</a>. Every business and creator may eventually have their own AI to interact with customers or communities <a class="yt-timestamp" data-t="00:40:22">[00:40:22]</a>.

### Safety Debate
A key debate around open source AI revolves around safety <a class="yt-timestamp" data-t="00:41:26">[00:41:26]</a>. Some argue that keeping models closed makes them safer by preventing malicious use <a class="yt-timestamp" data-t="00:41:40">[00:41:40]</a>. However, historical evidence from open source software suggests the opposite: open source is often safer and more secure because broader scrutiny from many developers helps identify and fix issues quicker <a class="yt-timestamp" data-t="00:41:59">[00:41:59]</a>. This leads to more robust and reliable models, benefiting everyone <a class="yt-timestamp" data-t="00:43:12">[00:43:12]</a>.

## Future of AI Scaling

A significant open question in the AI field is how far current methods for scaling AI will go <a class="yt-timestamp" data-t="00:44:17">[00:44:17]</a>. Unlike past AI architectures that hit plateaus, new transformer-based architectures developed over the last 5-10 years have not yet found an end to their scaling capabilities <a class="yt-timestamp" data-t="00:44:25">[00:44:25]</a>. This allows for continuous growth by training models on increasingly larger clusters of GPUs and generating more synthetic data <a class="yt-timestamp" data-t="00:44:44">[00:44:44]</a>.

While it's possible that a limit will eventually be reached, the current bet is that fundamental AI advances will continue for quite a while, leading to a dynamic technological landscape and compelling new products over the next 20 years <a class="yt-timestamp" data-t="00:45:06">[00:45:06]</a>. This ongoing scaling requires massive investments in infrastructure, amounting to hundreds of billions of dollars <a class="yt-timestamp" data-t="00:45:42">[00:45:42]</a>.