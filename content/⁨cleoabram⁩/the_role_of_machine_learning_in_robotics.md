---
title: The role of machine learning in robotics
videoId: nAgTgwak7ME
---

From: [[⁨cleoabram⁩]] <br/> 

The intelligence of advanced robots like Atlas is a common point of curiosity and misunderstanding for the public <a class="yt-timestamp" data-t="09:15:00">[09:15:00]</a>. When a robot performs impressive feats, observers may subconsciously assume it possesses a broader range of abilities or a deeper understanding beyond its programmed functions <a class="yt-timestamp" data-t="06:18:00">[06:18:00]</a>. However, this assumption doesn't apply to robots; their capabilities are often highly specialized <a class="yt-timestamp" data-t="06:28:00">[06:28:00]</a>. For example, a robot capable of performing a backflip may struggle with seemingly simple tasks like sitting in a chair <a class="yt-timestamp" data-t="06:45:00">[06:45:00]</a>. This phenomenon is known as Moravec's Paradox, which states that "the easy things are hard" for robots—meaning that tasks humans find trivial, like moving through the world and interacting with objects, are exceptionally difficult for robots to master <a class="yt-timestamp" data-t="06:02:00">[06:02:00]</a>.

## How Robots "Learn"

Currently, [[the_future_impact_of_humanoid_robots_on_human_society | humanoid robots]] like Atlas do not learn from every new physical experience or failure in the same way humans do <a class="yt-timestamp" data-t="11:10:00">[11:10:00]</a>. Improvements to Atlas's control system from hardware experiments still require human engineers to implement them <a class="yt-timestamp" data-t="11:27:00">[11:27:00]</a>.

Despite this, [[machine_learning_and_its_impact_on_ai_development | machine learning]] plays a significant role in their development <a class="yt-timestamp" data-t="11:38:00">[11:38:00]</a>. [[machine_learning_and_its_impact_on_ai_development | AI]] typically refers to models created through [[machine_learning_and_its_impact_on_ai_development | machine learning]], which involves giving a machine examples of inputs and outputs and allowing it to generate its own rules to connect them <a class="yt-timestamp" data-t="11:41:00">[11:41:00]</a>.

### Perception and Behavior Generation
Atlas's perception system is almost entirely driven by [[machine_learning_and_its_impact_on_ai_development | machine learning]] <a class="yt-timestamp" data-t="11:55:00">[11:55:00]</a>. It uses cameras to identify objects in its environment and localize itself within its surroundings <a class="yt-timestamp" data-t="12:00:00">[12:00:00]</a>.

[[machine_learning_and_its_impact_on_ai_development | Machine learning]] is also increasingly responsible for generating robot behavior <a class="yt-timestamp" data-t="12:09:00">[12:09:00]</a>. Rather than human engineers painstakingly programming every physical detail, systems can learn to perform tasks better through simulation, robot data, and trial-and-error experience <a class="yt-timestamp" data-t="12:13:00">[12:13:00]</a>.

For complex movements, like Atlas throwing a bag while jumping and turning 180 degrees, the robot is given a goal (e.g., the bag must land in a specific spot after a 180-degree turn) <a class="yt-timestamp" data-t="09:47:00">[09:47:00]</a>. The robot then figures out how to grab the bag, accelerate it, and release it according to Newton's laws <a class="yt-timestamp" data-t="09:58:00">[09:58:00]</a>. This coordination, which comes naturally to humans, requires immense computation for a robot, especially considering changes in balance and angular momentum caused by interacting with objects <a class="yt-timestamp" data-t="10:10:00">[10:10:00]</a>.

### Tesla Optimus's Approach
Tesla's Optimus robot heavily invests in this [[machine_learning_and_its_impact_on_ai_development | machine learning]] approach <a class="yt-timestamp" data-t="12:25:00">[12:25:00]</a>. When Optimus sorts blocks "fully autonomously," it means that given a high-level goal (e.g., "blue blocks here and green blocks here"), the robot uses a neural network—a type of [[machine_learning_and_its_impact_on_ai_development | machine learning]] system—to process visual information from its cameras and "decide" how to accomplish the task <a class="yt-timestamp" data-t="12:30:00">[12:30:00]</a>. Tesla also appears to use simulation data to train Optimus for improved task performance <a class="yt-timestamp" data-t="12:46:00">[12:46:00]</a>.

## The [[future_of_robotics_and_ai_applications | Robot Future]] and High-Level Commands
The [[future_of_robotics_and_ai_applications | robot future]], where [[the_future_impact_of_humanoid_robots_on_human_society | humanoid robots]] assist in daily tasks, depends on their ability to understand increasingly high-level concepts and commands <a class="yt-timestamp" data-t="13:02:00">[13:02:00]</a>. For instance, instructing a robot to "put my groceries away" is vastly different from detailing every precise movement: "rotate your left hand, pick up the bag like this, put the bag on the counter..." <a class="yt-timestamp" data-t="13:12:00">[13:12:00]</a>. A robot needs to comprehend not just physical locations but also concepts like "groceries," "away" (meaning "in the cabinet, not out the window"), and prioritize safety (e.g., "don't step on my dog!") <a class="yt-timestamp" data-t="13:23:00">[13:23:00]</a>. This highlights the immense challenges and the impressive [[technological_advances_enabling_ai_capabilities | AI capabilities]] required to create truly versatile [[the_future_impact_of_humanoid_robots_on_human_society | humanoid robots]] <a class="yt-timestamp" data-t="13:34:00">[13:34:00]</a>.