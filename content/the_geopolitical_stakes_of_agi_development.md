---
title: The geopolitical stakes of AGI development
videoId: zdbVtZIn9IM
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The development of Artificial General Intelligence (AGI) and eventual superintelligence is poised to be a transformative event in human history, with profound geopolitical implications. The stakes involved extend beyond mere technological advancement, potentially determining the survival of political systems and the global order for the next century [[impact_of_ai_on_future_technology_and_society | Impact of AI on future technology and society]], [[china_and_the_uss_race_in_ai_and_superintelligence | China and the US's race in AI and superintelligence]].

## The Race to Superintelligence

The progression towards AGI is marked by an accelerating investment in computational power and algorithmic innovation. This trajectory points towards an "intelligence explosion" where AI systems rapidly surpass human capabilities [[intelligence_explosion_and_ai_feedback_loops | Intelligence explosion and AI feedback loops]].

### The Exponential Growth of AI Clusters

AI development is an industrial process requiring massive infrastructure, including giant new data clusters, power plants, and eventually, fabrication plants [[data_center_energy_requirements_and_scaling | Data center energy requirements and scaling]]. Since ChatGPT, a "techno-capital acceleration" has been set in motion [[ai_scalability_and_breakthroughs | AI scalability and breakthroughs]].
The training compute for the largest AI systems has been growing by approximately half an order of magnitude (0.5 OOMs) per year for almost a decade. Projecting this forward:
* **GPT-4 (pre-trained 2022):** Cluster of ~25,000 A100s, roughly $500 million, 10 megawatts.
* **By 2024:** 100 MW cluster, 100,000 H100 equivalents, costing billions.
* **By 2026:** 1 gigawatt cluster (size of a large nuclear reactor), 1 million H100 equivalents, costing tens of billions.
* **By 2028:** 10 GW cluster (more power than most US states), 10 million H100 equivalents, costing hundreds of billions. This is the estimated range for achieving true AGI.
* **By 2030:** A "trillion-dollar cluster" using 100 gigawatts (over 20% of US electricity production), 100 million H100 equivalents [[challenges_and_opportunities_in_deploying_ai_at_scale | Challenges and opportunities in deploying AI at scale]].

Companies like OpenAI and Microsoft are reportedly planning a $100 billion cluster, potentially on the scale of a 10 GW facility. AMD forecasted a $400 billion AI accelerator market by 2027, suggesting a path towards $1 trillion of total AI investment by then [[microsofts_breakthroughs_in_ai_and_quantum_computing | Microsoft's breakthroughs in AI and quantum computing]].

### The Intelligence Explosion

Once AGI is achieved—defined as AI systems capable of performing cognitive tasks like a "drop-in remote worker"—the path to superintelligence could be swift [[artificial_general_intelligence_and_ai_systems | Artificial General Intelligence and AI Systems]].
* **Automating AI Research:** One of the first jobs AGI will automate is that of AI researchers and engineers [[ai_alignment_and_safety | AI alignment and safety]].
* **Accelerated Progress:** With potentially 100 million human-equivalent automated AI researchers, a decade's worth of ML research could occur in a year, leading to a 10x speed-up. This could allow a jump to AI vastly smarter than humans within one to two years [[ai_alignment_and_existential_risks | AI alignment and existential risks]].
* **Broad Technological Advancement:** This "intelligence explosion" would then apply to R&D across many fields, including robotics [[the_role_of_cultural_and_technological_innovations_in_human_evolution | The role of cultural and technological innovations in human evolution]]. This could compress a century's worth of technological progress into less than a decade [[economic_growth_and_ai | Economic growth and AI]].

## National Security and Geopolitical Competition

The development of superintelligence will be "absolutely decisive for national power", leading to intense international competition, particularly between the United States and China [[the_relationship_between_ai_government_and_geopolitical_dynamics | The relationship between AI, government, and geopolitical dynamics]].

### The US-China AI Race
The Chinese Communist Party (CCP) is expected to make an "all-out effort to infiltrate American AI labs" involving billions of dollars and thousands of people. The CCP will also try to "out-build" the US in terms of AI infrastructure [[china_and_the_uss_race_in_ai_and_superintelligence | China and the US's race in AI and superintelligence]]. China's capacity to rapidly increase power generation (adding as much power in the last decade as the entire US electric grid) gives it an advantage in building large-scale clusters like the 100 GW facility.

### Military Dominance
A lead of even a couple of years in superintelligence could confer an utterly decisive military advantage, comparable to the technological lead the Western coalition had in the first Gulf War.
* **Preempting Nuclear Deterrence:** Superintelligence could undermine existing nuclear deterrence by enabling the detection of nuclear stealth submarines or the deployment of countermeasures like millions of mosquito-sized drones to neutralize nuclear assets.
* **New WMDs:** The development of superintelligence could lead to "crazy new WMDs", further destabilizing the global security landscape [[geopolitical_implications_on_technology_and_data_centers | Geopolitical implications on technology and data centers]].

### Espionage and Intellectual Property Theft
The security of AI labs is a major concern [[security_risks_and_statelevel_espionage_in_ai_development | Security risks and state-level espionage in AI development]].
* **Stealing Weights:** Theft of the final AI model weights is akin to getting a "direct copy of the atomic bomb". If China, with its superior build capacity, could steal a US-developed superintelligence, they could rapidly deploy it.
* **Stealing Secrets (Algorithms & Techniques):** Secrets regarding new paradigms, such as solutions to the "data wall" (the "AlphaGo step two" involving self-play RL), are crucial. If China steals these, they can catch up; if not, they could be stuck.
* **Current Vulnerabilities:** AI labs are currently highly vulnerable. DeepMind rates its security as "level zero" (out of four, where four is resistant to state activity). A recent indictment showed an individual stealing important AI code from Google by copying it into Apple Notes and exporting it as a PDF [[challenges_in_ai_alignment_and_potential_risks | Challenges in AI alignment and potential risks]].

The historical example of Leo Szilard convincing Enrico Fermi not to publish data on graphite's effectiveness as a moderator for nuclear reactions is cited. This secrecy potentially prevented Nazi Germany from pursuing a more viable path to an atomic bomb [[historical_analysis_of_world_war_i_and_world_war_ii | Historical Analysis of World War I and World War II]].

## Strategic Location of AI Infrastructure

The physical location of the massive AI training clusters is a critical strategic consideration.

### The Case for US and Allied Democratic Nations
It is considered "incredibly important that these clusters are in the United States" or allied democracies.
* **Security Risks of Authoritarian Locations:** Building AGI/superintelligence clusters in authoritarian dictatorships (e.g., the UAE) creates irreversible security risks.
* **Exfiltration and Seizure:** Such locations make it easier to exfiltrate weights or for the host nation to seize the compute, potentially altering the balance of power.
* **Leverage:** It gives authoritarian dictatorships "seats at the AGI table" and implicit leverage [[strategies_for_maintaining_balance_of_power_in_ai_development | Strategies for maintaining balance of power in AI development]].

### Motivations for Building Elsewhere
Despite risks, some US entities are pursuing AI cluster development in regions like the Middle East.
* **Access to Capital:** Middle Eastern states offer "easy money". However, the US has deep financial markets and trillion-dollar companies capable of funding these projects.
* **Perceived US Inefficiency:** Some believe only autocracies can mobilize industrial capacity quickly enough, betting against the US liberal order.
* **The "China Gambit":** An argument is made that if the US doesn't work with these countries (e.g., UAE), they will turn to China. There are unconfirmed reports that OpenAI leadership once considered funding AGI by starting a bidding war between the US, China, and Russia.
* **Distinguishing Training vs. Inference:** Claims that compute in such locations is for inference, not training, are suspect, as RL can look like inference, and compute can be repurposed [[challenges_and_methodologies_in_ai_training_and_data_usage | Challenges and methodologies in AI training and data usage]].

A proposed approach involves a two-tiered coalition: a narrow one of democracies developing AGI, and a broader one (including dictatorships) offered benefit-sharing (e.g., access to last-gen models, AI products) but not a seat at the core AGI development table [[open_source_ai_models_and_their_implications | Open source AI models and their implications]].

### Enabling US Capacity
The US can host these massive clusters by:
1. **Utilizing Natural Gas:** Ample natural gas in places like West Texas or Pennsylvania could power 10 GW or even 100 GW clusters. This may require companies to reconsider climate commitments.
2. **Green Energy Megaprojects:** Requires broad deregulatory pushes (reforming FERC, NEPA exemptions, overcoming state-level hurdles) to expedite solar, batteries, SMRs, and geothermal projects [[energy_transitions_and_renewable_energy_challenges | Energy transitions and renewable energy challenges]].

Historical precedent from WWII shows the US mobilized immense industrial capacity despite internal challenges like labor disputes, starting from a very low base [[historical_influences_on_leadership_and_innovation | Historical influences on leadership and innovation]].

## Broader Societal and Political Upheaval

The advent of AGI will trigger significant societal and political transformations [[the_potential_economic_and_social_impacts_of_agi | The potential economic and social impacts of AGI]].

### The "March 2020 Moment"
A widespread realization of AGI's implications, similar to how COVID-19 became globally recognized in March 2020, is anticipated. Currently, most of the world, including many in AI, do not fully grasp the impending intensity. As models become more capable, "g-forces will intensify" and more people will "feel it" [[exploring_the_future_of_society_and_economy_with_ai | Exploring the future of society and economy with AI]].

### Impact on Governance
* **Entrenching Dictatorships:** Superintelligence could provide authoritarian regimes with perfectly loyal military and security forces, perfect lie detection, and pervasive surveillance, eliminating dissent and challenges to power.
* **Stakes for Global Systems:** The competition will address fundamental questions like whether liberal democracy can survive and whether the CCP can continue to exist. History suggests that periods of intense international competition and extraordinary events are the norm, rather than the recent decades of relative peace and US hegemony [[geopolitical_strategies_and_historical_conflicts | Geopolitical strategies and historical conflicts]].

### Shifting Power Dynamics
Initially, AI lab employees hold significant power (evidenced by events like the OpenAI board situation in November 2023). However, this influence is likely to depreciate as AI researchers themselves are automated [[ai_alignment_and_cooperation_challenges | AI alignment and cooperation challenges]]. Ultimately, politicians, generals, and the national security state will take charge, much like with the Manhattan Project [[comparisons_between_atomic_bomb_development_and_modern_ai_advancements | Comparisons between atomic bomb development and modern AI advancements]].

## The Urgency: A Narrow Window of Opportunity

The timeline for these developments is compressed, and leads of even months could be decisive [[timeline_predictions_for_agi_development | Timeline predictions for AGI development]].
* **A Small Lead Matters:** A six-month to two-year lead in AGI development could translate into a vastly superhuman system (potentially five OOMs difference) due to the intelligence explosion. This could create a technological advantage similar to the decades-long lead the US had in the first Gulf War.
* **Dangers of a "Feverish Struggle":** A neck-and-neck race (e.g., a three-month lead) would be incredibly dangerous, leading to a volatile situation with rapidly evolving military technologies and WMDs, where deterrence could change weekly [[challenges_and_advancements_in_ai_training_techniques | Challenges and advancements in AI training techniques]].
* **Buffer for Safety:** A significant lead provides "wiggle room" to address alignment and safety concerns during the intelligence explosion. Without this buffer, the pressure to proceed at maximum speed could lead to self-destruction [[ai_safety_and_alignment | AI Safety and Alignment]].

The current period is described as "the quiet period" before AGI's full impact, a last chance for normalcy before these intense dynamics take hold [[predicting_the_impact_and_management_of_superintelligence | Predicting the impact and management of superintelligence]].