---
title: Timeline predictions for AGI development
videoId: WLBsUarvWTw
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The development timeline for Artificial General Intelligence (AGI), particularly its capacity to replace human labor, is a subject of ongoing discussion. Guests Tamay Besiroglu and Ege Erdil, formerly of Epoch AI and now launching Mechanize, offer a more conservative outlook compared to some prevailing views in the AI community.

## Besiroglu and Erdil's Timelines

Besiroglu and Erdil generally project longer timelines for AGI capable of full remote worker replacement.

*  **Tamay Besiroglu** estimates a "drop-in remote worker replacement" around **2045** <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>.
*  **Ege Erdil** is slightly more bullish but still expects a significant period, suggesting his predictions might be shaded by "five years or by 20%" less than Besiroglu's <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>. When pressed for when AI could do "literally everything" a remote worker can, no specific year was given by Erdil, but the context implies a multi-decade timeframe.

## Factors Influencing Longer Timelines

Their longer timeline predictions stem from several core arguments:

### Critique of Rapid Extrapolation
Erdil cautions against simply extrapolating recent rapid progress in AI, such as the advancements from ChatGPT to current models capable of reasoning and coding <a class="yt-timestamp" data-t="00:03:03">[00:03:03]</a>, <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>. He argues that there isn't a clear trend to extrapolate for "full automation" because the current fraction of the economy automated by AI is very small <a class="yt-timestamp" data-t="00:03:58">[00:03:58]</a>.

### Core Capabilities and "Unlocks"
A central part of their reasoning is the concept of "big unlocks" or core capabilities that AI systems need to acquire.
<a class="yt-timestamp" data-t="00:04:18">[00:04:18]</a>
*  **Historical Unlocks:** Over the past 10-15 years, with approximately 9-10 orders of magnitude of compute scaling, AI has seen a few major capability unlocks <a class="yt-timestamp" data-t="00:04:43">[00:04:43]</a>. These include:
    * Solving complex games (e.g., Go, Chess, Dota) between 2015-2020 <a class="yt-timestamp" data-t="00:05:03">[00:05:03]</a>.
    * Sophisticated language capabilities with LLMs <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>.
    * Advanced abstract reasoning, coding, and math <a class="yt-timestamp" data-t="00:05:18">[00:05:18]</a>.
    These unlocks occurred roughly once every three years or every three orders of magnitude of compute <a class="yt-timestamp" data-t="00:05:35">[00:05:35]</a>.
*  **Future Unlocks Needed:** They believe several more such competencies are required for AI to match human capabilities in remote work, such as:
    * Coherence over very long horizons <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a>.
    * Agency and autonomy <a class="yt-timestamp" data-t="00:06:04">[00:06:04]</a>.
    * Full multimodal understanding <a class="yt-timestamp" data-t="00:06:13">[00:06:13]</a>.

### Compute Scaling Limitations
While past unlocks were fueled by rapid compute scaling, Besiroglu suggests this is becoming harder <a class="yt-timestamp" data-t="00:06:46">[00:06:46]</a>. This is related to challenges in AI scalability and breakthroughs – [[ai_scalability_and_breakthroughs]]. 
*  Extrapolations indicate perhaps only three or four more orders of magnitude of scaling are left before significant portions of world output would be needed for data centers, energy infrastructure, and fabs <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>. Refer also to data center energy requirements and scaling – [[data_center_energy_requirements_and_scaling]].
*  Currently, AI chip production is a relatively small fraction of even leading-edge semiconductor capacity (e.g., around 5% of TSMC's leading-edge capacity) <a class="yt-timestamp" data-t="00:07:18">[00:07:18]</a>, <a class="yt-timestamp" data-t="00:07:28">[00:07:28]</a>. This information relates to challenges and opportunities in deploying AI at scale – [[challenges_and_opportunities_in_deploying_ai_at_scale]].
This raises questions about whether the economy can sustain the compute scaling needed for further unlocks <a class="yt-timestamp" data-t="00:07:41">[00:07:41]</a>.

### Complexity of Human Labor
Erdil and Besiroglu argue that many underestimate the complexity of human jobs.
*   Tasks like booking a flight, which AI might soon master <a class="yt-timestamp" data-t="00:08:18">[00:08:18]</a>, represent a very small fraction of what most jobs entail <a class="yt-timestamp" data-t="00:08:46">[00:08:46]</a>.
*   Automating isolated tasks does not equate to automating entire jobs or having a significant economic impact <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>. This worldview difference, where they see jobs as requiring more competencies, contributes to their longer timelines compared to more bullish forecasters <a class="yt-timestamp" data-t="00:09:11">[00:09:11]</a>.

### The "Intelligence Explosion" Misconception
Tamay Besiroglu argues that the concept of an "intelligence explosion" is misleading, akin to calling the Industrial Revolution a "horsepower explosion" <a class="yt-timestamp" data-t="00:00:50">[00:00:50]</a>. While horsepower (raw physical power) increased, it was one of many complementary changes across sectors like agriculture, transportation, law, finance, and urbanization that drove the Industrial Revolution <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>. Similarly, for AI, smart systems will be just one part of a broader transition involving many moving parts <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>. Focusing solely on "intelligence" misses the broader economic and societal reorganization required <a class="yt-timestamp" data-t="00:44:55">[00:44:55]</a>. For more on intelligence explosion and its implications, refer to intelligence explosion and AI feedback loops – [[intelligence_explosion_and_ai_feedback_loops]].

### Moravec's Paradox
Besiroglu highlights Moravec's paradox: tasks hard for humans (e.g., abstract reasoning, chess, complex math) are often where AI progresses fastest, while tasks easy for humans (often evolutionarily older skills) are harder for AI <a class="yt-timestamp" data-t="00:31:53">[00:31:53]</a>.
*   Recent AI milestones in reasoning are impressive but fall into this category of newly evolved human skills <a class="yt-timestamp" data-t="00:32:59">[00:32:59]</a>.
*   While proficiency in these tasks correlates with broader competence in humans, this correlation isn't as strong for AI systems, which may lack other fundamental human abilities <a class="yt-timestamp" data-t="00:33:41">[00:33:41]</a>, <a class="yt-timestamp" data-t="00:26:35">[00:26:35]</a>.
*   Therefore, rapid progress on these "impressive" tasks shouldn't lead to over-updating on general AI competence, as they represent a narrow subset of economically valuable human skills <a class="yt-timestamp" data-t="00:34:47">[00:34:47]</a>.

## Contrasting (Bullish) Perspectives
The podcast also touched upon arguments for shorter timelines:

*   **The "Unhobbling" Framework:** This perspective, attributed to Leopold Aschenbrenner, suggests current AIs are like "baby AGIs" held back by artificial constraints (e.g., text-only training, limited context windows, lack of inference time for "meditation") <a class="yt-timestamp" data-t="00:09:22">[00:09:22]</a>. Removing these "hobblings" (e.g., by providing training data for Slack/Gmail environments, improving inference scaling) is seen as easier than unlocking entirely new capabilities <a class="yt-timestamp" data-t="00:10:06">[00:10:06]</a>. ChatGPT itself is cited as an example where a small amount of additional compute for post-training unlocked significant chatbot capabilities <a class="yt-timestamp" data-t="00:10:56">[00:10:56]</a>.
*   **METR Evals and Task Length:** The METR eval suggests models are doubling their ability to perform tasks of increasing human-equivalent time length every seven months <a class="yt-timestamp" data-t="00:15:49">[00:15:49]</a>, <a class="yt-timestamp" data-t="00:16:11">[00:16:11]</a>. Extrapolating this curve suggests AI could handle month- or year-long human tasks by 2030, implying progress towards long-term coherency <a class="yt-timestamp" data-t="00:16:17">[00:16:17]</a>. See also the future of AGI and societal implications – [[future_of_agi_and_societal_implications]].
*   **Simplicity of Intelligence:** The argument is made that recent breakthroughs (e.g., reasoning via chain-of-thought) suggest intelligence might be simpler than previously thought, and agency could follow a similar pattern of relatively easy unlocking <a class="yt-timestamp" data-t="00:16:55">[00:16:55]</a>, <a class="yt-timestamp" data-t="00:17:07">[00:17:07]</a>.

Besiroglu and Erdil counter that while some capabilities like reasoning might seem easy to unlock *now*, this stands on a huge stack of prior technological development (massive compute, large datasets, inference innovations) that was hard-won <a class="yt-timestamp" data-t="00:11:30">[00:11:30]</a>, <a class="yt-timestamp" data-t="00:12:45">[00:12:45]</a>. They argue that unlocking agency might similarly appear simple in retrospect but will require substantial underlying innovation <a class="yt-timestamp" data-t="00:12:55">[00:12:55]</a>.

## Potential Updates to Timelines
Besiroglu and Erdil would update their timelines based on certain developments:

*   **Demonstrated Advanced Capabilities:**
    *   AI performing very long-context tasks effectively <a class="yt-timestamp" data-t="00:20:40">[00:20:40]</a>.
    *   Meaningful integration of multimodal capabilities with reasoning and agency <a class="yt-timestamp" data-t="00:20:45">[00:20:45]</a>.
    *   Ability to take action over long horizons to accomplish complex tasks, not just in specific software environments but broadly <a class="yt-timestamp" data-t="00:20:56">[00:20:56]</a>. Refer also to artificial general intelligence and AI systems – [[artificial_general_intelligence_and_ai_systems]].
    *   A specific example: an AI downloading an arbitrary, new game from Steam (released after its training cutoff, with no online tutorials) and playing it to completion, accomplishing milestones challenging for humans <a class="yt-timestamp" data-t="00:21:08">[00:21:08]</a>. See the impact of AI and quantum computing on industries like gaming and healthcare – [[the_impact_of_ai_and_quantum_computing_on_industries_like_gaming_and_healthcare]].
*   **Significant Economic Impact:**
    *   OpenAI achieving revenue far exceeding $100 billion (e.g., $500 billion) would be a significant update <a class="yt-timestamp" data-t="00:21:56">[00:21:56]</a>. $100 billion in revenue, while substantial, is considered plausible (around 40% chance) and wouldn't itself be a huge update on its own <a class="yt-timestamp" data-t="00:22:04">[00:22:04]</a>, as people pay large sums for many things that aren't world-transforming <a class="yt-timestamp" data-t="00:22:39">[00:22:39]</a>. See impact of AI on economic and societal structures – [[impact_of_ai_on_economic_and_societal_structures]].