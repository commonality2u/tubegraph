---
title: The impact of AGI on human intelligence and productivity
videoId: NecVve6E2wo
---

From: [[bankless]] <br/> 

## Defining Artificial General Intelligence (AGI)

Artificial General Intelligence (AGI) is defined as a form of [[integration_of_human_intelligence_with_AI | intelligence]] that is smarter than a human across almost every medium <a class="yt-timestamp" data-t="01:32:41">[01:32:41]</a>. Initially, experts expected AGI to emerge in the 2040s, 2050s, or 2060s <a class="yt-timestamp" data-t="01:39:13">[01:39:13]</a>, but the current reality suggests it is "months away instead of decades" <a class="yt-timestamp" data-t="01:44:27">[01:44:27]</a>.

### The Human Baseline

Historically, human progress has stemmed from the "collective accumulation of knowledge over time" <a class="yt-timestamp" data-t="00:59:09">[00:59:09]</a>. This cumulative knowledge allowed for an exponential growth curve, even if it was a modest 2% year-over-year <a class="yt-timestamp" data-t="02:30:29">[02:30:29]</a>. Everything around us, from clothes to infrastructure, was made by people "no smarter than we are" <a class="yt-timestamp" data-t="00:39:46">[00:39:46]</a> <a class="yt-timestamp" data-t="00:44:07">[00:44:07]</a>. We have roughly the same brain size and cognitive ability as cavemen from 40,000 years ago, benefiting from accumulated knowledge rather than inherently greater individual intelligence <a class="yt-timestamp" data-t="00:55:01">[00:55:01]</a>.

## The Age of Hyper Acceleration

The arrival of AGI marks an inflection point, leading to an "age of hyper acceleration" <a class="yt-timestamp" data-t="03:41:40">[03:41:40]</a> <a class="yt-timestamp" data-t="05:10:48">[05:10:48]</a>. This new era differs from previous technological advancements because, for the first time, "people are actually smarter than we are" <a class="yt-timestamp" data-t="01:18:24">[01:18:24]</a>.

### Technological Drivers

*   **Moore's Law vs. Huang's Law**: For 60 years, human progress was significantly accelerated by Moore's Law, which stated that the number of transistors on a chip doubles every 24 months, effectively doubling computer processor speed every two years <a class="yt-timestamp" data-t="04:09:07">[04:09:07]</a> <a class="yt-timestamp" data-t="09:00:27">[09:00:27]</a>. Moore's Law is now constrained by physics as particles become too small <a class="yt-timestamp" data-t="09:27:06">[09:27:06]</a>. However, a new principle, Huang's Law, suggests a 25-fold improvement in GPU training capability every five years <a class="yt-timestamp" data-t="04:27:03">[04:27:03]</a> <a class="yt-timestamp" data-t="09:12:05">[09:12:05]</a>. This represents a 5x increase in the rate of acceleration compared to Moore's Law <a class="yt-timestamp" data-t="04:47:04">[04:47:04]</a>.
*   **Software Efficiency**: Alongside hardware advancements, significant improvements are seen in software efficiency. For example, Alibaba's qwq model is 20 times more efficient than DeepSeek R1, a model that "broke Wall Street," in just two months <a class="yt-timestamp" data-t="07:23:44">[07:23:44]</a> <a class="yt-timestamp" data-t="10:00:46">[10:00:46]</a>. This means that foundational models can be distilled to run on a desktop computer, representing a "thousandfold improvement" <a class="yt-timestamp" data-t="10:02:51">[10:02:51]</a>.
*   **Self-Fulfilling Acceleration**: The combination of hardware and software advancements creates a self-reinforcing loop: "the models help us design better hardware, the hardware gets better and we can run more powerful models and then the models can help us design more hardware" <a class="yt-timestamp" data-t="12:47:04">[12:47:04]</a>. This leads to an "optimization point extremely fast" <a class="yt-timestamp" data-t="12:57:42">[12:57:42]</a>.

### Collapsing the Cost of Intelligence

AGI is expected to "collapse the cost of intelligence to zero" <a class="yt-timestamp" data-t="14:15:23">[14:15:23]</a> <a class="yt-timestamp" data-t="15:29:43">[15:29:43]</a>. Previously, producing high-level intelligence required significant time and cost, such as putting humans through PhD programs <a class="yt-timestamp" data-t="14:24:28">[14:24:28]</a>. With AGI, "PhD Peak PhD level intelligence will be free in a few short years" <a class="yt-timestamp" data-t="14:43:08">[14:43:08]</a>.

## Transformative Impacts Across Industries

The downstream effects of cheap and abundant AGI-driven [[integration_of_human_intelligence_with_AI | intelligence]] are vast, leading to unprecedented changes across all industries.

*   **Biology and Medicine**:
    *   In the last two years, [[technological_advances_in_ai_efficiency | AI]] has enabled the discovery of 250 million protein structures, compared to only 150,000 discovered over the previous 60 years <a class="yt-timestamp" data-t="00:18:41">[00:18:41]</a> <a class="yt-timestamp" data-t="16:56:49">[16:56:49]</a>. The first person to reverse engineer a protein took 12 years to do just one <a class="yt-timestamp" data-t="00:03:00">[00:03:00]</a> <a class="yt-timestamp" data-t="16:40:02">[16:40:02]</a>.
    *   This understanding of proteins unlocks "really cool innovation" in [[synthetic_biology | synthetic biology]] <a class="yt-timestamp" data-t="17:23:41">[17:23:41]</a>.
    *   Recent breakthroughs include gene therapy that restored sight to a blind Irishman <a class="yt-timestamp" data-t="05:50:57">[05:50:57]</a> <a class="yt-timestamp" data-t="06:07:07">[06:07:07]</a>, and potential cures for forms of cancer and Alzheimer's <a class="yt-timestamp" data-t="06:35:10">[06:35:10]</a> <a class="yt-timestamp" data-t="17:25:39">[17:25:39]</a>.
    *   It also allows for the creation of new materials, such as protein structures that "eat plastic" in the ocean or highly heat-resistant materials <a class="yt-timestamp" data-t="17:37:37">[17:37:37]</a>.
*   **Science and Research**: Google [[AI agents and their potential impact in 2025 | AI]] has a "co-scientist" that can query the equivalent of 100 PhD students' worth of compute for about 10 cents and 10 minutes, accelerating scientific development <a class="yt-timestamp" data-t="06:51:30">[06:51:30]</a>.
*   **Transportation**:
    *   Autonomous vehicles, like Waymo in San Francisco, are emerging <a class="yt-timestamp" data-t="28:27:07">[28:27:07]</a>. The cost of transportation, currently a few dollars per mile, is expected to drop to "cents" once cars can drive themselves <a class="yt-timestamp" data-t="30:40:15">[30:40:15]</a>. This transforms unproductive travel time into productive time <a class="yt-timestamp" data-t="32:21:40">[32:21:40]</a>.
    *   Supersonic airplanes, such as those by Boom Aerospace, are being developed to fly faster and more efficiently without disturbing sound, potentially at a lower cost and higher safety <a class="yt-timestamp" data-t="34:16:35">[34:16:35]</a>.
*   **Manufacturing and Robotics**:
    *   [[AI in robotics and workforce implications | Humanoid robots]] with general-purpose [[integration_of_human_intelligence_with_AI | intelligence]] are beginning to work in factories, simulating and optimizing production lines <a class="yt-timestamp" data-t="38:03:59">[38:03:59]</a>.
    *   [[AI]] can perform numerous design iterations, allowing the "first version to actually be the fourth version" or the local maximum of what's possible <a class="yt-timestamp" data-t="38:40:55">[38:40:55]</a>.
    *   This will allow robots to perform "all the harmful jobs" and "less favorable things in life" that humans don't want to do <a class="yt-timestamp" data-t="01:05:27">[01:05:27]</a>.

### Economic Implications: Rapid Deflation

The application of [[integration_of_human_intelligence_with_AI | intelligence]] to industries outside of pure technology will lead to "rapid deflation" <a class="yt-timestamp" data-t="21:26:07">[21:26:07]</a>. Historically, deflation has primarily been seen in technology (e.g., phones, TVs becoming cheaper and more accessible) <a class="yt-timestamp" data-t="22:36:06">[22:36:06]</a>. As [[AI]] allows for overproduction and surplus in various sectors, the "downstream effects of that are more abundance, more surplus, and a lower cost of goods, a higher quality of living" <a class="yt-timestamp" data-t="23:04:19">[23:04:19]</a>.

### Energy: The Foundational Layer

Energy is considered an even more fundamental prerequisite than [[integration_of_human_intelligence_with_AI | intelligence]] itself, as it powers all intelligent systems <a class="yt-timestamp" data-t="36:32:02">[36:32:02]</a>. The correlation between a country's electricity consumption per capita and its GDP per capita is "perfectly linear" <a class="yt-timestamp" data-t="48:08:42">[48:08:42]</a>, indicating that "if you have more energy, your country is more wealthy" <a class="yt-timestamp" data-t="48:16:11">[48:16:11]</a>.

> "Nothing is really a resource until we assign the knowledge to it that it is a resource" <a class="yt-timestamp" data-t="37:27:26">[37:27:26]</a>.

Higher [[integration_of_human_intelligence_with_AI | intelligence]] enables access to more abundant energy sources, like extracting thorium and uranium from common rocks, which contain more potential energy than coal but require knowledge to process <a class="yt-timestamp" data-t="36:54:19">[36:54:19]</a>. The current move towards modular, safe nuclear reactors (Gen 4 reactors like those by Valor Electronics) is seen as the "end game" for energy, providing meltdown-proof, self-sufficient power <a class="yt-timestamp" data-t="50:07:07">[50:07:07]</a>.

## Job Market Evolution

The common concern that [[AI]] will "take my job" is met with the idea of "creative destruction" <a class="yt-timestamp" data-t="28:03:59">[28:03:59]</a>. While some jobs may be eliminated, new opportunities will be created, similar to how the internet led to new economies like YouTubers and influencers <a class="yt-timestamp" data-t="27:58:34">[27:58:34]</a>.

The fundamental shift is that [[AI]] solves problems, leading to a "more exciting world" <a class="yt-timestamp" data-t="29:21:40">[29:21:40]</a>. Solving bad problems creates "more problems, but these are problems to solve," implying a progression to more interesting and complex challenges <a class="yt-timestamp" data-t="29:27:07">[29:27:07]</a>. This mirrors historical shifts like the Agricultural and Industrial Revolutions, where initial job displacement led to vastly higher productive output and new industries <a class="yt-timestamp" data-t="29:38:43">[29:38:43]</a>.

## Concerns and the "Defensive Acceleration" Ethos

A significant concern is the potential for "outsized destruction" by individuals due to the "abundance of technology," low cost of technology, and cheap access to [[integration_of_human_intelligence_with_AI | information]]/[[integration_of_human_intelligence_with_AI | intelligence]] <a class="yt-timestamp" data-t="55:16:04">[55:16:04]</a>. This idea was foreseen by Ted Kaczynski (the Unabomber) <a class="yt-timestamp" data-t="55:10:48">[55:10:48]</a>.

However, the prevailing optimistic view is that "defense is always slightly easier than offense" in both software and hardware <a class="yt-timestamp" data-t="57:11:00">[57:11:00]</a>. While acknowledging that "bad things" will happen <a class="yt-timestamp" data-t="58:38:43">[58:38:43]</a>, the hope is that the "tradeoffs for making things better for moving faster will offset the downside of those few bad actors" <a class="yt-timestamp" data-t="58:45:00">[58:45:00]</a>. This aligns with the concept of "defensive acceleration," where technologies that are inherently defensive (e.g., cryptography, peer assets) are prioritized <a class="yt-timestamp" data-t="01:01:10">[01:01:10]</a>. Major [[AI]] labs are also "super concerned about alignment and safety" <a class="yt-timestamp" data-t="58:13:08">[58:13:08]</a>. Ultimately, the idea is to continue progress while being "very careful about the edge cases that can harm people" <a class="yt-timestamp" data-t="58:05:47">[58:05:47]</a>.