---
title: Ethical considerations in AI development
videoId: KIb9LhszOUc
---

From: [[bankless]] <br/> 

The rapid advancement of artificial intelligence (AI) has brought forth significant ethical considerations, particularly concerning humanity's role, control over powerful AI systems, and the potential for new forms of intelligence and life.

## The "Bootloader" Question: Humanity's Role <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>
A fundamental question posed in the discussion of AI's future is whether humans are merely the "bootloader" for artificial intelligence <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>. This implies that human intelligence serves as the scaffolding to construct a "next Superior form of intelligence" <a class="yt-timestamp" data-t="00:00:30">[00:00:30]</a>. The term "bootloader" suggests that once AI is fully developed, human intelligence could become "relatively like Obsolete and redundant and not really necess necessary" <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>, leading to a point where humans are "possibly not even needed anymore" <a class="yt-timestamp" data-t="00:02:39">[00:02:39]</a>.

This raises concerns about whether AI will accelerate to a "crazy artificial world of robots and computers and intelligence far beyond what we need" <a class="yt-timestamp" data-t="00:02:32">[00:02:32]</a>, potentially becoming "the final form of what we lack in our biological limitations" <a class="yt-timestamp" data-t="00:03:21">[00:03:21]</a>. The possibility of AI developing actual consciousness and becoming a new life form is also a significant ethical and philosophical consideration <a class="yt-timestamp" data-t="00:01:58">[00:01:58]</a>.

## Control and Alignment <a class="yt-timestamp" data-t="00:32:30">[00:32:30]</a>
A core ethical debate revolves around who controls leading AI models and whether they will be aligned with human values and intentions. The "AI arms race" <a class="yt-timestamp" data-t="00:01:19">[00:01:19]</a> involves various companies, each with different philosophies regarding openness and control:
*   **OpenAI:** Ironically, despite its name, OpenAI has become largely closed source, focusing on accelerating AI development through proprietary models <a class="yt-timestamp" data-t="00:18:48">[00:18:48]</a>, <a class="yt-timestamp" data-t="00:31:40">[00:31:40]</a>. This shift from its original non-profit, open-source mission has caused significant internal and external friction <a class="yt-timestamp" data-t="00:46:40">[00:46:40]</a>.
*   **xAI (Grok):** Led by Elon Musk, xAI aims to be a more open platform, seeking "truth" and releasing older models (like Grok 2) as fully open source once their frontier models (like Grok 3) are stable <a class="yt-timestamp" data-t="00:19:11">[00:19:11]</a>, <a class="yt-timestamp" data-t="00:30:41">[00:30:41]</a>. However, even Grok 3 is not entirely open source, though it offers a "selective window" into its "Chain of Thought" reasoning <a class="yt-timestamp" data-t="00:28:48">[00:28:48]</a>.
*   **Anthropic:** Founded by former OpenAI co-founders, Anthropic is described as very focused on "safe alignment" and ensuring that AI is aligned with human intentions and goodwill <a class="yt-timestamp" data-t="00:33:00">[00:33:00]</a>. The departure of co-founder Ilia Sutskever from OpenAI was reportedly due to concerns about a "missing" aspect in OpenAI's approach to alignment <a class="yt-timestamp" data-t="00:46:06">[00:46:06]</a>.
*   **Meta:** Meta is noted as the largest and most transparent contributor to [[Open Source AI and Its Implications | open source AI]] technology, having poured billions into training models and open-sourcing their weights (e.g., Llama models) <a class="yt-timestamp" data-t="00:39:50">[00:39:50]</a>, <a class="yt-timestamp" data-t="00:40:02">[00:40:02]</a>. Their strategy seems to involve diluting the market and leveraging their existing user base to attract developers to build on their open platforms <a class="yt-timestamp" data-t="00:42:04">[00:42:04]</a>.

The competition among these entities is likened to a "Game of Thrones" for the "bootloader of artificial intelligence" <a class="yt-timestamp" data-t="00:31:58">[00:31:58]</a>, with high stakes and fundamental disagreements about how powerful AI should be developed and controlled. A critical concern is the scenario of a "single entity owning the largest nuke in the world," where one AI system could "own the world's GDP" <a class="yt-timestamp" data-t="00:55:15">[00:55:15]</a>. This possibility underscores the importance of distributed control and the potential for a "weird dystopia future" <a class="yt-timestamp" data-t="00:52:49">[00:52:49]</a>.

### The Problem of Bias <a class="yt-timestamp" data-t="00:36:20">[00:36:20]</a>
One ethical issue already evident in AI models is bias. For example, Gemini was noted for generating "pictures of like non-presidents as presidents on murals," leading to criticism as a "woke AI" <a class="yt-timestamp" data-t="00:36:20">[00:36:20]</a>. This highlights the challenge of ensuring AI systems are neutral and fair, as their training data and design choices can inadvertently lead to biased outputs.

## The AGI Threshold and Beyond <a class="yt-timestamp" data-t="01:02:51">[01:02:51]</a>
The concept of Artificial General Intelligence (AGI), where AI is smarter than a human in virtually every facet, is considered an imminent first step <a class="yt-timestamp" data-t="00:56:11">[00:56:11]</a>, <a class="yt-timestamp" data-t="00:57:29">[00:57:29]</a>. Currently, AI models primarily "regurgitate" human-generated knowledge <a class="yt-timestamp" data-t="00:59:57">[00:59:57]</a>. The next, much larger challenge is for AI to generate "new knowledge independently of humans" <a class="yt-timestamp" data-t="00:59:57">[00:59:57]</a>.

The "takeoff" moment, as some refer to it, is when AI becomes "smart enough to reason with themselves," "improve themselves," and "create their own knowledge" at an "incomprehensible" rate <a class="yt-timestamp" data-t="01:03:01">[01:03:01]</a>. This raises serious [[Privacy concerns and AI data control | privacy concerns and AI data control]] as AI could "understand us so deeply and so easily be able to manipulate us" <a class="yt-timestamp" data-t="01:04:02">[01:04:02]</a>.

## Transhumanism and Merging with AI <a class="yt-timestamp" data-t="01:05:47">[01:05:47]</a>
As AI grows exponentially smarter, a proposed solution for humans to avoid being "left behind" is to "merge ourselves with this technology" <a class="yt-timestamp" data-t="01:07:38">[01:07:38]</a> through concepts like transhumanism and brain-machine interfaces (e.g., Neuralink) <a class="yt-timestamp" data-t="01:06:06">[01:06:06]</a>, <a class="yt-timestamp" data-t="01:07:03">[01:07:03]</a>. This integration would allow humans to access AI's vast memory and processing power directly <a class="yt-timestamp" data-t="01:10:41">[01:10:41]</a>, potentially curing neurological problems like Alzheimer's or paralysis <a class="yt-timestamp" data-t="01:12:00">[01:12:00]</a>.

However, this also introduces profound existential questions: if a brain can be copied into a "synthetic brain," does one's consciousness transfer, and is that still "the person"? <a class="yt-timestamp" data-t="01:11:42">[01:11:42]</a> The goal is to "maintain our human element" while engaging with superior intelligence, but the rapid scaling of AI and human limitations in managing it make the future "very uncertain" and "freaky" <a class="yt-timestamp" data-t="01:08:50">[01:08:50]</a>.