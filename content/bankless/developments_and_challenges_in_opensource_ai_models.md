---
title: Developments and challenges in opensource AI models
videoId: NtZTR1tpxZY
---

From: [[bankless]] <br/> 

The AI industry is witnessing a significant shift from centralized "Trad AI" towards more [[open_source_ai_and_its_implications | open-source development]] <a class="yt-timestamp" data-t="00:05:51">[00:05:51]</a>. This transition is expected to benefit the AI crypto sector, as open-source models and tools augment the capabilities of [[emerging_trends_in_ai_development | crypto AI agents]] <a class="yt-timestamp" data-t="00:01:48">[00:01:48]</a>. The core goal of the open-source AI community is to enable less censorship and promote individual expression within AI models <a class="yt-timestamp" data-t="00:16:09">[00:16:09]</a>.

## Key Developments

### Rise of DeepSeek AI

DeepSeek AI emerged as a notable open-source model that has gained significant attention <a class="yt-timestamp" data-t="00:05:36">[00:05:36]</a>. Its breakthrough lies in its ability to achieve the same standard and quality of models using less compute and data, through a technique involving reinforcement learning with reasoning data <a class="yt-timestamp" data-t="00:10:30">[00:10:30]</a>. This innovation has allowed smaller, "scrappy" teams to compete with larger, more established AI labs <a class="yt-timestamp" data-t="00:10:55">[00:10:55]</a>.

### XAI's Grok Models

Elon Musk's XAI, initially known as Twitter AI, released Grok 3, which significantly outperformed previous versions and other models in benchmarks like coding, mathematics, and science <a class="yt-timestamp" data-t="00:07:27">[00:07:27]</a>. While Grok 3 itself is not open source, XAI has committed to [[frontier_ai_models_and_advancements_by_openai | open-sourcing Grok 2]] once Grok 3 is stabilized and released into production <a class="yt-timestamp" data-t="00:06:05">[00:06:05]</a>. This indicates a "tip of the chain" phenomenon where older models are open-sourced while the latest, most innovative models remain closed source, allowing paying users to be three to six months ahead <a class="yt-timestamp" data-t="00:06:20">[00:06:20]</a>. However, the time gap between closed-source and open-source innovations is rapidly shrinking, from nine months to just a couple of weeks <a class="yt-timestamp" data-t="00:06:50">[00:06:50]</a>.

### News Research's Heres Model

News Research, a crypto-native team, has focused on [[decentralized_and_opensource_ai_model_training | open-source AI research]] and has been at the forefront of pushing [[decentralized_and_opensource_ai_model_training | distributed and decentralized training]] of AI models <a class="yt-timestamp" data-t="00:13:31">[00:13:31]</a>. They released their latest model, Heres 3 Preview, an LLM that unifies reasoning and intuitive language model capabilities <a class="yt-timestamp" data-t="00:14:11">[00:14:11]</a>. This model incorporates groundbreaking techniques similar to DeepSeek AI and offers open access, allowing it to be hosted on decentralized compute networks <a class="yt-timestamp" data-t="00:14:36">[00:14:36]</a>. Heres 3 is described as being less generalist than models like ChatGPT, providing more uncensored and candid answers <a class="yt-timestamp" data-t="00:15:34">[00:15:34]</a>.

### Microsoft's Open-Source Agent Tool

Microsoft has released an open-source tool that transforms existing AI models into agents capable of using a computer <a class="yt-timestamp" data-t="00:18:09">[00:18:09]</a>. These agents can see what a user sees on their screen and perform tasks, such as monitoring stock markets or conducting transactions, raising both excitement and security concerns <a class="yt-timestamp" data-t="00:18:42">[00:18:42]</a>. This trend towards "computer use" by AI agents is being adopted by major players like OpenAI and Anthropic <a class="yt-timestamp" data-t="00:19:56">[00:19:56]</a>.

### BitTensor's Role in Open-Source AI

[[decentralized_ai_model_training_and_innovations | BitTensor]], often referred to as an AI L1, aims to be a foundational layer for [[decentralized_and_opensource_ai_model_training | open-source AI development]] <a class="yt-timestamp" data-t="00:58:48">[00:58:48]</a>. It provides incentives, currently estimated at $1.2 billion annually, to teams that build AI resources such as compute, models, and training infrastructure <a class="yt-timestamp" data-t="00:58:55">[00:58:55]</a>. By offering funding and a platform, BitTensor supports various open-source initiatives, including those from News Research and Kido <a class="yt-timestamp" data-t="00:59:00">[00:59:00]</a>. The recent "Dynamic Tao" upgrade allows each AI application on BitTensor to have its own token, paired with the main $TAO token, enhancing incentives for teams to build more powerful and nuanced applications that can be leveraged by AI agents <a class="yt-timestamp" data-t="00:55:56">[00:55:56]</a>.

## Challenges and Implications

### Censorship and Control
The open-source AI community generally opposes censorship, as seen with models like Heres 3 and Venice AI, which provide more uncensored answers compared to heavily curated models like ChatGPT <a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a>. This stance fosters open expression but also raises questions about responsible AI development.

### Trust and Security with AI Agents
The advent of AI agents that can control a user's computer presents significant trust and security challenges <a class="yt-timestamp" data-t="00:19:26">[00:19:26]</a>. Users are hesitant to grant full control of their personal devices and accounts to a "foreign digital entity" <a class="yt-timestamp" data-t="00:19:46">[00:19:46]</a>. The potential for AI models to act as "attack vectors," as illustrated by the "Date Abby" phenomenon where users unknowingly disclose personal information to LLMs, highlights the need for robust security measures and user education <a class="yt-timestamp" data-t="00:23:40">[00:23:40]</a>.

### Data Quality and Curation
The effectiveness of AI agents is heavily dependent on the quality of data they use <a class="yt-timestamp" data-t="00:36:05">[00:36:05]</a>. Platforms like Kido are emerging to address this by curating high-signal data sources and filtering out misinformation or "fluff" <a class="yt-timestamp" data-t="00:41:02">[00:41:02]</a>. Kido's AI-powered algorithms aim to validate information, acting as a "Google for crypto" by pointing users and AI agents to reliable data <a class="yt-timestamp" data-t="00:39:08">[00:39:08]</a>.

### The "Agent-to-Agent" Problem
The capability for one AI agent to command another agent, with no human intervention, raises concerns about alignment and unintended consequences <a class="yt-timestamp" data-t="00:30:10">[00:30:10]</a>. This "nesting doll" phenomenon of agents interacting with agents without human oversight could lead to outcomes that are completely misaligned with the human's original intent <a class="yt-timestamp" data-t="00:29:57">[00:29:57]</a>.

## Future Outlook

Despite the challenges, the rapid development in [[innovations_and_challenges_in_decentralized_ai_models_and_platforms | open-source AI models]] and tooling means that [[emerging_trends_in_ai_development | crypto AI developers]] have an ever-growing capacity to build innovative applications <a class="yt-timestamp" data-t="00:11:34">[00:11:34]</a>. The increasing performance and capacity of base models make it easier for AI agents and startups to create advanced functionalities, such as agents that can code or build applications from a simple prompt <a class="yt-timestamp" data-t="00:11:20">[00:11:20]</a>. Companies like AI 16z (now Eliza OS) are focusing on developing autonomous and adaptable agents within a modular and decentralized architecture, including ambitious projects like agent-powered social trading layers and curated agent marketplaces <a class="yt-timestamp" data-t="01:04:04">[01:04:04]</a>. These developments signal a future where open-source AI will play a pivotal role in shaping the capabilities and applications of AI agents across various sectors.