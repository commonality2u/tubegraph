---
title: The potential of AI to enhance human agency and freedom
videoId: vMzfav01Cc0
---

From: [[bankless]] <br/> 

Reed Hoffman, co-founder of LinkedIn and author of "Superintelligence," offers a bullish perspective on artificial intelligence, viewing it as a powerful force for individual empowerment and societal advancement. His central thesis revolves around the concept of "super agency," where AI amplifies human capabilities rather than diminishing them <a class="yt-timestamp" data-t="00:01:00">[00:01:00]</a>.

## Defining Agency and Super Agency

**Agency** is defined as the ability to make plans, act upon intentions and desires, and express oneself in the world <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>. While no one possesses perfect agency, **super agency** occurs when millions of human beings gain access to transformative technology that provides them with "superpowers" <a class="yt-timestamp" data-t="00:07:48">[00:07:48]</a>.

A canonical example is the automobile: cars gave individuals the superpower to travel farther. When many people gained cars, society transformed, enabling new services like doctors visiting homes or in-car deliveries, ultimately increasing everyone's agency <a class="yt-timestamp" data-t="00:08:07">[00:08:07]</a>. In the context of AI, Hoffman contends that both humans and AI become super agents, with the emphasis being on humanity *gaining* agency <a class="yt-timestamp" data-t="00:08:42">[00:08:42]</a>. This means humans acquire new abilities and choice surface area that previous generations could not imagine <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a>.

## AI as a Democratizing Force

Hoffman views AI as a [[reid_hoffmans_perspective_on_ai_as_a_democratizing_force | democratizing technology]], similar to how smartphones became widely accessible <a class="yt-timestamp" data-t="00:17:32">[00:17:32]</a>. He notes that hundreds of millions of people are already using AI tools like ChatGPT <a class="yt-timestamp" data-t="00:15:02">[00:15:02]</a>, with examples like a taxi driver in Morocco using ChatGPT for translation <a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a>.

While acknowledging that wealth and power disparities will persist, Hoffman is optimistic that the "natural drive in technology" is to build for the mass market <a class="yt-timestamp" data-t="00:16:57">[00:16:57]</a>. Just as a smartphone is the same for a CEO and an Uber driver, he believes AI "superpowers" will be broadly available <a class="yt-timestamp" data-t="00:16:41">[00:16:41]</a>. This contrasts with concerns that AI might be controlled by a small cabal or governments, as the Silicon Valley ecosystem, which previously democratized the internet and smartphones, is now building AI for billions <a class="yt-timestamp" data-t="00:18:00">[00:18:00]</a>.

## Different Perspectives on AI: The "AI Religions"

Hoffman categorizes prevalent viewpoints on AI into four "religions" or ideologies:

*   **Doomers**: Believe AI will lead to the destruction of humanity, similar to "Terminator" scenarios, and should be stopped <a class="yt-timestamp" data-t="00:20:12">[00:20:12]</a>.
*   **Gloomers**: See a generally negative future for AI, predicting job displacement, increased misinformation, and enhanced surveillance, though they acknowledge it's unstoppable <a class="yt-timestamp" data-t="00:20:41">[00:20:41]</a>. This often aligns with mainstream media narratives <a class="yt-timestamp" data-t="00:27:00">[00:27:00]</a>.
*   **Zoomers**: Are maximally optimistic, believing AI will lead to spectacular outcomes like inventing fusion and that everything built with it will be amazing. They advocate for rapid acceleration ("just go forward, go fast") <a class="yt-timestamp" data-t="00:21:42">[00:21:42]</a>. This aligns with "Effective Accelerationists" <a class="yt-timestamp" data-t="00:24:53">[00:24:53]</a>.
*   **Bloomers**: (Hoffman's self-identified category) Share the Zoomer's accelerationist drive but emphasize intelligent navigation, avoiding pitfalls, and addressing dangers. They believe in building a positive future by intentional steering <a class="yt-timestamp" data-t="00:22:14">[00:22:14]</a>.

## Addressing Criticisms: The "Doomers" and "Gloomers"

### Countering the Doomer Perspective
Hoffman argues that the "Doomer" focus on AI as the sole existential risk is a mistake <a class="yt-timestamp" data-t="00:41:22">[00:41:22]</a>. Existential risk should be viewed as a portfolio, including pandemics, asteroids, nuclear weapons, and climate change <a class="yt-timestamp" data-t="00:42:11">[00:42:11]</a>. Hoffman's "vigorous and strong contention" is that AI, even unmodified, is "very positive on the existential risk portfolio" <a class="yt-timestamp" data-t="00:42:25">[00:42:25]</a>.

For instance, AI can be crucial for detecting and analyzing pandemics, and for rapidly developing therapeutics and vaccines <a class="yt-timestamp" data-t="00:42:54">[00:42:54]</a>. It can help identify and intervene on asteroids <a class="yt-timestamp" data-t="00:43:12">[00:43:12]</a>, and for climate change, it can accelerate fusion invention or better manage electric grids <a class="yt-timestamp" data-t="00:43:20">[00:43:20]</a>. Therefore, even a "full speed ahead" approach to AI development is net positive for humanity's survival <a class="yt-timestamp" data-t="00:43:53">[00:43:53]</a>. While minimizing risks like "killer robots" is important, AI itself can be part of the solution <a class="yt-timestamp" data-t="00:44:26">[00:44:26]</a>.

### Acknowledging Gloomer Concerns and the "Innovation as Safety" Argument
Hoffman is "very sympathetic" to the "Gloomer" view that the transition to new technologies is often painful for human societies <a class="yt-timestamp" data-t="00:45:06">[00:45:06]</a>. He cites the printing press, which, despite enabling science and literacy, led to a century of religious war <a class="yt-timestamp" data-t="00:45:27">[00:45:27]</a>. Similarly, AI will cause job transitions and transformations, and changes in information flows and privacy expectations <a class="yt-timestamp" data-t="00:46:57">[00:46:57]</a>. His goal with the "Bloomer" approach is to make this transition as graceful as possible by being intentional about "what could possibly go right" <a class="yt-timestamp" data-t="00:45:58">[00:45:58]</a>.

Hoffman advocates for **"innovation as safety"** <a class="yt-timestamp" data-t="01:03:17">[01:03:17]</a>. He compares this to car safety: features like anti-lock brakes, seatbelts, and crumple zones were innovations that made cars safer and allowed them to go faster <a class="yt-timestamp" data-t="01:03:41">[01:03:41]</a>. Similarly, future AI features will inherently build in safety measures. This is discovered through iterative deployment and learning from real-world use <a class="yt-timestamp" data-t="01:05:06">[01:05:06]</a>. The goal is to ensure AI agents are no more capable of misuse (e.g., by terrorists) than existing technologies like Google search <a class="yt-timestamp" data-t="01:05:30">[01:05:30]</a>.

## Examples of AI Enhancing Agency

Hoffman envisions a future where AI significantly enhances individual agency and quality of life. Even if large language models (LLMs) do not improve beyond their current state, the consumer surplus for an average 20-year-old living today is "millions of dollars over their lifetime" <a class="yt-timestamp" data-t="00:59:54">[00:59:54]</a>.

Examples include:
*   **Legal Assistance**: AI can provide useful analysis for understanding employment or rental contracts, making legal assistance accessible to those who cannot afford lawyers <a class="yt-timestamp" data-t="01:00:31">[01:00:31]</a>.
*   **Medical Assistants**: An AI medical assistant, "better than your average doctor," could be available 24/7 in every pocket, offering immediate health advice, including critical warnings to go to an emergency room <a class="yt-timestamp" data-t="00:49:01">[00:49:01]</a>. Such preventative care could lead to longer lifespans <a class="yt-timestamp" data-t="01:01:50">[01:01:50]</a>.
*   **Personal Tutors**: AI can serve as a tutor on any subject for every age, from 2 to 82 years old, fostering learning and understanding <a class="yt-timestamp" data-t="00:49:24">[00:49:24]</a>.
*   **Productivity Amplification**: AI can accelerate and amplify professional work, helping with coding, marketing plans, sales, and shifting time from "form entry" to more fulfilling, productive tasks <a class="yt-timestamp" data-t="00:52:51">[00:52:51]</a>.

On a societal level, Hoffman believes AI will lead to "much greater happiness" and more fulfilling lives <a class="yt-timestamp" data-t="00:51:59">[00:51:59]</a>. He suggests AI agents can encourage real-world social interaction by prompting users to meet friends in person <a class="yt-timestamp" data-t="00:51:45">[00:51:45]</a>. Overall, he asserts that the quality of life will be significantly better, just as the 2020s are undeniably better than the 1920s with advancements like antibiotics <a class="yt-timestamp" data-t="00:53:12">[00:53:12]</a>.

### The "Bait and Switch" Objection
Some critics fear a "bait and switch" where free AI services eventually lead to data exploitation and control, similar to concerns about social media <a class="yt-timestamp" data-t="00:53:54">[00:53:54]</a>. Hoffman counters this by likening it to Google's advertising model: users receive "amazing free services" in exchange for data, which is a voluntary transaction <a class="yt-timestamp" data-t="00:56:21">[00:56:21]</a>. He suggests future AI agents might operate on similar models or subscriptions, emphasizing that the value exchange should be transparent and voluntary <a class="yt-timestamp" data-t="00:57:00">[00:57:00]</a>. He challenges the "surveillance capitalism" narrative, arguing that data usage can be beneficial, like health tracking on a smartwatch <a class="yt-timestamp" data-t="00:57:56">[00:57:56]</a>.

Regarding the concern that AI "kills human autonomy" by making decisions, Hoffman reiterates that agency changes, rather than disappears <a class="yt-timestamp" data-t="01:07:37">[01:07:37]</a>. While meeting a spouse via algorithm might have seemed dystopian in the 1960s, it's common today, and many view it as an improvement over previous "lottery" methods of finding partners <a class="yt-timestamp" data-t="01:06:56">[01:06:56]</a>.

## AI and American Values

Hoffman has begun referring to artificial intelligence as "American intelligence" because he believes it's crucial for the United States to embrace this "cognitive Industrial Revolution" <a class="yt-timestamp" data-t="01:11:08">[01:11:08]</a>. Societies that embraced the original Industrial Revolution experienced prosperity <a class="yt-timestamp" data-t="01:11:20">[01:11:20]</a>. He believes that embedding "American values"—such as the American dream, empowerment of individuals, and the ability to progress economically—into AI development is vital <a class="yt-timestamp" data-t="01:11:42">[01:11:42]</a>. This perspective informs his view that regulatory stances should be "Bloomer Zoomer and accelerationist," rather than focused on putting on the brakes <a class="yt-timestamp" data-t="01:12:14">[01:12:14]</a>.

## Future Outlook

Hoffman asserts there is "zero chance" that AI innovation will flatline or significantly slow down <a class="yt-timestamp" data-t="01:12:53">[01:12:53]</a>. He points to the visible presence of technology in large-scale computing and learning systems. He predicts 2025 will see an acceleration in software coding driven by AI, which will serve as a template for advancing many other functions <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>. Even if cognitive capabilities improve only modestly, the implications throughout the "cognitive Industrial Revolution" are profound and already visibly present <a class="yt-timestamp" data-t="01:13:53">[01:13:53]</a>. The future of AI is about how it is built, configured, deployed, and integrated <a class="yt-timestamp" data-t="01:13:58">[01:13:58]</a>.