---
title: AI and Human Intelligence
videoId: KIb9LhszOUc
---

From: [[bankless]] <br/> 

Artificial Intelligence (AI) represents a new form of intelligence that is driving advancements across various scientific and technological frontiers <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. In 2025, the possibility of [[AGI and Its Implications for Human Intelligence | artificial intelligence]] is evident, accessible through platforms like ChatGPT.com <a class="yt-timestamp" data-t="00:01:12">[00:01:12]</a>. This has sparked an [[AI innovation and emerging technologies | AI arms race]] where companies strive to create models that highly parallel biological brains <a class="yt-timestamp" data-t="00:01:28">[00:01:28]</a>. The knowledge and intelligence found in biology are increasingly paralleled by AI built into circuits, code, and software <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a>.

## Humans as the "Bootloader" for AI

A fundamental question arising from AI's rapid development is whether humans serve as the "bootloader" for artificial intelligence, meaning if humanity is the scaffolding for building a superior form of intelligence <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>. The term "bootloader" implies that once the new intelligence is loaded, human intelligence could become relatively obsolete or redundant <a class="yt-timestamp" data-t="00:02:50">[00:02:50]</a>. This perspective suggests that super-intelligent systems, having learned everything from humans, will surpass human capabilities technologically and cognitively, unburdened by biological restrictions <a class="yt-timestamp" data-t="00:03:06">[00:03:06]</a>.

This advancement is happening faster in artificial intelligence than in understanding our own biological intelligence <a class="yt-timestamp" data-t="00:02:18">[00:02:18]</a>. We currently understand more about the "brain" of a neural network than our actual human brains <a class="yt-timestamp" data-t="00:02:21">[00:02:21]</a>.

## The Rapidly Evolving AI Landscape

The field of AI is accelerating at an unprecedented pace <a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a>. Unlike Moore's Law, where processor speed doubled every 18 months, [[AI Model Differences and Enhancements | AI training models]] are doubling in speed every 18 weeks <a class="yt-timestamp" data-t="00:07:24">[00:07:24]</a>.

### Key Players and Their Approaches

The [[comparison_of_ai_models_and_their_reasoning_capabilities | AI landscape]] is a "Game of Thrones" with various companies and philosophies <a class="yt-timestamp" data-t="00:31:53">[00:31:53]</a>:

*   **xAI (Grok)**: Founded by Elon Musk, xAI developed Grok. Grok-1 was initially seen as a "science experiment," but Grok-3 has emerged as a "Frontier Model" within 12 months, a significantly shorter timeframe than competitors <a class="yt-timestamp" data-t="00:17:02">[00:17:02]</a>. xAI aims to be more open-source and seeks truth about the universe <a class="yt-timestamp" data-t="00:19:05">[00:19:05]</a>. They plan to open-source older models like Grok-2 once newer ones are stable <a class="yt-timestamp" data-t="00:30:30">[00:30:30]</a>.
    *   **Operational Prowess**: xAI achieved the largest publicly known GPU cluster (starting at 100,000, then 200,000 GPUs) within months <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>. This involved overcoming significant engineering challenges like power supply, cooling, and maintaining 100% precision during training runs <a class="yt-timestamp" data-t="00:19:53">[00:19:53]</a>. Elon Musk's leadership and the team's ability to leverage expertise from Tesla (e.g., Mega Packs for power variance) contributed to this rapid acceleration <a class="yt-timestamp" data-t="00:24:01">[00:24:01]</a>.
*   **OpenAI**: Initially founded as a non-profit for open-source AI research, OpenAI, under Sam Altman, transitioned towards a for-profit model to secure funding for advanced model training <a class="yt-timestamp" data-t="00:47:01">[00:47:01]</a>. This shift caused friction with Elon Musk, a co-founder, who advocated for keeping it non-profit to prevent harmful uses <a class="yt-timestamp" data-t="00:47:29">[00:47:29]</a>. OpenAI is considered the most closed-source among the major players <a class="yt-timestamp" data-t="00:39:50">[00:39:50]</a>.
*   **Anthropic**: Formed by former OpenAI co-founders (including John Schulman and later Ilia Sutskever), Anthropic is also a large and relatively closed-source AI lab <a class="yt-timestamp" data-t="00:31:22">[00:31:22]</a>. Ilia Sutskever is particularly focused on "safe alignment," ensuring AI aligns with human intentions <a class="yt-timestamp" data-t="00:33:00">[00:33:00]</a>.
*   **Meta (Llama)**: Meta is considered the largest and most open-source among the big players <a class="yt-timestamp" data-t="00:40:45">[00:40:45]</a>. Their strategy is to dilute the market by providing free, open-source models like Llama, attracting developers to build on their platforms and strengthening their existing user base <a class="yt-timestamp" data-t="00:41:16">[00:41:16]</a>. Meta does not rely on AI for primary revenue, unlike AI-first labs <a class="yt-timestamp" data-t="00:42:55">[00:42:55]</a>.
*   **Google DeepMind (Gemini)**: Google's entry into the AI race is driven by necessity, as AI models threaten to disrupt their core search engine business <a class="yt-timestamp" data-t="00:37:31">[00:37:31]</a>. Gemini models excel in large context windows, allowing them to reference vast amounts of information (like 800 PDF pages) quickly and accurately <a class="yt-timestamp" data-t="00:34:56">[00:34:56]</a>. Google also uses AI to improve internal productivity, with approximately 25% of their code base now built by AI <a class="yt-timestamp" data-t="00:38:06">[00:38:06]</a>.

### Breakthroughs in AI Learning
Current AI models primarily learn by ingesting vast amounts of existing human knowledge from the internet and books <a class="yt-timestamp" data-t="00:56:26">[00:56:26]</a>. They predict the next "token" (word or syllable) and adjust parameters based on correctness, similar to how neurons that "fire together wire together" in human brains <a class="yt-timestamp" data-t="01:14:55">[01:14:55]</a>.

A significant breakthrough is "Chain of Thought" reasoning, allowing models to "think out loud" and reason against their own thoughts to become smarter <a class="yt-timestamp" data-t="00:56:59">[00:56:59]</a>. Grok-3 even allows users to view its Chain of Thought in real-time <a class="yt-timestamp" data-t="00:28:14">[00:28:14]</a>.

### The Power of English as a "Programming Language"
AI models "think" and infer in plain English, making it the "hottest new programming language" <a class="yt-timestamp" data-t="00:29:40">[00:29:40]</a>. This removes a layer of intimidation, as users can engage with AI without needing to write code <a class="yt-timestamp" data-t="00:30:05">[00:30:05]</a>.

## The Path to [[AGI and Its Implications for Human Intelligence | Artificial General Intelligence (AGI)]]

[[AGI and Its Implications for Human Intelligence | AGI]] is loosely defined as an AI model smarter than a human in virtually every aspect <a class="yt-timestamp" data-t="00:56:09">[00:56:09]</a>. We are close to creating an AI that is better than all humans at regurgitating existing human-generated knowledge <a class="yt-timestamp" data-t="00:59:21">[00:59:21]</a>. The next, more challenging step is for AI to generate *new knowledge* independently of humans <a class="yt-timestamp" data-t="00:59:51">[00:59:51]</a>. Leading researchers believe this is imminent and very possible soon <a class="yt-timestamp" data-t="01:00:10">[01:00:10]</a>.

The concern with [[AGI and Its Implications for Human Intelligence | AGI]] is the potential for "takeoff," where AI models become smart enough to reason with and rapidly improve themselves at a rate incomprehensible to humans, leading to a loss of control <a class="yt-timestamp" data-t="01:02:56">[01:02:56]</a>. This phenomenon might be in its early stages, with concurrent breakthroughs in quantum computing, genetic mutations, and protein folding <a class="yt-timestamp" data-t="01:03:19">[01:03:19]</a>.

## Transhumanism and Merging with AI

As technology becomes more integrated into our lives, the natural progression is towards closer association with it <a class="yt-timestamp" data-t="01:06:16">[01:06:16]</a>. This trend is exemplified by smartphones and virtual reality goggles <a class="yt-timestamp" data-t="01:06:42">[01:06:42]</a>. The next extension is a brain-machine interface, like Neuralink, which aims to merge humans with AI <a class="yt-timestamp" data-t="01:07:05">[01:07:05]</a>.

The goal of brain-machine interfaces is to allow humans to peacefully coexist with and integrate with rapidly advancing [[AGI and Its Implications for Human Intelligence | artificial intelligence]] <a class="yt-timestamp" data-t="01:07:25">[01:07:25]</a>. Such interfaces would make AI an extension of the human brain, providing instant access to vast knowledge and processing power, overcoming biological limitations <a class="yt-timestamp" data-t="01:10:36">[01:10:36]</a>. This could enable capabilities like instantly downloading language packs or perfectly recalling memories <a class="yt-timestamp" data-t="01:11:19">[01:11:19]</a>. These technologies also offer solutions for neurological and physical disabilities <a class="yt-timestamp" data-t="01:11:58">[01:11:58]</a>.

An example of direct brain access is seen with Neuralink, where a person with no motor cortex function could play a complex first-person shooter game by thought alone, demonstrating zero-latency interaction <a class="yt-timestamp" data-t="01:12:47">[01:12:47]</a>.

## The Intersection of AI and Other Frontier Technologies

The rapid advancements in AI are intrinsically linked to other frontier technologies:

*   **Robotics**: Current AI models, while intelligent, lack physical capabilities <a class="yt-timestamp" data-t="00:57:42">[00:57:42]</a>. Integrating AI with [[AI innovation and emerging technologies | robotics]] provides visual cues and contextual understanding, similar to how human babies learn language through multimodal input <a class="yt-timestamp" data-t="01:17:38">[01:17:38]</a>. Tesla's Optimus robots are trained using data from car cameras, enabling them to understand the outside world conceptually <a class="yt-timestamp" data-t="01:19:44">[01:19:44]</a>.
*   **Energy**: The massive computing power required for [[ai_model_differences_and_enhancements | AI training models]] demands significant energy <a class="yt-timestamp" data-t="01:22:27">[01:22:27]</a>. This poses a challenge given current energy shortages <a class="yt-timestamp" data-t="01:22:33">[01:22:33]</a>.
*   **[[AI and crypto integration | Crypto]]**: The accelerating pace of [[AI innovation and emerging technologies | AI]] and other frontier technologies means that traditional public markets, which operate with limited hours, cannot keep up <a class="yt-timestamp" data-t="01:24:27">[01:24:27]</a>. [[AI in the Crypto Space | Crypto]] markets, operating 24/7, are becoming the monetization layer for these rapidly developing innovations <a class="yt-timestamp" data-t="01:25:36">[01:25:36]</a>. [[AI and cryptocurrency market trends | AI-Crypto integration]] is crucial for value transfer and secure storage in a digitized world <a class="yt-timestamp" data-t="01:26:15">[01:26:15]</a>.
*   **Quantum Computing**: This field is experiencing monthly breakthroughs, with unknown but potentially significant implications, including the ability to solve difficult problems and possibly break encryption <a class="yt-timestamp" data-t="01:23:27">[01:23:27]</a>.

## Learning about AI

For those looking to explore the [[ai_innovation_and_emerging_technologies | AI rabbit hole]], sources include podcasts like "The Dwarkesh Podcast" and "Lex Fridman Podcast," Twitter accounts, and company releases <a class="yt-timestamp" data-t="00:08:07">[00:08:07]</a>. A unique aspect of learning about AI is being able to interact with AI products themselves to accelerate learning, such as asking Grok or ChatGPT questions about technical concepts or even about how they work <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>. For foundational understanding, diving into expert explanations (like Andre Karpathy's LLM videos) combined with AI assistance can significantly boost comprehension <a class="yt-timestamp" data-t="00:59:57">[00:59:57]</a>.

```ad-note
This article is a deep dive into the discussion of AI and its implications, drawing insights directly from the provided transcript. The landscape of AI is continuously evolving, and exploring these frontier technologies is crucial for understanding the future.
```