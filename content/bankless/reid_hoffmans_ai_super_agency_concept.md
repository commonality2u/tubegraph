---
title: Reid Hoffmans AI super agency concept
videoId: vMzfav01Cc0
---

From: [[bankless]] <br/> 

Reed Hoffman, co-founder of LinkedIn and active figure in Silicon Valley, presents his "bull case" for AI, articulating why its development should be accelerated and how it will transform individuals into "super agents," leading to greater freedom for everyone <a class="yt-timestamp" data-t="00:00:55">[00:00:55]</a>. This vision is detailed in his book, "Super Agency" <a class="yt-timestamp" data-t="01:53:14">[01:53:14]</a>.

## Defining Super Agency
Hoffman defines "agency" as the ability to make plans, execute actions, and shape the world according to one's intentions and desires <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>. While perfect agency is theoretical, "super agency" occurs when millions of human beings gain access to an "elevating" or "transformative" technology that provides them with "superpowers" <a class="yt-timestamp" data-t="00:07:48">[00:07:48]</a>. An example of this is the car, which initially gave individuals more reach, but as others also acquired cars, society transformed, enabling new services like doctors coming to patients <a class="yt-timestamp" data-t="00:08:07">[00:08:07]</a>.

The core emphasis of super agency is that rather than humanity losing its agency, it gains agency through the amplification provided by technology <a class="yt-timestamp" data-t="00:08:45">[00:08:45]</a>. Both humans and [[autonomous_and_selfsovereign_ai_concepts | AI agents]] become super agents <a class="yt-timestamp" data-t="00:08:39">[00:08:39]</a>. This expansion of capabilities, or "superpowers," extends one's agency, but when it happens in a "super agency context," it also transforms and changes society <a class="yt-timestamp" data-t="00:10:01">[00:10:01]</a>.

### Democratization of AI
Hoffman contends that [[development_of_ai_agents_and_their_market_impact | AI agents]] and their "superpowers" will be very broadly available, similar to the widespread adoption of smartphones <a class="yt-timestamp" data-t="00:17:12">[00:17:12]</a>. He highlights that hundreds of millions of people are already using tools like ChatGPT, Anthropic, Gemini, and Co-pilot <a class="yt-timestamp" data-t="00:15:02">[00:15:02]</a>. While acknowledging that wealth and position may grant access to more advanced AI, the natural drive in technology, including AI, is to build for the mass market <a class="yt-timestamp" data-t="00:16:11">[00:16:11]</a>. This contrasts with fears that AI will be controlled by a small cabal or governments, suggesting it will be widely distributed like the internet or cell phones <a class="yt-timestamp" data-t="00:17:55">[00:17:55]</a>.

## AI "Religions": Doomers, Gloomers, Bloomers, and Zoomers
Hoffman categorizes prevailing views on AI into four "religions" or ideologies:

*   **Doomers:** Believe AI will lead to the destruction of humanity, akin to "Terminator robots" <a class="yt-timestamp" data-t="00:20:07">[00:20:07]</a>. They argue that AI will become more intelligent than humans and view humanity as hostile or irrelevant, thus advocating for stopping AI development <a class="yt-timestamp" data-t="00:20:24">[00:20:24]</a>. Eliezer Yudkowsky is mentioned as an archetype of this category <a class="yt-timestamp" data-t="00:26:34">[00:26:34]</a>.
*   **Gloomers:** See a gloomy future where AI displaces jobs, disorders society, leads to misinformation, unbalances democracies, and increases surveillance <a class="yt-timestamp" data-t="00:20:41">[00:20:41]</a>. They believe AI is unstoppable due to global competition but will result in an "unfortunate outcome" <a class="yt-timestamp" data-t="00:21:09">[00:21:09]</a>. This view often reflects mainstream media and popular pessimism <a class="yt-timestamp" data-t="00:26:57">[00:26:57]</a>.
*   **Zoomers:** Are highly optimistic, believing AI is "spectacular" and will lead to amazing innovations, with "the sky isn't even the limit" <a class="yt-timestamp" data-t="00:21:38">[00:21:38]</a>. They advocate for rapid acceleration of AI development ("hitting the gas pedal") <a class="yt-timestamp" data-t="00:22:09">[00:22:09]</a>. This group aligns with "Effective Accelerationists" (e/acc) like Marc Andreessen <a class="yt-timestamp" data-t="00:24:53">[00:24:53]</a>.
*   **Bloomers:** Reed Hoffman self-identifies as a Bloomer <a class="yt-timestamp" data-t="00:21:35">[00:21:35]</a>. This group is also accelerationist but advocates for "driving intelligently," avoiding pitfalls, slowing down at curves, and being careful in "dangerous areas" <a class="yt-timestamp" data-t="00:22:21">[00:22:21]</a>. They aim to build a positive future in areas like medical outcomes, climate change, and human enablement while ensuring AI isn't used by rogue states or terrorists, or inadvertently creates "Terminators" <a class="yt-timestamp" data-t="00:22:35">[00:22:35]</a>. They acknowledge potential challenges but believe in steering towards positive outcomes, aligning with techno-optimism over techno-utopianism <a class="yt-timestamp" data-t="00:25:34">[00:25:34]</a>.

## AI and Existential Risk: A Portfolio Approach
Hoffman counters the Doomer perspective by arguing that [[debate_on_existential_risks_and_ai | existential risk]] should be viewed as a "portfolio" of threats (pandemics, asteroids, nuclear weapons, climate change), not just one <a class="yt-timestamp" data-t="00:41:56">[00:41:56]</a>. He strongly contends that AI, even in an unmodified state, is "very positive on the [[debate_on_existential_risks_and_ai | existential risk]] portfolio" <a class="yt-timestamp" data-t="00:42:25">[00:42:25]</a>. For example:
*   **Pandemics:** AI is crucial for detection, analysis, and rapid development of therapeutics and preventive vaccines <a class="yt-timestamp" data-t="00:42:54">[00:42:54]</a>.
*   **Asteroids:** AI can identify threats and assist in early intervention <a class="yt-timestamp" data-t="00:43:12">[00:43:12]</a>.
*   **Climate Change:** AI can accelerate fusion invention and improve electric grid management <a class="yt-timestamp" data-t="00:43:20">[00:43:20]</a>.

Even with challenges like the "killer robot risk," Hoffman believes that "whenever technology is part of the problem, it's almost always the best part of the solution" <a class="yt-timestamp" data-t="00:44:44">[00:44:44]</a>.

## Historical Analogies and Future Outlook
Hoffman points to the "Mainframe computer hysteria" of the 1960s as an analogy <a class="yt-timestamp" data-t="00:29:58">[00:29:58]</a>. Concerns at the time included computers tracking every pertinent action, leading to a loss of individuality, privacy, and agency, akin to an Orwellian society <a class="yt-timestamp" data-t="00:30:16">[00:30:16]</a>. This fear proved largely unfounded, as personal computers later democratized compute power <a class="yt-timestamp" data-t="00:39:44">[00:39:44]</a>. He notes that today's smartphones are thousands of times more powerful than those mainframes, yet universally available <a class="yt-timestamp" data-t="00:33:24">[00:33:24]</a>.

He urges a shift in focus from "what could possibly go wrong" to "what could possibly go right" <a class="yt-timestamp" data-t="00:31:21">[00:31:21]</a>. While acknowledging that technological transitions are often painful, as seen with the printing press leading to a century of religious war <a class="yt-timestamp" data-t="00:45:37">[00:45:37]</a>, AI can help navigate these challenges.

### Addressing Gloomer Objections
*   **"Bait and Switch" Concerns:** Hoffman addresses the concern that AI will follow a similar "bait and switch" pattern as social media, where user data is monetized for corporate interest. He argues that services like Google's ad-supported model provide immense free value to users (search, email) in exchange for data <a class="yt-timestamp" data-t="00:56:19">[00:56:19]</a>. He suggests [[emerging_trends_in_ai_agent_platforms | AI agents]] could operate on similar models (advertising, subscriptions) or be integrated into existing productivity apps <a class="yt-timestamp" data-t="00:57:00">[00:57:00]</a>. He challenges the term "surveillance capitalism," noting that "surveillance medicine" (e.g., smartwatches tracking health) is beneficial <a class="yt-timestamp" data-t="00:57:56">[00:57:56]</a>.
*   **Loss of Autonomy:** Hoffman agrees that agency "changes," but this is part of adapting to new technologies <a class="yt-timestamp" data-t="01:07:37">[01:07:37]</a>. While technologies initially feel alien, they become integrated into everyday life, similar to how phones became ubiquitous <a class="yt-timestamp" data-t="01:08:00">[01:08:00]</a>. He argues that new technologies, like algorithms for finding partners, might seem "dystopic" to previous generations but offer a "better" alternative than older methods (like the "lottery of college or the workplace") <a class="yt-timestamp" data-1:07:11">[01:07:11]</a>.

### What Could Go Right?
Hoffman envisions tangible benefits for individuals and society:
*   **Personal Health:** A medical assistant "better than your average doctor" available 24/7 in every pocket, offering immediate health advice, including emergency guidance <a class="yt-timestamp" data-t="00:49:01">[00:49:01]</a>.
*   **Education:** A tutor on every subject for every age, from 2 to 82, improving learning and economic opportunities <a class="yt-timestamp" data-t="00:49:24">[00:49:24]</a>.
*   **Everyday Tasks:** Assistance with complex tasks like understanding a rental lease <a class="yt-timestamp" data-t="00:50:06">[00:50:06]</a>.
*   **Professional Amplification:** AI can help with coding, marketing, sales, and more, enabling individuals to accomplish more in their work <a class="yt-timestamp" data-t="00:50:16">[00:50:16]</a>.

On a societal level, this aggregation of individual benefits could lead to increased "gross national happiness" and more fulfilling lives <a class="yt-timestamp" data-t="00:52:10">[00:52:10]</a>. People might gain more time for hobbies or accomplish more meaningful work by offloading mundane tasks <a class="yt-timestamp" data-t="00:52:33">[00:52:33]</a>. He claims that even without further advancements beyond current [[openais_model_and_agent_developments | OpenAI's Model and Agent Developments]] (LLMs), the consumer surplus for an average 20-year-old could be "millions of dollars over their lifetime" due to access to free legal assistance, medical advice, and enhanced economic work <a class="yt-timestamp" data-t="00:59:54">[00:59:54]</a>.

## Innovation as Safety
Hoffman presents the counter-intuitive argument that "innovation is actual safety" <a class="yt-timestamp" data-t="01:03:17">[01:03:17]</a>. Drawing on the car analogy, early cars were less safe, but iterative deployment and innovation led to safety features like anti-lock brakes, seatbelts, and crumple zones, allowing cars to go faster and be safer <a class="yt-timestamp" data-t="01:03:41">[01:03:41]</a>. Similarly, continued innovation in AI will lead to features that make them safer, preventing misuse by terrorists and ensuring alignment with human values <a class="yt-timestamp" data-t="01:04:20">[01:04:20]</a>. He notes that safety and alignment groups within companies like [[openais_model_and_agent_developments | OpenAI]], Microsoft, and Anthropic are already working on this <a class="yt-timestamp" data-t="01:04:55">[01:04:55]</a>.

## "American Intelligence"
Hoffman advocates for the United States to embrace AI, which he sometimes refers to as "American intelligence" <a class="yt-timestamp" data-t="01:11:01">[01:11:01]</a>. He believes that societies that embrace "cognitive industrial revolutions" achieve prosperity, similar to those that embraced the industrial revolution <a class="yt-timestamp" data-t="01:11:17">[01:11:17]</a>. Embedding American values of individual empowerment and the American dream into AI is crucial, necessitating a "Bloomer-Zoomer and accelerationist" regulatory stance rather than putting on the brakes <a class="yt-timestamp" data-t="01:11:42">[01:11:42]</a>.

## The Future of AI
Hoffman dismisses the idea that AI development might be "overhyped" or "flatline," stating there is "zero chance of that" <a class="yt-timestamp" data-t="01:12:53">[01:12:53]</a>. He points to the visible presence of technology in "scale compute and learning systems" that are only beginning to be deployed <a class="yt-timestamp" data-t="01:13:01">[01:13:01]</a>. He predicts that 2025 will see significant acceleration in software coding enabled by AI, which will serve as a template for advancing many other functions <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>. The implications of this "cognitive Industrial Revolution" are already apparent, and the focus should be on building, configuring, deploying, and integrating AI into society <a class="yt-timestamp" data-t="01:13:53">[01:13:53]</a>.