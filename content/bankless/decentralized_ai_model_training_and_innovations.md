---
title: Decentralized AI Model Training and Innovations
videoId: jzKssicScm4
---

From: [[bankless]] <br/> 

The AI space is experiencing rapid [[emerging_trends_in_ai_development | emerging trends]] and [[technological_advances_in_ai_efficiency | innovation]] at an incredible pace, with new models and applications launching weekly <a class="yt-timestamp" data-t="00:00:26">[00:00:26]</a>. This consistent innovation contrasts with broader market downturns, including crypto, where AI-related tokens are particularly affected <a class="yt-timestamp" data-t="00:00:38">[00:00:38]</a>. Despite market volatility, AI [[technological_advances_in_ai_efficiency | innovation]] continues full steam ahead <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>.

## Advancements in AI Media Generation

Recent [[technological_advances_in_ai_efficiency | technological advances]] highlight the speed of AI development in media:
*   **AI Podcasters** – Companies like Hideera (Character 3 Audio) have demonstrated the ability to create AI podcasters from a single image, with significant improvements in realism over the last year <a class="yt-timestamp" data-t="00:05:45">[00:05:45]</a>. While some "tells" remain, particularly in voice and eye movements, AI is moving out of the "uncanny valley" where human-like creations appear eerie <a class="yt-timestamp" data-t="00:07:44">[00:07:44]</a>.
*   **Google Gemini 2.0 Flash** – Google's new AI model offers native image generation and editing with impressive character consistency <a class="yt-timestamp" data-t="00:09:02">[00:09:02]</a>. This allows for realistic alterations like changing fur color <a class="yt-timestamp" data-t="00:09:24">[00:09:24]</a>, adding text <a class="yt-timestamp" data-t="00:09:34">[00:09:34]</a>, and generating complex scenes from simple prompts <a class="yt-timestamp" data-t="00:09:54">[00:09:54]</a>. The visual quality of still images generated by AI is now nearing parity with real photographs <a class="yt-timestamp" data-t="00:14:24">[00:14:24]</a>. This capability could revolutionize product mockups and photography <a class="yt-timestamp" data-t="00:13:00">[00:13:00]</a>.

## The Commoditization of AI Models

A significant [[developments_in_ai_model_competition | development in AI model competition]] is the increasing commoditization of large language models (LLMs) <a class="yt-timestamp" data-t="00:18:58">[00:18:58]</a>.
*   **Price Competition** – Chinese companies like Baidu are releasing models that outperform OpenAI's latest models while being significantly cheaper <a class="yt-timestamp" data-t="00:18:06">[00:18:06]</a>. This aggressive competition on both price and [[technological_advances_in_ai_efficiency | innovation]] is eroding the moat of established players like OpenAI <a class="yt-timestamp" data-t="00:18:43">[00:18:43]</a>.
*   **Value Capture Challenges** – With numerous strong competitive models, it's becoming unclear how companies developing frontier models will capture significant value or justify their high market caps <a class="yt-timestamp" data-t="00:20:14">[00:20:14]</a>. The value appears to be shifting to the "app layer" – the products and services that utilize these models, rather than the models themselves <a class="yt-timestamp" data-t="00:21:29">[00:21:29]</a>. This is analogous to how oil monopolies eventually leveraged distribution networks to maintain value despite oil becoming a commodity <a class="yt-timestamp" data-t="00:22:51">[00:22:51]</a>.
*   **AI Agents as the App Layer** – The "app layer" for AI models is envisioned as AI agents that can perform tasks, automate work, and act as personalized assistants <a class="yt-timestamp" data-t="00:25:33">[00:25:33]</a>. These [[decentralized_ai_agents_and_their_applications | decentralized AI agents]] could simplify user interaction, eliminating the need to download multiple apps and instead allowing users to simply ask an agent to perform a task <a class="yt-timestamp" data-t="00:26:40">[00:26:40]</a>.

## [[Decentralized and opensource AI model training | Decentralized and Opensource AI Model Training]]

A key area of [[innovations_and_challenges_in_decentralized_ai_models_and_platforms | innovations and challenges in decentralized AI models and platforms]] is model training. The traditional model requires rich companies like Microsoft or Google to spend tens of millions of dollars to train their own models <a class="yt-timestamp" data-t="01:02:37">[01:02:37]</a>.

### Plurales Research and Model Parallelism

Plurales Research is a new team that recently announced a $7.6 million seed round, with the goal of making [[open_source_ai_and_its_implications | open source AI]] a reality through [[decentralized_and_opensource_ai_model_training | decentralized and opensource AI model training]] <a class="yt-timestamp" data-t="00:59:02">[00:59:02]</a>.
*   **Problem Statement**: Previously, [[decentralized and opensource ai model training | decentralized AI model training]] typically relied on "data parallelism," where every computer contributing compute needed a full copy of the model and its weights <a class="yt-timestamp" data-t="01:00:17">[01:00:17]</a>. This made the model's design open-source and easily commoditized <a class="yt-timestamp" data-t="01:00:30">[01:00:30]</a>.
*   **The Innovation: Model Parallelism** – Plurales has cracked "model parallelism," a long-thought unsolvable problem <a class="yt-timestamp" data-t="01:00:08">[01:00:08]</a>. This approach splits the model across different computers providing compute <a class="yt-timestamp" data-t="00:59:51">[00:59:51]</a>.
*   **Benefits** – This innovation allows model creators to leverage decentralized compute power to train their models *without* open-sourcing the proprietary model weights <a class="yt-timestamp" data-t="01:01:01">[01:01:01]</a>. Essentially, it enables the training of proprietary models in an open-source manner <a class="yt-timestamp" data-t="01:01:12">[01:01:12]</a>.
*   **Economic Model** – For those providing compute, they receive part ownership of the model <a class="yt-timestamp" data-t="01:01:26">[01:01:26]</a>. Any revenue generated from accessing the model (which is exclusively via the network) is then split among these owners <a class="yt-timestamp" data-t="01:01:31">[01:01:31]</a>. This innovative design allows for the benefits of proprietary models while leveraging [[open_source_ai_and_its_implications | open source]] mechanisms for training and ownership <a class="yt-timestamp" data-t="01:01:45">[01:01:45]</a>.
*   **Team Expertise** – The Plurales team consists of individuals with PhDs in AI and ML research, who have authored leading research papers on model training and previously worked at Amazon's AI team <a class="yt-timestamp" data-t="01:02:03">[01:02:03]</a>. Their background suggests a strong capacity for executing on this frontier technology <a class="yt-timestamp" data-t="01:02:11">[01:02:11]</a>.

This development is significant because it provides a mechanism for individuals or smaller teams to train pioneering AI models without needing massive capital, by enabling shared ownership in return for compute <a class="yt-timestamp" data-t="01:02:44">[01:02:44]</a>. This approach directly addresses the challenges of commoditization seen in the centralized AI model landscape, offering a new pathway for value creation and ownership in the AI space <a class="yt-timestamp" data-t="01:03:17">[01:03:17]</a>.