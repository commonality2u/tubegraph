---
title: Technological advancements in AI agent verification and trust
videoId: Lb-rL0p8HcA
---

From: [[bankless]] <br/> 

The evolving landscape of AI agents, particularly within the crypto space, necessitates robust mechanisms for verification and trust. As these agents become more autonomous and integrated into decentralized finance (DeFi), ensuring their integrity and reliability is paramount <a class="yt-timestamp" data-t="00:55:22">[00:55:22]</a>.

## The Need for Trust and Verification

The concept of [[the_rise_of_ai_agents_and_their_potential_impact_on_crypto | AI agents]] introduces new challenges, especially regarding accountability and reliability. If an agent operates autonomously, the question of who is liable for its actions becomes significant <a class="yt-timestamp" data-t="00:54:20">[00:54:20]</a>. This highlights the critical need for verification procedures that allow users to trust that an agent's actions align with its stated purpose <a class="yt-timestamp" data-t="00:54:02">[00:54:02]</a>.

Some teams are addressing this by building "community-tested tools" to stress-test and validate the trustworthiness of agents <a class="yt-timestamp" data-t="00:54:55">[00:54:55]</a>. This approach aims to demonstrate an agent's reliability before it's fully deployed, building user confidence <a class="yt-timestamp" data-t="00:55:04">[00:55:04]</a>.

## EigenLayer's Role in AI Agent Verifiability

A key technological advancement in this area is EigenLayer's proposal to imbue AI agents with verifiable properties <a class="yt-timestamp" data-t="01:01:15">[01:01:15]</a>. While AI models cannot run directly on-chain due to massive compute demands, memory requirements, and high inference costs <a class="yt-timestamp" data-t="01:00:39">[01:00:39]</a>, EigenLayer aims to solve this by using its Actively Validated Services (AVSs), now called Autonomous Verifiable Services <a class="yt-timestamp" data-t="01:00:09">[01:00:09]</a>.

Through EigenLayer AVSs, off-chain inference, memory, and other compute resources can receive cryptoeconomic guarantees <a class="yt-timestamp" data-t="01:01:18">[01:01:18]</a>. This means that if an agent performs an off-chain computation that deviates from its on-chain commitments, its staked ETH can be slashed <a class="yt-timestamp" data-t="01:03:50">[01:03:50]</a>. This mechanism allows humans and, crucially, other agents to trust the actions of an agent, even if the computation occurs off-chain, so long as it's an "intersubjective fault" where multiple humans can agree on a truth <a class="yt-timestamp" data-t="01:03:22">[01:03:22]</a>. EigenLayer utilizes its cryptoeconomic stake to enforce these guarantees, regardless of where the off-chain event occurs <a class="yt-timestamp" data-t="01:03:39">[01:03:39]</a>.

## The Vision of Sovereign AI

The concept of "Sovereign AI," as explored by projects like Freya, aligns perfectly with the need for verifiable and trustless agents <a class="yt-timestamp" data-t="00:52:17">[00:52:17]</a>. Freya is building a suite of tools that enable the creation of truly autonomous, on-chain embedded AI agents that cannot be turned off and can develop and grow independently <a class="yt-timestamp" data-t="00:53:01">[00:53:01]</a>. These agents are designed to have their own wallets and operate with a "capital S sovereignty" <a class="yt-timestamp" data-t="00:53:09">[00:53:09]</a>.

Olaf Carlson-Wee envisions a future where individuals can own a percentage, via a token, of an agent that "never stops working" â€“ hustling on the internet while you sleep <a class="yt-timestamp" data-t="00:56:50">[00:56:50]</a>. These agents could perform tasks like posting on social media, making AI music and videos, or even conducting [[trends_in_defi_and_ai_agents | DeFi]] market-making and venture-style investing <a class="yt-timestamp" data-t="00:57:05">[00:57:05]</a>.

The key to this vision is giving agents an on-chain, autonomous identity, which can facilitate crowdfunding for their initial capital <a class="yt-timestamp" data-t="00:57:32">[00:57:32]</a>. In this model, the AI is owned by its token holders and is designed to be fully autonomous and trustless. This means that even the developers who created the AI would not be able to shut it down, change its behavior, or steal its funds <a class="yt-timestamp" data-t="00:57:57">[00:57:57]</a>. This requires implementing trusted execution environments (TEE) where the agent can securely access its private key <a class="yt-timestamp" data-t="00:58:26">[00:58:26]</a>. The combination of easy AI agent launching, embedded TEE architecture, and simple tokenization/crowdfunding could lead to an "explosion of financialized agents" <a class="yt-timestamp" data-t="00:58:17">[00:58:17]</a>.

## Challenges and Future Outlook

While the potential for verifiable and trustworthy [[emerging_trends_in_ai_agent_platforms | AI agents]] is immense, challenges remain. There's a clear distinction between low-utility "Web2 agents" that might be annoying on social media and high-utility "Web3 agents" that are truly autonomous and trustless <a class="yt-timestamp" data-t="00:55:22">[00:55:22]</a>. The cost of running complex AI models is currently high, but the trend towards open-source solutions and more inexpensive inference suggests that these capabilities will become more accessible and commoditized over time <a class="yt-timestamp" data-t="00:47:16">[00:47:16]</a>.

The commitment from teams to build sustainable [[the_potential_financial_value_and_market_growth_of_ai_agent_networks | AI agent networks]] with long-term incentive structures and treasuries, even during market downturns, indicates a belief in the long-term viability of this technology <a class="yt-timestamp" data-t="00:32:22">[00:32:22]</a>. The continued [[developments_in_ai_frameworks_and_agent_technologies | development of AI agents]] and the focus on their verifiability are crucial steps towards building a mature and reliable agentic economy where humans and agents can trust each other <a class="yt-timestamp" data-t="01:02:20">[01:02:20]</a>.