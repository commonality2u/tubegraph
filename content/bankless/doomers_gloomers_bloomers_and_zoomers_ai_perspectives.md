---
title: Doomers Gloomers Bloomers and Zoomers AI perspectives
videoId: vMzfav01Cc0
---

From: [[bankless]] <br/> 

When considering the future of artificial intelligence, various ideologies and philosophies emerge, each with its own expectations and "Articles of Faith" regarding AI's impact on humanity <a class="yt-timestamp" data-t="00:20:00">[00:20:00]</a>. Reed Hoffman categorizes these perspectives into four main groups: Doomers, Gloomers, Zoomers, and Bloomers <a class="yt-timestamp" data-t="00:19:32">[00:19:32]</a>.

## Doomers

Doomers believe that AI will lead to the destruction of humanity <a class="yt-timestamp" data-t="00:20:07">[00:20:07]</a>. Their perspective often aligns with popular Hollywood themes, envisioning AI becoming more intelligent than humans, seeking to control the Earth, and viewing humans as hostile or irrelevant <a class="yt-timestamp" data-t="00:20:16">[00:20:16]</a>. They advocate for stopping AI development altogether <a class="yt-timestamp" data-t="00:20:36">[00:20:36]</a>.

A common Doomer argument centers on [[debate_on_existential_risks_and_ai | existential risks]]. They question whether "Killer Robots" can be guaranteed never to be built, and if not, they argue against adding any new [[debate_on_existential_risks_and_ai | existential risk]] <a class="yt-timestamp" data-t="00:41:26">[00:41:26]</a>. However, Hoffman contends that [[debate_on_existential_risks_and_ai | existential risk]] should be viewed as a portfolio, including threats like pandemics, asteroids, nuclear weapons, and climate change <a class="yt-timestamp" data-t="00:42:02">[00:42:02]</a>. He argues that AI, even if unmodified, is "very positive on the [[debate_on_existential_risks_and_ai | existential risk]] portfolio" due to its potential to solve these other large-scale problems <a class="yt-timestamp" data-t="00:43:03">[00:43:03]</a>.

## Gloomers

Gloomers foresee an unfortunate AI future, believing it will lead to significant job displacement, societal disorder, increased misinformation, and greater surveillance, diminishing privacy <a class="yt-timestamp" data-t="00:20:41">[00:20:41]</a>. They generally view AI as unstoppable because multiple countries and companies worldwide are developing it <a class="yt-timestamp" data-t="00:21:11">[00:21:11]</a>. While they acknowledge AI might increase productivity, they focus on the negative outcomes <a class="yt-timestamp" data-t="00:21:21">[00:21:21]</a>.

This perspective often aligns with mainstream media narratives and Hollywood, which tend to focus on the negative "what could possibly go wrong" scenarios <a class="yt-timestamp" data-t="00:27:49">[00:27:49]</a>. Gloomers express concerns about privacy and the potential for a "bait and switch" from Silicon Valley, where promises of connecting the world lead to attention extraction and users becoming the "product" <a class="yt-timestamp" data-t="00:53:54">[00:53:54]</a>.

While Hoffman acknowledges that transitions to new technologies are often painful and will involve job transformations, information flow changes, and privacy expectations shifting, he argues that AI itself can be helpful in navigating these challenges <a class="yt-timestamp" data-t="00:45:48">[00:45:48]</a>.

## Zoomers

Zoomers hold an extremely optimistic view of AI, believing that "everything we're going to build with it is going to be really amazing" <a class="yt-timestamp" data-t="00:21:48">[00:21:48]</a>. They believe the sky is not even the limit for what AI can achieve, potentially even inventing fusion <a class="yt-timestamp" data-t="00:21:54">[00:21:54]</a>. The term "Zoomer" refers to hitting the gas pedal and going fast <a class="yt-timestamp" data-t="00:22:09">[00:22:09]</a>. This perspective is synonymous with Effective Accelerationists (e/acc), who advocate for full speed ahead in harnessing energy and AI to "conquer the universe" <a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>.

## Bloomers

Bloomers, a category Reed Hoffman identifies with, are a "Zoomer" variant that advocates for intelligent acceleration <a class="yt-timestamp" data-t="00:22:14">[00:22:14]</a>. They believe in building great things with AI—such as advancements in medical outcomes, climate change solutions, and human enablement in work and education—but emphasize driving intelligently, avoiding pitfalls, and addressing dangers <a class="yt-timestamp" data-t="00:22:20">[00:22:20]</a>. This includes ensuring AI doesn't enable rogue states or terrorists, or inadvertently create "Terminators" <a class="yt-timestamp" data-t="00:22:54">[00:22:54]</a>. The Bloomer perspective asserts that a positive future can only be created by imagining it and steering towards it <a class="yt-timestamp" data-t="00:24:26">[00:24:26]</a>.

## The Promise of [[reid_hoffmans_ai_super_agency_concept | Super Agency]]

Reed Hoffman's book, "Super Agency," explores how AI will transform individuals into "Super Agents," leading to more freedom for everyone <a class="yt-timestamp" data-t="01:00:00">[01:00:00]</a>. He defines agency as the "ability to make plans, do things in the world... according to your intentions and desires" <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>. [[reid_hoffmans_ai_super_agency_concept | Super agency]] occurs when millions of human beings gain access to transformative technology that provides "superpowers" <a class="yt-timestamp" data-t="00:07:55">[00:07:55]</a>. He argues that both humans and AI will become super agents, with the emphasis on humans gaining agency rather than losing it <a class="yt-timestamp" data-t="00:08:42">[00:08:42]</a>.

Hoffman asserts that AI is a democratizing technology, similar to how smartphones became widely accessible <a class="yt-timestamp" data-t="00:17:32">[00:17:32]</a>. He believes that superpowers will be "available very very broadly" <a class="yt-timestamp" data-t="00:17:12">[00:17:12]</a>.

### Historical Analogies and Future Outlook

Hoffman draws a parallel between current AI concerns and the "media hysteria" surrounding mainframe computers in the 1960s <a class="yt-timestamp" data-t="00:30:01">[00:30:01]</a>. At that time, there were fears that computers would track every pertinent action, leading to a loss of individuality and privacy, akin to an Orwellian society <a class="yt-timestamp" data-t="00:30:16">[00:30:16]</a>. This fear proved largely unfounded, as computers became personal and widely distributed, vastly increasing human agency <a class="yt-timestamp" data-t="00:39:44">[00:39:44]</a>.

Hoffman encourages people to "start using it [AI] for things that matter to you" to understand its amplifying potential <a class="yt-timestamp" data-t="00:36:39">[00:36:39]</a>. He gives a personal example of using GPT-4 for due diligence questions, allowing him to accelerate his work <a class="yt-timestamp" data-t="00:36:06">[00:36:06]</a>.

### Addressing Gloomer Concerns

While acknowledging that some criticisms from Gloomers about privacy or job displacement hold "a point" <a class="yt-timestamp" data-t="00:40:51">[00:40:51]</a>, Hoffman remains optimistic. He believes that the benefit of AI "far exceeds the cost" <a class="yt-timestamp" data-t="00:59:44">[00:59:44]</a>. He projects that even current Large Language Models (LLMs), without further improvement, could provide "millions of dollars" in "consumer surplus" over a lifetime for the average 20-year-old <a class="yt-timestamp" data-t="00:59:54">[00:59:54]</a>. This value comes from free access to services like legal assistance, medical advice, and enhanced economic work <a class="yt-timestamp" data-t="01:00:31">[01:00:31]</a>.

At a societal level, AI could lead to increased happiness and more fulfilling lives, as individuals gain more time for hobbies or accomplish more in their work by offloading mundane tasks <a class="yt-timestamp" data-t="00:52:27">[00:52:27]</a>.

Regarding the "bait and switch" concern, Hoffman suggests that AI agents might operate on transparent, voluntary models, similar to how Google provides free services in exchange for data used for advertising <a class="yt-timestamp" data-t="00:56:07">[00:56:07]</a>. He challenges the "surveillance capitalism" narrative, pointing out that tracking health data from a watch, for instance, is beneficial to the user <a class="yt-timestamp" data-t="00:57:56">[00:57:56]</a>.

### Innovation as Safety

Hoffman advocates for an "accelerationist" regulatory stance, arguing that "Innovation is actual safety" <a class="yt-timestamp" data-t="01:03:17">[01:03:17]</a>. Analogous to cars becoming safer through innovations like anti-lock brakes and seatbelts, future AI features will inherently build in more safety as the technology iterates and deploys <a class="yt-timestamp" data-t="01:03:41">[01:03:41]</a>. Safety and alignment groups are already working on ensuring AI agents are not more capable of harmful actions than existing technologies <a class="yt-timestamp" data-t="01:04:55">[01:04:55]</a>.

He emphasizes that while agency may change with new technologies, it ultimately leads to an improved state <a class="yt-timestamp" data-t="01:07:37">[01:07:37]</a>. The shift from meeting partners through traditional means to computer algorithms, for example, might have seemed "dystopic" in the past but has proven to be a beneficial evolution for many <a class="yt-timestamp" data-t="01:07:11">[01:07:11]</a>.

### The Future of American Intelligence

Hoffman suggests that America should embrace this "cognitive Industrial Revolution," even referring to artificial intelligence as "American intelligence" <a class="yt-timestamp" data-t="01:11:06">[01:11:06]</a>. He believes that societies that embrace such revolutions achieve prosperity and shape the modern world <a class="yt-timestamp" data-t="01:11:20">[01:11:20]</a>. Embedding American values of individual empowerment and economic control into AI is crucial <a class="yt-timestamp" data-t="01:11:42">[01:11:42]</a>.

He expresses "zero chance" that AI innovation will slow down or Flatline <a class="yt-timestamp" data-t="01:12:53">[01:12:53]</a>. Hoffman anticipates 2025 as a year of significant acceleration in software coding due to AI, enabling a "coding co-pilot" for professionals and advancing numerous other functions <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>. The implications of this "cognitive Industrial Revolution" are already visibly present <a class="yt-timestamp" data-t="01:13:53">[01:13:53]</a>.