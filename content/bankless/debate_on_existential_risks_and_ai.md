---
title: Debate on existential risks and AI
videoId: vMzfav01Cc0
---

From: [[bankless]] <br/> 

The discussion surrounding artificial intelligence (AI) frequently revolves around its potential existential risks, with various perspectives on the future impact of this transformative technology <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>. Reed Hoffman, an investor and co-founder of LinkedIn, presents a "bull case" for AI, arguing for its acceleration into the future and its potential to empower individuals as "super agents" <a class="yt-timestamp" data-t="00:00:54">[00:00:54]</a>.

## Superagency: Amplifying Human Potential

Hoffman's book, *Superagency*, defines "agency" as the ability to make plans and enact intentions in the world <a class="yt-timestamp" data-t="00:07:06">[00:07:06]</a>. "Superagency" occurs when millions of humans gain access to an elevating, transformative technology, receiving "superpowers" not only as individuals but also leading to a societal transformation <a class="yt-timestamp" data-t="00:07:48">[00:07:48]</a>. The elevation of capabilities through technology is seen as akin to gaining superpowers <a class="yt-timestamp" data-t="00:09:52">[00:09:52]</a>.

While [[the_rise_of_ai_agents_and_their_potential_impact_on_crypto | AI agents]] themselves gain agency, the primary emphasis is on humanity *gaining* agency, not losing it <a class="yt-timestamp" data-t="00:08:42">[00:08:42]</a>. Hoffman believes this empowerment will be broadly distributed, similar to how smartphones became ubiquitous, rather than being concentrated among the elite or governments <a class="yt-timestamp" data-t="00:15:17">[00:15:17]</a>. He confidently asserts that these "superpowers" will be widely available, although some differences may exist based on country and wealth <a class="yt-timestamp" data-t="00:17:09">[00:17:09]</a>.

### The Reed AI Experiment

Hoffman has personally experimented with [[the_rise_of_ai_agents_and_their_potential_impact_on_crypto | AI agents]], featuring an "AI co-host" version of himself, "Reed AI," on his podcast "Possible" <a class="yt-timestamp" data-t="00:11:10">[00:11:10]</a>. While the video avatars are not yet real-time, the project aims to familiarize people with a future where individuals can be sovereign over their own [[autonomous_and_selfsovereign_ai_concepts | AI agents]], potentially allowing their AI twin to perform work while they engage in personal pursuits <a class="yt-timestamp" data-t="00:13:37">[00:13:37]</a>. This concept suggests a democratizing future where individuals maintain ownership and control over their digital extensions <a class="yt-timestamp" data-t="00:14:01">[00:14:01]</a>.

## Four Perspectives on AI: Doomers, Gloomers, Bloomers, and Zoomers

Hoffman categorizes the prevailing ideologies or "religions" regarding AI:

*   **Doomers**: Believe AI will lead to the destruction of humanity, viewing it as an existential threat akin to the Terminator <a class="yt-timestamp" data-t="00:20:07">[00:20:07]</a>. They advocate for stopping AI development <a class="yt-timestamp" data-t="00:20:36">[00:20:36]</a>.
*   **Gloomers**: Acknowledge AI is unstoppable but foresee a negative future, characterized by job displacement, increased misinformation, surveillance, and unbalanced democracies <a class="yt-timestamp" data-t="00:20:41">[00:21:06]</a>. This perspective is often reflected in mainstream media and Hollywood <a class="yt-timestamp" data-t="00:27:00">[00:27:00]</a>.
*   **Zoomers**: Hold an extremely optimistic view, believing AI technology is inherently great and will lead to spectacular outcomes, pushing for rapid acceleration without significant caution <a class="yt-timestamp" data-t="00:21:42">[00:22:09]</a>. They align with "Effective Accelerationists" <a class="yt-timestamp" data-t="00:24:48">[00:24:48]</a>.
*   **Bloomers**: (Hoffman's self-identified category) Share the Zoomer's accelerationist drive but advocate for intelligent development, avoiding pitfalls, and addressing potential dangers responsibly <a class="yt-timestamp" data-t="00:22:14">[00:22:14]</a>. They believe in building a positive future by actively steering towards it <a class="yt-timestamp" data-t="00:24:26">[00:24:26]</a>.

## Challenging the Doomer and Gloomer Narratives

### The Existential Risk "Portfolio"

Hoffman contends that the "Doomer" argument often makes a mistake by focusing on AI as a single, isolated existential risk <a class="yt-timestamp" data-t="00:41:22">[00:41:22]</a>. He argues that existential risk should be viewed as a "portfolio" of threats, including pandemics, asteroids, nuclear weapons, and climate change <a class="yt-timestamp" data-t="00:42:04">[00:42:04]</a>. From this perspective, AI, even unmodified, is "very positive" on the existential risk portfolio <a class="yt-timestamp" data-t="00:42:25">[00:42:25]</a>.

> "The only existential risk for human beings is not [[ai_robots_and_their_impact_on_the_workforce | Killer Robots]] there's pandemics there's asteroids there's nuclear weapons there's climate change and the list kind of goes on and so you have to look at existential risk as a portfolio namely it's not just one thing it's a set of things and so when you look at any particular intervention you say well how does this affect the portfolio" <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>

AI can provide solutions to these existing risks, such as accelerating detection, analysis, and development of therapeutics and vaccines for pandemics <a class="yt-timestamp" data-t="00:42:38">[00:42:38]</a>, identifying and intervening on asteroids <a class="yt-timestamp" data-t="00:43:12">[00:43:12]</a>, and managing electric grids or inventing fusion for climate change <a class="yt-timestamp" data-t="00:43:19">[00:43:19]</a>.

### Learning from History: The Mainframe Analogy

Hoffman draws a parallel between current AI anxieties and the media hysteria surrounding mainframe computers in the 1960s <a class="yt-timestamp" data-t="00:29:49">[00:29:49]</a>. Concerns at the time included computers recalling every pertinent action of a citizen, leading to comparisons with George Orwell's *1984* and fears of citizens losing individuality, privacy, and agency, reduced to "magnetic tape" <a class="yt-timestamp" data-t="00:30:16">[00:30:16]</a>.

> "They think about well actually in fact this could um you know track everything make all the decisions take away the agency of people by putting it in kind of government centralized control... and then make you know kind of uh you know us as as human beings um essentially powerless and agency" <a class="yt-timestamp" data-t="00:31:28">[00:31:28]</a>

Despite these fears, the eventual outcome was the personal computer revolution, democratizing access to computing power far exceeding early mainframes <a class="yt-timestamp" data-t="00:39:44">[00:39:44]</a>. Hoffman argues that focusing energy on imagining positive outcomes and steering towards them is more productive than solely dwelling on potential negative outcomes <a class="yt-timestamp" data-t="00:33:50">[00:33:50]</a>.

### Addressing Gloomer Concerns: Painful Transitions and Economic Value

While acknowledging that technological transitions are often "painful" and lead to societal disruption (e.g., the printing press causing a century of religious war), Hoffman believes the overall outcome will be positive <a class="yt-timestamp" data-t="00:45:06">[00:45:06]</a>. Job transformations, misinformation flows, and privacy changes are challenges that need to be navigated intentionally <a class="yt-timestamp" data-t="00:47:04">[00:47:04]</a>. He asserts that AI itself can be helpful in addressing these issues <a class="yt-timestamp" data-t="00:47:14">[00:47:14]</a>.

Hoffman argues that AI will deliver significant economic value to individuals. For example, even if large language models (LLMs) improve no further than their current state, the "consumer surplus" for the average 20-year-old living today is in the millions of dollars over their lifetime <a class="yt-timestamp" data-t="00:59:50">[00:59:50]</a>. This value comes from access to free services like legal assistance, medical advice, and amplification of economic work, potentially leading to longer lifespans <a class="yt-timestamp" data-t="01:00:31">[01:00:31]</a>.

> [!NOTE|What could go right?]
> With widely deployed AI, the average American could benefit from:
> *   A medical assistant "better than your average doctor" available 24/7 in every pocket <a class="yt-timestamp" data-t="00:48:58">[00:48:58]</a>.
> *   A tutor for every subject and age <a class="yt-timestamp" data-t="00:49:24">[00:49:24]</a>.
> *   Assistance in understanding complex documents like rental leases <a class="yt-timestamp" data-t="00:50:06">[00:50:06]</a>.
> *   Amplification of work, leading to more fulfilling lives, hobbies, and increased productivity <a class="yt-timestamp" data-t="00:52:27">[00:52:27]</a>.

### Addressing the "Bait and Switch" and Autonomy Concerns

Concerns about AI following a "bait and switch" pattern, similar to social media extracting attention and data, are addressed <a class="yt-timestamp" data-t="00:54:56">[00:54:56]</a>. Hoffman argues that services like Google's ad-supported model offer a "panoply of amazing free services" in exchange for data, representing a "voluntary economic transaction" <a class="yt-timestamp" data-t="00:56:19">[00:56:19]</a>. He suggests [[the_rise_of_ai_agents_and_their_potential_impact_on_crypto | AI agents]] could operate similarly, or through subscriptions, while emphasizing transparency and user awareness <a class="yt-timestamp" data-t="00:57:00">[00:57:00]</a>. He challenges the "surveillance capitalism" slogan, pointing out benefits like "surveillance medicine" (e.g., smartwatches tracking health data) which are for the user's benefit <a class="yt-timestamp" data-t="00:57:47">[00:57:47]</a>.

Regarding the fear that AI "kills human autonomy" by making decisions for us, Hoffman reiterates that agency changes with new technologies <a class="yt-timestamp" data-t="01:06:04">[01:06:04]</a>. While new technologies can feel alien at first, they become part of everyday life (e.g., fire, agriculture, phones) <a class="yt-timestamp" data-t="01:07:58">[01:07:58]</a>. He uses the example of meeting partners through computer algorithms, which seemed "dystopic" in the 1960s but is now a normal, and often improved, reality <a class="yt-timestamp" data-t="01:06:42">[01:06:42]</a>. The goal is to make these changes lead to a better future <a class="yt-timestamp" data-t="01:08:39">[01:08:39]</a>.

## AI and America: Innovation as Safety

Hoffman advocates for an accelerationist approach to AI development in the United States, suggesting the term "American intelligence" instead of "artificial intelligence" <a class="yt-timestamp" data-t="01:11:06">[01:11:06]</a>. He believes that societies embracing this "cognitive Industrial Revolution" will achieve prosperity, just as those embracing the industrial revolution did <a class="yt-timestamp" data-t="01:11:17">[01:11:17]</a>. He emphasizes the importance of embedding American values—like individual empowerment and economic progress—into AI development <a class="yt-timestamp" data-t="01:11:41">[01:11:41]</a>.

Regarding [[regulation_and_future_implications_of_ai_in_america | regulation]], Hoffman argues that "innovation is actual safety" <a class="yt-timestamp" data-t="01:03:17">[01:03:17]</a>. Similar to how iterative deployment of cars led to safety features like anti-lock brakes and seatbelts <a class="yt-timestamp" data-t="01:03:41">[01:03:41]</a>, future AI development will incorporate safety features through ongoing innovation and deployment <a class="yt-timestamp" data-t="01:04:17">[01:04:17]</a>. This means a [[regulation_and_future_implications_of_ai_in_america | regulatory stance]] that is "Bloomer Zoomer and accelerationist" rather than one focused on applying "breaks" <a class="yt-timestamp" data-t="01:12:14">[01:12:14]</a>.

Hoffman maintains that the idea of AI being "overhyped" or that innovation will "slow to a crawl" has "zero chance" of happening <a class="yt-timestamp" data-t="01:12:53">[01:12:53]</a>. The visible presence of technology and its implications across the cognitive Industrial Revolution indicate continued, rapid advancement <a class="yt-timestamp" data-t="01:13:56">[01:13:56]</a>.