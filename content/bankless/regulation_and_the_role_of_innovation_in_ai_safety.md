---
title: Regulation and the role of innovation in AI safety
videoId: vMzfav01Cc0
---

From: [[bankless]] <br/> 

The discussion around artificial intelligence often includes various perspectives on its development and future, particularly concerning safety and the role of regulation. These views can be categorized into different "AI religions": Doomers, Gloomers, Bloomers, and Zoomers <a class="yt-timestamp" data-t="00:19:10">[00:19:10]</a>. While "Doomers" fear AI's destructive potential and "Gloomers" foresee negative societal consequences, the "Bloomer" perspective, articulated by Reed Hoffman, emphasizes that [[innovation_and_speculation_in_ai_and_crypto_space | innovation]] itself is a key component of AI safety <a class="yt-timestamp" data-t="01:03:17">[01:03:17]</a>.

## Innovation as Safety

Reed Hoffman, co-founder of LinkedIn and former OpenAI board member <a class="yt-timestamp" data-t="05:58:00">[05:58:00]</a>, champions the "Bloomer" viewpoint, suggesting that while concerns about AI are valid, the path to a positive future involves intentional steering and continuous development, rather than imposing blanket restrictions <a class="yt-timestamp" data-t="00:22:14">[00:22:14]</a>.

### The Car Analogy
Hoffman draws an analogy to the automotive industry to explain how [[innovation_and_speculation_in_ai_and_crypto_space | innovation]] can lead to safety. Early cars were dangerous, but subsequent [[technological_advances_in_ai_efficiency | innovation]] introduced safety features like anti-lock brakes, seat belts, crumple zones, and bumpers. These innovations made cars faster and safer <a class="yt-timestamp" data-t="01:03:41">[01:03:41]</a>. This iterative deployment, where a technology is put into use and then refined based on real-world learning, is crucial for discovering and building safety into the product <a class="yt-timestamp" data-t="01:05:11">[01:05:11]</a>.

### Applying to AI
Similarly, for AI, safety is not a static state to be achieved before deployment, but an ongoing process of [[innovation_and_speculation_in_ai_and_crypto_space | innovation]]. By continuously developing and deploying AI, developers can identify and build in [[ethical_considerations_in_ai_development | safety features]] <a class="yt-timestamp" data-t="01:06:00">[01:06:00]</a>. Companies like Microsoft, OpenAI, and Anthropic already employ "red teams" and "alignment groups" to proactively address safety concerns <a class="yt-timestamp" data-t="01:04:55">[01:04:55]</a>. The goal is to ensure that AI agents are not more capable of enabling harmful activities, such as terrorism or weapons of mass destruction, than existing tools like Google Search <a class="yt-timestamp" data-t="01:05:23">[01:05:23]</a>.

## Countering the Precautionary Principle

A common approach from governments regarding new technologies is the "precautionary principle," which focuses on preventing all potential negative outcomes before widespread adoption <a class="yt-timestamp" data-t="01:03:03">[01:03:03]</a>. Hoffman argues against this "all brakes" approach for AI, especially in a multi-polar world <a class="yt-timestamp" data-t="01:03:06">[01:03:06]</a>. He contends that if one nation or entity slows its AI development, adversaries might accelerate theirs, potentially leading to an undesirable global power imbalance <a class="yt-timestamp" data-t="01:02:49">[01:10:52]</a>.

## AI as "American Intelligence"

Hoffman suggests renaming "artificial intelligence" to "American intelligence" to underscore the importance of the United States embracing this "cognitive Industrial Revolution" <a class="yt-timestamp" data-t="01:11:08">[01:11:08]</a>. The societies that embraced the industrial revolution gained prosperity and shaped the modern world <a class="yt-timestamp" data-t="01:11:20">[01:11:20]</a>. Similarly, embedding American values—such as the American dream, individual empowerment, and economic control over one's destiny—into AI development is seen as crucial for the future of American society <a class="yt-timestamp" data-t="01:11:42">[01:11:42]</a>. Therefore, the regulatory stance needs to be "Bloomer Zoomer" and accelerationist rather than overly restrictive <a class="yt-timestamp" data-t="01:12:14">[01:12:14]</a>.

## Agency and the Future

Concerns about AI killing human autonomy and becoming a "control technology" are often raised <a class="yt-timestamp" data-t="01:06:04">[01:06:04]</a>. Hoffman's concept of "super agency" posits that rather than losing agency, humans gain it through AI, albeit in a transformed way <a class="yt-timestamp" data-t="00:08:45">[00:08:45]</a>. He compares this to how meeting a spouse via computer algorithm, which might have seemed dystopian in the 1960s, is now a common and accepted means of finding partners <a class="yt-timestamp" data-t="01:06:42">[01:06:42]</a>. While new technologies can feel alien at first, they eventually become integrated into everyday life, improving quality of life, similar to the advent of antibiotics compared to the 1920s <a class="yt-timestamp" data-t="01:08:00">[01:08:00]</a>. The key is to iteratively deploy and learn from these changes to make the future state better <a class="yt-timestamp" data-t="01:08:32">[01:08:32]</a>.

Hoffman asserts that the idea of AI development flatlining is a "zero chance" scenario <a class="yt-timestamp" data-t="01:12:53">[01:12:53]</a>. The scale of compute and learning systems currently being deployed suggests continuous acceleration, especially in areas like software coding, which will enable numerous other functions and empower professionals with "coding co-pilots" <a class="yt-timestamp" data-t="01:13:01">[01:13:01]</a>. The [[emerging_trends_in_ai_development | implications]] of the cognitive Industrial Revolution are already visibly present, and the focus should be on how to build, configure, deploy, and integrate this technology <a class="yt-timestamp" data-t="01:13:53">[01:13:53]</a>.