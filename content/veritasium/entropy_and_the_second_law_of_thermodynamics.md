---
title: Entropy and the Second Law of Thermodynamics
videoId: DxL2HoqLbyA
---

From: [[veritasium]] <br/> 

[[Entropy and the Second Law of Thermodynamics]] is described as one of the most important, yet least understood, concepts in physics, governing everything from molecular collisions to humongous storms <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. It influences the beginning and evolution of the universe to its inevitable end <a class="yt-timestamp" data-t="00:00:12">[00:00:12]</a>. It may determine the [[the_arrow_of_time_and_entropy|direction of time]] and even be the reason life exists <a class="yt-timestamp" data-t="00:00:19">[00:00:19]</a>.

## The Earth and the Sun: A Misconception

When asked what the Earth gets from the Sun, common answers include light, heat, warmth, vitamin D, and energy <a class="yt-timestamp" data-t="00:00:35">[00:00:35]</a>. While the Earth receives a certain amount of energy from the Sun daily <a class="yt-timestamp" data-t="00:00:57">[00:00:57]</a>, it radiates the exact same amount of energy back into space for most of its history <a class="yt-timestamp" data-t="00:01:37">[00:01:37]</a>. If this weren't the case, the Earth would get much hotter <a class="yt-timestamp" data-t="00:01:46">[00:01:46]</a>. This highlights a common confusion: if energy inflow equals energy outflow, what exactly are we getting from the Sun <a class="yt-timestamp" data-t="00:01:54">[00:01:54]</a>? The answer lies in a discovery made two centuries ago <a class="yt-timestamp" data-t="00:02:09">[00:02:09]</a>.

## Sadi Carnot and the Ideal Heat Engine

In the winter of 1813, Sadi Carnot, a 17-year-old student and son of one of Napoleon's generals, sought to join the fight against invading armies <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>. After Paris fell to the advancing armies, Carnot was devastated <a class="yt-timestamp" data-t="00:02:47">[00:02:47]</a>. Seven years later, he visited his father, a physicist who had written an essay on efficient energy transfer in mechanical systems <a class="yt-timestamp" data-t="00:02:56">[00:02:56]</a>. They discussed steam engines, the major breakthrough of the time, which were crucial for industrial and military might <a class="yt-timestamp" data-t="00:03:14">[00:03:14]</a>. French designs lagged behind those of other countries like Britain <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>. Carnot dedicated himself to understanding why <a class="yt-timestamp" data-t="00:03:37">[00:03:37]</a>.

At the time, even the best steam engines converted only about 3% of thermal energy into useful mechanical work <a class="yt-timestamp" data-t="00:03:45">[00:03:45]</a>. Carnot spent three years studying heat engines, leading to a key insight: the concept of an [[Carnots_Ideal_Heat_Engine|ideal heat engine]] with no friction or environmental losses <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>.

### How [[Carnots_Ideal_Heat_Engine|Carnot's Ideal Engine]] Works
An ideal heat engine operates between two large metal bars, one hot and one cold <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>.
1.  A chamber with air and a piston is brought into contact with the hot bar <a class="yt-timestamp" data-t="00:04:20">[00:04:20]</a>. Heat flows in, the air expands, pushing the piston up and turning a flywheel <a class="yt-timestamp" data-t="00:04:39">[00:04:39]</a>.
2.  The hot bar is removed, and the air continues to expand, cooling until it reaches the cold bar's temperature <a class="yt-timestamp" data-t="00:04:48">[00:04:48]</a>.
3.  The cold bar is contacted, and the flywheel pushes the piston down, compressing the air and transferring heat into the cold bar <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>.
4.  The cold bar is removed, and the flywheel compresses the gas further, increasing its temperature back to just below the hot bar's temperature <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>.
This cycle converts heat from the hot bar into flywheel energy <a class="yt-timestamp" data-t="00:05:23">[00:05:23]</a>.

### Reversibility and Efficiency
[[Carnots_Ideal_Heat_Engine|Carnot's ideal engine]] is completely reversible <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>. Running it in reverse would return everything to its original state without additional energy input <a class="yt-timestamp" data-t="00:06:00">[00:06:00]</a>. Despite this reversibility, its efficiency is not 100% <a class="yt-timestamp" data-t="00:06:25">[00:06:25]</a>. The efficiency is calculated by dividing the useful energy gained by the heat input from the hot bar <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>. The hot gas exerts greater pressure on the piston than the cold gas, meaning more work is done on the hot side than on the cold side <a class="yt-timestamp" data-t="00:07:03">[00:07:03]</a>.

Efficiency can be increased by raising the hot side's temperature or lowering the cold side's temperature <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>. Lord Kelvin realized that Carnot's engine could form the basis for an absolute temperature scale <a class="yt-timestamp" data-t="00:07:21">[00:07:21]</a>. The concept of absolute zero, where gas particles effectively stop moving and no heat is lost, would allow for a 100% efficient engine <a class="yt-timestamp" data-t="00:07:30">[00:07:30]</a>. Using the Kelvin scale, efficiency can be expressed as a function of the hot and cold temperatures <a class="yt-timestamp" data-t="00:07:56">[00:07:56]</a>. This means efficiency depends fundamentally on the temperatures of the hot and cold sides, not on materials or design <a class="yt-timestamp" data-t="00:08:15">[00:08:15]</a>. Achieving 100% efficiency requires infinite temperature on the hot side or absolute zero on the cold side, both impractical <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>. Heat must be dumped into the cold bar to return the piston to its original position, so not all energy remains in the flywheel <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.

Real engines, unlike ideal ones, experience friction, dissipate heat to the environment, and do not transfer heat at constant temperatures <a class="yt-timestamp" data-t="00:09:05">[00:09:05]</a>. This leads to less energy ending up in the flywheel, with the rest spreading out into the environment <a class="yt-timestamp" data-t="00:09:13">[00:09:13]</a>. When energy spreads out, it becomes impossible to get it back, making the process irreversible <a class="yt-timestamp" data-t="00:09:26">[00:09:26]</a>. The total energy remains the same, but it becomes less usable <a class="yt-timestamp" data-t="00:09:34">[00:09:34]</a>. Energy is most usable when concentrated and less usable when spread out <a class="yt-timestamp" data-t="00:09:39">[00:09:39]</a>.

## Rudolf Clausius and the Concept of Entropy

Decades later, German physicist Rudolf Clausius studied Carnot's engine and developed a way to measure how spread out energy is <a class="yt-timestamp" data-t="00:09:48">[00:09:48]</a>. He called this quantity [[Entropy_and_the_Second_Law_of_Thermodynamics|entropy]] <a class="yt-timestamp" data-t="00:09:58">[00:09:58]</a>.
*   Low entropy: all energy concentrated in the hot bar <a class="yt-timestamp" data-t="00:10:02">[00:10:02]</a>.
*   Increasing entropy: energy spreads to surroundings, making it less available to do work <a class="yt-timestamp" data-t="00:10:07">[00:10:07]</a>.

In 1865, Clausius summarized the first two laws of thermodynamics:
*   First Law: The energy of the universe is constant <a class="yt-timestamp" data-t="00:10:29">[00:10:29]</a>.
*   [[second_law_of_thermodynamics_and_disorder|Second Law of Thermodynamics]]: The entropy of the universe tends to a maximum <a class="yt-timestamp" data-t="00:10:33">[00:10:33]</a>. In other words, energy spreads out over time <a class="yt-timestamp" data-t="00:10:38">[00:10:38]</a>.

The [[second_law_of_thermodynamics_and_disorder|Second Law]] explains why hot things cool down, gas expands, and perpetual motion machines are impossible: usable energy in a closed system always decreases <a class="yt-timestamp" data-t="00:10:44">[00:10:44]</a>. While entropy is commonly described as [[second_law_of_thermodynamics_and_disorder|disorder]], a better way to think about it is as the tendency of energy to spread out <a class="yt-timestamp" data-t="00:11:04">[00:11:04]</a>.

## Ludwig Boltzmann and the Probability of Energy Spreading

Most laws of physics work the same forwards or backwards in time, so how does this time dependence arise <a class="yt-timestamp" data-t="00:11:22">[00:11:22]</a>? Ludwig Boltzmann provided an important insight: heat flowing from cold to hot is not impossible, but merely improbable <a class="yt-timestamp" data-t="00:12:53">[00:12:53]</a>.

Consider two small metal bars, one hot (7 energy packets) and one cold (3 energy packets), each with 8 atoms <a class="yt-timestamp" data-t="00:11:34">[00:11:34]</a>. Energy packets hop randomly between atoms <a class="yt-timestamp" data-t="00:12:05">[00:12:05]</a>. If we take a snapshot, it's possible for heat to have flowed from cold to hot (e.g., 9 packets in the left bar, 1 in the right) <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>. However, there are significantly more configurations where energy is evenly spread (e.g., 627,264 configurations with 5 packets in each bar) than where it's concentrated (e.g., 91,520 configurations with 9 in one bar) <a class="yt-timestamp" data-t="00:13:04">[00:13:04]</a>.

As the number of atoms and energy packets increases (e.g., 80 atoms per bar, 100 packets), the chance of the left bar ending up hotter than it started becomes infinitesimally small (0.05%) <a class="yt-timestamp" data-t="00:13:36">[00:13:36]</a>. In everyday solids with trillions of atoms, heat flowing from cold to hot is so unlikely it never happens <a class="yt-timestamp" data-t="00:13:55">[00:13:55]</a>. This is analogous to a Rubik's Cube: there's only one solved state, but quintillions of random states <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>. Without thought and effort, random turns always move the cube from an unlikely (solved) state to a more likely (messy) state <a class="yt-timestamp" data-t="00:14:36">[00:14:36]</a>.

## Entropy and Order: Life's Existence

If the natural tendency is for energy to spread out and things to get messier, how can ordered systems like air conditioning exist <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a>? A decrease in entropy (e.g., cooling a house) is only possible by increasing entropy a greater amount somewhere else <a class="yt-timestamp" data-t="00:15:12">[00:15:12]</a>. For example, a power plant releasing concentrated chemical energy from coal increases entropy in its environment, compensating for the local decrease in the house <a class="yt-timestamp" data-t="00:15:20">[00:15:20]</a>.

### The Role of the Sun
If the Earth were a closed system, energy would spread out completely, leading to the cessation of all life and decay <a class="yt-timestamp" data-t="00:16:05">[00:16:05]</a>. However, the Earth is not a closed system; it has the Sun <a class="yt-timestamp" data-t="00:16:17">[00:16:17]</a>. The Sun provides a steady stream of low-entropy, concentrated energy <a class="yt-timestamp" data-t="00:16:28">[00:16:28]</a>. The energy received from the Sun is more useful, compact, and clumped together than the energy radiated back <a class="yt-timestamp" data-t="00:16:35">[00:16:35]</a>.

[[Role_of_Energy_and_Entropy_in_Life_and_the_Universe|Life]] on Earth captures and utilizes this low-entropy energy:
*   Plants use it to grow and create sugars <a class="yt-timestamp" data-t="00:16:44">[00:16:44]</a>.
*   Animals eat plants (or other animals) and use the energy to maintain their bodies and move <a class="yt-timestamp" data-t="00:16:48">[00:16:48]</a>.
At each step, energy becomes more spread out <a class="yt-timestamp" data-t="00:16:58">[00:16:58]</a>. All energy from the Sun is ultimately converted into thermal energy and radiated back into space as the same amount of energy <a class="yt-timestamp" data-t="00:17:08">[00:17:08]</a>.

The increase in entropy is seen in the relative number of photons: for each photon received from the Sun, 20 photons are emitted from Earth <a class="yt-timestamp" data-t="00:17:27">[00:17:27]</a>. Everything that happens on Earth—plant growth, animal life, natural phenomena—occurs in the process of converting fewer, higher-energy photons into 20 times as many lower-energy photons <a class="yt-timestamp" data-t="00:17:40">[00:17:40]</a>. Without a concentrated energy source and a way to discard spread-out energy, life would be impossible <a class="yt-timestamp" data-t="00:18:01">[00:18:01]</a>.

It has been suggested that [[Role_of_Energy_and_Entropy_in_Life_and_the_Universe|life itself]] may be a consequence of the [[second_law_of_thermodynamics_and_disorder|Second Law of Thermodynamics]] <a class="yt-timestamp" data-t="00:18:10">[00:18:10]</a>. If the universe tends toward maximum entropy, [[Role_of_Energy_and_Entropy_in_Life_and_the_Universe|life]] offers a way to accelerate this tendency by being spectacularly good at converting low entropy into high entropy <a class="yt-timestamp" data-t="00:18:16">[00:18:16]</a>. For example, seawater with cyanobacteria produces 30% to 680% more entropy than without <a class="yt-timestamp" data-t="00:18:29">[00:18:29]</a>. Jeremy England proposed that a constant stream of clumped energy could favor structures that dissipate that energy, eventually leading to better dissipators and thus, life <a class="yt-timestamp" data-t="00:18:42">[00:18:42]</a>: "You start with a random clump of atoms, and if you shine light on it for long enough, it should not be so surprising that you get a plant" <a class="yt-timestamp" data-t="00:19:00">[00:19:00]</a>.

## Entropy and the Universe's Evolution

If life on Earth relies on low entropy from the Sun, then the Sun must have received its low entropy from the universe <a class="yt-timestamp" data-t="00:19:11">[00:19:11]</a>. Since the total entropy of the universe is increasing, it implies that entropy was lowest right after the Big Bang <a class="yt-timestamp" data-t="00:19:22">[00:19:22]</a>. This is known as the past hypothesis <a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a>.

The early universe was hot, dense, and almost completely uniform, with temperatures varying by at most 0.001% <a class="yt-timestamp" data-t="00:19:51">[00:19:51]</a>. This seemingly uniform state was actually low entropy due to gravity <a class="yt-timestamp" data-t="00:20:05">[00:20:05]</a>. Gravity tends to clump matter together, so matter being spread out uniformly was an extremely unlikely state, hence low entropy <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>.

As the universe expanded and cooled, matter clumped together, converting potential energy into kinetic energy <a class="yt-timestamp" data-t="00:20:26">[00:20:26]</a>. Collisions between matter converted some kinetic energy into heat, decreasing useful energy and increasing entropy <a class="yt-timestamp" data-t="00:20:45">[00:20:45]</a>. The formation of stars, planets, galaxies, and life all contributed to this increase in entropy <a class="yt-timestamp" data-t="00:20:58">[00:20:58]</a>.

## Black Holes and the Universe's Entropy

In 1972, Jacob Bekenstein proposed that the [[black_holes_and_entropy|entropy of a black hole]] should be proportional to its surface area <a class="yt-timestamp" data-t="00:21:36">[00:21:36]</a>. This idea was initially controversial because classical thermodynamics implied that if black holes had entropy, they would also have temperature and thus emit radiation, contradicting their "blackness" <a class="yt-timestamp" data-t="00:21:55">[00:21:55]</a>.

Stephen Hawking, attempting to disprove Bekenstein, surprisingly found that [[black_holes_and_entropy|black holes]] do emit radiation (Hawking radiation) and have a temperature <a class="yt-timestamp" data-t="00:22:12">[00:22:12]</a>. He confirmed that [[black_holes_and_entropy|black holes]] have entropy and refined Bekenstein's proposal <a class="yt-timestamp" data-t="00:22:38">[00:22:38]</a>. For example, the supermassive [[black_holes_and_entropy|black hole]] at the Milky Way's center has about 10^91 Boltzmann constants of entropy, which is 1,000 times more than the early observable universe and 10 times more than all other particles combined <a class="yt-timestamp" data-t="00:22:49">[00:22:49]</a>. All [[black_holes_and_entropy|black holes]] together account for approximately 3 x 10^104 Boltzmann constants worth of entropy, meaning almost all the universe's entropy is tied up in them <a class="yt-timestamp" data-t="00:23:04">[00:23:04]</a>.

The early universe had an incredibly low entropy state, only about 0.000000000000003% of its current entropy <a class="yt-timestamp" data-t="00:23:19">[00:23:19]</a>. Everything in the universe—planetary systems forming, galaxies merging, stars dying, life flourishing—happens because the universe's entropy was low and has been increasing <a class="yt-timestamp" data-t="00:23:31">[00:23:31]</a>.

## The Arrow of Time and Cosmic Fate

These processes only occur in one direction: we never see an asteroid uncrash or a planetary system unmix <a class="yt-timestamp" data-t="00:23:50">[00:23:50]</a>. The clear difference between past and future comes from entropy <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a>. The fact that we are moving from unlikely to more likely states is why there is an [[the_arrow_of_time_and_entropy|arrow of time]] <a class="yt-timestamp" data-t="00:24:07">[00:24:07]</a>.

This trend is expected to continue until the energy is so completely spread out that nothing interesting can happen again—the [[the_arrow_of_time_and_entropy|heat death of the universe]] <a class="yt-timestamp" data-t="00:24:16">[00:24:16]</a>. In the distant future, after the last [[black_holes_and_entropy|black hole]] has evaporated, the universe will be in its most probable state <a class="yt-timestamp" data-t="00:24:29">[00:24:29]</a>. At that point, on large scales, there will be no difference between time moving forwards or backwards, and the [[the_arrow_of_time_and_entropy|arrow of time]] will disappear <a class="yt-timestamp" data-t="00:24:40">[00:24:40]</a>.

## Complexity in the Midst of Entropy

While maximum entropy leads to a dull outcome with low complexity <a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>, low entropy does not necessarily mean maximum complexity <a class="yt-timestamp" data-t="00:25:00">[00:25:00]</a>. Both low and high entropy states are low in complexity <a class="yt-timestamp" data-t="00:25:26">[00:25:26]</a>. Complex structures, like patterns formed when pouring milk into tea, appear and thrive in the middle range of entropy <a class="yt-timestamp" data-t="00:25:07">[00:25:07]</a>. Since humanity finds itself in this middle range, we should make use of the low entropy we have while we can <a class="yt-timestamp" data-t="00:25:35">[00:25:35]</a>.