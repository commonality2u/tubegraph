---
title: Role of Energy and Entropy in Life and the Universe
videoId: DxL2HoqLbyA
---

From: [[veritasium]] <br/> 

## Introduction
[[entropy_and_the_second_law_of_thermodynamics | Entropy]], a concept described as one of the most important yet least understood in physics, governs phenomena from molecular collisions to galactic evolution and may even determine [[The Arrow of Time and Entropy | the direction of time]] and the existence of life itself <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.

## Energy Exchange Between Earth and Sun
When asked what the Earth receives from the Sun, common answers include light, heat, warmth, Vitamin D, and energy <a class="yt-timestamp" data-t="00:00:35">[00:00:35]</a>. While the Earth receives a significant amount of energy daily from the Sun, it radiates an exactly equal amount of energy back into space over most of its history <a class="yt-timestamp" data-t="00:01:39">[00:01:39]</a>. If this balance didn't exist, the Earth's temperature would drastically increase <a class="yt-timestamp" data-t="00:01:46">[00:01:46]</a>. This reveals that what the Earth truly gains from the Sun isn't net energy, but something else "special" that isn't commonly discussed <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>.

## Sadi Carnot and the Ideal Heat Engine
The fundamental insight into this concept traces back to Sadi Carnot in 1813, a 17-year-old student whose father was a physicist and general under Napoleon <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>. After witnessing France's military and industrial decline, Carnot sought to improve the efficiency of steam engines, which at the time converted only about 3% of thermal energy into useful mechanical work <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>.

Carnot's key insight involved an ideal heat engine, one without friction or environmental losses <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a>. This engine operates between a hot bar and a cold bar, using a chamber of air and a piston connected to a flywheel <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>. Heat flows from the hot bar to expand the air, pushing the piston up and turning the flywheel <a class="yt-timestamp" data-t="00:04:36">[00:04:36]</a>. The air then expands further, cools, is compressed while transferring heat to the cold bar, and then compressed further to increase its temperature before repeating the cycle <a class="yt-timestamp" data-t="00:04:48">[00:04:48]</a>.

### Reversibility and Efficiency
Carnot's ideal engine is completely reversible; running it in reverse returns everything to its original state without additional energy input <a class="yt-timestamp" data-t="00:05:33">[00:05:33]</a>. Despite its reversibility, its efficiency is not 100% <a class="yt-timestamp" data-t="00:06:25">[00:06:25]</a>. To return the piston to its original position, some heat must be dumped into the cold bar, meaning not all energy remains in the flywheel <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.

Lord Kelvin recognized that Carnot's engine could form the basis for an absolute temperature scale (the Kelvin scale) <a class="yt-timestamp" data-t="00:07:21">[00:07:21]</a>. On this scale, the efficiency of an ideal heat engine depends fundamentally only on the temperatures of the hot and cold sides <a class="yt-timestamp" data-t="00:08:15">[00:08:15]</a>. Achieving 100% efficiency would require an infinite temperature on the hot side or absolute zero on the cold side, both practically impossible <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>.

Real engines, unlike ideal ones, experience friction, dissipate heat to the environment, and do not transfer heat at constant temperatures <a class="yt-timestamp" data-t="00:09:05">[00:09:05]</a>. This causes energy to spread out, making the process irreversible and the energy less usable <a class="yt-timestamp" data-t="00:09:26">[00:09:26]</a>. Energy is most usable when concentrated and less usable when spread out <a class="yt-timestamp" data-t="00:09:39">[00:09:39]</a>.

## The Concept of Entropy
Decades later, Rudolf Clausius studied Carnot's engine and devised a way to measure how "spread out" energy is, coining the term **[[entropy_and_the_second_law_of_thermodynamics | entropy]]** <a class="yt-timestamp" data-t="00:09:48">[00:09:48]</a>. When energy is concentrated, it's low entropy; as it spreads to surroundings, entropy increases <a class="yt-timestamp" data-t="00:10:02">[00:10:02]</a>. The same amount of energy is present, but in a more dispersed form, it is less available to do work <a class="yt-timestamp" data-t="00:10:15">[00:10:15]</a>.

In 1865, Clausius summarized the first two laws of thermodynamics:
1.  The energy of the universe is constant <a class="yt-timestamp" data-t="00:10:29">[00:10:29]</a>.
2.  The [[second_law_of_thermodynamics_and_disorder | entropy]] of the universe tends to a maximum, meaning energy spreads out over time <a class="yt-timestamp" data-t="00:10:33">[00:10:33]</a>.

> [!NOTE] Common Misconception
> While entropy is often described as disorder (things becoming more mixed, random, and less ordered), a better way to think about it is as the tendency of energy to spread out <a class="yt-timestamp" data-t="00:11:04">[00:11:04]</a>.

## Why Energy Spreads Out
Most laws of physics are time-reversible, but the [[The Arrow of Time and Entropy | time dependence]] of entropy is clear: energy spreads out <a class="yt-timestamp" data-t="00:11:22">[00:11:22]</a>. Ludwig Boltzmann made the important insight that heat flowing from cold to hot (decreasing entropy) is not impossible, but merely improbable <a class="yt-timestamp" data-t="00:12:53">[00:12:53]</a>.

Consider two metal bars, one hot with 7 energy packets and one cold with 3 <a class="yt-timestamp" data-t="00:11:34">[00:11:34]</a>. Energy packets randomly hop between atoms. While a configuration where the cold bar gets hotter is possible, there are far more configurations where the energy is evenly spread <a class="yt-timestamp" data-t="00:13:04">[00:13:04]</a>. As the number of atoms and energy packets increases, the probability of energy concentrating (e.g., heat flowing from cold to hot) becomes vanishingly small, making it effectively never happen in macroscopic systems <a class="yt-timestamp" data-t="00:13:36">[00:13:36]</a>.

### The Rubik's Cube Analogy
This concept is like a Rubik's Cube: there's only one "solved" state, a few "almost solved" states, and quintillions of "random" or "messy" states <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>. Without conscious effort, random turns will always move the cube from a highly unlikely solved state to a more likely, messy state <a class="yt-timestamp" data-t="00:14:36">[00:14:36]</a>.

## Entropy, Order, and Life
Despite the universe's tendency towards increasing entropy, local order can arise. For example, air conditioning makes a house cooler (decreasing local entropy), but this is only possible because a greater increase in entropy occurs elsewhere, such as at a power plant where concentrated chemical energy is released and spread out <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a>. Any decrease in entropy in one place must be more than compensated by an increase elsewhere <a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a>.

### The Sun's Role
If Earth were a closed system, all energy would spread out, leading to the cessation of life and decay <a class="yt-timestamp" data-t="00:16:05">[00:16:05]</a>. Fortunately, Earth is an open system that receives a steady stream of low-entropy (concentrated, bundled) energy from the Sun <a class="yt-timestamp" data-t="00:16:17">[00:16:17]</a>. The energy received from the Sun is more useful, compact, and clumped together than the thermal energy Earth radiates back into space <a class="yt-timestamp" data-t="00:16:35">[00:16:35]</a>.

Life on Earth flourishes by capturing this low-entropy solar energy and converting it into higher-entropy forms. For each high-energy photon received from the Sun, Earth emits approximately 20 lower-energy photons <a class="yt-timestamp" data-t="00:17:34">[00:17:34]</a>. All biological processes, from plants growing to animals moving, occur in this process of converting fewer, higher-energy photons into many more lower-energy photons <a class="yt-timestamp" data-t="00:17:40">[00:17:40]</a>. Without a source of concentrated energy and a way to discard spread-out energy, life would not be possible <a class="yt-timestamp" data-t="00:18:01">[00:18:01]</a>.

### Life as an Entropy Accelerator
It has been suggested that life itself may be a consequence of the [[entropy_and_the_second_law_of_thermodynamics | second law of thermodynamics]] <a class="yt-timestamp" data-t="00:18:10">[00:18:10]</a>. Life offers a way to accelerate the natural tendency of the universe towards maximum entropy because living systems are highly efficient at converting low entropy into high entropy <a class="yt-timestamp" data-t="00:18:16">[00:18:16]</a>. For example, the presence of cyanobacteria and other organic matter in seawater significantly increases entropy production <a class="yt-timestamp" data-t="00:18:29">[00:18:29]</a>. Physicist Jeremy England proposes that a constant stream of clumped energy could favor structures that dissipate that energy, eventually leading to the emergence of life <a class="yt-timestamp" data-t="00:18:42">[00:18:42]</a>.

## Entropy and the Universe's Evolution
The reason the universe contains structured forms like stars, planets, and life is because it started with incredibly low [[entropy_and_the_second_law_of_thermodynamics | entropy]] <a class="yt-timestamp" data-t="00:19:19">[00:19:19]</a>. This is known as the **past hypothesis** <a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a>. Immediately after the Big Bang, the universe was hot, dense, and nearly uniform <a class="yt-timestamp" data-t="00:19:51">[00:19:51]</a>. While seemingly "mixed," this uniform state was actually very low entropy when considering gravity, which tends to clump matter together <a class="yt-timestamp" data-t="00:20:09">[00:20:09]</a>.

Over time, as the universe expanded and cooled, matter began to clump into denser regions <a class="yt-timestamp" data-t="00:20:26">[00:20:26]</a>. This process converted enormous amounts of potential energy into kinetic energy <a class="yt-timestamp" data-t="00:20:33">[00:20:33]</a>. Collisions between matter converted some of this kinetic energy into heat, thereby increasing entropy and decreasing usable energy <a class="yt-timestamp" data-t="00:20:45">[00:20:45]</a>. This increase in entropy facilitated the formation of stars, planets, and galaxies <a class="yt-timestamp" data-t="00:20:58">[00:21:01]</a>.

### [[Black Holes and Entropy | Black Holes]] as Entropy Dominators
In 1972, Jacob Bekenstein proposed that the entropy of a black hole should be proportional to its surface area <a class="yt-timestamp" data-t="00:21:36">[00:21:36]</a>. Initially met with skepticism because it implied black holes would have a temperature and emit radiation, Stephen Hawking later confirmed Bekenstein's idea, demonstrating that black holes do emit radiation (Hawking radiation) and have a temperature <a class="yt-timestamp" data-t="00:22:12">[00:22:12]</a>.

> [!INFO] Entropy Contributions in the Universe
> *   The universe started with approximately 10^88 Boltzmann constants of entropy <a class="yt-timestamp" data-t="00:21:09">[00:21:09]</a>.
> *   All stars in the observable universe contribute about 9.5 x 10^80 entropy <a class="yt-timestamp" data-t="00:21:15">[00:21:15]</a>.
> *   The interstellar and intergalactic medium have almost 10 times more <a class="yt-timestamp" data-t="00:21:20">[00:21:20]</a>.
> *   The supermassive black hole at the center of the Milky Way has about 10^91 Boltzmann constants of entropy, which is 1,000 times more than the early observable universe and 10 times more than all other particles combined <a class="yt-timestamp" data-t="00:22:49">[00:22:49]</a>.
> *   All black holes together account for 3 x 10^104 Boltzmann constants of entropy, representing almost all the universe's total entropy <a class="yt-timestamp" data-t="00:23:04">[00:23:04]</a>.

This means the early universe had an extraordinarily low percentage of the entropy it has now, highlighting the vast increase over cosmic time <a class="yt-timestamp" data-t="00:23:19">[00:23:19]</a>.

## The [[The Arrow of Time and Entropy | Arrow of Time]] and Heat Death
Everything that happens in the universe—from planetary systems forming to stars dying and life flourishing—occurs because the universe's entropy was initially low and has been continuously increasing <a class="yt-timestamp" data-t="00:23:31">[00:23:31]</a>. These processes happen in only one direction; an asteroid never "uncrashes" or a planetary system "unmixes" into its original dust cloud <a class="yt-timestamp" data-t="00:23:52">[00:23:52]</a>. This fundamental difference between past and future, the progression from unlikely to more likely states, is what defines the [[The Arrow of Time and Entropy | arrow of time]] <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a>.

This increase is expected to continue until all energy is spread out so completely that nothing interesting can ever happen again <a class="yt-timestamp" data-t="00:24:16">[00:24:16]</a>. This theoretical end state is known as the **heat death of the universe** <a class="yt-timestamp" data-t="00:24:26">[00:24:26]</a>. In this distant future, after the last black holes evaporate, the universe will be in its most probable state, and the [[The Arrow of Time and Entropy | arrow of time]] will disappear <a class="yt-timestamp" data-t="00:24:31">[00:24:31]</a>.

## Entropy and Complexity
While maximum entropy implies low complexity, low entropy does not necessarily mean maximum complexity <a class="yt-timestamp" data-t="00:25:00">[00:25:00]</a>. Complexity, like the patterns that emerge when milk mixes into tea, arises in the *middle* range of entropy, where complex structures can appear and thrive <a class="yt-timestamp" data-t="00:25:07">[00:25:07]</a>.