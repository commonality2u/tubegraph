---
title: cooperation in nature and evolution
videoId: mScpHTIi-kM
---

From: [[veritasium]] <br/> 

Cooperation, an unexpected phenomenon, is fundamental to understanding many interactions in nature <a class="yt-timestamp" data-t="00:00:26">[00:00:26]</a>. While seemingly counterintuitive for self-interested organisms, game theory, particularly through the lens of the prisoner's dilemma, helps explain how cooperative strategies can emerge and flourish <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.

## The Prisoner's Dilemma and its Challenges to Cooperation

The prisoner's dilemma is a foundational problem in game theory that illustrates why rational self-interest can lead to suboptimal outcomes for all parties involved <a class="yt-timestamp" data-t="00:03:44">[00:03:44]</a>.

The game involves two players, each choosing to either "cooperate" or "defect" <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>.
*   If both cooperate, they each receive a moderate reward (e.g., three coins) <a class="yt-timestamp" data-t="00:02:46">[00:02:46]</a>.
*   If one cooperates and the other defects, the defector receives a large reward (e.g., five coins), and the cooperater receives nothing <a class="yt-timestamp" data-t="00:02:50">[00:02:50]</a>.
*   If both defect, they each receive a minimal reward (e.g., one coin) <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>.

The dilemma arises because, regardless of the opponent's choice, defecting always yields a better individual outcome <a class="yt-timestamp" data-t="00:03:31">[00:03:31]</a>. However, if both players act rationally and defect, they both end up worse off than if they had both cooperated <a class="yt-timestamp" data-t="00:03:44">[00:03:44]</a>. This concept has been applied to various real-world scenarios, from international conflicts like the nuclear arms race between the US and the Soviet Union <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a> to everyday interactions <a class="yt-timestamp" data-t="00:00:03">[00:00:03]</a>.

### Impalas and Ticks: A Natural Dilemma

In nature, impalas face a similar dilemma when it comes to grooming <a class="yt-timestamp" data-t="00:04:44">[00:04:44]</a>. Impalas need to remove ticks to prevent disease, but they cannot reach all parts of their bodies, requiring help from other impalas <a class="yt-timestamp" data-t="00:04:50">[00:04:50]</a>. Grooming another impala incurs a cost in terms of saliva, electrolytes, time, and attention <a class="yt-timestamp" data-t="00:05:05">[00:05:05]</a>. If impalas interacted only once, the rational choice would be to defect (not groom others) <a class="yt-timestamp" data-t="00:05:34">[00:05:34]</a>.

## Robert Axelrod's Tournaments and the Emergence of Cooperation

In 1980, political scientist Robert Axelrod conducted a computer tournament to discover the best strategy for repeated prisoner's dilemma games <a class="yt-timestamp" data-t="00:06:18">[00:06:18]</a>. The tournament involved various computer programs, or "strategies," playing against each other over multiple rounds <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a>.

The winning strategy in the first tournament was surprisingly simple: **Tit for Tat** <a class="yt-timestamp" data-t="00:07:23">[00:07:23]</a>, <a class="yt-timestamp" data-t="00:08:21">[00:08:21]</a>.
*   **Tit for Tat** starts by cooperating <a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a>.
*   In subsequent moves, it copies exactly what its opponent did in the previous move <a class="yt-timestamp" data-t="00:08:31">[00:08:31]</a>.
*   It follows cooperation with cooperation and defection with defection, but is willing to return to cooperation if its opponent does <a class="yt-timestamp" data-t="00:08:35">[00:08:35]</a>.

### Qualities of Successful Strategies

Axelrod identified four key qualities shared by the best-performing strategies:

1.  **Nice:** Strategies that are never the first to defect <a class="yt-timestamp" data-t="00:10:15">[00:10:15]</a>. Eight out of fifteen strategies were nice in the first tournament, and the top eight performers were all nice <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>.
2.  **Forgiving:** Strategies that can retaliate but do not hold a grudge, not letting past defections influence current decisions beyond the most recent one <a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>.
    *   This "pays to be nice and forgiving" conclusion surprised experts who tried to implement tricky, nasty strategies <a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a>.
    *   A slightly more forgiving strategy, "Tit for Two Tats" (which defects only after an opponent defects twice), would have won the first tournament had it been submitted <a class="yt-timestamp" data-t="00:11:44">[00:11:44]</a>.
3.  **Retaliatory (Provokable):** If an opponent defects, the strategy immediately strikes back, avoiding being a "pushover" <a class="yt-timestamp" data-t="00:14:38">[00:14:38]</a>.
4.  **Clear:** Simple and understandable programs that allow for the establishment of trust <a class="yt-timestamp" data-t="00:14:57">[00:14:57]</a>. Opaque or random-like programs made it difficult for others to establish a pattern of trust <a class="yt-timestamp" data-t="00:15:01">[00:15:01]</a>.

### The Role of Noise and Generosity

In real-world scenarios, "noise" or random errors can occur <a class="yt-timestamp" data-t="00:19:36">[00:19:36]</a>. For example, a cooperation might be perceived as a defection <a class="yt-timestamp" data-t="00:19:42">[00:19:42]</a>. In a noisy environment, Tit for Tat can enter a cycle of alternating retaliations, leading to poor performance <a class="yt-timestamp" data-t="00:20:47">[00:20:47]</a>. To address this, a "generous Tit for Tat" strategy, incorporating around 10% more forgiveness, helps break out of echo effects while still being retaliatory <a class="yt-timestamp" data-t="00:21:21">[00:21:21]</a>.

## Cooperation in Nature: An Ecological Simulation

Axelrod conducted a simulation to model the ecological impact of these strategies, where successful strategies increased in number while unsuccessful ones declined <a class="yt-timestamp" data-t="00:16:35">[00:16:35]</a>.
*   Worst-performing strategies quickly went extinct <a class="yt-timestamp" data-t="00:16:44">[00:16:44]</a>.
*   Nasty strategies like "Harrington" initially grew by preying on others but then declined as their targets disappeared <a class="yt-timestamp" data-t="00:16:51">[00:16:51]</a>.
*   After a thousand generations, only nice strategies survived, with Tit for Tat being the most common <a class="yt-timestamp" data-t="00:17:11">[00:17:11]</a>.

This process, while not strictly [[role_of_evolution_in_human_attractiveness_to_mosquitoes | evolution]] (as it lacks mutations), is an ecological simulation that demonstrates how cooperation can emerge and spread <a class="yt-timestamp" data-t="00:17:25">[00:17:25]</a>. Even in a "nasty" world populated by defectors, a small cluster of Tit for Tat players can emerge, build up points, and eventually take over the population <a class="yt-timestamp" data-t="00:17:39">[00:17:39]</a>.

> [00:18:25] You don't have to be altruistic. You could be looking out for number one for yourself and your own interests. And yet cooperation can still emerge.

These findings suggest that cooperation can emerge in populations of self-interested players, even if they are not altruistic <a class="yt-timestamp" data-t="00:18:14">[00:18:14]</a>.

### Examples in Nature
The insights from game theory can explain how cooperation flourished from a world of selfish organisms <a class="yt-timestamp" data-t="00:18:38">[00:18:38]</a>.
*   **Impalas grooming each other** <a class="yt-timestamp" data-t="00:18:51">[00:18:51]</a>.
*   **Fish cleaning sharks** <a class="yt-timestamp" data-t="00:18:53">[00:18:53]</a>.

Many life forms face conflicts similar to the prisoner's dilemma, but because they interact repeatedly, cooperation becomes a beneficial strategy <a class="yt-timestamp" data-t="00:19:01">[00:19:01]</a>. This cooperation doesn't require conscious thought or trust; the strategy can be encoded in DNA, and if it performs better, it can spread throughout a population <a class="yt-timestamp" data-t="00:19:08">[00:19:08]</a>.

## Conclusion

Axelrod's insights have been applied to various fields, including [[role_of_evolution_in_human_attractiveness_to_mosquitoes | evolutionary biology]] and international relations <a class="yt-timestamp" data-t="00:27:27">[00:27:27]</a>. While the single "best" strategy in the repeated prisoner's dilemma can vary depending on the environment, the core principles remain: be nice, forgiving, but don't be a pushover <a class="yt-timestamp" data-t="00:24:09">[00:24:09]</a>.

This demonstrates that "winning" in many real-world situations, which are non-zero sum, doesn't mean beating another person but rather finding win-win situations where everyone benefits <a class="yt-timestamp" data-t="00:22:27">[00:22:27]</a>. Ultimately, cooperation pays, even among rivals <a class="yt-timestamp" data-t="00:23:04">[00:23:04]</a>.