---
title: The role of Hugging Face in the AI ecosystem
videoId: hzc1covUhYM
---

From: [[acquiredfm]] <br/> 

Hugging Face has become a central platform for [[the_growth_and_influence_of_communitydriven_ai_development | AI builders]] at a critical time for artificial intelligence <a class="yt-timestamp" data-t="00:00:15">[00:00:15]</a>. The company aims to provide a clear understanding of [[open_source_ai_vs_closed_ai_ecosystems | Open Source AI]] versus closed ecosystems, their differences, trade-offs, and virtues, all told through its own story <a class="yt-timestamp" data-t="00:00:39">[00:00:39]</a>.

## What is Hugging Face?
Hugging Face has established itself as the leading platform for [[the_growth_and_influence_of_communitydriven_ai_development | AI builders]] <a class="yt-timestamp" data-t="00:01:06">[00:01:06]</a>. In the current technology paradigm, creating technology involves training models, using datasets, and building AI applications, a process in which most AI builders today utilize the Hugging Face platform <a class="yt-timestamp" data-t="00:01:30">[00:01:30]</a>.

The ecosystem surrounding Hugging Face is likened to the Web 2.0 era (2008-2010), characterized by restful APIs that allowed for the "daisy chaining" of various company services <a class="yt-timestamp" data-t="00:01:55">[00:01:55]</a>. This new era of open, flexible AI building blocks is replacing previous capabilities, enabling new applications like AI-powered search and social networks <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>. It also unlocks entirely new capabilities, with some discussions even touching on super intelligence and AGI <a class="yt-timestamp" data-t="00:02:36">[00:02:36]</a>.

### Scale and Usage
As of recording, Hugging Face is valued at $4.5 billion, with investors including [[the_role_of_nvidia_in_the_artificial_intelligence_and_deep_learning_revolution | Nvidia]], Salesforce, Google, Amazon, Intel, AMD, Qualcomm, and IBM <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>.

Key metrics illustrating its scale include:
*   Over 5 million [[the_growth_and_influence_of_communitydriven_ai_development | AI builders]] use the platform daily <a class="yt-timestamp" data-t="00:01:47">[00:01:47]</a>.
*   Collectively, users have shared over 3 million models, datasets, and apps <a class="yt-timestamp" data-t="00:03:37">[00:03:37]</a>.
*   The platform is soon to cross 1 million public models, with nearly as many private models used internally by companies <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>.
*   A new model, dataset, or app is built on Hugging Face every 10 seconds <a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a>.

Hugging Face functions like GitHub for AI models, supporting both public, open-source projects and internal, closed-source repositories for companies <a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a>. It serves as the most used platform for this new class of technology buildersâ€”AI builders, much like GitHub for software engineers <a class="yt-timestamp" data-t="00:04:38">[00:04:38]</a>. Beyond hosting models, it provides platforms for datasets, application execution, and even compute for model training <a class="yt-timestamp" data-t="00:05:26">[00:05:26]</a>.

A crucial aspect of the platform is its collaboration features, recognizing that AI building is a team effort, often extending across different teams and even the broader field <a class="yt-timestamp" data-t="00:05:42">[00:05:42]</a>. Features like commenting, versioning code, models, and datasets, and reporting bugs are heavily utilized <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a>. Large companies like Microsoft, [[the_role_of_nvidia_in_the_artificial_intelligence_and_deep_learning_revolution | Nvidia]], and Salesforce have thousands of users on the Hugging Face platform, both privately and publicly <a class="yt-timestamp" data-t="00:06:38">[00:06:38]</a>.

## Hugging Face's Evolution
Hugging Face was co-founded in 2016 by Clem Delong, Julian, and Thomas <a class="yt-timestamp" data-t="00:07:06">[00:07:06]</a>. The company began as a chatbot aimed at teenagers, named after the Unicode "hugging face" emoji, rather than an [[the_evolution_and_impact_of_ai_model_hosting_platforms | AI model hosting platforms]] infrastructure company <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>. Despite its initial focus, the founders were driven by their excitement for AI, even when it was primarily referred to as machine learning or deep learning <a class="yt-timestamp" data-t="00:07:33">[00:07:33]</a>.

The pivot to its current form was largely organic and community-driven <a class="yt-timestamp" data-t="00:14:43">[00:14:43]</a>. The shift began with a co-founder, Thomas, porting Google's popular Transformer model, BERT, from TensorFlow to PyTorch over a weekend <a class="yt-timestamp" data-t="00:12:40">[00:12:40]</a>. This immediately garnered significant developer interest <a class="yt-timestamp" data-t="00:13:26">[00:13:26]</a>.

As other scientists sought to add their models, such as XLNet and GPT-2 (when OpenAI was still open-source), Hugging Face developed an abstraction layer to host multiple models and datasets for their conversational AI efforts <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a>. This capability, initially for their chatbot, became the foundation for the platform today <a class="yt-timestamp" data-t="00:11:12">[00:11:12]</a>. Users expressed needs for hosting larger models beyond GitHub's capacity and for searching within datasets, leading Hugging Face to build a "new GitHub for AI" <a class="yt-timestamp" data-t="00:16:12">[00:16:12]</a>. This community-driven development has been a key factor in their success <a class="yt-timestamp" data-t="00:16:42">[00:16:42]</a>.

## Openness and Philosophy
Hugging Face champions openness, allowing companies to be more open than they might otherwise be, without forcing them <a class="yt-timestamp" data-t="00:17:51">[00:17:51]</a>. Approximately half of the models, datasets, and apps on the platform are private, used internally by companies, which Hugging Face supports <a class="yt-timestamp" data-t="00:18:04">[00:18:04]</a>. The company believes that openness, especially [[open_source_ai_vs_closed_ai_ecosystems | open-source AI]] and open science, lifts all boats by enabling everyone to build, understand, and gain transparency into how AI works <a class="yt-timestamp" data-t="00:18:56">[00:18:56]</a>. This ultimately leads to a safer future, as a decentralized AGI, accessible to private companies, policymakers, nonprofits, and civil society, is preferred over a centralized one <a class="yt-timestamp" data-t="00:19:19">[00:19:19]</a>.

Clem Delong views current AI models as building blocks for AGI but prefers to call it "software 2.0" rather than "artificial intelligence," to avoid sci-fi associations and the perception of a looming "Robocop scenario" <a class="yt-timestamp" data-t="00:20:12">[00:20:12]</a>. This "software 2.0" provides immense leverage for builders, akin to a "bicycle for the mind," enabling rapid development and richer applications <a class="yt-timestamp" data-t="00:21:36">[00:21:36]</a>.

Delong also argues that the current AI field has become less open than it used to be, partly due to commercial considerations and "misleading arguments" about safety <a class="yt-timestamp" data-t="00:28:27">[00:28:27]</a>. While [[open_source_ai_vs_closed_ai_ecosystems | open source]] is the foundation for all AI, even closed-source companies heavily rely on open research <a class="yt-timestamp" data-t="00:26:57">[00:26:57]</a>. In 2017-2019, most research, including Transformers and BERT, was publicly shared, accelerating progress <a class="yt-timestamp" data-t="00:27:36">[00:27:36]</a>. He challenges the notion that existential risk of AI justifies less openness, comparing it to historical fears about books or software <a class="yt-timestamp" data-t="00:29:01">[00:29:01]</a>.

## Business Model and Sustainability
Hugging Face has raised over $500 million but has spent less than half of that, managing to be profitable <a class="yt-timestamp" data-t="00:38:39">[00:38:39]</a>. This is unusual for many AI startups and reflects an intentional decision to maintain a sustainable business model that supports its community platform and free, open-source offerings <a class="yt-timestamp" data-t="00:39:33">[00:39:33]</a>.

Unlike some foundational model companies with massive capital expenditure requirements for compute and training, Hugging Face partners with cloud providers and passes along costs to users who train models <a class="yt-timestamp" data-t="00:39:04">[00:39:04]</a>. They avoid the "race to the bottom" on compute prices <a class="yt-timestamp" data-t="00:41:51">[00:41:51]</a>. Instead, Hugging Face provides value by offering a seamless and integrated experience for AI builders, making complex tasks easier and reducing the need for large ML infrastructure teams <a class="yt-timestamp" data-t="00:42:20">[00:42:20]</a>. For example, their Enterprise Hub offering provides a higher-margin revenue stream <a class="yt-timestamp" data-t="00:41:06">[00:41:06]</a>. This strategy makes them a "very proven business model" within [[challenges_and_opportunities_in_ai_monetization_and_business_models | AI monetization and business models]] <a class="yt-timestamp" data-t="00:41:20">[00:41:20]</a>.

The company believes that being the number one platform for AI builders, assuming AI becomes the default for building technology, naturally leads to a massive and sustainable business model <a class="yt-timestamp" data-t="00:45:20">[00:45:20]</a>. Their focus remains on user adoption and community empowerment <a class="yt-timestamp" data-t="00:45:45">[00:45:45]</a>.

## Future of AI and Hugging Face's Vision
Delong sees AI as an opportunity to "redistribute the cards" and empower a new generation of companies and founders <a class="yt-timestamp" data-t="00:31:31">[00:31:31]</a>. He notes that building an AI startup is significantly different from a traditional software startup <a class="yt-timestamp" data-t="00:33:47">[00:33:47]</a>. While some AI companies require heavy capital for compute, like foundational model companies for LLMs or other modalities (video, biology, chemistry, audio, image), many applications can be built by small teams leveraging existing APIs <a class="yt-timestamp" data-t="00:34:08">[00:34:08]</a>.

He emphasizes the need for a new playbook for AI startups, as traditional software playbooks (e.g., Lean Startup) may not apply <a class="yt-timestamp" data-t="00:35:28">[00:35:28]</a>. AI startups often require scientists as co-founders, given that AI is more science-driven than traditional software <a class="yt-timestamp" data-t="00:55:00">[00:55:00]</a>. The development cycle is longer (months, not days), and progress is measured in significant leaps (e.g., 10x improvement), rather than small iterative gains <a class="yt-timestamp" data-t="00:56:29">[00:56:29]</a>.

Contrary to the idea that only a few large players will dominate the AI landscape by controlling foundational models, Hugging Face believes in a future with "almost as many models as code repositories today" <a class="yt-timestamp" data-t="00:51:10">[00:51:10]</a>. This is because models are optimized for specific domains, latency, hardware, and use cases, leading to smaller, more efficient, and cheaper models <a class="yt-timestamp" data-t="00:52:10">[00:52:10]</a>. While large generalist models serve broad applications like ChatGPT, specialized models are more suitable for specific tasks like banking customer support <a class="yt-timestamp" data-t="00:53:41">[00:53:41]</a>.

Ultimately, all tech companies will become AI companies, building and fine-tuning their own models for their specific needs <a class="yt-timestamp" data-t="00:51:04">[00:51:04]</a>. To get there, the world needs many more AI builders (currently 5 million compared to 50-100 million software engineers) <a class="yt-timestamp" data-t="01:05:35">[01:05:35]</a>. AI building has a lower barrier to entry than traditional software development, as contributions can include expertise or data, not just code, potentially leading to 10 times more AI builders than software builders <a class="yt-timestamp" data-t="01:06:33">[01:06:33]</a>. This shift promises more inclusive products and solutions for social issues <a class="yt-timestamp" data-t="01:07:35">[01:07:35]</a>.

### Challenges
A challenge for Hugging Face as a platform is its inherent "curse of visibility" or "sexiness" <a class="yt-timestamp" data-t="00:46:55">[00:46:55]</a>. Like GitHub, which empowers countless software engineers but remains largely in the background, Hugging Face operates behind the scenes as an [[the_evolution_and_impact_of_ai_model_hosting_platforms | AI model hosting platform]] <a class="yt-timestamp" data-t="00:47:01">[00:47:01]</a>.

Another ongoing challenge is balancing the need to build a mature, stable platform with the rapid innovation and iteration required in the fast-evolving AI technology landscape <a class="yt-timestamp" data-t="00:48:19">[00:48:19]</a>. Hugging Face maintains a lean team of 250 members, aiming to stay an order of magnitude smaller than peers, to reconcile fast building with the need for scalable tools <a class="yt-timestamp" data-t="00:48:52">[00:48:52]</a>.

To learn more, visit huggingface.com <a class="yt-timestamp" data-t="01:07:57">[01:07:57]</a>.