---
title: Open Source AI vs Closed AI ecosystems
videoId: hzc1covUhYM
---

From: [[acquiredfm]] <br/> 

The discussion around artificial intelligence often centers on the dichotomy between open source and closed ecosystems, each presenting distinct advantages and challenges for AI builders and the broader technological landscape <a class="yt-timestamp" data-t="00:00:39">[00:00:39]</a>. [[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]], a leading platform for AI builders, stands at the center of this debate, facilitating both open and private development <a class="yt-timestamp" data-t="00:01:06">[00:01:06]</a>.

## Understanding the Landscape

In the past, technology was primarily built by writing millions of lines of code <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. Today, the method has shifted to training models using datasets and building AI applications <a class="yt-timestamp" data-t="00:01:32">[00:01:32]</a>. This new paradigm is often referred to as "Software 2.0" <a class="yt-timestamp" data-t="00:20:50">[00:20:50]</a>. Most AI builders currently utilize platforms like [[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]] to find models, datasets, and develop applications <a class="yt-timestamp" data-t="00:01:39">[00:01:39]</a>.

The debate between open and closed source in AI is somewhat misleading because open source serves as the foundation for virtually all AI, including solutions from closed-source companies like OpenAI and Anthropic, which extensively use open research and open source components <a class="yt-timestamp" data-t="00:26:55">[00:26:55]</a>. The distinction lies in whether proprietary layers are built on top of this open-source foundation <a class="yt-timestamp" data-t="00:27:24">[00:27:24]</a>.

## Historical Context

Historically, the AI field was more open. From 2017 to 2019, much of the research, including foundational developments like Transformers and BERT, was publicly shared by the research community, including Google and OpenAI <a class="yt-timestamp" data-t="00:27:36">[00:27:36]</a>. This openness and collaboration significantly accelerated progress <a class="yt-timestamp" data-t="00:28:06">[00:28:06]</a>. For example, OpenAI's GPT-2 and GPT-3 were built on the Transformer architecture, leading to the current state of [[generative_ai_and_its_rapid_evolution | Generative AI and its rapid evolution]] <a class="yt-timestamp" data-t="00:28:16">[00:28:16]</a>.

However, in the last two to three years, the field has become less open, largely due to commercial considerations and "misleading arguments" concerning the safety of openness versus closeness <a class="yt-timestamp" data-t="00:28:27">[00:28:27]</a>.

## The Case for Openness

Proponents of open source AI emphasize several key benefits:

*   **Foundation for all AI** <a class="yt-timestamp" data-t="00:26:57">[00:26:57]</a>: Even closed-source companies rely on open-source frameworks and research.
*   **Accelerated Progress**: Openness fosters collaboration, leading to faster advancements in the field <a class="yt-timestamp" data-t="00:28:06">[00:28:06]</a>.
*   **Empowerment and Innovation**: Open access to models and datasets enables thousands of new AI companies to be built, redistributing power away from a few large tech companies <a class="yt-timestamp" data-t="00:31:09">[00:31:09]</a>. This allows a new generation of founders and teams to play a significant role <a class="yt-timestamp" data-t="00:31:40">[00:31:40]</a>.
*   **Safer Future**: A decentralized approach to AGI (Artificial General Intelligence) is considered safer than a future where only one company controls it <a class="yt-timestamp" data-t="00:19:23">[00:19:23]</a>. Providing access to technology for policy makers, non-profits, and civil society contributes to a more secure future <a class="yt-timestamp" data-t="00:19:41">[00:19:41]</a>.
*   **Societal Alignment and Inclusivity**: Greater participation in the building process can lead to better, more inclusive products that address a wider range of social issues <a class="yt-timestamp" data-t="01:07:35">[01:07:35]</a>.

## Arguments Against Openness (and Rebuttals)

A primary argument against openness revolves around the "existential risk" of AI, suggesting that sharing research is dangerous as "bad actors" could misuse it <a class="yt-timestamp" data-t="00:29:01">[00:29:01]</a>. However, this argument has been used in previous technology cycles (e.g., books, nuclear), and the rapid public awareness of AI might have amplified these fears <a class="yt-timestamp" data-t="00:29:23">[00:29:23]</a>. The term "artificial intelligence" itself can evoke sci-fi associations and create unnecessary fears <a class="yt-timestamp" data-t="00:30:14">[00:30:14]</a>.

Another argument for closed systems is the idea of data moats and tight integration between models and applications, allowing proprietary systems to continuously fine-tune and improve their models with real-time user interaction data <a class="yt-timestamp" data-t="01:01:06">[01:01:06]</a>. However, the exact mechanisms for creating "moats" and "economies of scale" in AI are still unclear <a class="yt-timestamp" data-t="01:01:45">[01:01:45]</a>. Many current winners, like OpenAI, did not initially have unique data advantages <a class="yt-timestamp" data-t="01:03:21">[01:03:21]</a>.

## [[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]]'s Model

[[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]] has become the leading [[the_evolution_and_impact_of_ai_model_hosting_platforms | AI model hosting platforms]] platform for AI builders, with over 5 million users sharing more than 3 million models, datasets, and applications <a class="yt-timestamp" data-t="00:01:06">[00:01:06]</a>. Their approach is famously open and [[the_growth_and_influence_of_communitydriven_ai_development | community-driven AI development]] <a class="yt-timestamp" data-t="00:16:42">[00:16:42]</a>.

Key aspects of [[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]]'s model:
*   **Facilitating Collaboration**: The platform provides features for collaboration, versioning, bug reporting, and reviews, enabling large teams to build AI together <a class="yt-timestamp" data-t="00:05:45">[00:05:45]</a>.
*   **Supporting Both Public and Private Use**: While championing openness, [[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]] allows half of its models, datasets, and apps to remain private for internal company use <a class="yt-timestamp" data-t="00:18:08">[00:18:08]</a>. This caters to companies that prefer varying degrees of openness <a class="yt-timestamp" data-t="00:18:17">[00:18:17]</a>.
*   **Sustainable [[challenges_and_opportunities_in_ai_monetization_and_business_models | AI monetization and business models]]**: [[the_role_of_hugging_face_in_the_ai_ecosystem | Hugging Face]] is profitable and has raised over $500 million, spending less than half of that <a class="yt-timestamp" data-t="00:38:42">[00:38:42]</a>. They avoid the "race to the bottom on compute" by providing value-added services, integrating compute seamlessly with platform features, making the experience significantly easier for companies <a class="yt-timestamp" data-t="00:41:51">[00:41:51]</a>. This "locked-in compute" model, along with Enterprise Hub offerings, allows for high margins <a class="yt-timestamp" data-t="00:43:05">[00:43:05]</a>.
*   **Community-Driven Development**: The platform's evolution has been driven by user feedback, starting from porting Google's BERT model to PyTorch and expanding to hosting models and datasets <a class="yt-timestamp" data-t="00:14:43">[00:14:43]</a>. This community contribution is central to their success <a class="yt-timestamp" data-t="00:16:54">[00:16:54]</a>.

## The Future of AI

It is predicted that all tech companies will eventually become AI companies, building and optimizing their own models for specific use cases and constraints <a class="yt-timestamp" data-t="00:51:04">[00:51:04]</a>. This contrasts with the current model of relying heavily on APIs from large foundational model companies <a class="yt-timestamp" data-t="00:50:02">[00:50:02]</a>. The argument for this future rests on the idea that specialized, smaller, more efficient, and cheaper models, purpose-built for specific domains or hardware, will become prevalent <a class="yt-timestamp" data-t="00:52:10">[00:52:10]</a>.

The number of AI builders is expected to grow significantly, potentially exceeding the current 50 million software engineers to reach 50-100 million or even more <a class="yt-timestamp" data-t="01:05:51">[01:05:51]</a>. This is because the barrier to entry for contributing to AI is lower than traditional software development; one can be an AI builder by contributing expertise or data, not just by writing code <a class="yt-timestamp" data-t="01:06:34">[01:06:34]</a>.

The [[Impact of AI on gaming | impact of AI on gaming]], [[the_impact_of_ai_on_financial_markets | financial markets]], and [[impact_of_ai_on_financial_services_and_operational_efficiency | financial services]] is already being seen, and the technology is unlocking new capabilities that were previously impossible <a class="yt-timestamp" data-t="00:02:36">[00:02:36]</a>. As investors like [[ai_and_machine_learning_insights_from_nvidia | Nvidia]] continue to back companies in this space, it highlights the perceived opportunities <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>.

AI presents an opportunity to "shake things up," challenging monopolies and fostering a new era of innovation <a class="yt-timestamp" data-t="01:05:01">[01:05:01]</a>. It's considered the "opportunity of the century" to break established positions and build something new <a class="yt-timestamp" data-t="01:05:01">[01:05:01]</a>.