---
title: Limitations and challenges of current AI technologies
videoId: TpZcGhYp4rw
---

From: [[fireship]] <br/> 

As of March 29, 2023, generative pre-trained transformers (GPTs) are significantly impacting the world, leading to widespread concern and discussions about their capabilities and future. OpenAI recently published a paper indicating that up to 49% of workers could have at least half of their job functions enhanced by AI <a class="yt-timestamp" data-t="00:00:13">[00:00:13]</a>. This has prompted over 1,000 individuals, including prominent figures like Steve Wozniak, Victoria Krakovna, and Elon Musk, to sign a petition urging AI labs to halt the training of systems more powerful than GPT-4 until safety can be assured <a class="yt-timestamp" data-t="00:00:29">[00:00:29]</a>.

Despite these concerns, there is a perspective that AI might be overhyped and presents several inherent [[ai_advancements_and_industry_challenges | challenges]] and [[technical_aspects_and_challenges_of_ai_video_modeling | limitations]].

## Real-World Performance and Application

While AI tools like ChatGPT excel at tasks where solutions are well-defined and pre-existing, such as solving LeetCode questions <a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>, their effectiveness diminishes when attempting to build complex, novel systems. AI models, particularly large language models, primarily "regurgitate" information found on the internet <a class="yt-timestamp" data-t="00:02:21">[00:02:21]</a>. They struggle significantly when faced with problems for which information has not been previously processed or "gurgitated" <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>.

For instance, an attempt to build a moderately complex .NET application with ChatGPT began to fail when multiple intricate components were introduced <a class="yt-timestamp" data-t="00:02:13">[00:02:13]</a>. While the ability for AI to execute its own code via plugins and generate numerous solutions to well-defined problems is a development that could potentially make writing source code by hand obsolete <a class="yt-timestamp" data-t="00:02:29">[00:02:29]</a>, it highlights a current reliance on known data and problem structures. This capability could lead to [[future_of_programming_with_ai | more efficient development]], akin to how garbage collectors made memory management less manual <a class="yt-timestamp" data-t="00:02:46">[00:02:46]</a>.

## Marketing Hype vs. Reality

A significant aspect of the current AI landscape is the pervasive marketing hype. OpenAI, led by CEO Sam Altman, a veteran of Y Combinator, is adept at accelerating growth <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>. Despite Altman's claims that GPT-4 is "not as good as it seems" <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>, the company simultaneously releases papers touting its "Sparks of AGI" without providing crucial technical details <a class="yt-timestamp" data-t="00:03:17">[00:03:17]</a>. This deliberate strategy includes discussions about the urgent need for AI regulation before artificial general intelligence (AGI) emerges <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a>. This approach is perceived as optics for marketing, greatly benefiting OpenAI, which has transformed from a niche tech company to a household name, with over 5% of the workforce using ChatGPT daily <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a>.

## Impact on Digital Authenticity

AI is contributing to a more "boring" internet by blurring the lines between human and AI-generated content <a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a>. It has become challenging to discern whether social media accounts or images are human-crafted <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>. This raises [[privacy_concerns_with_ai_tools_and_data_security_issues | concerns about authenticity]] and contributes to theories like the "dead internet theory," which posits that large tech companies might use AI to populate the internet with fake accounts to boost advertising revenue and encourage content creation <a class="yt-timestamp" data-t="00:04:38">[00:04:38]</a>.

## Inherent Limits and the Human Element

Many experts believe that AI, like all prior technologies, will eventually plateau <a class="yt-timestamp" data-t="00:05:05">[00:05:05]</a>, experiencing a "sigmoid of sorrow" rather than an exponential singularity <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a>. The algorithms underpinning large language models are not inherently complex; it's the massive computing power and time required to implement them effectively that is significant <a class="yt-timestamp" data-t="00:05:14">[00:05:14]</a>. The concept of a transformer in deep learning was introduced by Google in 2017 <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>; OpenAI's achievement was creating a user-friendly product from this idea <a class="yt-timestamp" data-t="00:05:28">[00:05:28]</a>.

Despite the advancements, GPT-4 is not considered close to AGI, and AGI's emergence is not anticipated anytime soon, or possibly ever <a class="yt-timestamp" data-t="00:05:35">[00:05:35]</a>. There is a "special" aspect to human existence, potentially metaphysical or spiritual, that science has yet to comprehend or replicate <a class="yt-timestamp" data-t="00:05:41">[00:05:41]</a>. It is argued that AI will remain skilled at mimicking human behavior but will not surpass human intellect, as its foundation is derived from existing internet content <a class="yt-timestamp" data-t="00:06:10">[00:06:10]</a>. This suggests a fundamental limitation in its capacity for true originality or consciousness.