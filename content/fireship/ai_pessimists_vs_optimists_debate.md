---
title: AI pessimists vs optimists debate
videoId: -2k1rcRzsLA
---

From: [[fireship]] <br/> 

The tech world is currently divided into two main camps regarding the future of Artificial Intelligence <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>.

## The Pessimists

This camp believes that AI is [[marketing_and_hype_surrounding_ai_advancements | overhyped]] and has [[skepticism_about_ai_achieving_general_intelligence | plateaued]], particularly with models like GPT 3.5 <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>. They tend to "sound smart" <a class="yt-timestamp" data-t="00:00:30">[00:00:30]</a>.

## The Optimists

Conversely, the optimists anticipate the emergence of an artificial super intelligence that will propel humanity into Ray Kurzweil's technological singularity <a class="yt-timestamp" data-t="00:00:19">[00:00:19]</a>. This camp is associated with "making money" <a class="yt-timestamp" data-t="00:00:32">[00:00:32]</a>.

## Challenges to Optimism

Being an AI optimist can be difficult due to the perceived need to trust "hype Jedi" like Sam Altman and "closed AI companies" such as OpenAI <a class="yt-timestamp" data-t="00:00:33">[00:00:33]</a>. Sam Altman himself has acknowledged that the [[marketing_and_hype_surrounding_ai_advancements | AI hype was out of control]] and that OpenAI has not internally achieved Artificial General Intelligence (AGI) <a class="yt-timestamp" data-t="00:01:18">[00:01:18]</a>.

Concerns about the current state of AI models include:
*   ChatGPT's bugginess, where a security researcher demonstrated how to make it perform Denial-of-Service (DoS) attacks on websites by crawling multiple URLs in parallel <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>. This behavior is seen as something "no truly intelligent being would do" <a class="yt-timestamp" data-t="00:01:37">[00:01:37]</a>, contributing to [[skepticism_about_ai_achieving_general_intelligence | skepticism about AI achieving general intelligence]].
*   [[criticism_of_openai_and_ai_industry_hype | Benchmarking concerns]]: There is a lack of trust in benchmarks, especially after Epic AI, a company providing a popular math benchmark, disclosed it was funded by OpenAI, raising questions about a conflict of interest <a class="yt-timestamp" data-t="00:01:57">[00:01:57]</a>.

## Recent Advancements and Open-Source Impact

Despite these debates, advancements continue in the [[ai_advancements_and_industry_challenges | AI race]] <a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>. The release of OpenAI's O1 model marked a step forward <a class="yt-timestamp" data-t="00:01:41">[00:01:41]</a>.

However, the open-source community has rapidly caught up with the release of DeepSeek R1 from China <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. DeepSeek R1 is a state-of-the-art, free, and open-source Chain of Thought reasoning model <a class="yt-timestamp" data-t="00:00:01">[00:00:01]</a>. It is licensed under an MIT-like license, allowing for free and commercial use <a class="yt-timestamp" data-t="00:01:00">[00:01:00]</a>.

### DeepSeek R1 Performance

DeepSeek R1's benchmarks indicate it is on par with OpenAI's O1 and even surpasses it in areas like math and [[ai_in_software_engineering | software engineering]] <a class="yt-timestamp" data-t="00:01:49">[00:01:49]</a>. This provides an open-source alternative to proprietary models like OpenAI O1, which can be costly <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>. The availability of such models for free use allows for their integration into various applications, potentially impacting [[implications_of_ai_advancements_on_different_professions | different professions]] and the [[impact_of_ai_on_creative_and_technical_professions | creative and technical professions]] <a class="yt-timestamp" data-t="00:01:03">[00:01:03]</a>.

### DeepSeek R1's Learning Approach

DeepSeek R1 distinguishes itself by not using supervised fine-tuning <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a>. Instead, it utilizes direct or pure reinforcement learning <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>. This method involves giving the model examples without solutions, allowing it to experiment and learn by finding the correct solution through reinforcement <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>. In this process, the AI attempts multiple times to generate answers (outputs), which are then grouped and assigned a reward score, guiding the AI to adjust its approach for higher-scoring answers <a class="yt-timestamp" data-t="00:03:14">[00:03:14]</a>.

### When to Use Chain of Thought Models

Chain of Thought models like DeepSeek R1 and O1 are particularly effective for complex problem-solving scenarios <a class="yt-timestamp" data-t="00:03:53">[00:03:53]</a>. They excel in:
*   Advanced math problems <a class="yt-timestamp" data-t="00:03:57">[00:03:57]</a>
*   Puzzles <a class="yt-timestamp" data-t="00:03:57">[00:03:57]</a>
*   Coding problems that require detailed planning <a class="yt-timestamp" data-t="00:03:58">[00:03:58]</a>

When prompting these models, it's recommended to keep the prompt concise and direct, allowing the model to perform its own "thinking" steps before providing the solution <a class="yt-timestamp" data-t="00:03:31">[00:03:31]</a>.