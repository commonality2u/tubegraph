---
title: Security vulnerabilities and exploits
videoId: Iq_r7IcNmUk
---

From: [[fireship]] <br/> 

Software bugs, while sometimes leading to humorous "features," can have severe consequences, impacting finances, critical infrastructure, and even human lives <a class="yt-timestamp" data-t="00:00:30">[00:00:30]</a>. This article explores various instances where software vulnerabilities and exploits have caused significant real-world problems.

## Communication System Vulnerabilities

### AT&T Long-Distance Crash (1990)

In 1990, a single faulty line of C code in a software update caused a widespread outage in AT&T's long-distance network <a class="yt-timestamp" data-t="00:04:46">[00:04:46]</a>. A `break` statement within an `if` clause inside a `switch` clause led to crucial data being overwritten when a second message was received while the switch was processing the first <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>. This caused a cascading failure across the network, blocking 50 million calls globally <a class="yt-timestamp" data-t="00:05:14">[00:05:14]</a>. This incident highlights the [[vulnerability_of_critical_infrastructures_to_software_errors | vulnerability of critical infrastructures to software errors]] due to seemingly minor coding errors.

## Consumer Device and Application Exploits

### Apple FaceTime Group Call Eavesdropping Bug (2019)

A significant [[website_security_vulnerabilities | website security vulnerability]] was discovered in Apple's FaceTime in 2019 <a class="yt-timestamp" data-t="00:02:23">[00:02:23]</a>. Users could initiate a FaceTime call, then add their own phone number as an additional person to create a group call before the recipient answered <a class="yt-timestamp" data-t="00:02:26">[00:02:26]</a>. This glitch activated the group call and allowed the initiator to eavesdrop on audio from the original recipient's phone <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a>. Pressing the power button on the recipient's end to dismiss the call would even activate their camera <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>. The bug, discovered by a 14-year-old, was initially ignored by Apple but gained viral attention on social media <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>. Apple responded by disabling group FaceTime and releasing a patch <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>. The core issue was a lack of state checking before activating the audio stream <a class="yt-timestamp" data-t="00:03:10">[00:03:10]</a>.

## Cyber Security and Internet Exploits

### Morris Worm (1988)

In November 1988, graduate student Robert Morris accidentally created the Morris worm <a class="yt-timestamp" data-t="00:07:18">[00:07:18]</a>. Designed to gauge the size of the internet, this self-replicating computer program rapidly spread across Unix-based systems <a class="yt-timestamp" data-t="00:07:26">[00:07:26]</a>. The worm exploited [[website_security_vulnerabilities | weaknesses]] in protocols like sendmail and a buffer overflow [[website_security_vulnerabilities | vulnerability]] in the finger program <a class="yt-timestamp" data-t="00:07:44">[00:07:44]</a>. It would then execute code remotely and spread itself <a class="yt-timestamp" data-t="00:07:54">[00:07:54]</a>. A bug in the code caused it to repeatedly reinfect the same computer, overwhelming resources and crashing thousands of machines, including those at MIT, UC Berkeley, and NASA <a class="yt-timestamp" data-t="00:07:59">[00:07:59]</a>. It affected about 10% of the internet at the time <a class="yt-timestamp" data-t="00:07:39">[00:07:39]</a> and resulted in Morris's felony conviction under the Computer Fraud and Abuse Act <a class="yt-timestamp" data-t="00:08:07">[00:08:07]</a>.

### Heartbleed (2014)

Heartbleed was a critical [[website_security_vulnerabilities | vulnerability]] discovered in OpenSSL in 2014, a library essential for secure internet communication <a class="yt-timestamp" data-t="00:12:19">[00:12:19]</a>. Caused by a missing bounds check in the Transport Layer Security (TLS) heartbeat extension, it allowed attackers to request memory contents from a server <a class="yt-timestamp" data-t="00:12:27">[00:12:27]</a>. This could potentially expose highly confidential data without detection <a class="yt-timestamp" data-t="00:12:47">[00:12:47]</a>. An estimated two-thirds of internet servers were vulnerable <a class="yt-timestamp" data-t="00:11:55">[00:11:55]</a>.

### CrowdStrike Configuration Error (2024)

In 2024, the cybersecurity company CrowdStrike experienced a major incident when a bad configuration file, "Channel file 291," was pushed to production <a class="yt-timestamp" data-t="00:12:42">[00:12:42]</a>. This resulted in millions of Windows machines entering the blue screen of death, disrupting hospitals, cancelling flights, and causing widespread chaos <a class="yt-timestamp" data-t="00:12:57">[00:12:57]</a>. This highlights [[challenges_with_automated_software_updates_and_system_safety | challenges with automated software updates and system safety]] and the [[impact_of_faulty_software_updates_on_global_systems | impact of faulty software updates on global systems]].

## Critical Infrastructure and Safety System Failures

### Northeastern Blackout (2003)

On August 14, 2003, nearly 50 million people in the United States and Canada lost power due to the Northeastern Blackout <a class="yt-timestamp" data-t="00:13:09">[00:13:09]</a>. FirstEnergy Corporation's power grid monitoring system had poor error handling code <a class="yt-timestamp" data-t="00:13:17">[00:13:17]</a>. If multiple alarms were generated rapidly, the system would enter an unrecoverable state without notifying operators, leading to no new alarms being shown and existing ones not being cleared <a class="yt-timestamp" data-t="00:13:20">[00:13:20]</a>. Operators were unaware of the deteriorating situation, showcasing a critical [[vulnerability_of_critical_infrastructures_to_software_errors | vulnerability of critical infrastructures to software errors]] in monitoring systems <a class="yt-timestamp" data-t="00:13:28">[00:13:28]</a>.

### Therac-25 Radiation Machine (1980s)

The Therac-25 radiation machine, used for cancer treatment, is one of the most infamous deadly software bugs <a class="yt-timestamp" data-t="00:14:11">[00:14:11]</a>. It suffered from inadequate error handling <a class="yt-timestamp" data-t="00:14:20">[00:14:20]</a>. When a race condition occurred, it would deliver lethal radiation doses to patients, leading to at least three deaths from doses 100 times higher than intended <a class="yt-timestamp" data-t="00:14:24">[00:14:24]</a>. The device also had mechanical interlocks removed, relying entirely on software for safety, which proved to be a fatal mistake <a class="yt-timestamp" data-t="00:14:35">[00:14:35]</a>. This case stands as a stark [[lessons_learned_from_catastrophic_software_failures | lesson learned from catastrophic software failures]].

## Military and Aviation Software Failures

### Royal Air Force Helicopter Crash (1994)

In 1994, a Royal Air Force helicopter crashed in Scotland during foggy conditions, killing 25 people <a class="yt-timestamp" data-t="00:14:44">[00:14:44]</a>. The aircraft's automatic throttle control system, which takes inputs from sensors, became overloaded in the challenging conditions <a class="yt-timestamp" data-t="00:14:48">[00:14:48]</a>. Pilots lost total control when the system malfunctioned <a class="yt-timestamp" data-t="00:14:58">[00:14:58]</a>. The investigation revealed that the throttle control software was not adequately tested under such extreme conditions <a class="yt-timestamp" data-t="00:15:06">[00:15:06]</a>.

### Patriot Missile System (1991)

During the 1991 Gulf War, a software bug in the Patriot missile system led to the failure to intercept a Scud missile, which killed 28 American soldiers <a class="yt-timestamp" data-t="00:14:51">[00:14:51]</a>. The system's 24-bit timer, which tracked time in tenths of seconds, overflowed after more than 100 hours of operation without a reset <a class="yt-timestamp" data-t="00:14:59">[00:14:59]</a>. This caused it to report incorrect information about incoming threats, illustrating a critical [[famous_software_bugs_in_history | famous software bug]] with deadly consequences <a class="yt-timestamp" data-t="00:15:09">[00:15:09]</a>.

### Aegis Combat System Disaster (1988)

In 1988, the Aegis combat system accidentally shot down a civilian Iranian plane, killing 290 people <a class="yt-timestamp" data-t="00:15:19">[00:15:19]</a>. The investigation found that a lack of user-friendly information on the system's display and a timing lag that led to misleading altitude data contributed to the misidentification of the friendly plane as a threat <a class="yt-timestamp" data-t="00:15:28">[00:15:28]</a>. This highlights how human-computer interaction design can introduce [[website_security_vulnerabilities | vulnerabilities]].

### Boeing 737 MAX MCAS (2018-2019)

Modern jets often rely heavily on software for flight control <a class="yt-timestamp" data-t="00:15:46">[00:15:46]</a>. The Boeing 737 MAX planes were updated with the Maneuvering Characteristics Augmentation System (MCAS), designed to automatically push the nose down to prevent a stall <a class="yt-timestamp" data-t="00:15:53">[00:15:53]</a>. A major oversight in the programming allowed the system to initiate this nose-down sequence if only one of its two angle of attack sensors provided faulty data <a class="yt-timestamp" data-t="00:16:01">[00:16:01]</a>. This flaw led to the tragic crashes of Lion Air Flight 610 in 2018 and Ethiopian Airlines Flight 302 in 2019, resulting in 346 deaths <a class="yt-timestamp" data-t="00:16:13">[00:16:13]</a>. The fix required both sensors to provide consistent data before MCAS could activate <a class="yt-timestamp" data-t="00:16:29">[00:16:29]</a>. This incident serves as a significant [[lessons_learned_from_catastrophic_software_failures | lesson learned from catastrophic software failures]] in aviation software.

## Financial System Glitches

### Chase ATM Glitch (2024)

In 2024, a glitch at JP Morgan Chase ATMs allowed individuals to withdraw tens of thousands of dollars they didn't have by depositing fake checks <a class="yt-timestamp" data-t="00:03:20">[00:03:20]</a>. The bug prevented a safeguard that normally requires checks to clear before funds can be withdrawn <a class="yt-timestamp" data-t="00:03:29">[00:03:29]</a>. While exploited for fraud, this highlights [[consequences_of_software_glitches_in_financial_systems | consequences of software glitches in financial systems]] built on older, proprietary code <a class="yt-timestamp" data-t="00:03:23">[00:03:23]</a>.

### Citi Bank Bad UI Disaster (2020)

In 2020, Citi Bank accidentally transferred the full loan amount of approximately $900 million instead of an intended $8 million interest payment <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>. This was due to a poorly designed user interface (UI) with a confusing three-screen process for payments, where checking certain boxes appeared to ensure only interest was paid but actually did the opposite <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>. This incident demonstrates how design flaws in software can lead to massive [[consequences_of_software_glitches_in_financial_systems | financial consequences]] <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>.

### Knight Capital Money Burn Speedrun (2012)

In 2012, algorithmic trading firm Knight Capital lost $440 million in a single day <a class="yt-timestamp" data-t="00:11:13">[00:11:13]</a>. Developers accidentally used a variable name linked to an outdated testing algorithm called Power Peg, designed to manipulate virtual markets by buying high and selling low <a class="yt-timestamp" data-t="00:10:42">[00:10:42]</a>. When pushed to production, the algorithm went haywire, flooding the New York Stock Exchange with 4 million incorrect trades in just 45 minutes <a class="yt-timestamp" data-t="00:11:05">[00:11:05]</a>. This catastrophic event wiped out 75% of the company's investor equity <a class="yt-timestamp" data-t="00:11:16">[00:11:16]</a>.