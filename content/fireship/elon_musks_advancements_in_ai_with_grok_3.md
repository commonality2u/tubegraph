---
title: Elon Musks advancements in AI with Grok 3
videoId: b0XI-cbel1U
---

From: [[fireship]] <br/> 

Just hours ago, [[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]], a new large language model, achieved the number one spot on the LM Marina leaderboard, crushing existing benchmarks <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>. This model, developed by Elon Musk's xAI, is noted for its intelligence and its mostly uncensored nature <a class="yt-timestamp" data-t="00:00:16">[00:00:16]</a>.

## [[features_and_capabilities_of_grok_3 | Features and Capabilities]]

[[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]] boasts several advanced [[features_and_capabilities_of_grok_3 | capabilities]]:
*   **Deep Thinking Mode** It includes a deep thinking mode, similar to DeepSeek Coder 1 <a class="yt-timestamp" data-t="00:00:19">[00:00:19]</a>.
*   **Text-to-Video** In the near future, it is expected to support text-to-video generation <a class="yt-timestamp" data-t="00:00:22">[00:00:22]</a>.
*   **Uncensored Content Generation** A significant distinguishing feature of [[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]] is its ability to generate content that may be illegal in many parts of the world, stemming from its optimization for "maximum truth seeking" even at the expense of political correctness <a class="yt-timestamp" data-t="00:01:23">[00:01:23]</a>. It is capable of generating images of celebrities or writing profanity-laden poems about racial stereotypes <a class="yt-timestamp" data-t="00:01:30">[00:01:30]</a>. While other LLMs block such prompts, [[grok_3_and_its_impact_on_ai_benchmarks | Grok]] does not <a class="yt-timestamp" data-t="00:01:36">[00:01:36]</a>. Despite these controversial [[features_and_capabilities_of_grok_3 | capabilities]], [[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]] is expected to become available in countries like Germany and the UK soon <a class="yt-timestamp" data-t="00:01:50">[00:01:50]</a>.
*   **Direct Twitter Data Access** [[grok_3_and_its_impact_on_ai_benchmarks | Grok]] is unique in having direct access to the "fire hose of data" from Twitter <a class="yt-timestamp" data-t="00:01:18">[00:01:18]</a>.

## [[grok_3_and_its_impact_on_ai_benchmarks | Performance and Benchmarks]]

[[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]] currently leads the LM Marina leaderboard, which uses a blind taste test method where humans compare different LLMs side-by-side <a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>. Another benchmark indicates that [[grok_3_and_its_impact_on_ai_benchmarks | Grok]] outperforms Gemini, Claude, DeepSeek, and GPT-4 in areas like math, science, and coding <a class="yt-timestamp" data-t="00:02:10">[00:02:10]</a>. However, this benchmark conveniently omits OpenAI's O3 model, and when O3 is included, the picture changes <a class="yt-timestamp" data-t="00:02:14">[00:02:14]</a>. Other benchmarks, such as Codeforces and Arc AGI, are also missing <a class="yt-timestamp" data-t="00:02:18">[00:02:18]</a>. It's noted that benchmarks are almost always cherry-picked <a class="yt-timestamp" data-t="00:02:20">[00:02:20]</a>.

In a "Vibe check," [[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]] was able to generate valid Svelte 5 code in one shot and assist in building a game in Godot <a class="yt-timestamp" data-t="00:02:28">[00:02:28]</a>. Overall, it performs well and appears to be plateauing at the same level as other state-of-the-art models <a class="yt-timestamp" data-t="00:02:33">[00:02:33]</a>.

## [[training_infrastructure_and_future_developments_of_grok_3 | Training Infrastructure]]

Details regarding the training of [[grok_3_and_its_impact_on_ai_benchmarks | Grok 3]] have been provided. It was trained at the Colossus supercomputer in Memphis, Tennessee, which is believed to be the world's largest [[developments_in_artificial_intelligence_and_aipowered_tools | AI]] supercomputer <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>. This facility houses a cluster of over 200,000 Nvidia H100 GPUs, with plans for expansion to 1 million GPUs <a class="yt-timestamp" data-t="00:02:58">[00:02:58]</a>. The immense power requirements of the facility necessitate the use of portable diesel generators, as the electricity demand cannot be fully met by the grid <a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a>.

## [[training_infrastructure_and_future_developments_of_grok_3 | Future Developments]]: Super Grok

A more powerful version, "Super Grok," is anticipated, which is expected to cost $30 per month <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>. This pricing would be highly competitive compared to Chat GPT Pro, which costs $200 per month <a class="yt-timestamp" data-t="00:03:15">[00:03:15]</a>.