---
title: Skepticism about AI achieving general intelligence
videoId: TpZcGhYp4rw
---

From: [[fireship]] <br/> 

While [[marketing_and_hype_surrounding_ai_advancements | AI advancements]] like generative pre-trained transformers (GPTs) are "transforming the world" and causing public concern, there is significant skepticism regarding their true capabilities and the likelihood of them achieving artificial general intelligence (AGI) <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a> <a class="yt-timestamp" data-t="00:00:06">[00:00:06]</a> <a class="yt-timestamp" data-t="00:00:08">[00:00:08]</a>. An OpenAI paper concluded that up to 49% of workers could have at least half of their job functions "enhanced by AI" <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a> <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. This has led to [[concerns_and_petitions_against_ai_development | concerns and petitions]], with over 1,000 people signing a petition to pause training for AI systems more powerful than GPT-4 until safety can be assured <a class="yt-timestamp" data-t="00:00:29">[00:00:29]</a> <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>. Prominent signatories include Steve Wozniak, Victoria Krakovna of DeepMind, and Elon Musk <a class="yt-timestamp" data-t="00:00:40">[00:00:40]</a>.

Despite these developments, many question whether AI is overhyped <a class="yt-timestamp" data-t="00:00:49">[00:00:49]</a>.

## [[limitations_and_challenges_of_current_ai_technologies | Limitations of Current AI Models]]

ChatGPT, while appearing miraculous for previously solved problems like LeetCode questions, is "far less impressive" when attempting to build complex systems <a class="yt-timestamp" data-t="00:01:59">[00:01:59]</a> <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>. For instance, it struggles when multiple moving parts are introduced in a moderately complex application <a class="yt-timestamp" data-t="00:02:14">[00:02:14]</a> <a class="yt-timestamp" data-t="00:02:17">[00:02:17]</a>.

The core issue is that large language models (LLMs) primarily "regurgitate information from the internet in clever ways" <a class="yt-timestamp" data-t="00:02:21">[00:02:21]</a>. They struggle with information that has never been previously processed or "gurgitated" <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a> <a class="yt-timestamp" data-t="00:02:26">[00:02:26]</a>. While new plugins allow AI to execute its own code and test thousands of solutions to well-defined problems, potentially making manual source code writing obsolete <a class="yt-timestamp" data-t="00:02:28">[00:02:28]</a> <a class="yt-timestamp" data-t="00:02:44">[00:02:44]</a>, this does not equate to AGI.

## Marketing and Hype

A significant portion of the perceived advancements in AI, particularly from companies like OpenAI, is attributed to "marketing hype" <a class="yt-timestamp" data-t="00:02:58">[00:02:58]</a>. Sam Altman, CEO of OpenAI, is noted for his ability to accelerate growth through marketing strategies <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a> <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>.

This [[criticism_of_openai_and_ai_industry_hype | criticism of OpenAI and the AI industry hype]] includes:
*   Altman not taking equity in OpenAI, while simultaneously warning that GPT-4 is "not as good as it seems" <a class="yt-timestamp" data-t="00:03:06">[00:03:06]</a> <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>.
*   OpenAI releasing papers touting GPT-4's capabilities and "sparks of AGI" without disclosing important technical details <a class="yt-timestamp" data-t="00:03:13">[00:03:13]</a> <a class="yt-timestamp" data-t="00:03:19">[00:03:19]</a>.
*   Advocating for immediate AI regulation due to the supposed emergence of AGI <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a>.
*   Conspiracy theories stemming from Altman's attendance at the Bilderberg meeting, suggesting a coordinated effort to control AI development and its narrative <a class="yt-timestamp" data-t="00:03:28">[00:03:28]</a> <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>.

The hype has been "hugely beneficial to OpenAI," transforming it into a household name, with over 5% of the workforce using ChatGPT daily <a class="yt-timestamp" data-t="00:03:45">[00:03:45]</a> <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a> <a class="yt-timestamp" data-t="00:03:53">[00:03:53]</a>. This is seen as a "coordinated product release schedule" often aligned with partners like Microsoft <a class="yt-timestamp" data-t="00:04:04">[00:04:04]</a> <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>.

## Impact on the Internet

AI is making the internet "boring" and difficult to distinguish between human-crafted and AI-generated content <a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a> <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>. The "dead internet theory" suggests that tech companies have used AI for years to populate the internet with fake accounts, boosting advertising revenue and motivating creators through fake engagement <a class="yt-timestamp" data-t="00:04:39">[00:04:39]</a> <a class="yt-timestamp" data-t="00:04:49">[00:04:49]</a>.

## The Plateau Effect and Human Uniqueness

A primary argument against imminent AGI is that AI, like other technologies, will "plateau" rather than leading to an "exponential Singularity" <a class="yt-timestamp" data-t="00:05:05">[00:05:05]</a> <a class="yt-timestamp" data-t="00:05:07">[00:05:07]</a> <a class="yt-timestamp" data-t="00:05:10">[00:05:10]</a>. This is referred to as a "sigmoid of sorrow" <a class="yt-timestamp" data-t="00:05:13">[00:05:13]</a>.

Arguments for this plateau include:
*   The algorithms powering LLMs are not inherently complex, though training them well requires massive computing power and time <a class="yt-timestamp" data-t="00:05:15">[00:05:15]</a> <a class="yt-timestamp" data-t="00:05:20">[00:05:20]</a>.
*   The transformer concept was introduced by Google in 2017; OpenAI's success lies in building a "delightful product" rather than revolutionary underlying technology <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a> <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>.
*   GPT-4 is "not even close" to AGI, and AGI may not be seen "anytime soon or possibly ever" <a class="yt-timestamp" data-t="00:05:35">[00:05:35]</a> <a class="yt-timestamp" data-t="00:05:39">[00:05:39]</a>.
*   There is something "special about being a human" that cannot be replicated on a silicon chip, suggesting a metaphysical or spiritual level of operation that science cannot explain <a class="yt-timestamp" data-t="00:05:41">[00:05:41]</a> <a class="yt-timestamp" data-t="00:05:44">[00:05:44]</a> <a class="yt-timestamp" data-t="00:05:48">[00:05:48]</a>. Concepts like consciousness and the soul are not fully understood or replicable <a class="yt-timestamp" data-t="00:05:52">[00:05:52]</a>.
*   Humans may be "missing some kind of Secret Sauce" required to achieve AGI <a class="yt-timestamp" data-t="00:06:06">[00:06:06]</a>.
*   AI will be "extremely good at mimicking humans" but will likely never surpass human intellect, as it is based on existing internet content, which can be seen as "garbage content" <a class="yt-timestamp" data-t="00:06:10">[00:06:10]</a> <a class="yt-timestamp" data-t="00:06:13">[00:06:13]</a> <a class="yt-timestamp" data-t="00:06:16">[00:06:16]</a>.

In conclusion, while [[artificial_intelligence_and_reasoning_models | AI]] is advancing rapidly and influencing various aspects of life and work, significant skepticism exists about its ability to reach true general intelligence. This skepticism is rooted in the perceived [[limitations_and_challenges_of_current_ai_technologies | limitations of current AI models]], the prevalent [[marketing_and_hype_surrounding_ai_advancements | marketing and hype]] surrounding its development, and the belief that AI will ultimately plateau due to the inherent uniqueness of human consciousness.