---
title: Effective altruism and long-term impacts
videoId: AHkmEnl55jo
---

From: [[dwarkeshpatel]] <br/>
Effective altruism (EA) has gained significant traction amongst intellectuals, philanthropists, and policy influencers. In the podcast featuring Tyler Cowen, the discussion delves into EA's profound focus on optimizing long-term impacts, a hallmark of its philosophy. This article explores these themes as discussed in the conversation and what they imply for existential threats and future planning.

## What is Effective Altruism?

Effective altruism is a movement and philosophy that applies evidence and reasoning to determine the most effective ways to benefit others. The aim is to maximize the impact of charitable actions and decisions, focusing on objectively measurable outcomes.

> [!info] The Shift in Altruistic Thinking
>
> As noted in the conversation, part of the appeal of EA is due to political polarization and the need to find impactful outlets for energies outside of traditional political channels. [[Libertarianism and anarcho-capitalism | Libertarianism]], which historically attracted similar demographics, no longer addresses contemporary issues like [[climate_change_and_historical_societies | climate change]] or pandemics effectively.

## Long-Term Focus of EA

The discussion with Tyler Cowen highlights a significant trend within EA: the focus on mitigating existential risks and ensuring the long-term survival and thriving of humanity. Proponents argue that by focusing on the scenarios where humanity survives for millions of years, the potential cumulative benefits would vastly outweigh short-term considerations.

### Skepticism About Epistemic Modesty

Tyler Cowen expresses skepticism about long-term predictions, particularly the ability to comprehensively address existential risks with foresight and accuracy. He suggests that while existential risks are indeed significant, the fervor with which some EA adherents focus on specific future hypotheses—especially concerning [[challenges_and_considerations_for_achieving_agi | artificial general intelligence (AGI)]]—might reflect overconfidence rather than modesty.

Cowen emphasizes that many beneficial activities, such as finding talent and fostering [[ai_and_economic_growth | economic growth]], also coincide with reducing existential threats naturally, without needing highly specific future targeting:

> "I do favor an asteroid Protection Program by the way" – Tyler Cowen <a class="yt-timestamp" data-t="01:04:39">[01:04:39]</a>

## Addressing Existential Risks

Cowen discusses how effective altruism could align with more traditional efforts to improve the human condition. These include economic growth, [[scientific advancement and innovation | scientific advancement]], and innovation, which he argues can mitigate existential risk indirectly.

He argues that while long-term existential threats are a legitimate concern, there is often a lack of good predictive and preventative mechanisms specific to those risks that differ greatly from general progress and protection-focused policies.

### The Robustness of Long-Term Thinking

EA, as discussed, has traits of durability akin to religion—something Cowen sees as a positive aspect. However, he raises concerns about the inherent unpredictability of long-term projections and warns against assuming we will always bounce back after possible future catastrophes:

> "We're not going to be here for another hundred thousand years," Cowen states, reflecting his skepticism of humanity’s long-term resilience <a class="yt-timestamp" data-t="01:07:28">[01:07:28]</a>.

## Conclusion

Effective altruism’s emphasis on [[optimizing_for_the_long_term_and_its_challenges | long-term impacts]] highlights the intersection between ethical intentionality and evidence-based action. Cowen’s perspectives introduce a balanced critique, acknowledging the importance of recognizing the limits of our predictive abilities. While endorsing efforts to reduce existential risk, he champions broader societal and economic growth strategies as naturally mitigating catastrophic outcomes. This approach embeds EA within a framework of sustainable progress, with a nod towards skepticism concerning highly specific, long-term predictions.
