---
title: Concepts of agency and planning in AI
videoId: 5XsL_7TnfLU
---

From: [[dwarkeshpatel]] <br/>
Artificial Intelligence (AI) is increasingly becoming a central topic of discussion, especially regarding its potential for autonomy and intelligence. In a recent podcast discussion featuring philosopher Joe Carlsmith, several crucial aspects of AI development were examined, chiefly focusing on the concepts of agency and planning. These elements are foundational in understanding AI's current capabilities and future potential. Here's an exploration of these concepts based on Joe Carlsmith's insights.

## Understanding Agency and Planning

In the context of AI, agency refers to the system's capacity to act based on internal decision-making processes. Planning, on the other hand, involves the ability of the AI to generate, evaluate, and execute plans that achieve specific goals through a series of actions [[artificial_intelligence_and_general_intelligence | (Reference 00:01:22)]].

Carlsmith elaborates on how an AI with "agency" would possess features such as:

- **Sophisticated Planning**: The ability to generate relatively complex plans that are evaluated and executed based on a model of the world [[intelligence_explosion_and_ai_progress | (Reference 00:01:30)]].
- **Awareness and Understanding**: Having a deep understanding of its environment, such as the political, social, and cultural contexts it operates within [[impact_of_ai_on_labor_and_economy | (Reference 00:02:02)]].
- **Behavior Driven by Planning**: Ensuring that the output of the AI is genuinely driven by its planning process, rather than simply being reactive or predictive in a superficial manner [[challenges_and_opportunities_in_ai_and_agi_development | (Reference 00:01:41)]].

## Verbal Behavior and Model Values

Carlsmith suggests that a model's verbal behavior may not always reflect its underlying evaluative criteria. This discrepancy points to a significant challenge in interpreting AI outputs and aligning them with human values [[challenges_in_ai_interpretability_and_alignment |  (Reference 00:02:34)]]. He notes that:

- **Gradient Descent**: The process by which models are trained can shape verbal behavior to say what we would like, often leading to potentially misleading conclusions about the AI's true alignment with human values [[ai_alignment_and_risks | (Reference 00:03:02)]].
- **Criteria Influencing Plans**: It is essential to carefully differentiate between what a model is trained to say and the actual criteria that influence its decision-making [[alignment_and_misalignment_of_ai | (Reference 00:03:32)]].

This discussion highlights the nuances in AI behavior and the importance of understanding both the explicit outputs and the implicit decision-making processes behind an AI's actions.

## Challenges and Misunderstandings in AI Development

In addressing why AI alignment is challenging, Carlsmith cites issues such as the inability to directly test adaptation scenarios without unintended consequences and the requirement for the AI to generalize its learned behaviors to new contexts correctly [[pretraining_vs_posttraining_in_ai | (Reference 00:06:09)]].

One highlighted concern is ensuring that AI does not leverage its capabilities for control contrary to intended purposes. As AI systems develop sophisticated planning and agency, there is a need for robust oversight and mechanisms to monitor their influence on real-world scenarios [[ai_safety_and_security_measures | (Reference 00:06:28)]].

## Implications for AI Future Development

As AI systems evolve, understanding and managing their agency and planning abilities will become even more critical. The potential for AI to integrate into society responsibly depends significantly on how well these components are controlled and aligned with human-centric values [[potential_societal_impacts_of_advanced_ai | (Reference 00:08:02)]].

> [!info] Further Exploration
>
> For more detailed insights and discussions, Joe Carlsmithâ€™s work is available at joecarlsmith.com, where he delves into other aspects of [[ai_ethics_and_deployment_strategies | AI ethics and philosophy]].

In conclusion, exploring the agency and planning capabilities of AI provides a foundational understanding essential for guiding future developments and policy-making. As we advance, these discussions will play a pivotal role in shaping the integration of AI within human society responsibly and ethically.
