---
title: Limitations of large language models in solving novel tasks
videoId: UakqL6Pj9xo
---

From: [[dwarkeshpatel]] <br/>
The conversation between François Chollet, an AI researcher at Google and creator of Keras, alongside Mike Knoop, co-founder of Zapier, highlights significant limitations of large language models (LLMs) when it comes to solving novel tasks. LLMs, while highly capable in some areas, struggle with novel, unfamiliar problems that require true reasoning rather than memorization.

## The Problem with Current LLM Benchmarks

LLMs are primarily trained on vast amounts of data, which allows them to excel in benchmarks that revolve around [[pretraining_vs_posttraining_in_ai | memorization]] or fetching previously learned patterns. However, when it comes to genuinely novel tasks, like those presented by the Abstraction and Reasoning Corpus (ARC) benchmark, LLMs often fall short <a class="yt-timestamp" data-t="00:01:18">[00:01:18]</a>. Chollet describes LLMs as “big interpolative memories,” indicating their reliance on memorized knowledge rather than on-the-fly problem-solving <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.

## The ARC Benchmark: An IQ Test for Machine Intelligence

ARC is crafted as an IQ test specifically designed to resist memorization and assess genuine machine intelligence. It requires what is known as "core knowledge," such as elementary physics or basic counting, rather than a vast database of learned facts <a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>. Unlike other benchmarks, each puzzle in ARC is novel, making it particularly challenging for LLMs to solve through memorization alone <a class="yt-timestamp" data-t="00:02:02">[00:02:02]</a>. This is emblematic of the [[understanding_arc_benchmarks_and_its_significance | challenges associated with assessing machine intelligence]].

## The Distinction Between Skill and Intelligence

Chollet argues that scaling up LLMs increases their skill and usefulness, but not their intelligence <a class="yt-timestamp" data-t="00:19:13">[00:19:13]</a>. Many benchmarks fail to differentiate between true reasoning and memorization, which can lead to a conflation of skill with intelligence in the evaluation of LLMs. LLM performance on algebra problems, for instance, can often resolve to merely retrieving and applying known solution templates rather than conducting genuine problem-solving <a class="yt-timestamp" data-t="00:35:34">[40:35:34]</a>. This highlights the [[comparison_between_human_intelligence_and_ai_learning_techniques | ongoing challenge in comparing AI learning and human reasoning]].

## Real-World Limitations

LLMs often falter when deployed in environments they weren't explicitly trained for. For example, self-driving car models trained in one city may struggle when relocated to new environments where rules or conditions differ <a class="yt-timestamp" data-t="00:30:20">[00:30:20]</a>. This echoes Chollet's contention that true intelligence — marked by adaptability to new conditions — is what separates human capability from LLM proficiency <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>. Such challenges are central to [[challenges_in_achieving_artificial_general_intelligence | achieving AGI]].

## The Path Forward: System 2 and Hybrid Models

Chollet suggests that the development of System 2 architectures, which would allow LLMs to perform logical and reasoning tasks, is pivotal <a class="yt-timestamp" data-t="00:56:02">[00:56:02]</a>. This would constitute a shift from memory and interpolation toward true intelligence. A hybrid approach combining deep learning's pattern recognition (System 1) with discrete program search (System 2) could pave the way towards models that can innovate and reason more like humans <a class="yt-timestamp" data-t="00:52:28">[00:52:28]</a>. This hybrid approach is viewed as a crucial next step in [[importance_of_new_approaches_in_ai_research | advancing AI research]].

> [!info] Limitations Overview
>
> - **Memorization Over True Reasoning**: LLMs largely rely on pre-trained data to solve tasks, which limits their ability to adapt to new, unfamiliar scenarios.
> - **Skill vs. Intelligence**: While scaling improves skill, it doesn't inherently enhance adaptability or intelligence.
> - **ARC Benchmark as a True Test**: Designed to resist memorization, ARC presents a unique challenge by focusing on abstract reasoning and core knowledge.
> - **Need for System 2 Architecture**: A hybrid model leveraging both System 1 and System 2 reasoning could address current loop-holes in LLM capabilities, highlighting the [[ai_alignment_challenges_and_strategies | importance of aligning AI systems with human-like reasoning]].

In summary, LLMs offer substantial capabilities in tasks that align with their training data but face intrinsic limitations with novel tasks that demand innovative reasoning. Overcoming these hurdles requires a strategic evolutionary leap in AI design, integrating the ability to process new information and adapt in real-time, essential for [[future_capabilities_and_progress_of_ai_models | future AI development]].
