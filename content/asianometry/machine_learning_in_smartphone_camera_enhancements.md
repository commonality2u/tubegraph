---
title: Machine learning in smartphone camera enhancements
videoId: yY8OFp0-UZw
---

From: [[asianometry]] <br/> 

Modern smartphone cameras increasingly rely on [[image_processing_and_computational_photography | computational photography]] and machine learning to achieve their impressive image quality, often overcoming the physical limitations of smaller sensors <a class="yt-timestamp" data-t="03:48:00">[03:48:00]</a>. Recent advancements in onboard AI processor technology have enabled camera makers to push imaging performance to new heights <a class="yt-timestamp" data-t="01:57:00">[01:57:00]</a>.

## Key Applications of Machine Learning

### White Balance Correction
One prominent application of machine learning is in white balance correction <a class="yt-timestamp" data-t="01:57:50">[01:57:50]</a>. Researchers have collected digital photos that were then manually white-balanced by professional photographers <a class="yt-timestamp" data-t="01:59:00">[01:59:00]</a>. This data is fed into a machine learning model to create significantly more effective color constancy algorithms <a class="yt-timestamp" data-t="02:01:00">[02:01:00]</a>. This method is particularly useful in [[low_light_and_nighttime_photography_in_smartphones | low light conditions]] and was a key feature in Google Pixel's Night Sight <a class="yt-timestamp" data-t="02:02:50">[02:02:50]</a>.

### Resolution Enhancement and Digital Zoom
While simpler algorithms have been used to sharpen blur from digitally zoomed photos, machine learning takes this a step further <a class="yt-timestamp" data-t="02:06:00">[02:06:00]</a>. A model can be trained with both high and low-resolution imagery data, allowing it to learn how to properly sharpen and enhance blurry edges in a picture <a class="yt-timestamp" data-t="02:07:00">[02:07:00]</a>. NVIDIA has applied similar concepts to digitally upscale video game image assets to resolutions and frame rates not originally supported, a technique they call [[resolution_enhancement_techniques_rets | Deep Learning Super Sampling (DLSS)]] <a class="yt-timestamp" data-t="02:08:50">[02:08:50]</a>.

### Bokeh Effect Simulation (Portrait Mode)
Traditional smartphone cameras typically keep the entire image in focus, or not at all, making it challenging to achieve a blurred background (bokeh) like larger cameras <a class="yt-timestamp" data-t="02:14:00">[02:14:00]</a>. [[image_processing_and_computational_photography | Computational photography]], powered by machine learning, enables mobile phones to generate a synthetic bokeh <a class="yt-timestamp" data-t="02:16:00">[02:16:00]</a>. Modern cameras can utilize a second camera or a dedicated depth sensor to determine the subject's distance <a class="yt-timestamp" data-t="02:19:00">[02:19:00]</a>. Subsequently, they introduce depth blur to simulate the depth of focus effect <a class="yt-timestamp" data-t="02:20:00">[02:20:00]</a>.

This is the foundation of iPhone's Portrait Mode, which initially focused on people but has expanded to include animals. The phone uses AI to recognize a person or animal and then blurs out the background <a class="yt-timestamp" data-t="02:37:00">[02:37:00]</a>. This bokeh effect has even begun appearing in normal camera modes, blurring backgrounds for objects like a cup on a table <a class="yt-timestamp" data-t="02:44:00">[02:44:00]</a>.

## The Nature of Smartphone Images
The significant amount of computer processing and image manipulation, from simple math operations to complex machine learning models, goes into creating today's digital photos <a class="yt-timestamp" data-t="02:58:00">[02:58:00]</a>. The image data saved and uploaded is heavily "doctored" from what the sensor actually "sees" <a class="yt-timestamp" data-t="03:10:00">[03:10:00]</a>. While the scene itself is reality, the smartphone camera's image of it has become increasingly less so over time, reflecting a user preference for "more teeth" (a more visually appealing result) rather than a pure, unfiltered reality <a class="yt-timestamp" data-t="03:45:00">[03:45:00]</a>.