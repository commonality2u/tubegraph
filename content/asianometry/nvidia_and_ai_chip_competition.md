---
title: Nvidia and AI chip competition
videoId: J-BvkmNtgAM
---

From: [[asianometry]] <br/> 

The **AI and AI chip boom** is a rapidly evolving landscape, with significant developments occurring outside of Taiwan <a class="yt-timestamp" data-t="00:00:11">[00:00:11]</a>. This includes massive investment proposals, such as Sam Altman's reported $1-7 trillion chip venture for the [[ai_and_ai_chip_boom | AI industry]] <a class="yt-timestamp" data-t="00:00:26">[00:00:26]</a>. While the $1-7 trillion figure is largely considered excessive, it represents the total investment required for an entire ecosystem, encompassing real estate, data center power, and chip manufacturing over several years <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>. This scale suggests a potential "COVID-like step function upwards" in capital expenditure for the semiconductor industry <a class="yt-timestamp" data-t="00:02:02">[00:02:02]</a>.

## Nvidia's Dominance and Strategy

Much attention has been given to [[nvidias_rise_in_the_graphics_card_industry | Nvidia]] and its competition in the [[role_of_ai_accelerators_in_neural_network_training_and_inference | AI accelerator]] market <a class="yt-timestamp" data-t="00:05:00">[00:05:00]</a>. [[nvidias_rise_in_the_graphics_card_industry | Nvidia]]'s CEO, Jensen Huang, is responding to competitive threats by aggressively increasing the pace of annual updates to their [[role_of_ai_accelerators_in_neural_network_training_and_inference | AI accelerator]] lineup <a class="yt-timestamp" data-t="00:05:14">[00:05:14]</a>.

This relentless product release schedule is reminiscent of [[nvidias_rise_in_the_graphics_card_industry | Nvidia]]'s strategy during the "Graphics Cards Wars," when they launched new products every six months <a class="yt-timestamp" data-t="00:05:27">[00:05:27]</a>. [[nvidias_rise_in_the_graphics_card_industry | Nvidia]] can maintain this speed because they utilize advanced computer software design and emulation tools to model and ship new GPU designs without first fabricating a physical chip, essentially "shipping before testing" <a class="yt-timestamp" data-t="00:05:40">[00:05:40]</a>, <a class="yt-timestamp" data-t="00:05:48">[00:05:48]</a>. This approach aims for "perfect chips" but can lead to initial problems for customers with drivers and associated software <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>. However, the [[nvidias_rise_in_the_graphics_card_industry | Nvidia]] brand can absorb such issues, unlike smaller [[ai_and_ai_chip_boom | AI chip]] startups, which require years to build a competent team and ship a working product <a class="yt-timestamp" data-t="00:06:28">[00:06:28]</a>.

While this rapid iteration pace can be challenging for customers who invest heavily in machines that quickly become outdated, many have limited alternatives <a class="yt-timestamp" data-t="00:06:40">[00:06:40]</a>.

## Competition from Tech Giants and Verticalization

[[nvidias_rise_in_the_graphics_card_industry | Nvidia]]'s primary concern isn't the startups or even established silicon players, but rather the major tech giants <a class="yt-timestamp" data-t="00:06:57">[00:06:57]</a>. Companies like Microsoft and Google are the main drivers of current [[ai_and_ai_chip_boom | AI investment]] and have the strongest incentive to reduce their reliance on [[nvidias_rise_in_the_graphics_card_industry | Nvidia]] <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>.

These tech giants are pursuing vertical integration by developing custom-designed chips or ASICs (Application-Specific Integrated Circuits) <a class="yt-timestamp" data-t="00:07:13">[00:07:13]</a>. This strategy mirrors historical trends where ASICs replaced multiple discrete components to reduce costs <a class="yt-timestamp" data-t="00:07:17">[00:07:17]</a>.

Notable examples of this trend include:
*   **Google TPU**: Google's Tensor Processing Unit, currently in its fourth iteration, significantly contributes to Google's compute advantage over other [[ai_and_ai_chip_boom | AI labs]] <a class="yt-timestamp" data-t="00:07:34">[00:07:34]</a>, <a class="yt-timestamp" data-t="00:07:39">[00:07:39]</a>. The first Google TPU was a very basic product, indicating a learning curve for such development <a class="yt-timestamp" data-t="00:08:42">[00:08:42]</a>.
*   **Microsoft**: Microsoft is aggressively pushing for vertical integration <a class="yt-timestamp" data-t="00:07:45">[00:07:45]</a>. CEO Satya Nadella noted that most Azure AI services usage comes from inference rather than training, a workload more easily shifted to custom ASICs <a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a>. Microsoft is also working on integrating other parts of the database stack, such as network cards for inter-server data transfer <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>, <a class="yt-timestamp" data-t="00:08:07">[00:08:07]</a>.

This vertical integration suggests either that the scale and cost of the [[ai_and_ai_chip_boom | AI database stack]] are so immense that every cost saving counts, or that growth in the industry might eventually lead to competition primarily on price <a class="yt-timestamp" data-t="00:08:16">[00:08:16]</a>. While it will take time for tech giants to ramp up their [[ai_and_ai_chip_boom | AI chip]] designs, [[nvidias_rise_in_the_graphics_card_industry | Nvidia]] must continue to push for performance-cost leadership in the medium to long term <a class="yt-timestamp" data-t="00:08:37">[00:08:37]</a>, <a class="yt-timestamp" data-t="00:08:48">[00:08:48]</a>.

## Financial Sustainability of the AI Boom

A critical question for the [[ai_and_ai_chip_boom | AI boom]] is its financial sustainability and whether it is "Real" with a capital R <a class="yt-timestamp" data-t="00:09:13">[00:09:13]</a>. Despite impressive technological advancements, like OpenAI's Sora model <a class="yt-timestamp" data-t="00:09:23">[00:09:23]</a>, the technology itself does not inherently constitute a hit product <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>. Major investments in [[ai_and_ai_chip_boom | AI]] will likely only occur if ordinary consumers significantly purchase [[ai_and_ai_chip_boom | AI]] services <a class="yt-timestamp" data-t="00:10:08">[00:10:08]</a>.

As of December 2023, ChatGPT had a reported $2 billion run-rate revenue, one of the few solid indicators of consumers paying for an LLM service <a class="yt-timestamp" data-t="00:10:18">[00:10:18]</a>. While it's early in the generative [[ai_and_ai_chip_boom | AI boom]], with ChatGPT being just over a year old <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>, comparisons to the rapid revenue growth of the iPhone highlight the current difference <a class="yt-timestamp" data-t="00:10:39">[00:10:39]</a>.

The Microsoft Copilot subscription service ($20/month) is another product closely watched to see if it gains traction with individuals and enterprises <a class="yt-timestamp" data-t="00:11:42">[00:11:42]</a>. If it succeeds, it could signal significant growth, but if not, mental models may need adjustment <a class="yt-timestamp" data-t="00:11:52">[00:11:52]</a>.

Ultimately, the most "real" impact of the LLM revolution might be its integration into existing products, such as [[ai_and_ai_chip_boom | AI]] automation in advertising sales <a class="yt-timestamp" data-t="00:12:07">[00:12:07]</a>. Examples include Google's Performance Max ads, which use [[ai_and_ai_chip_boom | AI]] to automate ad creation, deployment, and targeting, generating tens of billions of dollars <a class="yt-timestamp" data-t="00:12:22">[00:12:22]</a>, and Meta's use of [[ai_and_ai_chip_boom | AI]] to restore targeting accuracy after Apple's cookie tracking changes <a class="yt-timestamp" data-t="00:12:46">[00:12:46]</a>. This suggests that [[ai_and_ai_chip_boom | AI]] may function more as an enabling technology, enhancing existing industries rather than creating entirely new ones, making the [[ai_and_ai_chip_boom | AI boom]] real, albeit potentially in a less revolutionary way than some might hope <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>.