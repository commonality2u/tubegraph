---
title: AI and AI chip boom
videoId: J-BvkmNtgAM
---

From: [[asianometry]] <br/> 

A recent trip through Japan and the United States aimed to understand the [[ai_boom_and_data_center_demands | AI]] and AI chip boom landscape outside of Taiwan <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>.

## The Trillion-Dollar Venture

There has been significant news regarding a chip venture involving Sam Altman of OpenAI for the [[ai_accelerator_hardware_market_and_its_growth | AI industry]] <a class="yt-timestamp" data-t="00:00:23">[00:00:23]</a>. Initial reports indicated he was raising "billions" from Middle East investors <a class="yt-timestamp" data-t="00:00:30">[00:00:30]</a>. Discussions have since included TSMC, parties in Abu Dhabi, and the US Government <a class="yt-timestamp" data-t="00:00:44">[00:00:44]</a>.

A Wall Street Journal report cited an "eye catching" $1-7 trillion figure for this venture <a class="yt-timestamp" data-t="00:00:52">[00:00:52]</a>. Many believe this number is excessive and potentially a negotiating tactic <a class="yt-timestamp" data-t="00:01:07">[00:01:07]</a>. The Information clarified that this figure represents the total necessary investments across all participants, covering everything from real estate and power for [[ai_boom_and_data_center_demands | data centers]] to chip manufacturing over several years <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. This "ecosystem concept" provides more context <a class="yt-timestamp" data-t="00:01:41">[00:01:41]</a>.

For comparison, total semiconductor sales in 2023 were approximately $520 billion, with total capital expenditures around $140 billion <a class="yt-timestamp" data-t="00:01:41">[00:01:41]</a>. Even if the trillion-dollar figure is spread over five years and diluted with real estate and power expenses, it still signifies a substantial, "COVID-like step function upwards" in capital expenditure <a class="yt-timestamp" data-t="00:01:55">[00:01:55]</a>. The semiconductor industry is typically conservative <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.

## Scaling Laws

The driving concept behind this investment is "scaling laws" <a class="yt-timestamp" data-t="00:02:23">[00:02:23]</a>. This term originates from a 2020 OpenAI paper titled "Scaling laws for neural language models" <a class="yt-timestamp" data-t="00:02:27">[00:02:27]</a>. The core idea is that combining more data and compute leads to better results (less loss) <a class="yt-timestamp" data-t="00:02:36">[00:02:36]</a>. This principle was fundamental to OpenAI's GPT-series development <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>. Ilya Sutskever, an OpenAI co-founder, noted that earlier neural networks were "too small" to be effective, whereas larger networks can achieve unprecedented results <a class="yt-timestamp" data-t="00:02:56">[00:02:56]</a>. GPT-3 was large, GPT-4 even larger and better, and GPT-5 is expected to continue this trend, with no current indications that scaling laws are breaking down <a class="yt-timestamp" data-t="00:03:18">[00:03:18]</a>.

The parallels between scaling laws and Moore's Law in the semiconductor industry are noteworthy <a class="yt-timestamp" data-t="00:03:34">[00:03:34]</a>. Moore's Law served as a rallying cry for the semiconductor industry in the 1980s and 1990s <a class="yt-timestamp" data-t="00:03:45">[00:03:45]</a>. Similarly, scaling laws could significantly impact the [[ai_accelerator_hardware_market_and_its_growth | AI industry]], driving R&D roadmaps <a class="yt-timestamp" data-t="00:03:56">[00:03:56]</a>.

Arguments against scaling laws include the perceived scarcity of existing internet data <a class="yt-timestamp" data-t="00:04:09">[00:04:09]</a>. However, historical parallels with Moore's Law show that physics problems were overcome by new engineering solutions like High-K Metal Gate, FinFET, and DUV Lithography <a class="yt-timestamp" data-t="00:04:22">[00:04:22]</a>. The primary question then becomes whether there is sufficient funding to sustain this investment <a class="yt-timestamp" data-t="00:04:35">[00:04:35]</a>.

## [[nvidia_and_ai_chip_competition | Nvidia and AI Chip Competition]]

Profits inevitably attract competitors <a class="yt-timestamp" data-t="00:04:51">[00:04:51]</a>. Much has been written about the multi-pronged attack on [[nvidia_and_ai_chip_competition | Nvidia]]'s [[ai_accelerator_hardware_market_and_its_growth | AI accelerator profits]] <a class="yt-timestamp" data-t="00:04:55">[00:04:55]</a>. [[nvidia_and_ai_chip_competition | Nvidia]]'s CEO Jensen Huang is responding by aggressively increasing annual updates to their accelerator lineup <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>. This rapid pace echoes [[nvidia_and_ai_chip_competition | Nvidia]]'s strategy during the Graphics Cards Wars, where they released new products every six months <a class="yt-timestamp" data-t="00:05:27">[00:05:27]</a>.

[[nvidia_and_ai_chip_competition | Nvidia]] can maintain this speed because they effectively "ship before they test" <a class="yt-timestamp" data-t="00:05:40">[00:05:40]</a>. They use advanced computer software design and emulation tools to model and ship new GPU designs without first fabricating a physical chip <a class="yt-timestamp" data-t="00:05:48">[00:05:48]</a>. This approach prevents them from going out of business due to lengthy testing cycles <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>. While [[nvidia_and_ai_chip_competition | Nvidia]] aims for "perfect chips," this strategy can lead to initial software issues for customers <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>. However, the [[nvidia_and_ai_chip_competition | Nvidia]] brand can withstand such issues, unlike smaller [[ai_accelerator_hardware_market_and_its_growth | AI chip]] startups, which require years to build capable teams and products <a class="yt-timestamp" data-t="00:06:28">[00:06:28]</a>. This high iteration speed is challenging for customers, who may find a significantly better product released shortly after their purchase <a class="yt-timestamp" data-t="00:06:40">[00:06:40]</a>.

## Giants and Verticalization

[[nvidia_and_ai_chip_competition | Nvidia]] is more concerned about tech giants like Microsoft and [[impact_of_ai_chip_innovations_by_companies_like_google_and_amazon | Google]] than startups or established silicon players <a class="yt-timestamp" data-t="00:06:55">[00:06:55]</a>. These giants are driving current [[ai_boom_and_data_center_demands | AI investment]] and have strong incentives to reduce reliance on [[nvidia_and_ai_chip_competition | Nvidia]] by using custom-designed chips or ASICs (Application-Specific Integrated Circuits) <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>. An example is the [[impact_of_ai_chip_innovations_by_companies_like_google_and_amazon | Google TPU]], now in its fourth iteration, which significantly contributes to [[impact_of_ai_chip_innovations_by_companies_like_google_and_amazon | Google]]'s compute advantage over other AI labs <a class="yt-timestamp" data-t="00:07:34">[00:07:34]</a>.

Microsoft is particularly active in vertical integration <a class="yt-timestamp" data-t="00:07:45">[00:07:45]</a>. CEO Satya Nadella noted that most Azure [[ai_accelerator_hardware_market_and_its_growth | AI services]] usage comes from inference rather than training, which is easier to offload to custom ASICs <a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a>. Microsoft is also integrating other parts of the database stack, such as developing a network card to shuttle data between servers <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>. This trend implies that the scale of the [[ai_boom_and_data_center_demands | AI database stack]] is becoming so vast and expensive that every efficiency gain matters, or that industry growth is slowing, leading to price-based competition <a class="yt-timestamp" data-t="00:08:16">[00:08:16]</a>. While tech giants' [[impact_of_ai_chip_innovations_by_companies_like_google_and_amazon | AI chip designs]] will take time to mature (the first [[impact_of_ai_chip_innovations_by_companies_like_google_and_amazon | Google TPU]] was basic), [[nvidia_and_ai_chip_competition | Nvidia]] will likely continue to push for performance-cost leadership in the medium to long term <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>.

## Financially Sustainable?

A key question is whether the OpenAI boom is "Real" in terms of financial sustainability, particularly regarding consumer product adoption <a class="yt-timestamp" data-t="00:09:09">[00:09:09]</a>. While [[ai_accelerator_hardware_market_and_its_growth | AI]] technology, such as OpenAI's text-to-video Sora model, shows impressive output quality, it may not be a hit product on its own <a class="yt-timestamp" data-t="00:09:19">[00:09:19]</a>. The massive investments in the semiconductor industry driven by Moore's Law were fueled by real demand from various downstream sectors: military, consumer electronics (radios, calculators), PCs, smartphones, and cloud computing <a class="yt-timestamp" data-t="00:09:46">[00:09:46]</a>. These were all products ordinary people desired <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>.

Large [[ai_boom_and_data_center_demands | AI investments]] are unlikely to be sustained unless ordinary consumers begin purchasing these services significantly <a class="yt-timestamp" data-t="00:10:08">[00:10:08]</a>. The Financial Times reported ChatGPT reached a $2 billion run-rate revenue in December 2023, one of the few solid indicators of consumers paying for an LLM service <a class="yt-timestamp" data-t="00:10:18">[00:10:18]</a>. Although the generative [[ai_accelerator_hardware_market_and_its_growth | AI boom]] is still young (ChatGPT is just over a year old), its growth is rapid <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>. For context, two years after its 2007 release, Apple sold 20 million iPhones, generating $13 billion in revenue, with continued exponential growth <a class="yt-timestamp" data-t="00:10:39">[00:10:39]</a>.

ChatGPT is one of the fastest-growing consumer tech products historically <a class="yt-timestamp" data-t="00:11:07">[00:11:07]</a>, with Altman stating it generates 100 billion words daily <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>. Like Facebook building an audience before monetization, ChatGPT might be employing an Aggregator approach <a class="yt-timestamp" data-t="00:11:21">[00:11:21]</a>. However, few products are as costly to use, suggesting [[ai_accelerator_hardware_market_and_its_growth | AI]] might have a shorter leash regarding profitability expectations <a class="yt-timestamp" data-t="00:11:32">[00:11:32]</a>. The Microsoft Copilot subscription service ($20/month) is a key product to watch; its success will indicate if the [[ai_accelerator_hardware_market_and_its_growth | AI boom]] is truly "off to the races" <a class="yt-timestamp" data-t="00:11:39">[00:11:39]</a>.

## Conclusion

The "[[ai_boom_and_data_center_demands | AI revolution]]" may find its most significant impact when embedded into existing products <a class="yt-timestamp" data-t="00:12:04">[00:12:04]</a>. For example, [[impact_of_ai_chip_innovations_by_companies_like_google_and_amazon | Google]]'s Performance Max ads use [[ai_accelerator_hardware_market_and_its_growth | AI]] to automate ad creation, deployment, and targeting, generating tens of billions of dollars <a class="yt-timestamp" data-t="00:12:17">[00:12:17]</a>. Similarly, Meta/Facebook leveraged [[ai_accelerator_hardware_market_and_its_growth | AI]] to restore ad targeting accuracy after Apple's cookie tracking changes, clawing back billions in sales <a class="yt-timestamp" data-t="00:12:33">[00:12:33]</a>. This suggests that the "killer app" for [[ai_accelerator_hardware_market_and_its_growth | AI]] might simply be more effective advertising <a class="yt-timestamp" data-t="00:12:54">[00:12:54]</a>.

Ben Thompson and others suggest [[ai_accelerator_hardware_market_and_its_growth | AI]] is primarily an "enabling technology," making the already rich richer, rather than creating an entirely new class of wealth like the PC or electrification eras <a class="yt-timestamp" data-t="00:12:59">[00:12:59]</a>. While this perspective might be disappointing, it nonetheless solidifies the reality of the [[ai_boom_and_data_center_demands | AI boom]] <a class="yt-timestamp" data-t="00:13:11">[00:13:11]</a>.