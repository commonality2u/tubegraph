---
title: Traditional vs digital cameras
videoId: yY8OFp0-UZw
---

From: [[asianometry]] <br/> 

Photography has undergone a significant transformation from traditional analog methods to sophisticated digital imaging, particularly with the advent and rapid advancements of smartphone cameras. While both aim to capture an image, their underlying technologies and operational methods differ considerably <a class="yt-timestamp" data-t="01:37:37">[01:37:37]</a>.

## Traditional Analog Cameras

Traditional analog cameras capture images by exposing photographic film to light <a class="yt-timestamp" data-t="01:31:31">[01:31:31]</a>.

## Digital Cameras

Modern digital cameras, including DSLRs and smartphones, operate on a fundamentally different principle than analog cameras <a class="yt-timestamp" data-t="01:41:41">[01:41:41]</a>.

### Basic Structure and Function
A basic digital camera module features a simple physical structure: a lens positioned on top of an image sensor chip <a class="yt-timestamp" data-t="01:47:47">[01:47:47]</a>. Module makers and integrators may also add sensors and actuators to enhance camera performance <a class="yt-timestamp" data-t="01:54:54">[01:54:54]</a>. This core digital camera structure is shared across all digital devices <a class="yt-timestamp" data-t="02:02:02">[02:02:02]</a>.

### Image Sensor Technology
The science behind silicon photodetectors dates back to the 1920s <a class="yt-timestamp" data-t="03:54:54">[03:54:54]</a>.
*   **Charge-Coupled Devices (CCDs)**: First proposed by William Boyle and George Smith at Bell Labs in 1969, CCDs became a technical reality a year later <a class="yt-timestamp" data-t="03:58:58">[03:58:58]</a>. Boyle and Smith received the Nobel Prize in Physics in 2009 for their work <a class="yt-timestamp" data-t="04:10:10">[04:10:10]</a>. CCDs held the majority share of the early mobile imaging sensor market <a class="yt-timestamp" data-t="04:17:17">[04:17:17]</a>.
*   **Complementary Metal-Oxide-Semiconductors (CMOS)**: CMOS sensors emerged later with greater potential <a class="yt-timestamp" data-t="04:21:21">[04:21:21]</a>. Over time, CMOS sensors replaced CCDs in consumer and professional devices due to lower power consumption, manufacturing by conventional foundries like TSMC, and lower cost <a class="yt-timestamp" data-t="04:30:30">[04:30:30]</a>. Their integration into smartphones solidified their dominance in the imaging industry <a class="yt-timestamp" data-t="04:41:41">[04:41:41]</a>.

The imaging chip business was estimated to be around $20 billion in 2020, dominated by Samsung, Sony, and Omnivision <a class="yt-timestamp" data-t="04:50:50">[04:50:50]</a>. However, fundamental physical constraints mean that image sensor technology can only advance so far, eventually leading to limitations like a "ridiculous" camera bump <a class="yt-timestamp" data-t="05:05:05">[05:05:05]</a>.

### Digital Single-Lens Reflex (DSLR) Cameras
DSLRs are a type of digital camera known for their larger size and capabilities compared to smartphones <a class="yt-timestamp" data-t="02:11:11">[02:11:11]</a>.
*   **Sensor Size**: DSLR image sensors are significantly larger; full-size sensors can be 36 millimeters by 24 millimeters <a class="yt-timestamp" data-t="02:37:37">[02:37:37]</a>. A larger image sensor is desirable because it allows more light to fall onto a pixel, reducing motion blur, image noise, and increasing dynamic range <a class="yt-timestamp" data-t="02:43:43">[02:43:43]</a>.
*   **Optics**: DSLR optics are larger and more adjustable than those found in smartphones <a class="yt-timestamp" data-t="02:56:56">[02:56:56]</a>.
*   **Zoom Function**: Traditional cameras achieve zoom by physically moving the lens along the optical axis <a class="yt-timestamp" data-t="10:06:06">[10:06:06]</a>.
*   **Low Light Photography**: High-quality low-light photography was historically considered possible only with DSLRs, which possessed larger image pixels, adjustable apertures, and could be used with tripods to capture sufficient light <a class="yt-timestamp" data-t="12:26:26">[12:26:26]</a>.

### Smartphone Cameras
Modern smartphones are equipped with increasingly powerful cameras, with performance often headlining marketing messages for new models <a class="yt-timestamp" data-t="00:08:08">[00:08:08]</a>. The camera is a key factor driving people to upgrade their phones <a class="yt-timestamp" data-t="00:18:18">[00:18:18]</a>. Top smartphone makers invest heavily in this area; Apple, for example, employed 800 people just for the iPhone's camera in 2015 <a class="yt-timestamp" data-t="00:35:35">[00:35:35]</a>, and Xiaomi announced plans to hire thousands for their phone cameras in 2021 <a class="yt-timestamp" data-t="00:43:43">[00:43:43]</a>.

#### [[Challenges in smartphone camera engineering | Challenges and Engineering]]
The smartphone setting presents both advantages and disadvantages compared to larger [[digital_photography_disruption | digital photography]] equipment like DSLRs <a class="yt-timestamp" data-t="02:06:06">[02:06:06]</a>.
*   **Size Constraints**: The biggest limitation is that the camera's internal components must be much smaller and thinner, typically housed in areas 7 to 10 millimeters thick to maintain portability <a class="yt-timestamp" data-t="02:15:15">[02:15:15]</a>. Modern smartphone sensors are usually about 5 millimeters by 4 millimeters <a class="yt-timestamp" data-t="02:30:30">[02:30:30]</a>.
*   **Limited Aperture**: Smartphones have a fixed and limited aperture, which restricts the amount of light falling onto the sensor <a class="yt-timestamp" data-t="03:09:09">[03:09:09]</a>.
*   **Limited Zoom Function**: Physical lens movement for optical zoom is not easily achievable in thin smartphone cameras <a class="yt-timestamp" data-t="10:12:12">[10:12:12]</a>. Some attempts by Samsung, Nokia, and Asus resulted in sizable camera bumps with disappointing zoom performance <a class="yt-timestamp" data-t="10:17:17">[10:17:17]</a>.

#### Advantages of Computing Power
Despite physical limitations, smartphones offer significantly more computing power than discrete cameras, with some chips being as powerful as laptops <a class="yt-timestamp" data-t="03:40:40">[03:40:40]</a>. This processing capability has been crucial in overcoming the physical deficits of smaller sensors <a class="yt-timestamp" data-t="03:48:48">[03:48:48]</a>.

#### [[Computational photography techniques | Computational Photography]]
[[Computational photography techniques | Computational photography]] is a rapidly growing field responsible for many of the industry's recent advancements <a class="yt-timestamp" data-t="05:18:18">[05:18:18]</a>.
*   **Image Processing Pipeline**: When a photo is taken, the camera image sensor, a 2D grid of photodiodes, converts photons into electrical charges <a class="yt-timestamp" data-t="05:59:59">[05:59:59]</a>. Each photodiode has a color filter (often a Bayer filter, proposed by [[Kodak and Fujifilm rivalry | Kodak's]] Bryce Bayer in 1975) layered on top <a class="yt-timestamp" data-t="06:09:09">[06:09:09]</a>. Smartphone manufacturers often use multi-cell pixel clusters to enhance light sensitivity <a class="yt-timestamp" data-t="06:38:38">[06:38:38]</a>.
    *   **Demosaicing**: The raw output (Bayer pattern image) is a mosaic with gaps <a class="yt-timestamp" data-t="06:56:56">[06:56:56]</a>. Image processors use demosaicing algorithms to fill these gaps and reconstruct the scene's actual color, mimicking human vision where the brain compares signals from different cone types <a class="yt-timestamp" data-t="07:04:04">[07:04:04]</a>.
    *   **White Balance**: The image is processed for white balance to correct colors to appear as if lit by neutral white light <a class="yt-timestamp" data-t="08:03:03">[08:03:03]</a>. Algorithms estimate scene illumination and apply illumination values to pixel RGB values <a class="yt-timestamp" data-t="08:31:31">[08:31:31]</a>.
    *   **Color Manipulation**: Image colors can be manipulated based on user settings (e.g., "vivid" mode) or vendor pre-programming to differentiate camera performance (e.g., Samsung photos look different than iPhones) <a class="yt-timestamp" data-t="08:43:43">[08:43:43]</a>.
    *   **Noise Reduction**: Algorithms reduce artifacts (noise) in the image <a class="yt-timestamp" data-t="09:09:09">[09:09:09]</a>. Achieving the right balance in denoising is critical for perceived camera performance <a class="yt-timestamp" data-t="09:27:27">[09:27:27]</a>.
    *   **Final Output**: The image processor resizes data, adjusts RGB values for screen presentation, and saves it in formats like JPEG, PNG, or HEIC <a class="yt-timestamp" data-t="09:39:39">[09:39:39]</a>.

#### [[Challenges in smartphone camera engineering | Overcoming Challenges]] through Computational Methods
*   **Zoom**:
    *   **Digital Zoom**: Achieved by cropping the original image and upscaling the remainder, often resulting in weakened resolution <a class="yt-timestamp" data-t="10:30:30">[10:30:30]</a>. Algorithms enhance missing details, but simple methods haven't been sufficient <a class="yt-timestamp" data-t="10:44:44">[10:44:44]</a>.
    *   **Multiple Rear Cameras**: Most modern manufacturers use multiple rear cameras, typically a wide and a telephoto lens <a class="yt-timestamp" data-t="10:59:59">[10:59:59]</a>. These "dual aperture zoom cameras" were introduced in 2014 by Corephotonics and adopted by leading phone makers like Apple, Xiaomi, and Oppo <a class="yt-timestamp" data-t="11:12:12">[11:12:12]</a>.
    *   **Folded Zoom**: A few companies use a folded zoom approach, bending light sideways with a 45-degree mirror and using a prism for stability to achieve zoom without increasing camera thickness <a class="yt-timestamp" data-t="11:30:30">[11:30:30]</a>. High-end phones by Oppo, Samsung, and Huawei offer this feature, claiming up to 100x zoom capability <a class="yt-timestamp" data-t="11:45:45">[11:45:45]</a>.

*   **Low Light/Nighttime Performance**: The iPhone 13 Pro's low-light and nighttime performance exemplifies advancements in computational photography <a class="yt-timestamp" data-t="11:56:56">[11:56:56]</a>. Recognizing that the human eye is colorblind in the dark, camera makers aim to create colorful, noise-free low-light photos rather than being strictly faithful to the scene <a class="yt-timestamp" data-t="12:06:06">[12:06:06]</a>.
    *   **Burst Processing**: Smartphone cameras adapt a technique from astrophotography called image stacking or burst processing <a class="yt-timestamp" data-t="12:41:41">[12:41:41]</a>. This involves continuously capturing and storing multiple image frames, then merging them into a single high-quality image when the shutter is pressed <a class="yt-timestamp" data-t="13:00:00">[13:00:00]</a>. Challenges include reliably aligning images to prevent distortion <a class="yt-timestamp" data-t="13:15:15">[13:15:15]</a>. The 2018 Google Pixel phone pioneered this with its Night Sight feature, accounting for jittery hands and moving objects <a class="yt-timestamp" data-t="13:27:27">[13:27:27]</a>. Burst photography is also used for denoising, increasing image resolution, and high dynamic range compression <a class="yt-timestamp" data-t="13:48:48">[13:48:48]</a>.

#### [[Role of AI in smartphone photography | Role of AI in Smartphone Photography]]
Recent advancements in onboard AI processor technology have significantly enhanced imaging performance <a class="yt-timestamp" data-t="13:56:56">[13:56:56]</a>.
*   **White Balance Correction**: Machine learning models, trained on professionally white-balanced photos, create more effective color constancy algorithms, especially helpful in low-light conditions (e.g., Google Pixel's Night Sight) <a class="yt-timestamp" data-t="14:06:06">[14:06:06]</a>.
*   **Image Sharpening and Enhancement**: Machine learning models trained on high and low-resolution imagery data can properly sharpen and enhance blurry edges in digitally zoomed photos <a class="yt-timestamp" data-t="14:35:35">[14:35:35]</a>. NVIDIA applies similar concepts (Deep Learning Super Sampling or DLSS) to upscale video game assets <a class="yt-timestamp" data-t="14:48:48">[14:48:48]</a>.
*   **Bokeh Effect**: Since smartphone cameras typically have a fixed depth of field, [[computational_photography_techniques | computational photography]] uses machine learning to generate a synthetic bokeh effect <a class="yt-timestamp" data-t="15:01:01">[15:01:01]</a>. Modern cameras use a second camera or a dedicated depth sensor to determine subject distance, then introduce depth blur to simulate the desired effect <a class="yt-timestamp" data-t="15:19:19">[15:19:19]</a>. This is the basis of iPhone's Portrait Mode, which uses AI to recognize subjects like people or animals and blur the background <a class="yt-timestamp" data-t="15:30:30">[15:30:30]</a>.

Overall, modern [[digital_photography_disruption | digital photos]], particularly from smartphones, involve extensive computer processing and image manipulation <a class="yt-timestamp" data-t="15:55:55">[15:55:55]</a>. The image data saved is heavily "doctored" from what the sensor initially captures, reflecting a preference for a great-looking image over a strict representation of reality <a class="yt-timestamp" data-t="16:06:06">[16:06:06]</a>.