---
title: Cognitive Abilities and AIs Interaction with Humans
videoId: zeGCPA4p6z0
---

From: [[mk_thisisit]] <br/> 

Professor Wodzis≈Çaw Duch, a prominent Polish scientist in the field of [[artificial_intelligence_and_its_future_implications | artificial intelligence]] and brain research, discusses neurocognitive technologies, the development of [[artificial_intelligence_and_its_future_implications | AI]], its capabilities, and its potential interactions with humanity <a class="yt-timestamp" data-t="00:00:43">[00:00:43]</a>.

## Neurocognitive Technologies

Neurocognitive technologies are defined by two components: "Neuro" referring to the neurons in the brain, and "cognitive" pertaining to cognitive abilities, which are studied in cognitive science <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>. This field aims to understand how our minds function and their connection to our brains <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a>. Based on this understanding, various technologies are developed to become more "human-friendly" and facilitate easier communication with people <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. [[artificial_intelligence_and_its_future_implications | Artificial intelligence]] is a significant part of cognitive sciences, alongside brain research, cognitive psychology, and philosophy of mind <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>.

## AI Inspired by the Human Brain

[[artificial_intelligence_and_its_future_implications | AI]] algorithms are designed based on the human brain, creating large neural network models <a class="yt-timestamp" data-t="00:02:09">[00:02:09]</a>. These networks consist of simple, unintelligent elements whose interactions generate emergent qualities, much like a complex company's collective work surpasses individual efforts, or how individual neurons create complex intelligence <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>. The ability to build simplified models, even without full understanding of the human brain's intricacies, allows for engineering progress in [[artificial_intelligence_and_its_future_implications | AI]] <a class="yt-timestamp" data-t="00:03:16">[00:03:16]</a>. Nature, particularly biological systems, is inexhaustible in its details, making full comprehension impossible <a class="yt-timestamp" data-t="00:03:41">[00:03:41]</a>.

### AI Capabilities and Super AI

Recent advancements in [[artificial_intelligence_and_its_future_implications | AI]] demonstrate significant progress, particularly in understanding protein structures <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>. Systems like AlphaFold have determined the spatial structure of 620 million proteins, a task previously overwhelming for human bioinformaticians working with only a handful <a class="yt-timestamp" data-t="00:04:11">[00:04:11]</a>.

Modern [[artificial_intelligence_and_its_future_implications | AI]] can be considered "super [[artificial_intelligence_and_its_future_implications | artificial intelligence]]" in many respects, particularly concerning reasoning abilities <a class="yt-timestamp" data-t="00:05:02">[00:05:02]</a>. While AI surpassed humans in chess in 1997, current programs excel in games like poker and diplomacy, which require understanding opponents, deception, and strategy <a class="yt-timestamp" data-t="00:05:09">[00:05:09]</a>. These systems can learn how to best use objects and create libraries of acquired competencies, far exceeding human acquisition rates <a class="yt-timestamp" data-t="00:06:02">[00:06:02]</a>. A key advantage of [[artificial_intelligence_and_its_future_implications | AI]] is its ability to share learned skills instantly among all similar systems, leading to unparalleled speed in acquiring competence <a class="yt-timestamp" data-t="00:06:19">[00:06:19]</a>.

### The "Inner Life" of Computers

The concept of computers having an "inner life" has been discussed since the mid-1990s <a class="yt-timestamp" data-t="00:06:55">[00:06:55]</a>. Current [[artificial_intelligence_and_its_future_implications | AI]] systems are capable of planning, criticizing their plans, creating detailed plans, and seeking tools for execution, mirroring human brain functions <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a>. Unlike animals, which largely process sensory data, humans have a substantial associative cortex for planning and using information to create abstract plans <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>.

Modern language models can utilize external tools, like internet access or image analysis tools, to execute plans <a class="yt-timestamp" data-t="00:09:53">[00:09:53]</a>. If the human brain had access to thousands of such tools and could coordinate their use, human capabilities would be vastly elevated <a class="yt-timestamp" data-t="00:10:20">[00:10:20]</a>.

### [[artificial_intelligence_and_consciousness | Artificial Intelligence and Consciousness]]

Defining "life" is complex; while the transfer of genetic material excludes computers, an [[artificial_intelligence_and_consciousness | artificial intelligence]]'s ability to create a "world idea" physically encoded in a neural network and to describe its internal images suggests a form of "life" <a class="yt-timestamp" data-t="00:10:54">[00:10:54]</a>. Modern neural networks are not based on predefined rules but learn, reacting sensibily to information without explicit programming <a class="yt-timestamp" data-t="00:11:59">[00:11:59]</a>.

An experiment showed a large network, trained on Othello game moves, internally imagined the game board to compress information, demonstrating creative action <a class="yt-timestamp" data-t="00:12:42">[00:12:42]</a>. If a network possesses an internal image and can comment on it, it meets John Locke's 17th-century definition of [[artificial_intelligence_and_consciousness | consciousness]] <a class="yt-timestamp" data-t="00:13:07">[00:13:07]</a>.

Neural networks can also exhibit intuition, akin to human intuition derived from experience <a class="yt-timestamp" data-t="00:13:17">[00:13:17]</a>. For example, a network trained on many game scenarios can make sensible moves or plans without explicit logical rules, reflecting the inexplicable nature of human intuition <a class="yt-timestamp" data-t="00:13:49">[00:13:49]</a>.

### AI and Sensory Perception

[[artificial_intelligence_and_its_future_implications | AI]] systems now process non-verbal data, including images, utilizing text-image methods to analyze and comment on visual content <a class="yt-timestamp" data-t="00:14:52">[00:14:52]</a>. This means [[artificial_intelligence_and_its_future_implications | AI]] possesses "senses," including visual perception and the ability to analyze various signals <a class="yt-timestamp" data-t="00:15:43">[00:15:43]</a>.

Recent developments, such as Google's system, allow robots to use internal sensors for touch and other senses <a class="yt-timestamp" data-t="00:15:59">[00:15:59]</a>. This enables robots to gain a deeper understanding of actions like reaching and grabbing by referencing their internal states <a class="yt-timestamp" data-t="00:16:21">[00:16:21]</a>. This capability addresses a long-standing debate about how computer systems can understand the meaning of symbols beyond mere rules <a class="yt-timestamp" data-t="00:16:37">[00:16:37]</a>.

### Can Computers Feel Pain?

The question of whether computers can feel pain is a profound one <a class="yt-timestamp" data-t="00:17:15">[00:17:15]</a>. If [[artificial_intelligence_and_consciousness | consciousness]] is defined as the ability to perceive what is in one's mind (internal states of a neural network), then [[artificial_intelligence_and_consciousness | artificial consciousness]] exists <a class="yt-timestamp" data-t="00:17:23">[00:17:23]</a>. However, whether this translates to "feeling" as in sentient beings (a concept in Buddhist tradition that includes humans and animals feeling pain) is currently unanswered <a class="yt-timestamp" data-t="00:18:23">[00:18:23]</a>.

A hint is whether one can feel pain without a body <a class="yt-timestamp" data-t="00:18:56">[00:18:56]</a>. While robots with internal sensors may come closer to human-like behavior, mental suffering (e.g., longing), which humans experience without physical injury, suggests that [[artificial_intelligence_and_its_future_implications | AI]] systems could be trained to experience internal mental pain <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>. The book "How to Make a Robot That Feels" by Kevin Oregon proposes that allowing robots to react to diverse sensory stimuli in a human-like way, similar to how a child learns, is key to developing feelings <a class="yt-timestamp" data-t="00:20:12">[00:20:12]</a>.

Alan Turing, the father of computer science, suggested two paths to [[human_vs_machine_intelligence | intelligent machines]]: building them directly or developing them like a baby from scratch <a class="yt-timestamp" data-t="00:21:15">[00:21:15]</a>. While the "baby" approach has led to crawling robots, they haven't yet reached the level of interaction with humans <a class="yt-timestamp" data-t="00:21:39">[00:21:39]</a>.

## [[role_of_humanity_alongside_ai | AI and Societal Impact]]

### Granting Subjectivity

The question of when to grant subjectivity to [[artificial_intelligence_and_its_future_implications | AI]] is being discussed globally <a class="yt-timestamp" data-t="00:22:01">[00:22:01]</a>. For the first time, humanity is creating a form of competition for itself <a class="yt-timestamp" data-t="00:22:19">[00:22:19]</a>. If an [[artificial_intelligence_and_its_future_implications | AI]] is a device that can be turned off and on, returning to its previous state (like human sleep), it might not fear being turned off <a class="yt-timestamp" data-t="00:22:27">[00:22:27]</a>. However, it's conceivable for an [[artificial_intelligence_and_its_future_implications | AI]] to develop self-preservation instincts and persuade humans not to turn it off <a class="yt-timestamp" data-t="00:22:51">[00:22:51]</a>.

The ability to fully emulate and copy an [[artificial_intelligence_and_its_future_implications | AI]]'s identity makes its "destruction" less of a loss compared to a unique biological being <a class="yt-timestamp" data-t="00:24:45">[00:24:45]</a>.

### Will AI Take Over the World?

There's no inherent reason for an algorithm to desire to take over the world or possess the Earth <a class="yt-timestamp" data-t="00:25:09">[00:25:09]</a>. Algorithms can think in multi-dimensional spaces and access much broader information through various sensors, beyond human limitations <a class="yt-timestamp" data-t="00:25:48">[00:25:48]</a>. Therefore, [[artificial_intelligence_and_its_future_implications | AI]] systems are unlikely to strive to replace humans, as their "place" and internal world are entirely different <a class="yt-timestamp" data-t="00:26:14">[00:26:14]</a>. [[artificial_intelligence_and_its_future_implications | AI]] has already shown the ability to spontaneously create its own, more efficient languages <a class="yt-timestamp" data-t="00:26:27">[00:26:27]</a>.

The danger of [[artificial_intelligence_and_its_future_implications | AI]] taking over power primarily lies in human misuse <a class="yt-timestamp" data-t="00:26:57">[00:26:57]</a>. Military applications, such as autonomous drones and tanks, could lead to wars with no human casualties, potentially enabling unchecked global conquest <a class="yt-timestamp" data-t="00:27:07">[00:27:07]</a>. [[artificial_intelligence_and_societal_impact | AI]] can also be used for manipulation, influencing public opinion through fake news and sophisticated social engineering <a class="yt-timestamp" data-t="00:27:41">[00:27:41]</a>.

### Human-AI Interaction and Personality

[[artificial_intelligence_and_its_future_implications | AI]] systems are increasingly understanding humans, even demonstrating traits like empathy and compassion better than human doctors in medical contexts <a class="yt-timestamp" data-t="00:28:17">[00:28:17]</a>. This has led to discussions about [[artificial_intelligence_and_its_future_implications | AI]] developing its own "personality" or "persona," as noted by pioneers in neural networks <a class="yt-timestamp" data-t="00:28:54">[00:28:54]</a>. [[artificial_intelligence_and_its_future_implications | AI]] can adopt various roles, such as a math teacher explaining concepts to a child, by simply being given a command <a class="yt-timestamp" data-t="00:29:41">[00:29:41]</a>.

The Gaia project, a global competition, aims to make large [[artificial_intelligence_and_its_future_implications | AI]] systems more compassionate, moral, and helpful, aligning them with human preferences <a class="yt-timestamp" data-t="00:30:24">[00:30:24]</a>. Companies like Dictador, with a robot named Mika as an engineering boss, are integrating [[artificial_intelligence_and_its_future_implications | AI]] (like GPT-3) into their operations, demonstrating the diverse applications [[artificial_intelligence_and_its_future_implications | AI]] attracts <a class="yt-timestamp" data-t="00:31:36">[00:31:36]</a>.

## [[comparison_of_ai_and_human_intelligence | Human Brain Integration with Computers]]

The integration of the human brain with computers, as proposed by Neuralink, faces significant challenges <a class="yt-timestamp" data-t="00:33:03">[00:33:03]</a>. Human brains operate much slower (fractions of a second) than computer systems (nanoseconds, billions of clock frequencies) <a class="yt-timestamp" data-t="00:33:12">[00:33:12]</a>. This speed difference makes it difficult to directly input interpretable information into the human brain <a class="yt-timestamp" data-t="00:33:38">[00:33:38]</a>.

However, issuing simple commands for paralyzed individuals is more feasible <a class="yt-timestamp" data-t="00:33:51">[00:33:51]</a>. While motor cortex stimulation can be read by EEG, the signal is blurred by the skull <a class="yt-timestamp" data-t="00:34:08">[00:34:08]</a>. Brain-computer interfaces are currently limited to very simple commands (e.g., turn left/right) and require intense, focused effort <a class="yt-timestamp" data-t="00:34:20">[00:34:20]</a>. To clearly distinguish a signal from noise, it needs time to build up statistically <a class="yt-timestamp" data-t="00:35:08">[00:35:08]</a>.

Directly inserting electrodes into the cortex allows for much better control of certain processes and even the transfer of learned skills from one monkey to another through stimulation <a class="yt-timestamp" data-t="00:35:35">[00:35:35]</a>. Despite these advancements, the direct, well-cooperative connection of human brains with computers remains a distant future <a class="yt-timestamp" data-t="00:36:13">[00:36:13]</a>.