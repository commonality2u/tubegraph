---
title: Neural networks and biological systems
videoId: 39Gpo7dSAMA
---

From: [[mk_thisisit]] <br/> 

John J. Hopfield, a recipient of the 2024 Nobel Prize in Physics, was honored for his fundamental discoveries that enabled [[the_evolution_of_neural_networks_and_machine_learning | machine learning]] using neural networks <a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a>. Often referred to as the "father of artificial neural networks," Hopfield published his seminal model in 1982, which integrated statistical physics with neurobiology, paving the way for modern deep learning <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>.

## Distinguishing AI from Biological Processes

Advanced AI neural networks are most interesting because of what [[distinguishing_features_of_ai_from_biological_processes | distinguishes them most from biology]] <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>. One area of focus for improvement is to actually try to incorporate neural networks into biological fields <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>, as well as engineering <a class="yt-timestamp" data-t="00:02:53">[00:02:53]</a>. This approach would allow both biology and the abstract world of mathematics to share any concerns or merits regarding these systems <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>.

A key difference lies in the learning algorithms. In biology, changes in synapses do not occur in infinitesimal quantities, and there is inherent noise, with "n or n + 1 proteins" in a synapse <a class="yt-timestamp" data-t="00:13:06">[00:13:06]</a>. While the learning algorithm in advanced AI nominally resembles that in biology, it is not the same <a class="yt-timestamp" data-t="00:13:22">[00:13:22]</a>. There is a potential future turn in the field of neural networks when the focus shifts to understanding the real biological learning algorithm and how its essence can be included in engineering <a class="yt-timestamp" data-t="00:13:34">[00:13:34]</a>.

## The Essence of Imitation

Hopfield's work on neural networks aimed to imitate biology as best as possible without slavishly copying every tiny aspect <a class="yt-timestamp" data-t="00:05:51">[00:05:51]</a>. This approach, which avoids copying everything verbatim from biology, has proven to be much more advantageous <a class="yt-timestamp" data-t="00:06:03">[00:06:03]</a>. Modern physics emphasizes capturing the essence of a phenomenon rather than all its details <a class="yt-timestamp" data-t="00:06:41">[00:06:41]</a>. Slavish imitation, conversely, consumes computer resources and provides little insight <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>. The goal is to achieve something universal, like phase transition systems, which help understand biology, physics, and collective systems <a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a>.

## Understanding Brain Activity and Consciousness

Before Hopfield networks, greater emphasis was placed on tracking the detailed occurrence of action potentials in each neuron over time to describe brain activity <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>. Hopfield's realization was the need to understand computation in a physical system, specifically the dynamics in a multidimensional space of coupled variables, rather than just the activities of basic elements <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a>. Computation does not need to be limited to logic alone, unlike modern computer calculations <a class="yt-timestamp" data-t="00:10:25">[00:10:25]</a>.

Hopfield also recognized that the way biologists and psychologists view memory is isomorphic to certain claims physicists make about the interaction of spin and spin systems with magnetism <a class="yt-timestamp" data-t="00:10:37">[00:10:37]</a>. This allowed for combining already similar concepts in a more coherent way, deriving the same equations from completely different perspectivesâ€”biology and engineering <a class="yt-timestamp" data-t="00:11:05">[00:11:05]</a>.

The question of consciousness has been debated for decades <a class="yt-timestamp" data-t="00:00:22">[00:00:22]</a>. One key consideration is whether neurons can be thought of as independent systems, or if they must be viewed as exhibiting collective behavior <a class="yt-timestamp" data-t="00:00:29">[00:00:29]</a>. Language, for example, might be a collective behavior describable at a higher level, not relying on every lower-level detail <a class="yt-timestamp" data-t="00:17:08">[00:17:08]</a>.

While Roger Penrose strongly believes human consciousness arises from [[quantum_mechanics_in_biological_systems_like_photosynthesis_and_brain_function | quantum phenomena]] in the human brain <a class="yt-timestamp" data-t="00:19:57">[00:19:57]</a>, Hopfield notes that it cannot be ruled out that consciousness is a problem of classical mechanics rather than quantum mechanics <a class="yt-timestamp" data-t="00:00:39">[00:00:39]</a>, <a class="yt-timestamp" data-t="00:21:12">[00:21:12]</a>. The decision of what role quantum mechanics plays is a secondary issue, and no one can definitively state whether consciousness is purely a matter of classical or quantum physics <a class="yt-timestamp" data-t="00:22:21">[00:22:21]</a>.

## Evolution of Neural Networks

The history of neural networks shows gradual progress <a class="yt-timestamp" data-t="00:14:31">[00:14:31]</a>:
*   Early networks had one neuron <a class="yt-timestamp" data-t="00:13:53">[00:13:53]</a>.
*   Then came the perceptron network with a forward-flowing information layer <a class="yt-timestamp" data-t="00:13:59">[00:13:59]</a>.
*   The Hopfield network introduced feedback <a class="yt-timestamp" data-t="00:14:05">[00:14:05]</a>.
*   The Boltzmann machine allowed for building more complex topological networks <a class="yt-timestamp" data-t="00:14:11">[00:14:11]</a>.
*   Finally, deep learning emerged, with a method for learning in multi-layered networks <a class="yt-timestamp" data-t="00:14:17">[00:14:17]</a>.

The shift from Hopfield networks to advanced AI was driven by focusing on understanding knowledge hidden in the network rather than its origin <a class="yt-timestamp" data-t="01:21:13">[01:21:13]</a>, and the creation of a network structure that could be run through numerous learning algorithms <a class="yt-timestamp" data-t="00:01:28">[00:01:28]</a>.

## Physics and Broader Science

Professor Hopfield views physics as the science of all phenomena in matter <a class="yt-timestamp" data-t="00:23:21">[00:23:21]</a>. He believes it is limiting to confine physics to judging whether something is "AI or not AI," or to prioritize only fields with practical applications <a class="yt-timestamp" data-t="00:24:02">[00:24:02]</a>. He cautions against focusing solely on engineering efficiency in the future, advocating for science in a broader context which enables diverse engineering uses <a class="yt-timestamp" data-t="00:24:51">[00:24:51]</a>.

His own work defies easy categorization, with papers classified as either physical or biological depending on the perspective <a class="yt-timestamp" data-t="00:25:36">[00:25:36]</a>. This interdisciplinary nature highlights [[the_intersection_of_biology_and_electronics | the intersection of biology and electronics]] and physics in understanding complex systems.