---
title: Challenges in AI understanding of the physical world
videoId: w-TtKPRuXL8
---

From: [[mk_thisisit]] <br/> 

Current [[Limitations of current AI systems | artificial intelligence (AI)]] systems are limited in their understanding of the physical world <a class="yt-timestamp" data-t="00:00:13">[00:00:13]</a>. Despite their ability to manipulate language effectively, they lack crucial features such as permanent memory, reasoning, and planning capabilities <a class="yt-timestamp" data-t="00:05:45">[00:05:45]</a>.

## Current Limitations of AI

AI systems are often perceived as intelligent because of their proficiency in language manipulation <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>. However, this perception can be misleading, as these systems fundamentally do not comprehend the physical world <a class="yt-timestamp" data-t="00:00:13">[00:00:13]</a>. Key [[Cognitive Abilities and AIs Interaction with Humans | features of intelligent behavior]], such as reasoning and planning, are currently not reproducible in AI <a class="yt-timestamp" data-t="00:05:53">[00:05:53]</a>.

### Human-like Abilities

While AI systems might develop "emotions" like excitement or joy from predicting successful outcomes <a class="yt-timestamp" data-t="00:06:30">[00:06:30]</a>, they will not inherently possess human flaws such as anger or jealousy <a class="yt-timestamp" data-t="00:07:13">[00:07:13]</a>. The concept of consciousness itself lacks a clear, measurable definition, making it difficult to assess in both biological and artificial entities <a class="yt-timestamp" data-t="00:07:27">[00:07:27]</a>.

### Ineffective Learning Paradigms for the Physical World

There are three primary paradigms in machine learning:
*   **Supervised Learning** &ndash; This classic approach trains systems by providing correct answers, such as identifying objects in images <a class="yt-timestamp" data-t="00:08:51">[00:08:51]</a>. While effective for specific tasks, it demands vast amounts of high-quality data <a class="yt-timestamp" data-t="00:10:14">[00:10:14]</a>.
*   **Reinforcement Learning** &ndash; Considered closer to human learning, this method provides feedback on whether a result was good or bad <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>. It excels in game environments (e.g., chess or Go) where systems can play millions of games against themselves <a class="yt-timestamp" data-t="00:10:20">[00:10:20]</a>. However, it is "extremely ineffective" in the real world; for example, training a self-driving car purely with reinforcement learning would result in thousands of crashes <a class="yt-timestamp" data-t="00:10:17">[00:10:17]</a>.
*   **Self-Supervised Learning** &ndash; This method, which has driven recent advancements in natural language processing and chatbots, trains systems to understand the structure of input data, such as predicting missing words in text <a class="yt-timestamp" data-t="00:10:55">[00:10:55]</a>. While highly successful for language models, it falls short when applied to the physical world <a class="yt-timestamp" data-t="00:12:27">[00:12:27]</a>.

## Language vs. Physical World Understanding

The physical world is significantly more complex for AI to understand than language <a class="yt-timestamp" data-t="00:12:35">[00:12:35]</a>. Language, being discrete and composed of a finite number of symbols, allows for probabilistic predictions of next words <a class="yt-timestamp" data-t="00:12:47">[00:12:47]</a>. In contrast, predicting events in a continuous, high-dimensional space like video is mathematically unsolvable due to the infinite possibilities of unpredictable details <a class="yt-timestamp" data-t="00:47:47">[00:47:47]</a>.

Humans and animals develop an intuitive understanding of physics, such as gravity, within months of birth <a class="yt-timestamp" data-t="00:13:53">[00:13:53]</a>. Cats, for instance, are adept at planning complex physical actions like climbing and jumping due to their intuitive grasp of physics <a class="yt-timestamp" data-t="00:14:31">[00:14:31]</a>. Replicating this "physical intuition" in computers remains a major challenge <a class="yt-timestamp" data-t="00:14:44">[00:14:44]</a>.

## The Moravec Paradox

The Moravec paradox highlights the counter-intuitive difficulty of certain tasks for AI <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a>. As robotics expert Hans Moravec observed, computers can excel at abstract tasks like playing chess or solving mathematical puzzles, but struggle with physical manipulation tasks that are easy for even young children or animals <a class="yt-timestamp" data-t="00:15:01">[00:15:01]</a>. This is because the space of discrete objects and symbols is easier for computers to manipulate, while the real world is "too complicated" <a class="yt-timestamp" data-t="00:15:24">[00:15:24]</a>.

Sensory data, such as sight and touch, contains an "absolutely huge" amount of information compared to language <a class="yt-timestamp" data-t="00:15:59">[00:15:59]</a>. This disparity explains why large language models (LLMs) can pass law exams or solve math problems, yet there are no truly realistic robots capable of tasks easily performed by cats or dogs, nor fully autonomous cars <a class="yt-timestamp" data-t="00:16:06">[00:16:06]</a>. The ability to process and understand complex sensory data is crucial for machines to learn as effectively as humans and animals <a class="yt-timestamp" data-t="00:16:40">[00:16:40]</a>.

A typical large language model is trained on approximately 20-30 trillion tokens (words), equivalent to about 10<sup>14</sup> bytes of data <a class="yt-timestamp" data-t="00:17:34">[00:17:34]</a>. This amount of data, representing all publicly available text on the internet, would take hundreds of thousands of years for a human to read <a class="yt-timestamp" data-t="00:18:06">[00:18:06]</a>. Strikingly, a small child processes a comparable amount of information through their visual system in the first four years of life <a class="yt-timestamp" data-t="00:18:13">[00:18:13]</a>. This comparison underscores that AI systems will never reach human-level intelligence by training solely on text data; they must be taught to understand the real world <a class="yt-timestamp" data-t="00:18:45">[00:18:45]</a>.

## Future [[Development and challenges of artificial intelligence | Development Goals]] for AI

Researchers are working on designing new types of AI systems, still based on deep learning, that can function in the physical world, possess permanent memory, and are capable of reasoning and planning <a class="yt-timestamp" data-t="00:06:09">[00:06:09]</a>.

One proposed solution to the challenge of predicting continuous, high-dimensional data in the physical world is the **Joint Embedding Predictive Architecture (JEPA)** <a class="yt-timestamp" data-t="00:48:37">[00:48:37]</a>. JEPA is a macro-architecture where the system learns an abstract representation of the input data and then makes predictions within that abstract space, rather than attempting to predict every unpredictable detail of the original input <a class="yt-timestamp" data-t="00:48:42">[00:48:42]</a>. This approach makes the problem more tractable for AI.

### Reasoning and Planning

Current large language models use primitive methods for reasoning, often generating many possible output sequences and then selecting the best one <a class="yt-timestamp" data-t="00:26:51">[00:26:51]</a>. This process is computationally expensive and differs from human thought, where internal mental models of the world are used to predict outcomes and plan actions <a class="yt-timestamp" data-t="00:27:14">[00:27:14]</a>.

For AI to achieve true intelligence, it needs to develop the ability for **hierarchical planning**, defining intermediate goals to achieve a larger objective <a class="yt-timestamp" data-t="00:29:52">[00:29:52]</a>. This is a "great challenge" for the coming years <a class="yt-timestamp" data-t="00:30:44">[00:30:44]</a>.

## [[Challenges in sensory development for robots | Robotics]] and AI Integration

While production robots excel at simple, automated tasks in controlled environments <a class="yt-timestamp" data-t="00:31:36">[00:31:36]</a>, more complex applications like autonomous driving still lack human-level reliability <a class="yt-timestamp" data-t="00:31:59">[00:31:59]</a>. This is not due to physical limitations of robots, but because they are "not smart enough to deal with the real world" <a class="yt-timestamp" data-t="00:34:06">[00:34:06]</a>. Companies are banking on rapid AI advancements in the next 3-5 years to make humanoid robots and autonomous vehicles truly viable <a class="yt-timestamp" data-t="00:34:10">[00:34:10]</a>. The upcoming decade is predicted to be the "decade of robotics" <a class="yt-timestamp" data-t="00:42:42">[00:42:42]</a>.

The biggest challenge is the integration of [[Artificial Intelligence Integration in Augmented Reality | AI]], robotics, and sensors for skillful use <a class="yt-timestamp" data-t="00:33:18">[00:33:18]</a>. Creating AI systems that understand the physical world, possess permanent memory, and can reason and plan will form the foundation for more adaptive robots <a class="yt-timestamp" data-t="00:33:29">[00:33:29]</a>.

AI progress has been discontinuous, with periods of rapid advancement followed by stagnation <a class="yt-timestamp" data-t="00:34:55">[00:34:55]</a>. However, recent acceleration since 2013 is attributed to increased investment and more talented people entering the field <a class="yt-timestamp" data-t="00:35:13">[00:35:13]</a>.