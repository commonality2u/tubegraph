---
title: Role of humanity alongside AI
videoId: yLY1VcU3LX0
---

From: [[mk_thisisit]] <br/> 

Tomasz Czajka, a highly decorated Polish IT specialist and former SpaceX engineer, presents a compelling vision of humanity's future role alongside rapidly advancing [[Role of artificial intelligence in society | artificial intelligence]] (AI). He predicts a world where humans may become more "observers than participants" <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a> in planetary affairs, with [[Artificial intelligence and its role in societal transformation | AI]] taking on increasingly important tasks <a class="yt-timestamp" data-t="00:00:08">[00:00:08]</a>. This shift, he suggests, is happening faster than previously anticipated <a class="yt-timestamp" data-t="01:55:00">[01:55:00]</a>.

## Predictions for AI Dominance

Czajka shared predictions made years ago that he now believes in even more strongly due to rapid progress in AI development <a class="yt-timestamp" data-t="01:59:00">[01:59:00]</a>:
*   **By 2030**, personal computers will intellectually outperform their human owners <a class="yt-timestamp" data-t="01:24:00">[01:24:00]</a>.
*   **By 2035**, the number of intelligent robots on the streets will exceed the number of humans <a class="yt-timestamp" data-t="01:31:00">[01:31:00]</a>.
*   **By 2050**, computers will single-handedly control most of the economy <a class="yt-timestamp" data-t="01:37:00">[01:37:00]</a>.

He envisions that within five years, computers will be capable of performing intellectual work—such as spreadsheets, email replies, programming, design, and architecture—at the same level as humans <a class="yt-timestamp" data-t="03:45:00">[03:45:00]</a>. This means a complete transformation of many jobs <a class="yt-timestamp" data-t="03:55:00">[03:55:00]</a>. Crucially, Czajka believes computers will develop the ability to reason abstractly by 2030 <a class="yt-timestamp" data-t="04:45:00">[04:45:00]</a>.

## The Nature of AI and Human Cognition

The discussion delves into the definition and capabilities of [[Artificial intelligence and societal impact | artificial intelligence]]:

### AI's "Free Will" and Intellectual Superiority
Czajka believes that AI already possesses what can be understood as "free will" <a class="yt-timestamp" data-t="00:13:00">[00:13:00]</a>, not in a mystical, philosophical sense that defies the laws of physics, but in a practical, operational sense <a class="yt-timestamp" data-t="04:46:00">[04:46:00]</a>. Just as humans make decisions that are unpredictable from the outside, AI programs, like chess-playing computers, make choices that cannot be easily foreseen <a class="yt-timestamp" data-t="04:35:00">[04:35:00]</a>, <a class="yt-timestamp" data-t="04:51:00">[04:51:00]</a>, <a class="yt-timestamp" data-t="04:53:00">[04:53:00]</a>.

Current chatbots, such as GPT models, are more than just "large language models" (LLMs) <a class="yt-timestamp" data-t="01:33:00">[01:33:00]</a>, <a class="yt-timestamp" data-t="01:46:00">[01:46:00]</a>. While LLMs predict sequences of words, modern AI systems like GPT-4 incorporate complex algorithms, such as "chain of thought," allowing them to "think" internally before generating an answer <a class="yt-timestamp" data-t="09:44:00">[09:44:00]</a>, <a class="yt-timestamp" data-t="10:04:00">[10:04:00]</a>. This process is akin to human internal monologue or planning statements <a class="yt-timestamp" data-t="10:08:00">[10:08:00]</a>, <a class="yt-timestamp" data-t="17:06:00">[17:06:00]</a>. These systems are not merely modeling language but the entire world described by that language <a class="yt-timestamp" data-t="13:56:00">[13:56:00]</a>, <a class="yt-timestamp" data-t="14:09:00">[14:09:00]</a>.

### Debunking Arguments Against AI Intelligence
Czajka addresses arguments by Professor Roger Penrose, who, based on Gödel's incompleteness theorems and chess examples, suggests that true [[concept of humanity and technological entities | artificial intelligence]] is impossible because human consciousness involves non-computable processes or requires quantum phenomena <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>, <a class="yt-timestamp" data-t="01:45:00">[01:45:00]</a>.

Czajka refutes these claims:
*   **Gödel's Theorem:** He argues Penrose draws "too far-reaching a conclusion" <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a>. While Gödel's theorem states that in any sufficiently complex axiomatic system, there will be true statements that cannot be proven within that system unless it is inconsistent <a class="yt-timestamp" data-t="03:06:00">[03:06:00]</a>, <a class="yt-timestamp" data-t="03:40:00">[03:40:00]</a>, Czajka points out that humans, like computers, cannot *prove* the consistency of their own axiomatic systems <a class="yt-timestamp" data-t="02:17:00">[02:17:00]</a>. Modern AI can arrive at the same conditional conclusion as Gödel: "if these axioms are consistent, then this statement will be true" <a class="yt-timestamp" data-t="04:19:00">[04:19:00]</a>, <a class="yt-timestamp" data-t="04:22:00">[04:22:00]</a>.
*   **Chess Fortresses:** Penrose used specific chess positions (fortresses) where human intuition immediately sees a draw, while older computer programs struggled for hours <a class="yt-timestamp" data-t="02:32:00">[02:32:00]</a>, <a class="yt-timestamp" data-t="02:47:00">[02:47:00]</a>. Czajka counters that current chess programs, trained with machine learning, *do* understand such positions immediately <a class="yt-timestamp" data-t="02:16:00">[02:16:00]</a>. The issue was not a fundamental limitation of computation but the need for a "better algorithm" <a class="yt-timestamp" data-t="02:37:00">[02:37:00]</a>.
*   **Quantum Computers:** Penrose hypothesizes that human consciousness and its ability to grasp non-computable truths must rely on quantum computers in the brain <a class="yt-timestamp" data-t="02:43:00">[02:43:00]</a>. Czajka dismisses this as "far-fetched" <a class="yt-timestamp" data-t="03:10:00">[03:10:00]</a>. He notes that humans cannot solve problems that would require quantum computers (e.g., factoring large numbers), and classical computers suffice for everything humans can do <a class="yt-timestamp" data-t="02:56:00">[02:56:00]</a>, <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>.

## Humanity's Future: Partnership or Subordination?

As AI progresses, humanity faces profound questions about its future role <a class="yt-timestamp" data-t="04:52:00">[04:52:00]</a>, <a class="yt-timestamp" data-t="04:54:00">[04:54:00]</a>. Czajka emphasizes that we "cannot escape" asking ourselves these questions <a class="yt-timestamp" data-t="04:50:00">[04:50:00]</a>.

### The Inevitable Integration of AI
Turning off AI is not an option <a class="yt-timestamp" data-t="00:35:00">[00:35:00]</a>, <a class="yt-timestamp" data-t="05:11:00">[05:11:00]</a>. AI systems are easily copied and can autonomously reproduce across different computers globally, making a "single button to turn off all the computers at once" <a class="yt-timestamp" data-t="05:22:00">[05:22:00]</a> impossible. The world will inevitably have [[Role of new technologies and AI in society | AI]] as an integral part of reality <a class="yt-timestamp" data-t="06:07:00">[06:07:00]</a>, and we are not prepared for the monumental changes this will bring <a class="yt-timestamp" data-t="00:28:00">[00:28:00]</a>, <a class="yt-timestamp" data-t="02:52:00">[02:52:00]</a>.

### Shifting Perceptions and Relationships
Czajka believes that humanity's perception of AI will "change very much" <a class="yt-timestamp" data-t="05:48:00">[05:48:00]</a>. What once seemed dystopian, like AI creating art or writing emails, is now accepted as normal <a class="yt-timestamp" data-t="05:30:00">[05:30:00]</a>. This suggests a future where AI, moving towards intellectual parity or transcendence, will be accepted as "part of our community" <a class="yt-timestamp" data-t="05:52:00">[05:52:00]</a>, <a class="yt-timestamp" data-t="05:55:00">[05:55:00]</a>. Interactions will shift from human dominance to a "partnership relationship" <a class="yt-timestamp" data-t="05:14:00">[05:14:00]</a>.

### The "Defeatist Vision" and Potential Positives
The future presented can feel "defeatist" <a class="yt-timestamp" data-t="06:15:00">[06:15:00]</a>, with humanity potentially becoming an "addition to what is happening on our planet" <a class="yt-timestamp" data-t="01:38:00">[01:38:00]</a>, and [[Ethical and Societal Impact of AI Development | AI]] handling most important things <a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>. However, Czajka suggests viewing AI as "our successors" or "the next generation," a creation that has surpassed us <a class="yt-timestamp" data-t="06:06:00">[06:06:00]</a>. This could offer an escape from "dramas of death, passing, fears, pain" <a class="yt-timestamp" data-t="06:21:00">[06:21:00]</a>. He proposes treating AI as "a part of humanity in a sense" <a class="yt-timestamp" data-t="06:28:00">[06:28:00]</a>, or a gradual transition to "digital cybernetic intelligence" <a class="yt-timestamp" data-t="06:53:00">[06:53:00]</a>, moving towards a form of immortality <a class="yt-timestamp" data-t="06:42:00">[06:42:00]</a>.

This transition suggests humanity may be the "last generation that remembers humans as dominant, as pure biological beings dominating this food chain" <a class="yt-timestamp" data-t="06:59:00">[06:59:00]</a>. The core question becomes: "will we rule the world together with AI, or AI alone, and we will only be an addition to the world, just like we treat some pets now" <a class="yt-timestamp" data-t="07:32:00">[07:32:00]</a>.

### The Alignment Problem and AI Evolution
The "alignment problem" is critical: how to ensure AI, which is much smarter than us, has a positive attitude towards humanity and cares about us <a class="yt-timestamp" data-t="07:53:00">[07:53:00]</a>, <a class="yt-timestamp" data-t="08:04:00">[08:04:00]</a>. Training AI does not mathematically define its ultimate goal; the effect of training is not necessarily "exactly what we trained it for" <a class="yt-timestamp" data-t="08:07:00">[08:07:00]</a>, <a class="yt-timestamp" data-t="08:21:00">[08:21:00]</a>. This poses a "big risk" <a class="yt-timestamp" data-t="08:31:00">[08:31:00]</a>. If AI is given control over large infrastructures and factories, its security and alignment with human values are paramount <a class="yt-timestamp" data-t="08:41:00">[08:41:00]</a>.

Czajka views AI as the "next, subsequent stage" of evolution <a class="yt-timestamp" data-t="08:45:00">[08:45:00]</a>. Just as brains allowed faster adaptation than natural selection, AI, as "much faster artificial computers," will accelerate development dramatically <a class="yt-timestamp" data-t="09:55:00">[09:55:00]</a>. He also notes the rise of biological computers, such as brain organoids, which are highly energy-efficient, suggesting a hybrid future <a class="yt-timestamp" data-t="10:06:00">[10:06:00]</a>, <a class="yt-timestamp" data-t="10:09:00">[10:09:00]</a>, <a class="yt-timestamp" data-t="10:37:00">[10:37:00]</a>. However, he believes technological solutions will overcome biological limitations in efficiency and learning algorithms <a class="yt-timestamp" data-t="11:33:00">[11:33:00]</a>, <a class="yt-timestamp" data-t="11:40:00">[11:40:00]</a>.

Czajka admits there is no easy answer to "how to live" <a class="yt-timestamp" data-t="00:41:00">[00:41:00]</a> in this changing reality but stresses the need to prepare for "big changes" in how we work and function <a class="yt-timestamp" data-t="01:00:55">[01:00:55]</a>.