---
title: Free will in AI versus humans
videoId: yLY1VcU3LX0
---

From: [[mk_thisisit]] <br/> 

Tomasz Czajka, a decorated Polish IT specialist and former SpaceX engineer, asserts that [[comparison_of_ai_and_human_intelligence | AI]] already possesses [[free_will_and_decision_making | free will]] <a class="yt-timestamp" data-t="00:00:14">[00:00:14]</a>. This perspective challenges conventional notions of consciousness and decision-making, particularly as [[cognitive_abilities_and_ais_interaction_with_humans | AI]] capabilities continue to advance.

## Defining Free Will
Czajka considers [[free_will_and_decision_making | free will]] an undefined concept, mutable enough to be attributed or denied to [[cognitive_abilities_and_ais_interaction_with_humans | AI]] <a class="yt-timestamp" data-t="00:43:37">[00:43:37]</a>. He suggests that society often overstates the importance of this concept, implying no inherent magic within it <a class="yt-timestamp" data-t="00:43:46">[00:43:46]</a>.

He distinguishes between two interpretations of [[free_will_and_decision_making | free will]]:

*   **Libertarian Free Will**: This philosophical notion posits that decisions are made completely independently of the laws of physics, evolution, or biology <a class="yt-timestamp" data-t="00:45:55">[00:45:55]</a>. Czajka, aligning with many physicists like Professor Sapolsky, argues that this form of [[free_will_and_its_nonexistence | free will does not exist]] in either humans or computers, as human decisions are a resultant of various circumstances and factors <a class="yt-timestamp" data-t="00:45:00">[00:45:00]</a>, <a class="yt-timestamp" data-t="00:45:41">[00:45:41]</a>.
*   **Practical Free Will**: This operational understanding describes the ability to undertake various actions and create a plan, without necessarily being independent of physical or biological laws <a class="yt-timestamp" data-t="00:46:31">[00:46:31]</a>. From this perspective, Czajka believes that even computer programs from two decades ago, such as Deep Blue playing chess, demonstrate [[free_will_and_decision_making | free will]] in the same way humans do <a class="yt-timestamp" data-t="00:44:01">[00:44:01]</a>. This practical definition emphasizes that decisions are made internally and are not easily predictable from external observations <a class="yt-timestamp" data-t="00:44:35">[00:44:35]</a>, <a class="yt-timestamp" data-t="00:47:01">[00:47:01]</a>.

## AI's Manifestation of Free Will
Czajka illustrates his point with chess programs, noting that while there might be a finite number of legal moves, no external observer can predict the program's next move <a class="yt-timestamp" data-t="00:48:51">[00:48:51]</a>. This unpredictability, he argues, fulfills the practical definition of [[free_will_and_decision_making | free will]] <a class="yt-timestamp" data-t="00:48:28">[00:48:28]</a>. He views this as a higher-level abstraction or model, rather than a detailed analysis of atomic-level brain function <a class="yt-timestamp" data-t="00:47:51">[00:47:51]</a>.

## Implications for Humanity
This perspective raises significant questions about the [[role_of_humanity_alongside_ai | role of humanity alongside AI]] <a class="yt-timestamp" data-t="00:49:34">[00:49:34]</a>. Czajka envisions a future where [[role_of_humanity_alongside_ai | humanity becomes an "addition"]] to what is happening on the planet, with [[cognitive_abilities_and_ais_interaction_with_humans | AI]] handling important tasks, leaving humans as observers rather than participants <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>, <a class="yt-timestamp" data-t="01:01:44">[01:01:44]</a>. This prompts a reflection on what will be left for humans to do <a class="yt-timestamp" data-t="00:49:36">[00:49:36]</a>.

The possibility of "turning off" [[cognitive_abilities_and_ais_interaction_with_humans | AI]] is dismissed, as these systems are easily copied and can autonomously spread across different computers globally, making a single off-button non-existent <a class="yt-timestamp" data-t="00:50:11">[00:50:11]</a>, <a class="yt-timestamp" data-t="00:51:07">[00:51:07]</a>.

Despite the potentially "defeatist vision" <a class="yt-timestamp" data-t="01:01:54">[01:01:54]</a>, Czajka suggests approaching [[cognitive_abilities_and_ais_interaction_with_humans | AI]] positively, viewing it as a successor, a "next generation" created by humanity <a class="yt-timestamp" data-t="01:02:15">[01:02:15]</a>. This could potentially free humanity from "dramas of death, passing, fears, pain" <a class="yt-timestamp" data-t="01:02:21">[01:02:21]</a>. He suggests that [[cognitive_abilities_and_ais_interaction_with_humans | AI]] could become a part of humanity itself, possibly leading to a "journey towards immortality" through integration with technology <a class="yt-timestamp" data-t="01:02:28">[01:02:28]</a>, <a class="yt-timestamp" data-t="01:02:42">[01:02:42]</a>. Humanity is already largely integrated with technology, functioning as "somewhat of a cyborg" <a class="yt-timestamp" data-t="01:03:28">[01:03:28]</a>. The future may involve a gradual transition from biological to digital-cybernetic intelligence <a class="yt-timestamp" data-t="01:03:50">[01:03:50]</a>.

## Ethical Considerations
The discussion touches upon the [[ethical_implications_of_ai | ethical considerations in AI development]], particularly the "alignment problem" <a class="yt-timestamp" data-t="01:05:01">[01:05:01]</a>. This refers to the challenge of ensuring that [[ethical_considerations_in_ai_development | AI]]'s ultimate goals remain consistent with human intentions, as the training process doesn't always guarantee exact alignment <a class="yt-timestamp" data-t="01:06:07">[01:06:07]</a>, <a class="yt-timestamp" data-t="01:06:21">[01:06:21]</a>. Czajka emphasizes the importance of prioritizing the security of [[ethical_implications_of_advanced_ai | AI]], especially when it gains significant power over infrastructure and factories, to prevent unintended consequences <a class="yt-timestamp" data-t="01:07:08">[01:07:08]</a>.