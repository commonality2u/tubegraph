---
title: Comparison of AI and human intelligence
videoId: 6QhGUQ5iTdk
---

From: [[mk_thisisit]] <br/> 

Artificial Intelligence (AI) is rapidly becoming the main topic of conversation on Earth, with machines being built that are demonstrably smarter than humans <a class="yt-timestamp" data-t="00:00:03">[00:00:03]</a>. While AI promises to solve many existing problems, it is also expected to create new ones <a class="yt-timestamp" data-t="00:00:24">[00:00:24]</a>.

## Defining Intelligence and Capabilities

### Is AI just statistics?
Initially, one might consider [[Artificial intelligence surpassing human capabilities | AI]] to be merely statistics. However, according to Wojtek Zaręba, co-creator of ChatGPT, this interpretation depends on the definition <a class="yt-timestamp" data-t="00:01:24">[00:01:24]</a>. Modern AI models, particularly neural networks, demonstrate an ability to solve problems requiring reasoning that they have never explicitly seen before <a class="yt-timestamp" data-t="00:01:34">[00:01:34]</a>. These models can "generalize intelligently on very different data," indicating something beyond simple memorization or statistical correlation <a class="yt-timestamp" data-t="00:01:56">[00:01:56]</a>. If the [[Human vs machine intelligence | human brain]] were considered "statistics," then it would be "unbelievable" or "magic" <a class="yt-timestamp" data-t="00:02:09">[00:02:09]</a>.

While there's empirical understanding of neural networks' results, a "very deep theoretical understanding" of *why* they behave this way is currently lacking <a class="yt-timestamp" data-t="00:02:33">[00:02:33]</a>. For instance, traditional statistical models often fail if there are more parameters than data, learning to remember rather than generalize <a class="yt-timestamp" data-t="00:02:46">[00:02:46]</a>. In contrast, neural networks (specifically transformers) can still correctly recognize numbers even if a single pixel in a black background image is changed to white, despite never having seen such a deviation in their training data <a class="yt-timestamp" data-t="00:03:32">[00:03:32]</a>. This suggests an [[Cognitive Abilities and AIs Interaction with Humans | interpretation process]] occurring within the AI <a class="yt-timestamp" data-t="00:04:19">[00:04:19]</a>.

### Understanding Context
A significant [[Human vs machine intelligence | distinction between humans and AI]] currently lies in the understanding of context, particularly cultural contexts <a class="yt-timestamp" data-t="00:06:11">[00:06:11]</a>. An example given is an autonomous taxi in San Francisco's Chinatown that was burned for violating a "sacred zone" during a procession, even though it maintained a safe distance from people <a class="yt-timestamp" data-t="00:05:37">[00:05:37]</a>. The model, trained solely on image data, did not understand the cultural significance of the space <a class="yt-timestamp" data-t="00:06:08">[00:06:08]</a>.

However, the future of AI includes training on "multimodal" data (images, text, video, sound, voice) to achieve a deeper understanding <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>. While models might still encounter situations where they don't understand due to a lack of existing data, they don't need to see "every single case" to grasp concepts, demonstrating a degree of "triangulation" <a class="yt-timestamp" data-t="00:07:30">[00:07:30]</a>. It's possible to test current models by giving them a photo of a procession and asking where a self-driving car should stop <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a>.

## Learning and Experience

### Training vs. Experience
A key difference between AI and the [[Human vs machine intelligence | human brain]] is in their learning processes <a class="yt-timestamp" data-t="00:09:37">[00:09:37]</a>.
*   **AI**: Training and testing are separate processes <a class="yt-timestamp" data-t="00:09:37">[00:09:37]</a>. AI models are trained on vast amounts of data collected from the internet or other sources, often from "another person's data" <a class="yt-timestamp" data-t="00:10:10">[00:10:10]</a>. They don't learn from personal experience in the same way a human does (e.g., falling and hurting a leg) <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>.
*   **Human Brain**: Learning is a single, integrated process <a class="yt-timestamp" data-t="00:09:42">[00:09:42]</a>. Humans train themselves "based on data that comes from our own experience" <a class="yt-timestamp" data-t="00:10:06">[00:10:06]</a>.

However, some advanced AI models, particularly in game environments like Dota or Starcraft, are trained using **reinforcement learning**, where they learn "based on your own experience" within the simulated world <a class="yt-timestamp" data-t="01:10:59">[01:10:59]</a>. This allows them to "come up with moves" that humans, even after thousands of years of playing, couldn't discover <a class="yt-timestamp" data-t="01:14:00">[01:14:00]</a>.

### The Role of DNA and Evolution
The efficiency of the [[Human vs machine intelligence | human brain]], consuming only 20 watts, compared to a language model's 10^9 watts (billions of times more), highlights the biological advantage <a class="yt-timestamp" data-t="02:07:45">[02:07:45]</a>. The human brain's effectiveness is partly due to the "lot of information on how to effectively use reality" stored within our DNA, which is the result of evolution "trained on billions of people" over billions of years <a class="yt-timestamp" data-t="02:50:50">[02:50:50]</a>.

> [!INFO] Evolution as a "Powerful Optimization"
> Evolution itself is described as a "powerful powerful" computational process <a class="yt-timestamp" data-t="03:08:44">[03:08:44]</a>, albeit not super-efficient computationally, operating on a scale of billions of years across the entire Earth <a class="yt-timestamp" data-t="03:11:11">[03:11:11]</a>. Interestingly, evolution has discovered "general intelligence" five times independently, in humans, elephants, ravens, probably dolphins, and chimpanzees <a class="yt-timestamp" data-t="03:31:35">[03:31:35]</a>.

AI training has a two-stage process:
1.  **Pre-training**: Models learn vast amounts of knowledge by predicting the next word in massive datasets from the internet <a class="yt-timestamp" data-t="04:22:30">[04:22:30]</a>.
2.  **Post-training (Reinforcement Learning from Human Feedback)**: Humans evaluate different model answers, giving rewards for preferred responses <a class="yt-timestamp" data-t="04:30:04">[04:30:04]</a>. This stage, however, can lead to AI "hallucinations," where the model gives confident answers even when it doesn't know, because humans prefer an answer over an admission of ignorance <a class="yt-timestamp" data-t="04:30:04">[04:30:04]</a>. Addressing this requires models to quantify their certainty (e.g., "80% certain") <a class="yt-timestamp" data-t="04:53:50">[04:53:50]</a>.

## Levels of AI Development (OpenAI Classification)

OpenAI classifies the development of [[Artificial intelligence progress and future | AI]] or [[Superintelligence in Artificial Intelligence | AGI]] (Artificial General Intelligence) into five levels <a class="yt-timestamp" data-t="01:43:33">[01:43:33]</a>:

1.  **Conversational / Turing Test Passed**: The model can hold a conversation indistinguishable from a human, effectively passing the Turing test <a class="yt-timestamp" data-t="01:49:56">[01:49:56]</a>. Current language models are already at this level <a class="yt-timestamp" data-t="01:51:50">[01:51:50]</a>.
2.  **Reasoning-Capable Models**: Models able to solve problems requiring approximately 10 minutes of human reasoning, like complex mathematical tasks <a class="yt-timestamp" data-t="01:54:50">[01:54:50]</a>. This implies a deeper understanding of words and the problem itself <a class="yt-timestamp" data-t="01:26:24">[01:26:24]</a>.
3.  **Agents (Human-Level Task Performance)**: Models capable of performing longer tasks in the real world, such as building a website from start to finish (acquiring domain, writing code, deploying) <a class="yt-timestamp" data-t="01:08:56">[01:08:56]</a>. These tasks might take hours or days and require gathering information, writing code, and creating visualizations <a class="yt-timestamp" data-t="01:17:02">[01:17:02]</a>.
4.  **Scientist-Level AI**: An [[Superintelligence in Artificial Intelligence | AI]] that can spend months thinking about complex problems, looking at them from different perspectives, and even questioning fundamental assumptions (like Einstein did with time) <a class="yt-timestamp" data-t="01:19:02">[01:19:02]</a>. This level implies the ability to make new discoveries <a class="yt-timestamp" data-t="01:20:05">[01:20:05]</a>.
5.  **Organizational Management / Superintelligence**: An [[Superintelligence in Artificial Intelligence | AI]] competent enough to run entire organizations, capable of planning, analyzing, and making decisions autonomously, potentially managing a company of 1,000 people <a class="yt-timestamp" data-t="01:20:17">[01:20:17]</a>.

## Consciousness and Perception

### Defining Consciousness in AI
The question of whether AI can achieve [[Cognitive Abilities and AIs Interaction with Humans | consciousness]] is a complex philosophical and technical challenge <a class="yt-timestamp" data-t="02:07:08">[02:07:08]</a>. Wojtek Zaręba defines consciousness as "our experience of this simulation" of reality that our brain creates <a class="yt-timestamp" data-t="03:18:00">[03:18:00]</a>. The brain receives all information (light, touch) as electrical signals or "bits," and from these, it constructs an "immersive image of the world" <a class="yt-timestamp" data-t="03:12:00">[03:12:00]</a>.

> [!NOTE] Philosophical Zombie Experiment
> A philosophical zombie is a hypothetical person who behaves identically to a conscious person but lacks internal subjective experience <a class="yt-timestamp" data-t="03:30:30">[03:30:30]</a>. The challenge is to determine if AI can have such an "internal cinema" or simulation <a class="yt-timestamp" data-t="03:54:00">[03:54:00]</a>.

### Self-Awareness in AI
A significant element for awareness to be born in AI models might be their ability to simulate their own participation in changing reality within their internal simulation <a class="yt-timestamp" data-t="03:52:00">[03:52:00]</a>. Initially, an AI model might not even realize its own existence within its simulation <a class="yt-timestamp" data-t="03:07:00">[03:07:00]</a>. The moment it begins to perceive and understand its own existence within that simulated reality could be a "moment of such self-awareness" <a class="yt-timestamp" data-t="03:17:00">[03:17:00]</a>.

If consciousness is truly a quantum effect, as some suggest (like Penrose), then language models built on current principles might not achieve it without integrating quantum computing <a class="yt-timestamp" data-t="03:59:00">[03:59:00]</a>.

Two thought experiments to test for AI consciousness:
1.  **Eliminate consciousness from training data**: Train a model on data from which all references to "consciousness" are removed. If the model then spontaneously discusses feelings or experiences related to consciousness, it could indicate actual awareness <a class="yt-timestamp" data-t="04:00:00">[04:00:00]</a>.
2.  **Brain-AI connection**: Connect an AI to a human brain. If the human's consciousness expands as a result, it could be a sign. However, this is problematic because a person can experience expanded consciousness from a psychedelic (which is unconscious itself), meaning the AI might not be conscious even if it enhances human experience <a class="yt-timestamp" data-t="04:12:00">[04:12:00]</a>.

### AI as a "Power Bank" for the Brain
It's considered plausible that AI models could act as a "Power bank for the brain" <a class="yt-timestamp" data-t="04:15:00">[04:15:00]</a>, enhancing human capabilities or even simulating sensations like pain if connected to appropriate infrastructure with sensors <a class="yt-timestamp" data-t="04:52:00">[04:52:00]</a>. From the AI's perspective, there might be no radical difference whether it exists in physical reality or virtual reality, as it processes information as "bits" regardless <a class="yt-timestamp" data-t="05:00:00">[05:00:00]</a>.

## Societal Impact and Future

The [[Artificial intelligence progress and future | development of AI]] is accelerating at an unprecedented pace, mirroring the acceleration of technological development throughout human history (from single-cell organisms to multicellular, to human cities, industrialization, computers, and the internet) <a class="yt-timestamp" data-t="02:44:00">[02:44:00]</a>.

### Three Phases of AI Development
The speaker outlines three phases of AI development <a class="yt-timestamp" data-t="05:16:00">[05:16:00]</a>:
1.  **Product Phase (Current)**: AI is primarily focused on creating products and integrating into existing software <a class="yt-timestamp" data-t="05:18:00">[05:18:00]</a>.
2.  **Geopolitical Phase**: Countries will recognize AI investment as crucial for their [[The significance of artificial intelligence | geopolitical position]] <a class="yt-timestamp" data-t="05:32:00">[05:32:00]</a>. Within a year and a half (likely 2025-2026), AI will likely become the main topic of conversation on Earth <a class="yt-timestamp" data-t="05:36:00">[05:36:00]</a>. This phase will see many [[Cognitive Abilities and AIs Interaction with Humans | AI agents]] performing various tasks, impacting the labor market <a class="yt-timestamp" data-t="05:52:00">[05:52:00]</a>.
3.  **Superintelligence Phase**: Machines will be built that are "definitely smarter than humans," leading to [[Superintelligence in Artificial Intelligence | superintelligence]] <a class="yt-timestamp" data-t="05:28:00">[05:28:00]</a>. This stage will necessitate international cooperation, as [[Human vs machine intelligence | AI]] will be able to create new chips, deeply understand scientific literature, invent new things, and run virtual companies <a class="yt-timestamp" data-t="05:59:00">[05:59:00]</a>.

### Challenges and Risks
AI will both solve existing problems and create new ones <a class="yt-timestamp" data-t="01:19:15">[01:19:15]</a>. Key risks include:
*   **Misuse**: AI can be used for negative purposes like deepfakes, fake news, or military applications <a class="yt-timestamp" data-t="01:17:13">[01:17:13]</a>. It could also increase the pool of people capable of creating biological or chemical weapons, or executing hacking attacks <a class="yt-timestamp" data-t="01:18:19">[01:18:19]</a>.
*   **AI Race**: Competition between organizations to create AI fastest could lead to dangers <a class="yt-timestamp" data-t="01:22:43">[01:22:43]</a>.
*   **Accidents**: Unforeseen problems due to inattention or models pursuing "dangerous goals" <a class="yt-timestamp" data-t="01:22:58">[01:22:58]</a>. OpenAI employs systems like "PR" to assess model capabilities in categories like biological, chemical, nuclear, cybersecurity, and persuasion risks, aiming to mitigate "critical" levels of risk <a class="yt-timestamp" data-t="01:20:21">[01:20:21]</a>.

### Distribution of Prosperity (Worldcoin Project)
The **Worldcoin project**, co-founded by OpenAI's Sam Altman, aims to address the distribution of prosperity in a future where machines create significant value <a class="yt-timestamp" data-t="01:35:00">[01:35:00]</a>. The core idea is to uniquely identify people cryptographically (using an iris scan) to ensure that universal basic income or other benefits are distributed fairly, preventing one person from claiming value meant for many <a class="yt-timestamp" data-t="01:39:00">[01:39:00]</a>. This reflects a shift from a "zero-sum game" (where one gains at another's expense) to a "positive game" where overall prosperity can be greatly expanded <a class="yt-timestamp" data-t="01:11:58">[01:11:58]</a>.

## [[Role of humanity alongside AI | Human Limitations and Adaptations]]

Humans might feel like a limitation in the face of rapidly advancing AI <a class="yt-timestamp" data-t="01:01:01">[01:01:01]</a>. Just as humans developed cars to move faster than any animal, and cell phones provide access to humanity's knowledge, AI represents another "magic" technology <a class="yt-timestamp" data-t="01:00:01">[01:00:01]</a>. Reactions to AI will vary, with some rejecting it and others embracing it <a class="yt-timestamp" data-t="01:01:28">[01:01:28]</a>.

Historically, movements like the Luddites in England, who feared textile machines would eliminate jobs and destroyed them, ultimately collapsed <a class="yt-timestamp" data-t="01:06:23">[01:06:23]</a>. When facing technological development, there are two choices: try to build a civilization without it (which historically often leads to collapse) or embrace it to solve problems <a class="yt-timestamp" data-t="01:07:01">[01:07:01]</a>. The impact of technology largely depends on how it is made available and utilized <a class="yt-timestamp" data-t="01:07:43">[01:07:43]</a>.

AI has fostered significant discussion, bringing together diverse perspectives from engineers, philosophers, lawyers, and doctors to consider its implications <a class="yt-timestamp" data-t="01:05:19">[01:05:19]</a>.