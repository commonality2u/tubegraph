---
title: Artificial Intelligence as an automatic scientist
videoId: ltHYWEGsDxY
---

From: [[mk_thisisit]] <br/> 

An automatic scientist is defined as an entity capable of developing proofs of theorems, such as mathematical ones, or discovering new chemical compounds and fundamental laws based on large amounts of data and experiments <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. The concept explores the potential for [[artificial_intelligence_development_and_control|AI]] to replicate or even surpass human scientific discovery <a class="yt-timestamp" data-t="08:15:00">[08:15:00]</a>.

## Evolution of Artificial Intelligence

The field of [[artificial_intelligence_development_and_control|Artificial Intelligence]] (AI) was born at Carnegie Mellon University (CMU), specifically the Computer Science Department, which is considered one of the best globally <a class="yt-timestamp" data-t="00:50:00">[00:50:00]</a>. The concept of machine learning was invented around 1951, and by the 1960s, it was firmly established <a class="yt-timestamp" data-t="03:31:00">[03:31:00]</a>. Nobel Prize winner Professor Simon, one of the co-creators of mathematical methods of intelligence, contributed significantly to its early development <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>.

Originally, [[artificial_intelligence_evolution_and_misconceptions|AI]] was conceived to automate theorem proving using mathematical logic <a class="yt-timestamp" data-t="03:51:00">[03:51:00]</a>. However, researchers later found purely mathematical methods difficult to apply in practice due to their specific limitations <a class="yt-timestamp" data-t="04:18:00">[04:18:00]</a>. This led to a shift towards statistics, which became a convenient tool for systematically understanding the uncertain world <a class="yt-timestamp" data-t="04:32:00">[04:32:00]</a>. While statistics might seem unnatural to many, it has enabled numerous [[role_of_artificial_intelligence_in_society|applications]] for [[artificial_intelligence_progress_and_future|AI]] that continue to grow <a class="yt-timestamp" data-t="04:47:00">[04:47:00]</a>.

### The "Black Box" Problem and Hallucinations

Despite advancements, a significant challenge in [[artificial_intelligence_progress_and_future|AI]] development, particularly with large language models like ChatGPT, is the "black box" problem <a class="yt-timestamp" data-t="19:17:00">[19:17:00]</a>. These models, while appearing to demonstrate reasoning and the ability to infer unstated information, are fundamentally statistical <a class="yt-timestamp" data-t="05:28:00">[05:28:00]</a>.

Large language models can "hallucinate," meaning they often make mistakes and can be easily fooled, indicating that the technology is not yet fully perfected <a class="yt-timestamp" data-t="06:42:00">[06:42:00]</a>. This characteristic, while concerning for reliable [[artificial_intelligence_development_and_control|AI]], is ironically similar to human imperfection, as people also make mistakes and talk nonsense <a class="yt-timestamp" data-t="07:01:00">[07:01:00]</a>.

The challenge of legal liability also hinders the mass adoption of [[artificial_intelligence_development_and_control|AI]] in critical areas like autonomous cars <a class="yt-timestamp" data-t="17:03:00">[17:03:00]</a>. For example, in medicine, if an [[artificial_intelligence_development_and_control|AI]] recommends a drastic procedure, the question of who is responsible for the outcome – the [[artificial_intelligence_development_and_control|AI]] or the human doctor – remains unclear <a class="yt-timestamp" data-t="18:08:00">[18:08:00]</a>. Statistical models might offer a 95% confidence rate, but the remaining 5% of uncertainty lacks clear answers based solely on statistics <a class="yt-timestamp" data-t="18:40:00">[18:40:00]</a>.

> [!CAUTION]
> The risk of "black box" behavior and hallucinations is unknowingly taken by users of tools like ChatGPT <a class="yt-timestamp" data-t="19:23:00">[19:23:00]</a>.

To address these limitations, there is a proposal to return to the roots of [[artificial_intelligence_development_and_control|AI]] in mathematical logic <a class="yt-timestamp" data-t="20:27:00">[20:27:00]</a>. The aim is to create a "protective layer" around [[artificial_intelligence_development_and_control|AI]] technology by mathematically proving that these complex models work correctly in certain contexts <a class="yt-timestamp" data-t="20:35:00">[20:35:00]</a>. This verifiable approach is considered crucial if [[artificial_intelligence_development_and_control|AI]] is to be genuinely helpful <a class="yt-timestamp" data-t="21:05:00">[21:05:00]</a>.

### AI as a Tool vs. Competitor

While some may fear [[superintelligence_in_artificial_intelligence|AI]] replacing humans, particularly concerning intellectual supremacy, the perspective shared is that [[artificial_intelligence_development_and_control|AI]] should be viewed as a tool, not a competitor <a class="yt-timestamp" data-t="09:32:00">[09:32:00]</a>. Delegating important decisions, such as medical ones, solely to machines would be dangerous <a class="yt-timestamp" data-t="10:11:00">[10:11:00]</a>. Humans, for ethical and operational reasons, should remain central to decision-making processes <a class="yt-timestamp" data-t="10:23:00">[10:23:00]</a>.

Interestingly, recent research indicates that [[artificial_intelligence_and_consciousness|AI]] can provide more empathetic medical advice than human doctors, suggesting that humans can learn from these algorithms <a class="yt-timestamp" data-t="10:40:00">[10:40:00]</a>. The ideal scenario is an "Intelligent Assistant" that monitors human decisions and suggests better alternatives, acting as a valuable aid <a class="yt-timestamp" data-t="11:19:00">[11:19:00]</a>.

Skepticism remains regarding whether current [[artificial_intelligence_and_consciousness|AI]] systems possess genuine intuition or can generate pain <a class="yt-timestamp" data-t="16:02:00">[16:02:00]</a>. The current understanding of [[artificial_intelligence_development_and_control|AI]]'s capabilities does not fully align with the broader societal perceptions <a class="yt-timestamp" data-t="16:19:00">[16:19:00]</a>.

## New Paradigms in AI Development

A new paradigm is emerging: [[artificial_intelligence_development_and_control|Distributed Artificial Intelligence]], also known as federated learning <a class="yt-timestamp" data-t="00:29:00">[00:29:00]</a>. This approach addresses the impracticality of the current paradigm, which requires transmitting and harmonizing large amounts of data from disparate sources <a class="yt-timestamp" data-t="23:22:00">[23:22:00]</a>.

In [[artificial_intelligence_development_and_control|distributed AI]], models are trained locally on data where it resides, and then only small models (or updates) are shared between nodes or a central aggregator <a class="yt-timestamp" data-t="25:31:00">[25:31:00]</a>. This method overcomes challenges such as data privacy (e.g., hospitals unwilling to share patient data with competitors) <a class="yt-timestamp" data-t="23:59:00">[23:59:00]</a> and the time-consuming process of data collection and harmonization <a class="yt-timestamp" data-t="24:55:00">[24:55:00]</a>. It allows for faster responses to changing conditions, as demonstrated by insights from the war in Ukraine <a class="yt-timestamp" data-t="24:43:00">[24:43:00]</a>.

Furthermore, this paradigm allows models to learn from arbitrarily constructed formats and databases, meaning database compatibility is no longer an obstacle <a class="yt-timestamp" data-t="26:38:00">[26:38:00]</a>. This approach, while not entirely new, is gaining prominence as a practical solution to current [[artificial_intelligence_development_and_control|AI]] deployment challenges <a class="yt-timestamp" data-t="25:43:00">[25:43:00]</a>.

### Applications in Medicine and Other Sectors

[[Role of artificial intelligence in society|AI]] is being actively developed for [[role_of_artificial_intelligence_in_society|applications]] in medicine, particularly in intensive care <a class="yt-timestamp" data-t="27:39:00">[27:39:00]</a>. With increasing sensor technology generating vast amounts of patient physiological data, [[role_of_artificial_intelligence_in_society|AI]] can process this data and extract operationally valuable information, thereby assisting doctors and nurses in decision-making <a class="yt-timestamp" data-t="27:50:00">[27:50:00]</a>.

The development of [[artificial_intelligence_development_and_control|AI]] can also involve systems training themselves using synthetic data generated by algorithms, a concept rooted in methods like the Monte Carlo method <a class="yt-timestamp" data-t="12:55:00">[12:55:00]</a>. This allows for training without extensive real-world experiments, which can be expensive or dangerous <a class="yt-timestamp" data-t="13:25:00">[13:25:00]</a>.

## Poland's Potential in AI Development

Poland possesses significant human potential in the field of [[artificial_intelligence_and_future_prospects|AI]], with highly educated individuals <a class="yt-timestamp" data-t="29:22:00">[29:22:00]</a>. This is partly evidenced by the Polish roots of some of the founders of machine learning, such as Professor Ryszard Michalski <a class="yt-timestamp" data-t="30:47:00">[30:47:00]</a>. Polish students have also excelled in international computer science olympiads <a class="yt-timestamp" data-t="31:11:00">[31:11:00]</a>.

The field of [[artificial_intelligence_development_and_control|AI]] does not require massive financial investments, primarily relying on intellectual capital and a few computers <a class="yt-timestamp" data-t="32:05:00">[32:05:00]</a>. This presents a unique opportunity for Poland to become a leader, rather than just a follower, in [[artificial_intelligence_and_its_future_implications|AI]] development in Europe <a class="yt-timestamp" data-t="32:28:00">[32:28:00]</a>. Overcoming a "defeatist attitude" and actively participating in this "exceptional circumstance" is crucial <a class="yt-timestamp" data-t="32:52:00">[32:52:00]</a>.