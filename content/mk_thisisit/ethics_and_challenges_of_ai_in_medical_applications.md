---
title: Ethics and challenges of AI in medical applications
videoId: ltHYWEGsDxY
---

From: [[mk_thisisit]] <br/> 

The development and application of Artificial Intelligence (AI) in medicine present significant opportunities, but also considerable ethical and practical challenges. Experts emphasize the importance of understanding the limitations and implications of AI, especially in critical fields like healthcare.

## AI as a Tool in Medicine

AI is viewed as a powerful tool that can assist humans, rather than replace them <a class="yt-timestamp" data-t="00:09:47">[00:09:47]</a>. There are "great applications" for AI to monitor human decisions and suggest better alternatives, serving as an "Intelligent Assistant" <a class="yt-timestamp" data-t="00:11:11">[00:11:11]</a>. In medical journals, there are many publications on AI, even from institutions without a medical school <a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a>.

## Ethical and Practical Considerations

### Verification and Accountability
A significant challenge in AI, particularly in sensitive areas like medicine, is the inability to fully explain *how* it works or *why* it makes certain decisions <a class="yt-timestamp" data-t="00:17:11">[00:17:11]</a>. Unlike aviation, where planes undergo rigorous certification tests and meet safety standards, AI lacks this verifiable framework <a class="yt-timestamp" data-t="00:16:38">[00:16:38]</a>. The question of legal liability is also unclear, similar to issues with autonomous cars that hinder their mass adoption <a class="yt-timestamp" data-t="00:17:03">[00:17:03]</a>.

When an AI system suggests a critical medical action, such as an amputation, a user would naturally ask why they should trust this "black box" <a class="yt-timestamp" data-t="00:18:10">[00:18:10]</a>. While AI can state its confidence (e.g., 95% convinced), this statistical assurance doesn't answer concerns about the remaining percentage or accountability if something goes wrong <a class="yt-timestamp" data-t="00:18:40">[00:18:40]</a>, <a class="yt-timestamp" data-t="00:19:08">[00:19:08]</a>.

It is considered "dangerous to delegate important decisions to machines," specifically medical decisions in patient care <a class="yt-timestamp" data-t="00:10:11">[00:10:11]</a>. From the point of view of [[ethical_implications_of_ai | ethics]] and operational properties, humans should remain central to decision-making <a class="yt-timestamp" data-t="00:10:22">[00:10:22]</a>.

### Hallucinations and Reasoning
Large language models, such as those related to ChatGPT, are known to "often make mistakes" or "hallucinate" <a class="yt-timestamp" data-t="00:06:42">[00:06:42]</a>. While some argue this imperfection makes AI more human-like <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>, it highlights the inherent risk <a class="yt-timestamp" data-t="00:19:23">[00:19:23]</a>. Currently, researchers are exploring the use of mathematical logic to create a "protective layer" around AI technology, verifying the truthfulness of its decisions and mitigating "hallucinations" <a class="yt-timestamp" data-t="00:20:27">[00:20:27]</a>, <a class="yt-timestamp" data-t="00:22:35">[00:22:35]</a>. This approach would allow for mathematical proofs of correctness in certain contexts <a class="yt-timestamp" data-t="00:20:35">[00:20:35]</a>.

### The "Black Box" Problem
The increasing complexity of AI models means the "black box" area, where decisions are opaque, will only grow <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>. This poses a risk that users are unknowingly taking when using tools like ChatGPT <a class="yt-timestamp" data-t="00:19:26">[00:19:26]</a>.

## Current Projects and Solutions

### Distributed Artificial Intelligence
A new paradigm for AI development is emerging: distributed artificial intelligence, also known as federated learning <a class="yt-timestamp" data-t="00:25:17">[00:25:17]</a>, <a class="yt-timestamp" data-t="00:25:43">[00:25:43]</a>. This approach addresses the impracticality of the current paradigm, where large amounts of data must be collected from various sources, harmonized, and then used to train a single large model <a class="yt-timestamp" data-t="00:23:22">[00:23:22]</a>.

In distributed AI, instead of transmitting large datasets, smaller models are trained locally on the data where it resides <a class="yt-timestamp" data-t="00:26:21">[00:26:21]</a>. These trained models are then shared between nodes or with a central aggregator, which makes it practically sensible <a class="yt-timestamp" data-t="00:26:25">[00:26:25]</a>, <a class="yt-timestamp" data-t="00:26:55">[00:26:55]</a>. This resolves issues such as:
*   **Data sharing reluctance**: Organizations like hospitals are often unwilling to share patient data with competitors due to legal and patient safety concerns <a class="yt-timestamp" data-t="00:23:59">[00:23:59]</a>.
*   **Data volume and harmonization**: Moving and reconciling very large datasets from disparate sources is time-consuming and effort-intensive, leading to outdated models <a class="yt-timestamp" data-t="00:24:15">[00:24:15]</a>.
*   **Compatibility**: Local models can learn on arbitrarily constructed formats and databases, without requiring databases to be compatible with each other <a class="yt-timestamp" data-t="00:26:38">[00:26:38]</a>.

This paradigm allows for faster responses to changing situations, as demonstrated by insights from the war in Ukraine <a class="yt-timestamp" data-t="00:24:43">[00:24:43]</a>. While the military application was mentioned, this technology has broad applications, including defense <a class="yt-timestamp" data-t="00:27:12">[00:27:12]</a>.

### Intensive Care Applications
AI can significantly improve intensive care by processing the ever-increasing volume of data generated by patient physiological sensors <a class="yt-timestamp" data-t="00:27:50">[00:27:50]</a>, <a class="yt-timestamp" data-t="00:28:02">[00:28:02]</a>. AI can extract "operationally valuable" information from this data, helping doctors and nurses cope with the "human hardness" of their work <a class="yt-timestamp" data-t="00:28:33">[00:28:33]</a>, <a class="yt-timestamp" data-t="00:28:42">[00:28:42]</a>.

## Future of AI in Medicine
While there are moments where it seems AI development is complete <a class="yt-timestamp" data-t="00:07:22">[00:07:22]</a>, the journey is ongoing. The goal is to ensure AI acts as a beneficial tool, not a competitor <a class="yt-timestamp" data-t="00:10:00">[00:10:00]</a>. Recent research at the University of San Diego indicated that AI-generated medical advice was perceived as more empathetic than human doctors', suggesting humans can learn from these algorithms <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>, <a class="yt-timestamp" data-t="00:11:06">[00:11:06]</a>. However, the overarching [[risks_and_ethics_of_ai_development | risk and ethics of AI development]] must be carefully managed.