---
title: Impact of social media on violence and racism
videoId: od867_xRuQs
---

From: [[mk_thisisit]] <br/> 

Journalist Max Fisher, nominated for the Cersa Pool Award for his 2019 investigative report on how [[role_of_social_media_algorithms_in_political_polarization | social media algorithms]] affect global chaos, discusses the profound and often fatal [[Impact of Technology on Human Society | impact of social media]] in his book, "In the Modes of Chaos" <a class="yt-timestamp" data-t="01:13:26">[01:13:26]</a>. He challenges the initial skepticism regarding social media's capacity for harm, asserting that after years of study, he has come to believe that social media can lead to the death of people <a class="yt-timestamp" data-t="02:07:06">[02:07:06]</a>.

## Social Media as a Catalyst for Violence and Hatred

Fisher initially viewed [[technological advancements and societal impact | technology]] as less serious than international conflicts <a class="yt-timestamp" data-t="06:58:24">[06:58:24]</a>. However, while covering events like the genocide in Myanmar and community conflicts in various countries, he consistently observed social media fueling racial hatred and driving [[effects_of_social_media_on_democracy | political polarization]] <a class="yt-timestamp" data-t="07:06:21">[07:06:21]</a>.

He likens social media's impact to that of drugs, stating that while it doesn't kill people directly like cigarettes causing cancer, it leads to death indirectly through the events it causes <a class="yt-timestamp" data-t="01:54:19">[01:54:19]</a>.

> "I started to believe even though I was initially very skeptical about the idea that social media can lead to the death of people through what it causes" <a class="yt-timestamp" data-t="02:01:23">[02:01:23]</a>

Fisher points to specific instances where a significant number of people died as a result of racist or other violence triggered on social media, which he believes would not have occurred without these platforms <a class="yt-timestamp" data-t="02:49:15">[02:49:15]</a>.

### Examples of Social Media's Harmful Impact

*   **Myanmar Genocide:** Facebook researchers reportedly warned about the platform's role in the genocide in Myanmar <a class="yt-timestamp" data-t="03:58:19">[03:58:19]</a>. They received repeated warnings from people on the ground that Facebook was promoting specific conspiracy theories, hate speech, and religious/racial incitement that would not exist without the platform's interference <a class="yt-timestamp" data-t="04:17:15">[04:17:15]</a>.
*   **Sri Lanka Violence:** Violence in Sri Lanka is cited as another case where social media contributed to significant harm <a class="yt-timestamp" data-t="02:44:11">[02:44:11]</a>.
*   **Communal Violence in India:** Similar to Myanmar and Sri Lanka, communal violence in India was fueled by social media <a class="yt-timestamp" data-t="02:45:51">[02:45:51]</a>.

## The Role of Algorithms and Human Psychology

Max Fisher explains that social media platforms are designed with algorithms that select what users see, how they see it, and in what order <a class="yt-timestamp" data-t="05:08:18">[05:08:18]</a>. These systems are specifically designed to maximize user time on the platforms to generate more revenue <a class="yt-timestamp" data-t="05:16:34">[05:16:34]</a>.

> "Because of how our minds work how human nature works in certain contexts the things that are most stimulating to us and cause us to spend the most time on the platform is fear of others a sense of us versus them conspiracy theories hate conspiracy fear sleep a sense of social outrage collective outrage" <a class="yt-timestamp" data-t="05:28:01">[05:28:01]</a>

This design intentionally promotes content that evokes fear, "us vs. them" narratives, conspiracy theories, and social outrage, as these emotions are highly engaging and keep users active <a class="yt-timestamp" data-t="05:39:15">[05:39:15]</a>.

### The News Feed Case Study

The introduction of Facebook's News Feed in 2006 serves as an early example of how these mechanisms work <a class="yt-timestamp" data-t="10:59:17">[10:59:17]</a>. Initially, some users disliked the News Feed due to privacy concerns, leading to the formation of "anti-News Feed" and "anti-Mark Zuckerberg" groups <a class="yt-timestamp" data-t="12:40:24">[12:40:24]</a>. When someone joined these groups, it appeared in their friends' News Feeds <a class="yt-timestamp" data-t="12:53:14">[12:53:14]</a>. Because social outrage is a powerful emotion that grabs attention, many people clicked "like" or joined these groups, creating an "illusion of the majority" that everyone shared the same opinion <a class="yt-timestamp" data-t="13:00:23">[13:00:23]</a>. This phenomenon led to real-world protests in front of Facebook offices <a class="yt-timestamp" data-t="14:19:35">[14:19:35]</a>.

Mark Zuckerberg recognized that this outrage drove traffic to the site, leading to News Feed's permanence and a significant increase in Facebook's engagement <a class="yt-timestamp" data-t="14:34:03">[14:34:03]</a>. This early experience demonstrated how social media could generate massive disinformation and false perceptions of widespread anger by exploiting human psychology <a class="yt-timestamp" data-t="15:14:50">[15:14:50]</a>.

## Corporate Responsibility and Lack of Action

Max Fisher argues that while the creators of these platforms, like Mark Zuckerberg, may not intend to cause harm, their companies bear [[responsibility of social media companies | responsibility for the deaths]] that occur due to their platforms <a class="yt-timestamp" data-t="03:11:06">[03:11:06]</a>. He believes Zuckerberg genuinely thought he was creating something helpful <a class="yt-timestamp" data-t="03:36:34">[03:36:34]</a>. However, the people managing these companies had repeated evidence from their own researchers that the platforms trigger behaviors leading to violence and death <a class="yt-timestamp" data-t="03:42:07">[03:42:07]</a>.

> "The fact that Mark Zuckerberg knew about it had evidence that people warned him about it even in specific cases saying that it would kill thousands of people and he did nothing that doesn't make him a murderer but in my opinion makes the companies responsible for the deaths of the people that they didn't save" <a class="yt-timestamp" data-t="06:01:21">[06:01:21]</a>

## Social Media's Impact on Elections and Politics

Social media has had a significant impact on presidential elections, making it impossible to accurately quantify the number of votes influenced by these platforms <a class="yt-timestamp" data-t="17:19:15">[17:19:15]</a>. The effects are dispersed, subtly shifting individual users' tendencies towards polarization, conspiracy theories, or other views <a class="yt-timestamp" data-t="17:33:04">[17:33:04]</a>.

The Cambridge Analytica scandal and the 2016 US presidential election highlighted the role of algorithms <a class="yt-timestamp" data-t="16:52:16">[16:52:16]</a>. Studies after the 2016 election showed that platforms like Facebook and Twitter artificially amplified far-right news sources such as Breitbart News, which focused on conspiracy theories and supported Donald Trump <a class="yt-timestamp" data-t="18:04:10">[18:04:10]</a>. When algorithms were changed, Breitbart News' audience on these platforms significantly decreased, demonstrating that its reach was artificially amplified by algorithms designed to maximize engagement <a class="yt-timestamp" data-t="18:24:26">[18:24:26]</a>.

## Addiction and the Power of AI

Social media applications are intentionally designed to be difficult to put down <a class="yt-timestamp" data-t="09:33:07">[09:33:07]</a>. Companies like Facebook and Google (which owns YouTube) have hired top minds in [[artificial_intelligence_and_societal_impact | artificial intelligence]] and computer programming to make users addicted to their platforms, a goal in which they are highly effective <a class="yt-timestamp" data-t="09:35:05">[09:35:05]</a>.

## Regulation and the Future

In Europe, there is an effort to introduce regulations like GDPR and new regulations regarding [[artificial_intelligence_and_societal_impact | artificial intelligence]] <a class="yt-timestamp" data-t="21:01:13">[21:01:13]</a>. However, in the United States, there is no federal regulation on social media <a class="yt-timestamp" data-t="21:14:48">[21:14:48]</a>.

Fisher notes a growing consensus that current regulations, often focusing on content moderation, are insufficient <a class="yt-timestamp" data-t="21:38:09">[21:38:09]</a>. The problem lies in the inherent design of platforms that artificially promote divisive and hateful content <a class="yt-timestamp" data-t="21:58:10">[21:58:10]</a>. The only effective way to regulate, he believes, is to address the design of the systems themselves, particularly the algorithms and content promotion mechanisms <a class="yt-timestamp" data-t="22:08:48">[22:08:48]</a>.

While social media has exacerbated [[effects_of_social_media_on_democracy | democratic crises]] and [[role_of_social_media_algorithms_in_political_polarization | political polarization]], Fisher emphasizes that these trends started before social media became prevalent <a class="yt-timestamp" data-t="29:59:04">[29:59:04]</a>. However, social media undeniably accelerates and worsens these issues by shaping public perception and identity <a class="yt-timestamp" data-t="30:08:24">[30:08:24]</a>.