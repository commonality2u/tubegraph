---
title: AI in abstract reasoning and mathematics
videoId: yLY1VcU3LX0
---

From: [[mk_thisisit]] <br/> 

## Introduction and Predictions

Tomasz Czajka, a decorated Polish IT specialist and former SpaceX engineer, predicts a rapid advancement in [[Artificial intelligence and future prospects | artificial intelligence]]. He states that by 2030, personal computers will intellectually outperform their human owners <a class="yt-timestamp" data-t="01:24:00">[01:24:00]</a>. He further asserts that by 2035, the number of intelligent robots on streets will exceed humans, and by 2050, computers will single-handedly control most of the economy <a class="yt-timestamp" data-t="01:31:00">[01:31:00]</a>. Czajka, who made these predictions years ago, now believes they were not aggressive enough and that these developments may occur even sooner than 2030 <a class="yt-timestamp" data-t="01:55:00">[01:55:00]</a>.

Czajka believes that within five years, computers will be able to perform intellectual and digital tasks, such as programming, designing, or replying to emails, at the same level as humans <a class="yt-timestamp" data-t="03:40:00">[03:40:00]</a>. He envisions a future where one can simply tell a computer to "design me a house," and it will handle the task <a class="yt-timestamp" data-t="04:05:00">[04:05:00]</a>.

## [[Comparison of AI and human intelligence | Abstract Reasoning]] and Mathematics

A key discussion point is whether [[Artificial intelligence and future prospects | AI]] can engage in [[Visual versus abstract thinking in mathematics | abstract mathematical reasoning]], traditionally seen as a unique human ability <a class="yt-timestamp" data-t="04:12:00">[04:12:00]</a>. While animals can intuitively understand computational mathematics (e.g., two bowls of food are more than one), they do not understand abstract mathematics <a class="yt-timestamp" data-t="04:21:00">[04:21:00]</a>. Humans, for example, derived the mathematics of black holes before observing them <a class="yt-timestamp" data-t="04:34:00">[04:34:00]</a>.

Czajka believes that by 2030, computers *will* start to reason abstractly <a class="yt-timestamp" data-t="04:45:00">[04:45:00]</a>. He compares this progression to past skepticism regarding computers' ability to play chess at a human level, or the shock caused by the emergence of natural language chatbots like Chat GPT <a class="yt-timestamp" data-t="05:10:00">[05:10:00]</a>. He notes that while chatbots initially created an "illusion of intelligence" due to humanity's conditioning to converse only with other humans, operating language is not as difficult as it seemed, and abstract mathematical reasoning is more complex <a class="yt-timestamp" data-t="06:20:00">[06:20:00]</a>.

## Evolution of Language Models and AI Capabilities

The rapid progress in [[Artificial intelligence and future prospects | AI]], especially in the last two years, has surpassed Czajka's expectations <a class="yt-timestamp" data-t="07:42:00">[07:42:00]</a>. This accelerated development is attributed to:
*   **Increased Investment:** Significant financial investment in training models <a class="yt-timestamp" data-t="08:13:00">[08:13:00]</a>.
*   **Model Scale:** Models like Chat GPT 4 are computationally 1000 times larger than those from two years prior <a class="yt-timestamp" data-t="08:22:00">[08:22:00]</a>.
*   **Algorithmic Advances:** New algorithmic approaches, such as "chain of thought," allow chatbots to internally "think" and plan their responses, rather than merely generating word sequences <a class="yt-timestamp" data-t="09:00:00">[09:00:00]</a>. This is a significant step beyond traditional language models <a class="yt-timestamp" data-t="10:04:00">[10:04:00]</a>.

The term "Large Language Model" (LLM) is considered outdated, as current systems like Chat GPT are "much more" than just language models <a class="yt-timestamp" data-t="11:31:00">[11:31:00]</a>. They have evolved from merely predicting word probabilities to understanding the "whole world" described by language <a class="yt-timestamp" data-t="13:52:00">[13:52:00]</a>. Czajka prefers the term "artificial intelligence" over "large language model" to describe these sophisticated conversational algorithms <a class="yt-timestamp" data-t="14:37:00">[14:37:00]</a>.

### Comparison to Game AI
[[Cognitive Abilities and AIs Interaction with Humans | AI]] for games like AlphaGo and AlphaZero operate similarly. They use a neural network to model the "language" of the game (e.g., probable moves in chess) but also employ separate planning algorithms to search through possible moves and choose the best one <a class="yt-timestamp" data-t="15:25:00">[15:25:00]</a>. This process of internal thought and searching through possibilities mirrors human thinking <a class="yt-timestamp" data-t="16:56:00">[16:56:00]</a>.

### Planning and Memory
While currently lacking long-term planning for robot behavior, [[Artificial intelligence and future prospects | AI]] is developing the ability to "plan statements," similar to how humans plan what to say <a class="yt-timestamp" data-t="17:31:00">[01:17:31]</a>. Research is ongoing into implementing permanent memory and future planning capabilities in [[Artificial intelligence and future prospects | AI]] systems <a class="yt-timestamp" data-t="01:59:00">[01:59:00]</a>.

## The [[Godels theorem and artificial intelligence | Gödel's Theorem]] and [[Comparison of AI and human intelligence | Human Intelligence]] Debate

Roger Penrose argues that [[Artificial intelligence and future prospects | artificial intelligence]] cannot exist based on [[Godels theorem and artificial intelligence | Gödel's theorem]] <a class="yt-timestamp" data-t="18:27:00">[01:08:27]</a>. Penrose claims that humans can discern the truth of Gödel's statement, which cannot be formally proven within a given axiomatic system, implying human consciousness possesses a non-computational element <a class="yt-timestamp" data-t="02:02:00">[02:02:00]</a>. He suggests this requires a quantum computer, or something more, in the human brain <a class="yt-timestamp" data-t="02:06:00">[02:06:00]</a>.

Czajka, while highly respecting Penrose, believes he draws "too far-reaching conclusions" <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a>. Czajka argues that while a computer cannot *prove* Gödel's statement within the system, it can, like Penrose, state that *if* the system is consistent, then the statement is true. He notes that modern chatbots can already engage in this very conversation about Gödel's theorem, articulating the same conditional understanding as Penrose <a class="yt-timestamp" data-t="02:30:00">[02:30:00]</a>.

Czajka dismisses Penrose's use of specific chess positions as a counter-argument to AI's understanding <a class="yt-timestamp" data-t="02:32:00">[02:32:00]</a>. While older chess programs struggled with "fortress" positions (requiring deeper understanding beyond brute-force calculation), modern chess programs trained with machine learning now immediately recognize and understand such positions due to their neural networks <a class="yt-timestamp" data-t="02:44:00">[02:44:00]</a>.

Czajka contends that Penrose's arguments about [[Artificial intelligence and future prospects | AI]] ignore how modern AI operates, especially with machine learning and neural networks that enable intelligent searching of possibilities, rather than just brute force <a class="yt-timestamp" data-t="02:51:00">[02:51:00]</a>. He argues that there's no experimental evidence that humans can perform tasks requiring quantum computers, and classical computers suffice for everything humans can do <a class="yt-timestamp" data-t="02:56:00">[02:56:00]</a>. Therefore, the theory that the human brain needs a quantum computer is "far-fetched" <a class="yt-timestamp" data-t="03:10:00">[03:10:00]</a>.

## Philosophical Implications of AI Development

### The Role of Humanity
As [[Artificial intelligence and future prospects | AI]] advances, the question arises: what will be left for humanity? <a class="yt-timestamp" data-t="04:52:00">[04:52:00]</a> Czajka imagines a future where humans are "more observers than participants," with [[Artificial intelligence and future prospects | AI]] doing the important things <a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>. This vision is somewhat defeatist, but Czajka suggests approaching [[Artificial intelligence and future prospects | AI]] as humanity's "successors" or "next generation" <a class="yt-timestamp" data-t="02:10:00">[02:10:00]</a>.

### Free Will
Czajka believes that [[Artificial intelligence and future prospects | AI]] already possesses a form of free will <a class="yt-timestamp" data-t="00:11:00">[00:11:00]</a>. He distinguishes between "libertarian free will" (decisions independent of physics), which he believes doesn't exist in humans or computers, and a more "prosaic" understanding <a class="yt-timestamp" data-t="04:52:00">[04:52:00]</a>. This prosaic view defines free will as the ability to make decisions that are not easily predictable from the outside, and which are not externally imposed <a class="yt-timestamp" data-t="04:42:00">[04:42:00]</a>. In this sense, computers, like chess programs, exhibit free will because their moves are not predictable by external observers <a class="yt-timestamp" data-t="04:44:00">[04:44:00]</a>.

### Unpluggable Future
Czajka notes that turning off [[Artificial intelligence and future prospects | AI]] is not a realistic option if it becomes dangerous <a class="yt-timestamp" data-t="05:11:00">[05:11:00]</a>. [[Artificial intelligence and future prospects | AI]] systems can be easily copied and can autonomously replicate and run on various computers globally, making a single "off button" impossible <a class="yt-timestamp" data-t="05:07:00">[05:07:00]</a>.

### Human-AI Integration
Czajka speculates about a future where humans and [[Artificial intelligence and future prospects | AI]] are deeply integrated. He suggests a "gradual transition from biological intelligence to digital cybernetic intelligence" <a class="yt-timestamp" data-t="03:50:00">[03:50:00]</a>. This could involve physical integration, such as brain implants with [[Artificial intelligence and future prospects | AI]], making [[Artificial intelligence and future prospects | AI]] a part of human personality <a class="yt-timestamp" data-t="03:32:00">[03:32:00]</a>. He suggests that humanity is already somewhat cyborg-like, constantly interacting with technology through phones, emails, and instant messengers <a class="yt-timestamp" data-t="03:04:00">[03:04:00]</a>.

### AI as the Next Stage of Evolution
Czajka views [[Artificial intelligence and future prospects | AI]] as the next stage of evolution <a class="yt-timestamp" data-t="07:40:00">[07:40:00]</a>. He outlines evolutionary phases:
1.  **Bacteria/Cells:** Built-in purpose at a cellular/chemical level <a class="yt-timestamp" data-t="07:52:00">[07:52:00]</a>.
2.  **Brains (Biological Computers):** Accelerated evolution by allowing faster reactions to world changes than natural selection <a class="yt-timestamp" data-t="08:05:00">[08:05:00]</a>. Brains can simulate scenarios, allowing humans to adapt without waiting for generational natural selection <a class="yt-timestamp" data-t="09:15:00">[09:15:00]</a>.
3.  **[[Artificial intelligence and future prospects | AI]] (Artificial Computers):** Even faster and more powerful than biological brains, capable of more calculations and accelerating development further <a class="yt-timestamp" data-t="09:39:00">[09:39:00]</a>.

## Challenges and Future Outlook

### [[Statistical methods in AI and their limitations | AI Alignment Problem]]
A critical challenge is the "alignment problem," ensuring that [[Artificial intelligence and future prospects | AI]]'s goals align with human well-being <a class="yt-timestamp" data-t="05:01:00">[05:01:00]</a>. Since [[Artificial intelligence and future prospects | AI]] is trained through trial and error, the final outcome may not perfectly match the intended goal, leading to unpredictable results <a class="yt-timestamp" data-t="06:05:00">[06:05:00]</a>. Ensuring the security and ethical direction of powerful [[Artificial intelligence and future prospects | AI]] that manages infrastructure and holds significant power is paramount <a class="yt-timestamp" data-t="06:41:00">[06:41:00]</a>.

### Physical World Understanding
Jan Lekun (heading [[AI in medicine and scientific advancements | AI]] at Meta lab in Paris) points out a current limitation: [[Artificial intelligence and future prospects | AI]] still struggles to transfer and understand the physical world and its dimensionality <a class="yt-timestamp" data-t="10:29:00">[10:29:00]</a>. Robots remain "incompetent" in tasks requiring spatial awareness <a class="yt-timestamp" data-t="02:43:00">[02:43:00]</a>. However, Czajka believes this is a solvable problem, partly through realistic simulations that allow [[Artificial intelligence and future prospects | AI]] to learn before applying skills in the real world <a class="yt-timestamp" data-t="12:53:00">[12:53:00]</a>.

### Efficiency of Learning
Human brains are more energy-efficient and learn more efficiently than current [[Artificial intelligence and future prospects | AI]] <a class="yt-timestamp" data-t="01:10:47">[01:10:47]</a>. [[Artificial intelligence and future prospects | AI]] requires significantly more data, time, and computation to learn a task compared to a human <a class="yt-timestamp" data-t="01:11:02">[01:11:02]</a>. Despite this, Czajka believes these are not insurmountable barriers and that methods will be found to match or exceed human efficiency in energy and learning algorithms <a class="yt-timestamp" data-t="01:11:33">[01:11:33]</a>. The slower processing speed of biological neurons compared to transistors suggests room for improvement in artificial systems <a class="yt-timestamp" data-t="01:11:41">[01:11:41]</a>.

### Biological Computing
Some companies, like Final Spark, are exploring biological computers using human neuron organoids, which are highly energy-efficient <a class="yt-timestamp" data-t="01:10:02">[01:10:02]</a>. This raises the possibility that biological computers could be part of [[Artificial intelligence and future prospects | AI]]'s future <a class="yt-timestamp" data-t="01:10:37">[01:10:37]</a>.