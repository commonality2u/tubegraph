---
title: Development and impact of deep learning
videoId: w-TtKPRuXL8
---

From: [[mk_thisisit]] <br/> 

[[the_evolution_of_neural_networks_and_machine_learning | Deep learning]], a subfield of [[the_evolution_of_neural_networks_and_machine_learning | machine learning]], has seen significant advancements and experienced periods of both enthusiastic growth and dormancy. It is fundamentally about teaching systems to capture the structure of input data and learn abstract representations, which has proven crucial for progress in [[development_and_challenges_of_artificial_intelligence | AI]] <a class="yt-timestamp" data-t="00:24:45">[00:24:45]</a>.

## Historical Waves of Development

The progress of [[the_evolution_of_neural_networks_and_machine_learning | deep learning]] has been discontinuous, with two significant waves of interest and a period of decline <a class="yt-timestamp" data-t="00:34:55">[00:34:55]</a>.

### First Wave (Late 1980s - Mid 1990s)

The first wave of excitement occurred in the late 1980s when researchers began achieving good results using multi-layer [[the_evolution_of_neural_networks_and_machine_learning | neural networks]] for tasks like image recognition, particularly for simple images such as handwritten characters <a class="yt-timestamp" data-t="00:03:19">[00:03:19]</a>. This period saw a wave of enthusiasm, as it suggested a complete change in the approach to pattern recognition and potential leads to computer vision and general [[development_and_challenges_of_artificial_intelligence | intelligence]] <a class="yt-timestamp" data-t="00:03:42">[00:03:42]</a>.

However, this initial interest died down around the mid-1990s because the techniques required large amounts of data and expensive computers, which were not widely available before the internet's prevalence. Applications were limited to specific areas like handwriting or speech recognition <a class="yt-timestamp" data-t="00:04:08">[00:04:08]</a>.

### Resurgence and Explosion of Interest (2000s - 2013 onwards)

Interest in [[the_evolution_of_neural_networks_and_machine_learning | deep learning]] gradually grew in the 2000s, leading to a significant "explosion" around 2013 <a class="yt-timestamp" data-t="00:04:42">[00:04:42]</a>. This year was pivotal as the research world realized that [[the_evolution_of_neural_networks_and_machine_learning | deep learning]] "works really well" and could be applied across many different fields <a class="yt-timestamp" data-t="00:04:53">[00:04:53]</a>. Since then, its [[artificial_intelligence_progress_and_future | development]] has accelerated at a dizzying pace, with another turning point occurring in 2015 <a class="yt-timestamp" data-t="00:05:02">[00:05:02]</a>.

A 2015 article on [[the_evolution_of_neural_networks_and_machine_learning | deep learning]], co-authored with Nobel Prize winner Jeff Hinton, was cited in nearly 100,000 scientific publications, becoming one of the most frequently cited <a class="yt-timestamp" data-t="00:01:13">[00:01:13]</a>. This article was more of a "manifesto" or review aimed at popularizing a new set of effective techniques and offering tips for [[future_implications_and_applications_of_AI_technology | future development]] <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>.

## Understanding [[the_evolution_of_neural_networks_and_machine_learning | Machine Learning]] Paradigms

There are three basic paradigms in [[the_evolution_of_neural_networks_and_machine_learning | machine learning]]:

*   **Supervised Learning:** The most classic approach, where a system is trained by being given correct answers (e.g., showing an image and labeling it "table"). The system adjusts its parameters to match expected results <a class="yt-timestamp" data-t="00:08:51">[00:08:51]</a>.
*   **Reinforcement Learning:** The system receives feedback on whether a result was good or bad, rather than explicit correct answers. This mimics human learning (e.g., learning to ride a bike by trial and error). While effective for games like chess or Go, it is "extremely ineffective" in the real world due to the need for millions of trials <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>. For example, training a self-driving car purely with reinforcement learning would involve thousands of crashes <a class="yt-timestamp" data-t="00:10:35">[00:10:35]</a>.
*   **Self-supervised Learning:** This method has driven recent advances in natural language understanding and chatbots. The system learns the structure of input data (e.g., text) by being trained to predict missing words or the next word in a sequence. This is the principle behind large language models (LLMs) <a class="yt-timestamp" data-t="00:10:55">[00:10:55]</a>.

## Limitations of Current [[development_and_challenges_of_artificial_intelligence | AI]] and [[the_evolution_of_neural_networks_and_machine_learning | Deep Learning]]

Despite impressive progress, current [[development_and_challenges_of_artificial_intelligence | AI]] systems, particularly those based on [[the_evolution_of_neural_networks_and_machine_learning | deep learning]], have significant limitations <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>:

*   **Lack of Physical World Understanding:** They do not understand the physical world, unlike humans and animals <a class="yt-timestamp" data-t="00:00:13">[00:00:13]</a>.
*   **No Permanent Memory:** They lack permanent memory <a class="yt-timestamp" data-t="00:00:15">[00:00:15]</a>.
*   **Inability to Reason or Plan:** Current systems cannot truly reason or plan, which are key features of intelligent behavior <a class="yt-timestamp" data-t="00:05:52">[00:05:52]</a>. Their "reasoning" is often a primitive search in token space, generating many sequences and selecting the best, which is expensive and not how humans think <a class="yt-timestamp" data-t="00:26:51">[00:26:51]</a>.
*   **Difficulty with Continuous Data:** While language is discrete (finite number of words), the physical world is continuous and much harder to understand and predict <a class="yt-timestamp" data-t="00:13:53">[00:13:53]</a>. Predicting exact future frames in video recordings is impossible due to too many unpredictable details <a class="yt-timestamp" data-t="00:47:49">[00:47:49]</a>.
*   **Moravec's Paradox:** This paradox highlights that what is easy for humans (e.g., physical tasks like manipulating objects, walking) is hard for computers, while what is hard for humans (e.g., playing chess, solving mathematical puzzles) is easy for computers <a class="yt-timestamp" data-t="00:14:50">[00:14:50]</a>.
*   **Information Volume:** The amount of visual information a child absorbs in their first four years of life is comparable to the training data of the largest language models <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>. This suggests that training systems solely on text will never achieve human-level [[development_and_challenges_of_artificial_intelligence | AI]] <a class="yt-timestamp" data-t="00:18:45">[00:18:45]</a>.

### Current [[development_and_challenges_of_artificial_intelligence | AI]] "Stupidity"

```ad-note
"Currently, [[development_and_challenges_of_artificial_intelligence | AI]] systems are very stupid in many ways, we let ourselves be fooled. Considering them intelligent because they can manipulate language very well, but they cannot, they do not understand the physical world, they do not have permanent memory like we have." <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>
```

## [[future_implications_and_applications_of_AI_technology | Future Directions]] and Innovations

### Designing New [[development_and_challenges_of_artificial_intelligence | AI]] Systems

Current research aims to design a new type of [[development_and_challenges_of_artificial_intelligence | AI]] system, still based on [[the_evolution_of_neural_networks_and_machine_learning | deep learning]], that can:
*   Function in the physical world <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>.
*   Have permanent memory <a class="yt-timestamp" data-t="00:06:16">[00:06:16]</a>.
*   Be able to reason and plan <a class="yt-timestamp" data-t="00:06:18">[00:06:18]</a>.

Such systems might experience emotions like excitement or joy, linked to predicting successful goal achievement, but not anger or jealousy, as these would not be permanently built into them <a class="yt-timestamp" data-t="00:06:25">[00:06:25]</a>.

### Consciousness

The concept of consciousness remains undefined and lacks measurable indicators, making it difficult to ascertain in machines <a class="yt-timestamp" data-t="00:07:27">[00:07:27]</a>. Some experts believe the question itself might be ill-posed <a class="yt-timestamp" data-t="00:23:00">[00:23:00]</a>.

### Joint Embedding Predictive Architecture (JEPA)

JEPA is a macro-architecture where different modules, potentially including Transformers, are arranged. It is an alternative to current large language models that solely rely on autoregressive, decoder-based Transformer architectures <a class="yt-timestamp" data-t="00:45:27">[00:45:27]</a>.

The main idea behind JEPA is to train systems to learn an abstract representation of input data and then make predictions within that representation space, rather than trying to predict every detail in the original input space <a class="yt-timestamp" data-t="00:48:40">[00:48:40]</a>. This approach addresses the problem of unpredictability in high-dimensional continuous data like video, where discrete text-based prediction methods fail <a class="yt-timestamp" data-t="00:47:47">[00:47:47]</a>.

### Convolutional Neural Networks (CNNs)

A significant invention in [[the_evolution_of_neural_networks_and_machine_learning | deep learning]] is the Convolutional Neural Network (CNN), developed in 1988 <a class="yt-timestamp" data-t="00:50:07">[00:50:07]</a>. Inspired by the visual cortex, CNNs are designed to process natural signals like images, video, sound, and speech <a class="yt-timestamp" data-t="00:50:13">[00:50:13]</a>. They are widely used today in applications such as:
*   Driver assistance systems (automatic braking) <a class="yt-timestamp" data-t="00:50:30">[00:50:30]</a>
*   Speech recognition <a class="yt-timestamp" data-t="00:51:20">[00:51:20]</a>
*   Image recognition (e.g., identifying plant species from a photo) <a class="yt-timestamp" data-t="00:51:29">[00:51:29]</a>
*   Handwriting and character recognition (e.g., reading postal codes, checks) <a class="yt-timestamp" data-t="00:50:59">[00:50:59]</a>

## Open Research and Collaboration

Open research and open-source software are crucial for accelerating [[artificial_intelligence_progress_and_future | progress]] in [[development_and_challenges_of_artificial_intelligence | AI]] <a class="yt-timestamp" data-t="00:36:34">[00:36:34]</a>. When research is published and code is open, the entire world benefits, leading to faster development and broader contributions from a global community <a class="yt-timestamp" data-t="00:37:01">[00:37:01]</a>. This collaborative approach fosters innovation and ensures that no single institution holds a monopoly on good ideas <a class="yt-timestamp" data-t="00:38:10">[00:38:10]</a>.

An example is PyTorch, an open-source software used by almost the entire [[development_and_challenges_of_artificial_intelligence | AI]] industry for research and development <a class="yt-timestamp" data-t="00:39:37">[00:39:37]</a>.

## Challenges of [[future_implications_and_applications_of_AI_technology | AI]] Integration and Robotics

The "coming decade will be the decade of robotics" <a class="yt-timestamp" data-t="00:42:42">[00:42:42]</a>, driven by advances in [[development_and_challenges_of_artificial_intelligence | AI]]. While current industrial robots excel at repetitive, simple tasks in controlled environments <a class="yt-timestamp" data-t="00:31:36">[00:31:36]</a>, more adaptive robots require [[development_and_challenges_of_artificial_intelligence | AI]] systems that can understand the physical world, possess permanent memory, and reason and plan <a class="yt-timestamp" data-t="00:33:29">[00:33:29]</a>. Many robotics companies are betting on rapid [[artificial_intelligence_progress_and_future | AI advances]] in the next 3-5 years to make humanoid robots smart enough to handle the complexities of the real world <a class="yt-timestamp" data-t="00:34:10">[00:34:10]</a>.

Predictions about achieving Level 5 autonomous driving (fully autonomous) within a few years have been consistently wrong <a class="yt-timestamp" data-t="00:32:18">[00:32:18]</a>. This illustrates the ongoing challenge of enabling [[development_and_challenges_of_artificial_intelligence | AI]] to learn as effectively as humans and animals in complex, real-world conditions <a class="yt-timestamp" data-t="00:16:54">[00:16:54]</a>.

## [[ethical_and_societal_impact_of_ai_development | Societal Impact]] and [[potential_economic_impact_of_artificial_intelligence | Economic Implications]]

The [[future_implications_and_applications_of_AI_technology | future of AI]] involves billions of people using [[development_and_challenges_of_artificial_intelligence | AI]] assistance daily through smart devices like glasses and smartphones <a class="yt-timestamp" data-t="00:42:51">[00:42:51]</a>. This necessitates a "huge computing infrastructure" because running LLMs and other [[development_and_challenges_of_artificial_intelligence | AI]] systems is not cheap and requires significant computing power <a class="yt-timestamp" data-t="00:43:15">[00:43:15]</a>. Most large investments in [[development_and_challenges_of_artificial_intelligence | AI]] infrastructure are for "inference costs" (running systems for users) rather than training <a class="yt-timestamp" data-t="00:44:06">[00:44:06]</a>.

Europe is seen as having a crucial role in the global [[development_and_challenges_of_artificial_intelligence | AI]] race, particularly in implementing regulations <a class="yt-timestamp" data-t="00:51:55">[00:51:55]</a>. It also possesses significant advantages due to its talent pool of programmers, mathematicians, physicists, computer scientists, and engineers, many of whom are leading scientists in the [[development_and_challenges_of_artificial_intelligence | AI]] field globally <a class="yt-timestamp" data-t="00:53:05">[00:53:05]</a>.

## [[future_implications_and_applications_of_AI_technology | Applications of Deep Learning]] in Healthcare

[[the_evolution_of_neural_networks_and_machine_learning | Deep learning]] methods show extreme promise in medical applications, particularly in diagnosis using imaging <a class="yt-timestamp" data-t="00:57:17">[00:57:17]</a>. For example, they are already implemented in breast cancer diagnosis through mammography <a class="yt-timestamp" data-t="00:57:22">[00:57:22]</a>. The ambition extends beyond diagnosis to integrate measurements directly into treatment protocols <a class="yt-timestamp" data-t="00:58:21">[00:58:21]</a>.