---
title: Regulation and ethical considerations in AI
videoId: LVxZ1hHo34s
---

From: [[mk_thisisit]] <br/> 

The development of artificial intelligence (AI) is progressing rapidly, but concerns regarding its regulation and [[Ethical considerations in AI development | ethical implications]] are becoming increasingly prominent <a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a>. Experts suggest that humanity may not have been fully prepared for the current pace of AI advancement <a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a>, <a class="yt-timestamp" data-t="00:17:14">[00:17:14]</a>.

## Defining Artificial Intelligence

Historically, artificial intelligence was conceived over 50 years ago as a copy of human intelligence <a class="yt-timestamp" data-t="00:02:04">[00:02:04]</a>. However, the term "intelligence" in AI is often misunderstood, especially when referring to human intelligence, which current computers cannot achieve <a class="yt-timestamp" data-t="00:03:02">[00:03:02]</a>. There's an ongoing debate, even in scientific texts, about "conscious artificial intelligence" and "strong artificial intelligence," with some leaders in the field, like the head of OpenAI, explicitly pursuing strong, conscious AI <a class="yt-timestamp" data-t="00:03:39">[00:03:39]</a>. Strong intelligence, in this context, aims to produce arguments and derivations very similar to those of a human <a class="yt-timestamp" data-t="00:04:04">[00:04:04]</a>.

## Challenges with Current AI Systems

Current AI systems, particularly large language models (LLMs), operate on statistics and pattern matching, not true understanding or consciousness <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>, <a class="yt-timestamp" data-t="00:13:07">[00:13:07]</a>. This statistical approach can lead to "hallucinations," where models generate confident but incorrect information <a class="yt-timestamp" data-t="00:12:20">[00:12:20]</a>. While efforts are underway to combine statistics with logic, it remains a challenge to create creative models that don't hallucinate <a class="yt-timestamp" data-t="00:10:41">[00:10:41]</a>, <a class="yt-timestamp" data-t="00:26:33">[00:26:33]</a>.

### Autonomous Systems and Safety
Autonomous taxis, while leveraging advanced AI, highlight significant practical and [[Risks and Ethics of AI Development | ethical risks]] <a class="yt-timestamp" data-t="00:07:50">[00:07:50]</a>. In San Francisco, autonomous taxis have caused protests due to their tendency to stop when uncertain, creating dangerous situations, such as blocking ambulances <a class="yt-timestamp" data-t="00:07:50">[00:07:50]</a>, <a class="yt-timestamp" data-t="00:08:19">[00:08:19]</a>. An extreme incident involved an autonomous car driving into a Chinese New Year celebration, leading to it being burned <a class="yt-timestamp" data-t="00:08:46">[00:08:46]</a>. Unlike human drivers, these cars lack the nuanced understanding of context and non-verbal cues (e.g., gestures, intent) necessary for safe real-world interaction <a class="yt-timestamp" data-t="00:18:46">[00:18:46]</a>, <a class="yt-timestamp" data-t="00:19:07">[00:19:07]</a>. Tesla's "automatic" cars are also not fully autonomous, as the driver remains responsible for incidents <a class="yt-timestamp" data-t="00:06:00">[00:06:00]</a>.

A core challenge is replicating human intuition and learning processes, which are not yet fully understood by scientists <a class="yt-timestamp" data-t="00:13:33">[00:13:33]</a>, <a class="yt-timestamp" data-t="00:21:34">[00:21:34]</a>. Children, for example, learn differently than current language models <a class="yt-timestamp" data-t="00:13:52">[00:13:52]</a>, and humans possess mental models that current AI systems lack <a class="yt-timestamp" data-t="00:24:10">[00:24:10]</a>.

## The Need for Regulation and a Unified Approach

The current public debate on AI suffers from a fundamental misunderstanding due to different fields using different terminologies and perspectives <a class="yt-timestamp" data-t="00:22:24">[00:22:24]</a>. For instance, a psychologist's understanding of "learning" differs significantly from a programmer's "machine learning" <a class="yt-timestamp" data-t="00:22:44">[00:22:44]</a>.

The deployment of generative AI models like ChatGPT was considered early by some, suggesting a lack of readiness <a class="yt-timestamp" data-t="00:16:26">[00:16:26]</a>. This mirrors historical patterns with new technologies, such as early aviation, where regulations and safety systems only emerged after accidents <a class="yt-timestamp" data-t="00:17:19">[00:17:19]</a>.

### Key Regulatory Challenges
1.  **Copyright and Data Use**: A major challenge is the lack of appropriate global and local [[Regulation and Control of AI Technologies | regulation and control of AI technologies]] for copyrighted works used in training, developing, and testing AI systems <a class="yt-timestamp" data-t="00:32:21">[00:32:21]</a>.
2.  **Harmonization of Laws**: Different countries have varied approaches to issues like privacy, complicating global regulation <a class="yt-timestamp" data-t="00:31:59">[00:31:59]</a>. While the EU AI Act aims to establish a strong regional framework, it must still pass through national parliaments to become law <a class="yt-timestamp" data-t="00:32:58">[00:32:58]</a>.
3.  **Black Box Problem**: AI models are trained in ways that can isolate their decision-making processes from human oversight, creating a "black box" where decisions are made without full transparency <a class="yt-timestamp" data-t="00:15:20">[00:15:20]</a>, <a class="yt-timestamp" data-t="00:15:33">[00:15:33]</a>. Ensuring that adequate security measures are in place alongside these models is crucial <a class="yt-timestamp" data-t="00:15:57">[00:15:57]</a>.

### Future Directions in AI Development
Rather than focusing solely on more data, future progress in AI should prioritize intelligent data utilization and the integration of physical models of the world <a class="yt-timestamp" data-t="00:29:50">[00:29:50]</a>, <a class="yt-timestamp" data-t="00:30:33">[00:30:33]</a>. This may involve developing multi-agent AI systems that can predict human behavior, such as a pedestrian's intent to cross the road <a class="yt-timestamp" data-t="00:34:40">[00:34:40]</a>, <a class="yt-timestamp" data-t="00:35:47">[00:35:47]</a>.

The goal is to develop AI that can "think and reason like a human," which requires a fundamentally different approach to teaching these systems <a class="yt-timestamp" data-t="00:30:09">[00:30:09]</a>, <a class="yt-timestamp" data-t="00:31:05">[00:31:05]</a>. This also necessitates greater collaboration between computer scientists, psychologists, and neuroscientists to bridge the current understanding gaps <a class="yt-timestamp" data-t="00:21:52">[00:21:52]</a>.