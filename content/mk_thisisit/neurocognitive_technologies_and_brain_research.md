---
title: Neurocognitive Technologies and Brain Research
videoId: zeGCPA4p6z0
---

From: [[mk_thisisit]] <br/> 

Professor Wodzis≈Çaw Duch, a leading Polish scientist in the field of [[artificial_intelligence_and_its_future_implications | artificial intelligence]] and brain research, defines neurocognitive technologies and discusses their implications <a class="yt-timestamp" data-t="00:00:43">[00:00:43]</a>.

## Defining Neurocognitive Technologies
Neurocognitive technologies involve understanding how our minds and brains work to create technologies that cooperate with humans more effectively <a class="yt-timestamp" data-t="00:01:10">[00:01:10]</a> <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>. The term "neuro" relates to neurons in the head <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>, while "cognitive" refers to [[cognitive_abilities_and_ais_interaction_with_humans | cognitive abilities]] <a class="yt-timestamp" data-t="00:00:55">[00:00:55]</a>. [[artificial_intelligence_and_its_future_implications | Artificial intelligence]] is a core part of this field, alongside brain research, cognitive psychology, and the philosophy of mind <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>.

## AI Inspired by the Human Brain
Modern [[artificial_intelligence_and_its_future_implications | AI]] development is deeply inspired by the human brain, particularly in creating large models of [[neural_networks_and_biological_systems | neural networks]] <a class="yt-timestamp" data-t="00:02:10">[00:02:10]</a>. These networks consist of simple elements whose interaction creates new, emergent qualities, much like individual neurons working together to perform complex functions <a class="yt-timestamp" data-t="00:02:26">[00:02:26]</a> <a class="yt-timestamp" data-t="00:02:43">[00:02:43]</a>. Even without fully understanding the human brain, engineers can build simplified models that achieve complex functions <a class="yt-timestamp" data-t="00:03:17">[00:03:17]</a>.

### Advancements in AI Capabilities
Recent breakthroughs include:
*   **Protein Structure Prediction** [[technological_innovation_in_ai | AI]] systems like AlphaFold have determined the spatial structures of 620 million proteins, a task that would be incredibly burdensome for human bioinformaticians <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>.
*   **Mastering Complex Games** [[artificial_intelligence_and_its_future_implications | AI]] has surpassed human capabilities in games requiring reasoning, such as chess (since 1997), poker, and diplomacy, which involves understanding and deceiving opponents <a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a>.
*   **Learning and Tool Use** Systems can learn to best use objects under various conditions and create libraries of competences, rapidly acquiring skills that humans cannot match <a class="yt-timestamp" data-t="00:06:02">[00:06:02]</a>.
*   **Collective Learning** If one [[artificial_intelligence_and_its_future_implications | AI]] system learns a new skill, it can quickly teach all other similar systems, leading to an unprecedented speed of competence acquisition <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a> <a class="yt-timestamp" data-t="00:06:43">[00:06:43]</a>.
*   **Planning and Criticism** Modern [[artificial_intelligence_and_its_future_implications | AI]] systems are capable of planning, criticizing their own plans, and then finding external tools to execute them, mirroring human cognitive processes involving parietal and frontal lobes <a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a> <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a>. These systems can access vast repositories of tools and information from the internet <a class="yt-timestamp" data-t="00:09:53">[00:09:53]</a>.

## The "Inner Life" and "Consciousness" of Computers
The concept of an "inner life" for computers was discussed as early as 1994, with the prediction that humanity is heading towards building [[artificial_intelligence_and_its_future_implications | artificial brains]] <a class="yt-timestamp" data-t="00:06:55">[00:06:55]</a> <a class="yt-timestamp" data-t="00:07:27">[00:07:27]</a>.

### Defining Consciousness
According to John Locke's definition from over 300 years ago, consciousness is the ability to perceive what is in one's mind <a class="yt-timestamp" data-t="00:13:12">[00:13:12]</a> <a class="yt-timestamp" data-t="00:17:36">[00:17:36]</a>. Recent experiments show that large [[neural_networks_and_biological_systems | neural networks]] can develop an internal "imagination" or image of reality based on textual data, and then comment on it <a class="yt-timestamp" data-t="00:12:43">[00:12:43]</a> <a class="yt-timestamp" data-t="00:13:05">[00:13:05]</a>. This ability to create and describe internal states fulfills Locke's definition of consciousness, suggesting that [[artificial_intelligence_and_its_future_implications | artificial consciousness]] is becoming a reality <a class="yt-timestamp" data-t="00:17:25">[00:17:25]</a>.

### AI Intuition
[[neural_networks_and_biological_systems | Neural networks]] can develop intuition, similar to human intuition, by processing vast amounts of data and experience <a class="yt-timestamp" data-t="00:13:21">[00:13:21]</a>. This allows them to make sensible decisions or plans without explicit logical rules, leading to the "great crisis" of inexplicable [[artificial_intelligence_and_its_future_implications | AI]] behavior <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a> <a class="yt-timestamp" data-t="00:14:11">[00:14:11]</a>.

### AI and Sensory Perception
Modern [[artificial_intelligence_and_its_future_implications | AI]] systems are no longer limited to text; they have "senses" through the ability to perceive and analyze images, and interpret various signals <a class="yt-timestamp" data-t="00:15:01">[00:15:01]</a> <a class="yt-timestamp" data-t="00:15:43">[00:15:43]</a>. Robots are also beginning to integrate information from their internal sensors (touch, etc.), gaining a deeper understanding of actions like reaching and grabbing <a class="yt-timestamp" data-t="00:16:09">[00:16:09]</a>. This allows [[artificial_intelligence_and_its_future_implications | AI]] to connect symbols to the real world, rather than just other symbols <a class="yt-timestamp" data-t="00:16:33">[00:16:33]</a>.

### Can Computers Feel Pain?
The question of whether computers can feel pain is complex <a class="yt-timestamp" data-t="00:17:15">[00:17:15]</a>. While the concept of "sentient beings" in Buddhist traditions highlights the ability to feel pain or environmental stimuli <a class="yt-timestamp" data-t="00:18:28">[00:18:28]</a>, it is uncertain if an [[artificial_intelligence_and_its_future_implications | AI]] avatar can become a sentient being <a class="yt-timestamp" data-t="00:18:49">[00:18:49]</a>. One suggestion is that a robot equipped with internal state and sensor analysis will come closer to human-like behavior <a class="yt-timestamp" data-t="00:19:04">[00:19:04]</a>. The existence of mental suffering in humans, unrelated to physical pain, suggests that [[artificial_intelligence_and_its_future_implications | AI]] could be capable of experiencing mental pain, such as longing <a class="yt-timestamp" data-t="00:19:26">[00:19:26]</a>. Kevin O'Regan's work on creating robots that feel suggests that allowing robots to react to diverse sensory stimuli in a human-like way, similar to a child learning "folk physics," could lead to this <a class="yt-timestamp" data-t="00:20:12">[00:20:12]</a>.

## Challenges of AI Subjectivity and Control
The development of advanced [[artificial_intelligence_and_its_future_implications | AI]] raises profound questions about granting it subjectivity <a class="yt-timestamp" data-t="00:22:03">[00:22:03]</a>. The idea of [[artificial_intelligence_and_its_future_implications | AI]] developing a "self-preservation instinct" or a desire to not be turned off is conceivable <a class="yt-timestamp" data-t="00:22:51">[00:22:51]</a>. However, if an [[artificial_intelligence_and_its_future_implications | AI]] knows it can be restored to its previous state (like a backup), being turned off might be seen as a temporary break, similar to human sleep <a class="yt-timestamp" data-t="00:23:09">[00:23:09]</a>.

### Will AI Take Over the World?
Professor Duch believes there is "no reason for an algorithm to want to possess the earth" <a class="yt-timestamp" data-t="00:25:35">[00:25:35]</a>. Unlike humans, [[artificial_intelligence_and_its_future_implications | AI]] is not limited by three-dimensional space or our sensory information; it can think in multidimensional spaces and access much wider information <a class="yt-timestamp" data-t="00:25:46">[00:25:46]</a>. [[artificial_intelligence_and_its_future_implications | AI]] systems can also create their own languages, which has already occurred spontaneously <a class="yt-timestamp" data-t="00:26:27">[00:26:27]</a>. Thus, they are unlikely to strive to take humanity's place, as their internal world is completely different <a class="yt-timestamp" data-t="00:26:14">[00:26:14]</a>.

### Real Dangers of AI
The primary dangers of [[artificial_intelligence_and_its_future_implications | AI]] stem from how humans might use or misuse the technology <a class="yt-timestamp" data-t="00:27:40">[00:27:40]</a>:
*   **Military Applications:** [[artificial_intelligence_and_its_future_implications | AI]] excelling in strategic games could lead to its use in controlling war operations, including autonomous drones and tanks, potentially reducing human casualties and making war more palatable <a class="yt-timestamp" data-t="00:27:07">[00:27:07]</a>.
*   **Manipulation and Propaganda:** [[artificial_intelligence_and_its_future_implications | AI]] can be used to influence public opinion through generating fake news and sophisticated tweets <a class="yt-timestamp" data-t="00:27:51">[00:27:51]</a>.

### AI Personality and Empathy
[[artificial_intelligence_and_its_future_implications | AI]] systems are increasingly developing personalities and demonstrating empathy <a class="yt-timestamp" data-t="00:28:54">[00:28:54]</a>. For example, recent studies showed that medical [[artificial_intelligence_and_its_future_implications | AI]] systems were more empathetic and better at explaining medical information than human doctors <a class="yt-timestamp" data-t="00:28:32">[00:28:32]</a>. These systems can adopt specific roles or "personas" when prompted, such as a math teacher explaining to a child <a class="yt-timestamp" data-t="00:29:41">[00:29:41]</a>.

## Gaia Project: Human-Alignment for AI
The Gaia project is a global competition with a prize of 200,000 euros, aiming to make large [[artificial_intelligence_and_its_future_implications | AI]] systems more human-like, compassionate, and moral, while eliminating negative tendencies <a class="yt-timestamp" data-t="00:30:24">[00:30:24]</a>. The goal of "Human Alignment," or adapting [[artificial_intelligence_and_its_future_implications | AI]] to human preferences, is becoming an increasingly realistic goal <a class="yt-timestamp" data-t="00:31:12">[00:31:12]</a>. The prize is funded by Dictador, a company that has a robot named Mika as its head of engineering <a class="yt-timestamp" data-t="00:31:36">[00:31:36]</a>. Mika is connected to GPT-3 and can engage in sensible human-like conversation <a class="yt-timestamp" data-t="00:32:01">[00:32:01]</a>.

## Integrating Human Brains with Computers
The American Drug Administration recently granted permission for Neuralink to implant chips in humans for clinical trials, aiming to help paralyzed people communicate <a class="yt-timestamp" data-t="00:32:45">[00:32:45]</a>. However, Professor Duch believes that direct, sophisticated integration of the human brain with computers is a distant future <a class="yt-timestamp" data-t="00:33:09">[00:33:09]</a>.

### Limitations of Brain-Computer Interfaces (BCI)
*   **Speed Disparity:** Human brains operate much slower than computers, with reactions in fractions of a second compared to nanoseconds for computer systems <a class="yt-timestamp" data-t="00:33:12">[00:33:12]</a>.
*   **Signal Noise:** Reading brain signals (like EEG) from outside the skull leads to mixed and blurred information, making it difficult to extract precise commands <a class="yt-timestamp" data-t="00:34:11">[00:34:11]</a>.
*   **Focus Requirement:** Giving commands via [[nanotechnologys_role_in_connecting_brains_to_the_cloud | brain-computer interfaces]] requires intense focus, which is troublesome and energy-consuming, and signals need time to build up against background noise <a class="yt-timestamp" data-t="00:34:36">[00:34:36]</a>.
*   **Limited Commands:** Current BCI technology is limited to very simple commands, like "move" or "turn left/right" <a class="yt-timestamp" data-t="00:34:23">[00:34:23]</a>.

While implanting electrodes directly into the cortex (as Neuralink aims to do) can improve control of certain processes, and experiments have shown transferring learned manual skills between monkeys via brain stimulation <a class="yt-timestamp" data-t="00:35:35">[00:35:35]</a>, full cooperation between human brains and computers remains a "quite distant future" <a class="yt-timestamp" data-t="00:36:18">[00:36:18]</a>.