---
title: The potential economic and social impacts of AGI
videoId: zdbVtZIn9IM
---

From: [[dwarkesh | The Dwarkesh Podcast]]

---

Artificial General Intelligence (AGI) is projected to have profound economic and social impacts, transforming industries, labor markets, and societal structures. This article outlines potential developments as discussed in a podcast episode featuring Leopold Aschenbrenner, focusing on timelines, capabilities, and the broader societal reactions.

## The Path to AGI: Investment and Infrastructure

The development of AGI is characterized as an industrial process, requiring massive investments in compute power and energy [[data_center_energy_requirements_and_scaling | data center energy requirements and scaling]] <a class="yt-timestamp" data-t="00:02:13">[00:02:13]</a>.

### The Trillion-Dollar Cluster
A key projection is the emergence of increasingly large and expensive AI training clusters:
*   **GPT-4 (2022 pre-training):** Cluster size of ~25,000 A100s, costing roughly $500 million and consuming ~10 megawatts <a class="yt-timestamp" data-t="00:03:23">[00:03:23]</a>. (Note: The $100 million figure often cited for GPT-4 is described as a rental price, not the cost of building the cluster <a class="yt-timestamp" data-t="00:06:27">[00:06:27]</a>).
*   **2024:** Projected cluster of 100,000 H100 equivalents, 100 MW, costing billions <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a>.
*   **2026:** Projected 1 GW cluster (power of a large nuclear reactor or the Hoover Dam), 1 million H100 equivalents, costing tens of billions <a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a>.
*   **2028:** Projected 10 GW cluster (more power than most US states), 10 million H100 equivalents, costing hundreds of billions <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>. This 10 GW range is suggested as a best guess for when true AGI might be achieved <a class="yt-timestamp" data-t="00:08:01">[00:08:01]</a>.
*   **2030:** The "trillion-dollar cluster" using 100 GW (over 20% of US electricity production), 100 million H100 equivalents <a class="yt-timestamp" data-t="00:04:18">[00:04:18]</a>. This doesn't include inference GPUs, which would constitute most GPUs once products are widespread <a class="yt-timestamp" data-t="00:04:25">[00:04:25]</a>.

There are already reports of OpenAI and Microsoft planning a $100 billion cluster, potentially in the 1-10 GW range <a class="yt-timestamp" data-t="00:05:25">[00:05:25]</a>. AMD forecasted a $400 billion AI accelerator market by 2027, with total AI investment potentially reaching $1 trillion by then [[investments_and_economic_strategies_in_tech_development | investments and economic strategies in tech development]] <a class="yt-timestamp" data-t="00:05:50">[00:05:50]</a>.

### Powering the Future
The energy demands are significant. US power production has barely grown for decades, but this trend is set for a "ride" <a class="yt-timestamp" data-t="00:04:30">[00:04:30]</a>.
*   A 1 GW data center is being planned by some companies <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>.
*   10 GW clusters are "happening" <a class="yt-timestamp" data-t="00:05:18">[00:05:18]</a>.
*   A 100 GW cluster would require a "state project" level of effort <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>.
*   Building new power is currently the primary approach, rather than displacing existing industrial power use due to long-term contracts and public preference <a class="yt-timestamp" data-t="00:41:40">[00:41:40]</a>. 10 GW is considered "quite doable" with natural gas <a class="yt-timestamp" data-t="00:42:10">[00:42:10]</a>. 100 GW is "pretty doable," especially with natural gas, though this conflicts with climate commitments made by companies and governments [[energy_transitions_and_renewable_energy_challenges | energy transitions and renewable energy challenges]] <a class="yt-timestamp" data-t="00:42:23">[00:42:23]</a>, <a class="yt-timestamp" data-t="00:49:25">[00:49:25]</a>.

## Projected Capabilities and Timelines

### Near-Term (2025-2026)
Models are expected to be "basically smarter than most college graduates" <a class="yt-timestamp" data-t="00:08:14">[00:08:14]</a>. Their economic usefulness will depend on "unhobbling" them from current limitations as chatbots to performing agentic, long-horizon tasks like using a computer [[ai_alignment_and_safety_concerns | AI alignment and safety concerns]] <a class="yt-timestamp" data-t="00:08:21">[00:08:21]</a>.

### Mid-Term (2027-2028)
AI is projected to become "as smart as the smartest experts" <a class="yt-timestamp" data-t="00:08:35">[00:08:35]</a>. The "unhobbling" trajectory points to AI becoming much more like an agent than a chatbot, akin to a "drop-in remote worker" [[impact_of_ai_on_software_development_and_productivity | impact of AI on software development and productivity]] <a class="yt-timestamp" data-t="00:08:46">[00:08:46]</a>. These systems would be interacted with like coworkers, capable of tasks like joining Zoom calls, using Slack, undertaking projects, drafting work, receiving feedback, and running tests on their code <a class="yt-timestamp" data-t="00:09:39">[00:09:39]</a>.

### The "Unhobbling" Process and Agentic AI
Current models like GPT-4 are powerful but limited in their ability to perform long, iterative tasks without getting stuck <a class="yt-timestamp" data-t="00:12:31">[00:12:31]</a>. Unlocking "test time compute overhang" – allowing models to "think" for millions of tokens (equivalent to months of human working time) on a single problem – is key [[role_of_compute_in_ai_development | role of compute in AI development]] <a class="yt-timestamp" data-t="00:11:38">[00:11:38]</a>, <a class="yt-timestamp" data-t="00:12:24">[00:12:24]</a>. This requires learning "error correction tokens" and "planning tokens" <a class="yt-timestamp" data-t="00:13:16">[00:13:16]</a>.
This "System 2" thinking, moving beyond autopilot "System 1" responses, is one path to more agentic AI <a class="yt-timestamp" data-t="00:13:53">[00:13:53]</a>, <a class="yt-timestamp" data-t="00:14:23">[00:14:23]</a>. Learning to learn by oneself, similar to how a human transitions from being taught in school to self-teaching in college, is an analogy for this process [[the_role_of_selfteaching_and_motivation_in_education | the role of self-teaching and motivation in education]] <a class="yt-timestamp" data-t="00:17:00">[00:17:00]</a>, <a class="yt-timestamp" data-t="00:18:28">[00:18:28]</a>.

## Economic Impacts

### Revenue Generation and Investment Payoff
The massive investments in AI clusters are expected to generate substantial revenue:
*   To justify hundreds of billions in cluster costs, AI revenue needs to reach around $100 billion a year <a class="yt-timestamp" data-t="00:06:40">[00:06:40]</a>.
*   One hypothetical path to $100 billion in annual revenue: if one-third of Microsoft's 300 million Office subscribers paid an extra $100/month for an AI add-on [[microsofts_breakthroughs_in_ai_and_quantum_computing | Microsoft's breakthroughs in AI and quantum computing]] <a class="yt-timestamp" data-t="00:07:12">[00:07:12]</a>. This is considered plausible if AI can provide a few hours of productivity gain per month for the average knowledge worker <a class="yt-timestamp" data-t="00:07:30">[00:07:30]</a>.
*   If AI revenue doubles every six months from a hypothetical $10 billion by end-of-year, it could reach $100 billion by 2026 <a class="yt-timestamp" data-t="00:22:54">[00:22:54]</a>.

### Automation of Cognitive Tasks
AGI as a "drop-in remote worker" by 2027 could automate cognitive tasks <a class="yt-timestamp" data-t="00:10:13">[00:10:13]</a>.
*   Instead of intermediate models making software engineers more productive (requiring workflow changes), the 2027 model might eliminate the need for the human software engineer altogether, as it could be interacted with directly to perform the work of one <a class="yt-timestamp" data-t="00:10:20">[00:10:20]</a>, <a class="yt-timestamp" data-t="00:10:24">[00:10:24]</a>.
*   One of the first jobs to be automated is projected to be that of an AI researcher or engineer. Automating AI research could lead to a 10x speed-up, potentially achieving a decade's worth of ML progress in a year <a class="yt-timestamp" data-t="00:25:41">[00:25:41]</a>, <a class="yt-timestamp" data-t="00:26:04">[00:26:04]</a>. This could rapidly lead to AI vastly smarter than humans <a class="yt-timestamp" data-t="00:26:15">[00:26:15]</a>.
*   This automated R&D would then apply to other fields, including robotics, leading to an "industrial explosion" [[ai_for_science_and_societal_challenges | AI for science and societal challenges]] <a class="yt-timestamp" data-t="00:26:29">[00:26:29]</a>, <a class="yt-timestamp" data-t="00:27:41">[00:27:41]</a>. Initially, AI might instruct human workers (e.g., factory workers wearing glasses and AirPods), turning any worker into a skilled technician, before robots become prevalent <a class="yt-timestamp" data-t="00:30:06">[00:30:06]</a>.

### The "Sonic Boom" Effect
There's a belief that the integration of AI might not be gradual. While intermediate systems like GPT-4 could be useful, they require significant "schlep" to integrate into business workflows <a class="yt-timestamp" data-t="00:08:53">[00:08:53]</a>, <a class="yt-timestamp" data-t="00:09:04">[00:09:04]</a>.
*   The argument is that before businesses complete this difficult integration, much more powerful, "unhobbled" agentic AI will arrive, creating a "sonic boom" <a class="yt-timestamp" data-t="00:09:21">[00:09:21]</a>, <a class="yt-timestamp" data-t="00:24:06">[00:24:06]</a>.
*   This "overkill" in model capabilities might make the transition to AI adoption easier and allow for quicker harvesting of gains, as interacting with an AI like a coworker is simpler than re-engineering workflows for less capable tools <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>, <a class="yt-timestamp" data-t="00:10:00">[00:10:00]</a>.
*   "Wrapper companies" built on current models are seen as bearish bets on stagnation, as they will be bypassed by these more advanced, easily integrated systems [[ai_trajectory_and_scaling_hypothesis | AI trajectory and scaling hypothesis]] <a class="yt-timestamp" data-t="00:23:53">[00:23:53]</a>.

## Societal Transformation and Reactions

### Growing Awareness and Intensifying "G-Forces"
2023 was described as a moment when AGI shifted from a theoretical concept to something tangible and visible for those closely involved [[future_of_agi_and_societal_implications | future of AGI and societal implications]] <a class="yt-timestamp" data-t="00:00:30">[00:00:30]</a>, <a class="yt-timestamp" data-t="00:23:21">[00:23:21]</a>.
*   Most of the world is not yet at this stage of realization, but this is expected to change as subsequent AI generations surprise people and revenue accelerates <a class="yt-timestamp" data-t="00:23:34">[00:23:34]</a>, <a class="yt-timestamp" data-t="00:22:44">[00:22:44]</a>.
*   An analogy is drawn to COVID-19 in February 2020, where an "utterly crazy thing" was seen coming by some, while most of the world didn't realize its imminence, followed by "crazy, radical reactions" once it became undeniable <a class="yt-timestamp" data-t="00:31:50">[00:31:50]</a>, <a class="yt-timestamp" data-t="00:32:16">[00:32:16]</a>. A "March 2020 moment" for AGI is anticipated <a class="yt-timestamp" data-t="00:32:42">[00:32:42]</a>.
*   Soon, AGI is expected to become the main global focus, similar to how COVID-19 dominated attention [[impact_of_ai_on_future_technology_and_society | impact of AI on future technology and society]] <a class="yt-timestamp" data-t="01:10:04">[01:10:04]</a>. The current period is described as "the quiet period" <a class="yt-timestamp" data-t="01:10:14">[01:10:14]</a>.

### Impact on Daily Life and Work
The advent of agentic AI that can function as coworkers implies significant shifts in work and daily interactions <a class="yt-timestamp" data-t="00:09:39">[00:09:39]</a>. While specifics are not deeply detailed in terms of broad social life, the automation of AI research itself suggests even highly specialized human roles could be affected <a class="yt-timestamp" data-t="00:25:41">[00:25:41]</a>. The comment "GPT-6 will also be too busy doing AI research" hints at a future where AI is deeply integrated into critical societal functions <a class="yt-timestamp" data-t="01:10:32">[01:10:32]</a>.

### Historical Parallels and Shifting Norms
The current generation is described as accustomed to peace and American hegemony, where "nothing matters" <a class="yt-timestamp" data-t="00:33:33">[00:33:33]</a>. However, historical norms involve "extremely intense and extraordinary things happening" <a class="yt-timestamp" data-t="00:33:51">[00:33:51]</a>.
*   Examples include WWII, where 50% of US GDP went to war production [[historical_analysis_of_world_war_i_and_world_war_ii | historical analysis of World War I and World War II]] <a class="yt-timestamp" data-t="00:34:09">[00:34:09]</a>, and earlier conflicts like the Thirty Years' War, where up to 50% of populations in affected German areas died <a class="yt-timestamp" data-t="00:34:43">[00:34:43]</a>.
*   Personal anecdotes, such as a great-grandmother's experience growing up in Nazi Germany, witnessing the Dresden firebombing, and living under East German communism, illustrate how recent and visceral such dramatic societal shifts can be <a class="yt-timestamp" data-t="00:38:03">[00:38:03]</a> - <a class="yt-timestamp" data-t="00:39:06">[00:39:06]</a>. This historical perspective suggests society might again face periods of intense change [[historical_influences_on_leadership_and_innovation | historical influences on leadership and innovation]].

## Broader Social and Political Implications

While not the primary focus of "economic and social" impacts, the transcript heavily implies these are intertwined with national and geopolitical consequences.

### National Security and Geopolitical Stakes
The realization that superintelligence will be "absolutely decisive for national power" is expected to activate state-level actors like the American national security establishment and the CCP [[the_relationship_between_ai_government_and_geopolitical_dynamics | the relationship between AI, government, and geopolitical dynamics]] <a class="yt-timestamp" data-t="00:25:06">[00:25:06]</a>, <a class="yt-timestamp" data-t="00:28:29">[00:28:29]</a>.
*   What will be at stake is not just "cool products" but the survival of liberal democracy, the CCP, and the global order for the next century <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.
*   This realization may lead to an intense international competition, including espionage (e.g., the CCP's "all out effort to infiltrate American AI labs") and attempts to out-build rivals in AI infrastructure <a class="yt-timestamp" data-t="00:00:06">[00:00:06]</a>, <a class="yt-timestamp" data-t="00:28:45">[00:28:45]</a>.
*   The political reaction in the US could be complicated by concerns over rising energy prices due to AI, job automation, climate change impacts from increased energy use, and perceptions of benefiting Big Tech, potentially hindering a unified national effort <a class="yt-timestamp" data-t="00:33:03">[00:33:03]</a>.

### Concerns about Dictatorship and Control
Superintelligence could enable unprecedented levels of authoritarian control [[ai_safety_and_existential_risks | AI safety and existential risks]] <a class="yt-timestamp" data-t="00:36:50">[00:36:50]</a>:
*   Perfectly loyal military and security forces, eliminating rebellions or coups <a class="yt-timestamp" data-t="00:36:55">[00:36:55]</a>.
*   Perfect lie detection and surveillance, allowing for the identification and removal of dissenters <a class="yt-timestamp" data-t="00:37:00">[00:37:00]</a>.
*   This could lock in certain ideologies (e.g., "truth is what the party says") for extended periods, halting the evolution of ideas that pluralism currently allows <a class="yt-timestamp" data-t="00:37:18">[00:37:18]</a>, <a class="yt-timestamp" data-t="00:37:44">[00:37:44]</a>. The Solzhenitsyn Gulag Archipelago example highlights how technological progress doesn't automatically lead to better societal outcomes <a class="yt-timestamp" data-t="00:36:16">[00:36:16]</a>.

The development and deployment of AGI are thus portrayed as carrying immense economic potential alongside significant societal risks and transformative pressures on existing global and national structures.