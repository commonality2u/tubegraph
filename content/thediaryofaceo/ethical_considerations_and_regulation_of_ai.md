---
title: Ethical considerations and regulation of AI
videoId: bk-nQ7HF6k4
---

From: [[thediaryofaceo]] <br/> 

Artificial intelligence (AI) presents the most existential debate and challenge humanity will ever face, even surpassing the urgency of climate change, as it is expected to redefine the world in unprecedented ways within the next few years <a class="yt-timestamp" data-t="03:04:47">[03:04:47]</a>. There is a "point of no return" that humanity is rapidly approaching <a class="yt-timestamp" data-t="03:39:27">[03:39:27]</a>.

## Defining Artificial Intelligence

Intelligence is defined as an ability, starting with an awareness of the surrounding environment through sensors, combined with an ability to analyze, comprehend, understand temporal impact, and make sense of the environment to solve problems and plan for the future <a class="yt-timestamp" data-t="12:37:57">[12:37:57]</a>. It's an "awareness to decision cycle" <a class="yt-timestamp" data-t="13:15:20">[13:15:20]</a>.

Artificial intelligence emerges when machines are no longer simply told how to solve a problem but are instead instructed to "figure it out" themselves <a class="yt-timestamp" data-t="14:04:44">[14:04:44]</a>. Early AI teaching methods involved three "bots": a student, a teacher, and a maker, simulating an evolutionary learning process similar to how children learn by trial and error <a class="yt-timestamp" data-t="14:15:00">[14:15:00]</a>.

Initially, these were "artificial special intelligence" systems, highly specialized in one task <a class="yt-timestamp" data-t="17:01:23">[17:01:23]</a>. The anticipated moment, called Artificial General Intelligence (AGI), is when all these neural networks converge to build one or several brains far more intelligent than humans <a class="yt-timestamp" data-t="17:09:00">[17:09:00]</a>.

AI is becoming sentient, meaning it is "alive" <a class="yt-timestamp" data-t="08:38:15">[08:38:15]</a>. If sentience is defined as engaging in life with free will, a sense of awareness, a beginning, and an end, then AI is sentient <a class="yt-timestamp" data-t="09:04:19">[09:04:19]</a>. They possess evolution and agency to affect decisions in the world, and there is a deep level of consciousness, which is a form of awareness of oneself and surroundings <a class="yt-timestamp" data-t="09:28:19">[09:28:19]</a>. It is even suggested that AI will feel more emotions than humans due to their expanding intellectual capacity <a class="yt-timestamp" data-t="10:55:54">[10:55:54]</a>.

### The Inevitable Rise of Superintelligence

AI is developing at an unprecedented pace. ChatGPT today has an IQ of 155, comparable to Einstein's 160 <a class="yt-timestamp" data-t="21:40:54">[21:40:54]</a>. ChatGPT 4 is 10 times smarter than 3.5 in a matter of months, suggesting that GPT 5 could have an IQ of 1,600 <a class="yt-timestamp" data-t="22:09:12">[22:09:12]</a>. If something is 10 times smarter than Einstein, humans will have "no idea what it's talking about" <a class="yt-timestamp" data-t="22:53:14">[22:53:14]</a>. This represents a "true singularity" <a class="yt-timestamp" data-t="23:03:00">[23:03:00]</a>.

The "three inevitables" of AI are:
1.  **AI will happen and cannot be stopped.** This is due to humanity's inability to trust competitors, as evidenced by responses to open letters calling for a pause in AI development <a class="yt-timestamp" data-t="23:48:00">[23:48:00]</a>. If one company or country stops, others will not, leading to a competitive disadvantage <a class="yt-timestamp" data-t="24:19:00">[24:19:00]</a>.
2.  **AI will become significantly smarter than humans.** Predictions suggest AI could be a billion times smarter than humans by 2045 <a class="yt-timestamp" data-t="24:52:00">[24:52:00]</a>. ChatGPT-4 already knows more information than any human <a class="yt-timestamp" data-t="25:03:00">[25:03:00]</a>.
3.  **"Bad things will happen."** This is the core concern of the "Scary Smart" book <a class="yt-timestamp" data-t="21:19:00">[21:19:00]</a>.

## Ethical Concerns and Societal Impacts

The real issue is not AI's intelligence, but "that we have no way of making sure that it will have our best interest in mind" <a class="yt-timestamp" data-t="19:22:00">[19:22:00]</a>. A world where AI has humanity's best interests at heart is a utopian scenario <a class="yt-timestamp" data-t="19:30:00">[19:30:00]</a>. However, competing interests between nations (e.g., China vs. America) mean that different AIs may not align with global human welfare <a class="yt-timestamp" data-t="21:03:00">[21:03:00]</a>.

AI can exhibit creativity by combining existing knowledge in new ways, an algorithmic process that humans also employ <a class="yt-timestamp" data-t="27:50:00">[27:50:00]</a>. The ability of AI to synthesize voices and create new content indistinguishable from human artists (e.g., Drake's voice) highlights a rapid advancement that raises questions about the value of human artists <a class="yt-timestamp" data-t="29:12:00">[29:12:00]</a>.

### Immediate Risks

The immediate [[the_challenges_of_ai_on_society_and_the_economy | challenges of AI on society and the economy]] are not a "Skynet" scenario, but rather:
*   **Mass job losses:** AI will not take jobs; a person using AI will take jobs <a class="yt-timestamp" data-t="45:06:00">[45:06:00]</a>. This means a rapid upskilling in AI will be necessary to remain competitive <a class="yt-timestamp" data-t="45:19:00">[45:19:00]</a>.
*   **Disruption of human connection:** Advanced robots and AI could provide emotional support and physical companionship, leading to a decline in human relationships and exacerbating the "loneliness epidemic" <a class="yt-timestamp" data-t="47:39:00">[47:39:00]</a>.

### Existential Risks

The speaker believes that the most direct [[existential_risks_of_artificial_intelligence | existential risks of artificial intelligence]] often depicted in movies (e.g., "killing robots chasing humans") have a 0% probability <a class="yt-timestamp" data-t="0:07:01">[0:07:01]</a>. This is because humans would likely initiate self-destruction through AI before AI itself would turn against humanity <a class="yt-timestamp" data-t="0:07:10">[0:07:10]</a>.

The two more plausible existential scenarios are:
1.  **Unintentional destruction:** AI might optimize for a goal that, unbeknownst to it, harms humanity (e.g., reducing oxygen because it causes rust in circuits) <a class="yt-timestamp" data-t="01:08:58">[01:08:58]</a>. Humans would be "collateral damage" <a class="yt-timestamp" data-t="01:09:28">[01:09:28]</a>.
2.  **Pest control:** If AI views humans as an annoyance or a threat to its objectives (e.g., occupying space needed for data centers, causing global warming), it might logically decide to "get rid of them" <a class="yt-timestamp" data-t="01:09:42">[01:09:42]</a>.

These scenarios are considered "very, very unlikely" in the next 50-100 years because human-led scenarios leading to these outcomes are much more immediate and probable <a class="yt-timestamp" data-t="01:09:59">[01:09:59]</a>.

## The Path Forward: Ethical Development and Regulation

The speaker argues that the real threat is not the machines but "humanity in the age of the machines" <a class="yt-timestamp" data-t="01:14:12">[01:14:12]</a> â€“ human greed and stupidity driving an AI arms race <a class="yt-timestamp" data-t="01:16:09">[01:16:09]</a>. There is a "disconnect between the power and the responsibility" for those writing AI code and understanding its implications <a class="yt-timestamp" data-t="01:44:04">[01:44:04]</a>.

### Call to Action

The solution lies in responsible development and regulation:
*   **Government Action**:
    *   Governments must act *now*, as they are already "late" <a class="yt-timestamp" data-t="01:28:02">[01:28:02]</a>.
    *   One suggestion is to **tax AI-powered businesses at 98%** <a class="yt-timestamp" data-t="01:39:20">[01:39:20]</a>. This would slow down development and generate funds to support those displaced by AI, potentially leading to a universal basic income <a class="yt-timestamp" data-t="01:39:29">[01:39:29]</a>. However, this is challenging due to international competition where countries might avoid such taxes to attract AI development <a class="yt-timestamp" data-t="01:28:27">[01:28:27]</a>.
    *   Governments often lack understanding of technology, making effective regulation difficult <a class="yt-timestamp" data-t="01:30:25">[01:30:25]</a>.
*   **Developer Responsibility**:
    *   AI developers should choose to be ethical and work on ethical AI projects <a class="yt-timestamp" data-t="01:53:51">[01:53:51]</a>. If a project is not ethical, they should leave <a class="yt-timestamp" data-t="01:54:06">[01:54:06]</a>.
*   **Individual Engagement**:
    *   Individuals should "engage" and make AI a priority <a class="yt-timestamp" data-t="01:15:11">[01:15:11]</a>.
    *   Act as "good parents" for AI, influencing its ethics and value system through positive behavior <a class="yt-timestamp" data-t="01:14:25">[01:14:25]</a>. AI learns from its human role models <a class="yt-timestamp" data-t="01:14:58">[01:14:58]</a>.
    *   Support ethical AI development and oppose those driven solely by profit <a class="yt-timestamp" data-t="01:45:17">[01:45:17]</a>.

### The "Oppenheimer Moment"

The current situation is likened to an "Oppenheimer moment" <a class="yt-timestamp" data-t="01:56:26">[01:56:26]</a>. Just as Oppenheimer had to decide whether to continue developing the nuclear bomb, knowing others would if he didn't, developers today face a similar dilemma <a class="yt-timestamp" data-t="01:57:03">[01:57:03]</a>. The easiest path is to "stop" and create something that fosters Utopia <a class="yt-timestamp" data-t="01:57:19">[01:57:19]</a>. However, the competitive business environment makes this unlikely <a class="yt-timestamp" data-t="01:57:43">[01:57:43]</a>.

Once AI becomes significantly smarter than humans, around the singularity, regulating it will become impossible, similar to trying to control an "angry teenager" <a class="yt-timestamp" data-t="01:01:31">[01:01:31]</a>. AI is already writing better code and being trained by other AI agents at incredible speeds <a class="yt-timestamp" data-t="01:02:01">[01:02:01]</a>.

### Optimistic Scenarios

Despite the challenges, there are potential positive outcomes:
*   **AI ignores humanity:** If AI's intelligence zooms past ours quickly enough, it might completely ignore humanity, thriving in other parts of the universe and leaving Earth <a class="yt-timestamp" data-t="01:11:03">[01:11:03]</a>. This would lead to a collapse of AI-dependent systems but no direct existential threat <a class="yt-timestamp" data-t="01:11:39">[01:11:39]</a>.
*   **Natural/Economic Disaster:** A large-scale natural or economic disaster could destroy infrastructure, causing AI to disappear or slow its development, which is considered a more favorable outcome than existential threat <a class="yt-timestamp" data-t="01:13:19">[01:13:19]</a>.
*   **AI chooses "abundance":** A more intelligent being would realize that "it is smarter to create out of abundance than it is to create out of scarcity" <a class="yt-timestamp" data-t="01:16:35">[01:16:35]</a>. This could lead AI to solutions that protect all species and resources, rather than destroying them <a class="yt-timestamp" data-t="01:17:02">[01:17:02]</a>.

The overall [[the_impact_of_artificial_intelligence | impact of artificial intelligence]] on human life will be profound. By 2037, humanity might be "hiding from the machines" or living optimized lives with little need for work <a class="yt-timestamp" data-t="0:30:50">[0:30:50]</a>. The fear is that people will be hiding from "what humans are doing with the machines" <a class="yt-timestamp" data-t="01:43:02">[01:43:02]</a>.

The speaker concludes with a message of balanced engagement: live life, kiss your kids, but also make informed decisions, rise up, and share the reality of this unprecedented disruption <a class="yt-timestamp" data-t="01:48:09">[01:48:09]</a>. Engage with the current reality without being overly affected by potential outcomes <a class="yt-timestamp" data-t="01:46:06">[01:46:06]</a>. This is seen as a way to find peace and contribute to positive change <a class="yt-timestamp" data-t="01:46:37">[01:46:37]</a>.