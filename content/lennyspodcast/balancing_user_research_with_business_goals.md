---
title: Balancing user research with business goals
videoId: L6RKi9ZvkT4
---

From: [[lennyspodcast]] <br/> 

User-centered performance is a phenomenon where customer obsession or user-centered practices are symbolic rather than genuinely focused on learning and decision-making <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. This often manifests as work done to signal customer obsession, not to make different product decisions <a class="yt-timestamp" data-t="00:00:15">[00:00:15]</a>. A common example is a Product Manager (PM) asking a researcher at the end of a product process to "just run a quick user study to validate our assumptions" <a class="yt-timestamp" data-t="00:00:26">[00:00:26]</a>. At this stage, it's often too late to matter, and the goal is simply to "check the box" before shipping the product <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>.

Instead of validating assumptions, the focus should be on falsifying them â€“ actively seeking to be proven wrong <a class="yt-timestamp" data-t="00:00:41">[00:00:41]</a>. Many PMs and designers are not in this mindset; they seek validation, which is a key indicator of user-centered performance <a class="yt-timestamp" data-t="00:00:47">[00:00:47]</a>.

## The User Research Reckoning

Jud Anon, who helped build user research practices at Facebook and led research at Airbnb, notes that the user research field is currently undergoing a "reckoning" <a class="yt-timestamp" data-t="00:01:27">[00:01:27]</a>. The discipline of UX research, as it has existed over the past 15 years, is "dying," but can survive and thrive through adaptation <a class="yt-timestamp" data-t="00:05:46">[00:05:46]</a>. This reckoning is partly triggered by recent layoffs in the tech industry, where user experience (UX) and UX research teams have been particularly hard hit <a class="yt-timestamp" data-t="00:08:00">[00:08:00]</a>.

The core thesis is that the system is broken because research is not driving the [[leveraging_user_insights_for_product_development | value or impact]] it should <a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a>. This is due to both internal issues within research and how companies [[integrating_ux_research_into_product_development_cycles | leverage user research]] <a class="yt-timestamp" data-t="00:08:43">[00:08:43]</a>. A significant problem is doing too much of the "wrong type of research" <a class="yt-timestamp" data-t="00:08:50">[00:08:50]</a>.

### Three Categories of Research

Research can be categorized into three types:

1.  **Macro Research** <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>:
    *   Big picture, strategic, business-focused, and forward-looking <a class="yt-timestamp" data-t="00:09:09">[00:09:09]</a>.
    *   Involves innovation, market analysis, competitor analysis, and long-term product direction <a class="yt-timestamp" data-t="00:09:13">[00:09:13]</a>.
    *   Examples: Understanding overall competitive landscape, concept car projects, strategic planning, Total Addressable Market (TAM) studies <a class="yt-timestamp" data-t="00:12:23">[00:12:23]</a>.

2.  **Micro Research** <a class="yt-timestamp" data-t="00:09:22">[00:09:22]</a>:
    *   Highly technical and focused, often related to usability <a class="yt-timestamp" data-t="00:09:22">[00:09:22]</a>.
    *   Aims to enable high-quality, pixel-perfect product releases <a class="yt-timestamp" data-t="00:09:28">[00:09:28]</a>.
    *   Examples: Laser-focused research to [[understanding_and_analyzing_user_behavior | understand AB test results]] <a class="yt-timestamp" data-t="00:09:33">[00:09:33]</a>.
    *   This type of research can go "super fast" and drive significant business value, such as quickly identifying and fixing a problematic button text that impacts conversion <a class="yt-timestamp" data-t="00:35:16">[00:35:16]</a>. It should be much more common <a class="yt-timestamp" data-t="00:37:57">[00:37:57]</a>.

3.  **Middle Range Research** <a class="yt-timestamp" data-t="00:09:38">[00:09:38]</a>:
    *   This is the "blob place" where research questions are of "middle altitude" <a class="yt-timestamp" data-t="00:09:41">[00:09:41]</a>.
    *   Often involves understanding user needs (e.g., "how Airbnb hosts feel about their payment options") <a class="yt-timestamp" data-t="00:12:45">[00:12:45]</a>.
    *   This type of research is often interesting to researchers but not impactful enough for the business <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>.
    *   It yields results that are interesting but hard to operationalize, often confirming what people already "knew" (post-hoc bias) <a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>.
    *   It contributes to the stereotype that research is slow because it's not "pointed enough" at a specific business problem <a class="yt-timestamp" data-t="00:38:31">[00:38:31]</a>.

## The Shift Towards Business Acumen in User Research

For user research to be impactful, researchers need to be much more business-oriented <a class="yt-timestamp" data-t="00:21:13">[00:21:13]</a>. While user experience practice is rightly focused on empathy and user-centeredness, researchers must explicitly find the overlap between user needs and business profit <a class="yt-timestamp" data-t="00:21:39">[00:21:39]</a>.

This means:
*   **Understanding the Business Language**: Reading quarterly reports, listening to shareholder calls, and understanding company strategies, OKRs, metrics, and conversion funnels <a class="yt-timestamp" data-t="00:22:00">[00:22:00]</a>.
*   **Proposing Targeted Research**: Using business understanding to frame research questions that drive maximum business impact and product improvement <a class="yt-timestamp" data-t="00:22:33">[00:22:33]</a>.
*   **Focusing on Solutions**: Moving beyond merely identifying problems to contributing to actionable solutions <a class="yt-timestamp" data-t="00:28:28">[00:28:28]</a>.

## Improving Collaboration: PMs and Researchers

A major challenge in user research is the relationship with product managers <a class="yt-timestamp" data-t="00:32:58">[00:32:58]</a>. Many researchers are not included in the product process from the beginning <a class="yt-timestamp" data-t="00:33:20">[00:33:20]</a>.

### Integrating Research into Product Development

To maximize impact, user research needs to be much more fully integrated into product development cycles <a class="yt-timestamp" data-t="00:14:35">[00:14:35]</a>. This means:
*   **Consistent Relationships**: Researchers should be part of the product process from beginning to end <a class="yt-timestamp" data-t="00:14:48">[00:14:48]</a>.
*   **Proactive Engagement**: Rather than being a reactive "service function" called in at the end, researchers should be in the room, participating in conversations, and influencing the framing of questions <a class="yt-timestamp" data-t="00:15:04">[00:15:04]</a>.
*   **Shared Metrics**: Product teams, including PMs, engineers, designers, and researchers, should share the same set of metrics for success <a class="yt-timestamp" data-t="00:31:51">[00:31:51]</a>.
*   **Ruthless Prioritization**: PMs should partner with researchers to prioritize tasks, as researchers often handle too many projects at once <a class="yt-timestamp" data-t="00:51:44">[00:51:44]</a>.

### Intuition vs. Evidence

While great product leaders develop strong intuition, this "gut feeling" is also where cognitive biases and blind spots lie <a class="yt-timestamp" data-t="00:27:08">[00:27:08]</a>. [[understanding_and_analyzing_user_behavior | Great researchers]] can expose these biases and help expand horizons, constantly improving intuition <a class="yt-timestamp" data-t="00:27:27">[00:27:27]</a>.

To check intuition:
*   **Engage "System 2" thinking**: Utilize slow, methodical analytic thinking to scrutinize initial judgments <a class="yt-timestamp" data-t="00:30:36">[00:30:36]</a>.
*   **Leverage the "wisdom of the crowd"**: Bring together diverse sources of information and judgment from different people in the room to foster open discussion and challenge assumptions <a class="yt-timestamp" data-t="00:30:58">[00:30:58]</a>.

### Common Misconceptions (Tropes) about User Research

Researchers often hear common tropes from PMs and other stakeholders:

*   **"Research just slows us down"**: This is often false. Good research can be done quickly (in a day or week for micro-level insights) and actually speeds up the product development process by helping teams "get it right the first time" <a class="yt-timestamp" data-t="00:33:52">[00:33:52]</a>.
*   **"I can do my own research; why do I need researchers?"**: Anyone can talk to a user, but that doesn't constitute research or insights work <a class="yt-timestamp" data-t="00:39:03">[00:39:03]</a>. A single user can be idiosyncratic; researchers know how to get to the heart of the matter, situate conversations, and avoid biases <a class="yt-timestamp" data-t="00:39:30">[00:39:30]</a>.
*   **"AB test everything"**: While AB tests are valuable for making causal claims, they rarely explain *why* something happened <a class="yt-timestamp" data-t="00:40:12">[00:40:12]</a>. Researchers provide the "how and why," which is crucial for building better products and avoiding future mistakes <a class="yt-timestamp" data-t="00:41:40">[00:41:40]</a>. Effective partnerships between data scientists and researchers are essential <a class="yt-timestamp" data-t="00:41:58">[00:41:58]</a>.
*   **The Henry Ford "horses" quote**: The quote "If I'd asked my users, they would have said faster horses" is apocryphal <a class="yt-timestamp" data-t="00:42:27">[00:42:27]</a>. More importantly, researchers do not simply ask customers what they want; a researcher who does this is considered a "bad researcher" <a class="yt-timestamp" data-t="00:42:59">[00:42:59]</a>.
*   **"We knew this already; that was obvious"**: This reflects post-hoc bias or hindsight bias, a cognitive bias where people selectively remember and construct narratives to feel they already knew an outcome <a class="yt-timestamp" data-t="00:43:18">[00:43:18]</a>. As sociologist Duncan Watts argues in *Everything is Obvious If You Already Know the Answer*, intuition can lead us astray <a class="yt-timestamp" data-t="00:43:29">[00:43:29]</a>.

## [[how_to_evaluate_and_hire_effective_ux_researchers | Evaluating and Hiring Effective User Researchers]]

Great researchers possess a "Swiss army knife" of skills <a class="yt-timestamp" data-t="00:20:11">[00:20:11]</a>. They are multi-method and have five key tools:
1.  **Formative or Generative User Experience Research**: Looking ahead, innovation-focused, open-ended, potentially ethnographic (e.g., talking to users in the field) <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>.
2.  **Evaluative Research**: Such as usability testing <a class="yt-timestamp" data-t="00:18:28">[00:18:28]</a>.
3.  **Rigorous Survey Design**: For scaled responses from communities <a class="yt-timestamp" data-t="00:18:35">[00:18:35]</a>.
4.  **Applied Statistics**: Essential for [[understanding_and_analyzing_user_behavior | interpreting AB test results]] and other quantitative data <a class="yt-timestamp" data-t="00:18:46">[00:18:46]</a>.
5.  **Technical Skills**: Traditionally SQL for running queries, now potentially prompt engineering for interacting with generative AI <a class="yt-timestamp" data-t="00:19:01">[00:19:01]</a>.

When interviewing, candidates should ideally propose multi-method approaches to open-ended research questions <a class="yt-timestamp" data-t="00:20:26">[00:20:26]</a>. The ability to break down complex problems simply is a key differentiator <a class="yt-timestamp" data-t="01:10:49">[01:10:49]</a>.

## Optimizing User Research Staffing

There isn't a single "right ratio" for the number of researchers to other team members <a class="yt-timestamp" data-t="00:57:10">[00:57:10]</a>. The organizing principle should be relationships: ensuring that people who need a consistent research partner have one <a class="yt-timestamp" data-t="00:57:28">[00:57:28]</a>. It's better to create "pain of loss" by demonstrating the value of a few highly impactful researchers, rather than spreading many researchers too thinly <a class="yt-timestamp" data-t="00:57:36">[00:57:36]</a>.

Even early-stage companies, including startups, can benefit significantly from a researcher <a class="yt-timestamp" data-t="00:59:17">[00:59:17]</a>. A good researcher helps a company go faster, not slower, and drives impact by answering questions impossible to answer otherwise <a class="yt-timestamp" data-t="00:59:18">[00:59:18]</a>. They can provide evidence for tough decisions, reducing reliance on guesses <a class="yt-timestamp" data-t="01:00:54">[01:00:54]</a>.

## Critique of Net Promoter Score (NPS)

NPS is often considered a flawed metric in the survey science community <a class="yt-timestamp" data-t="01:04:14">[01:04:14]</a>.
*   The "likelihood to recommend" question is problematic due to its 0-10 scale, often unlabeled options, and the large number of items (11), which can reduce precision <a class="yt-timestamp" data-t="01:04:20">[01:04:20]</a>.
*   The question itself can be fundamentally flawed, as not everyone is inclined to recommend products like operating systems <a class="yt-timestamp" data-t="01:05:00">[01:05:00]</a>.
*   While NPS is argued to indicate loyalty, a simple "customer satisfaction" (CSAT) metric (e.g., "overall how satisfied are you with your experience?") is better <a class="yt-timestamp" data-t="01:05:17">[01:05:17]</a>. CSAT has better data properties, is more precise, and is more correlated to business outcomes <a class="yt-timestamp" data-t="01:05:21">[01:05:21]</a>.
*   NPS is also idiosyncratic and inconsistent in how it's asked, meaning benchmarking it against industry NPS is often not an "apples to apples" comparison <a class="yt-timestamp" data-t="01:06:19">[01:06:19]</a>.

## Conclusion

The future of user research is bright, but it requires an evolution <a class="yt-timestamp" data-t="01:02:28">[01:02:28]</a>. Researchers need to:
*   Develop diverse research skills <a class="yt-timestamp" data-t="01:08:01">[01:08:01]</a>.
*   Deepen their business knowledge <a class="yt-timestamp" data-t="01:08:12">[01:08:12]</a>.
*   Build strong relationships with product partners <a class="yt-timestamp" data-t="01:08:20">[01:08:20]</a>.
*   Learn to say no and focus on high-impact projects <a class="yt-timestamp" data-t="01:08:44">[01:08:44]</a>.
*   Be excellent communicators, adapting their message to different audiences <a class="yt-timestamp" data-t="01:02:53">[01:02:53]</a>.

Companies, in turn, need to stop siloing insights disciplines (like UX research, market research, data science, customer service feedback) and create a unified insights function <a class="yt-timestamp" data-t="01:05:05">[01:05:05]</a>. Most importantly, they must [[integrating_ux_research_into_product_development_cycles | integrate researchers]] into a unified, lean process where they are "arm-in-arm" from the beginning <a class="yt-timestamp" data-t="01:11:13">[01:11:13]</a>. This ensures maximum [[leveraging_user_insights_for_product_development | value extraction]] and helps move user research beyond being a mere "service discipline" <a class="yt-timestamp" data-t="01:11:03">[01:11:03]</a>.