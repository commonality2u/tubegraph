---
title: Using Qualitative Feedback for Product Development
videoId: VjJ6xcv7e8s
---

From: [[lennyspodcast]] <br/> 

Qualitative feedback plays a crucial role in [[integrating_customer_feedback_into_product_development | product development]], especially in the early stages of a product's lifecycle and for identifying [[the_importance_of_productmarket_fit_and_customer_feedback | Product-Market Fit]]. It helps product teams understand user needs, identify "must-have" features, and drive sustainable growth [01:49:17].

## The Shaun Ellis Test

The Shaun Ellis Test is a simple yet profound idea that has significantly [[the_impact_of_user_feedback_on_product_development | impacted the startup world]] [00:00:02]. It aims to determine if a product is considered a "must-have" by its users [03:30:30].

The core question posed to users is:
> "How would you feel if you could no longer use this product?" <a class="yt-timestamp" data-t="03:36:03">[03:36:03]</a>

Users are given choices such as "very disappointed," "somewhat disappointed," or "not disappointed/not applicable" <a class="yt-timestamp" data-t="03:41:43">[03:41:43]</a>. The goal is to identify the percentage of users who would be "very disappointed" if the product disappeared <a class="yt-timestamp" data-t="03:54:19">[03:54:19]</a>.

Historically, a benchmark of **40% or more** of users selecting "very disappointed" has been identified as a leading indicator of [[the_importance_of_productmarket_fit_and_customer_feedback | Product-Market Fit]] <a class="yt-timestamp" data-t="06:33:04">[06:33:04]</a>. This 40% threshold emerged from observing patterns across numerous startups in Silicon Valley: products meeting this percentage tended to perform well, while those below it often struggled [00:00:13, 07:51:24, 07:57:12]. While 40% is a common target, it's not rigid, and companies like Newbank use a 50% threshold [07:22:27].

### Leading vs. Lagging Indicators

The Shaun Ellis Test is considered a *leading indicator* of [[the_importance_of_productmarket_fit_and_customer_feedback | Product-Market Fit]] <a class="yt-timestamp" data-t="06:39:10">[06:39:10]</a>. The *lagging indicator* is actual user retentionâ€”whether people continue using the product over time <a class="yt-timestamp" data-t="06:43:03">[06:43:03]</a>. The test's benefit is providing insights quickly, sometimes even on day one, without requiring a sophisticated analytics system for long-term retention data [07:04:08, 07:08:08].

## Using the Shaun Ellis Test for Product Improvement

The primary value of the Shaun Ellis Test lies not just in the score, but in the qualitative insights it provides, especially from the "very disappointed" users [01:17:00]. This [[customer_feedback_and_product_improvement | customer feedback and product improvement]] approach is crucial.

### Identifying "Must-Have" Users and Their Needs
*   **Digging Deeper**: Once a product has a group of "very disappointed" users, the next step is to deeply understand who they are, how they use the product, what problems it solves for them, and what they used before [01:49:17].
*   **Primary Benefit Question**: A valuable follow-up question to these users is: "What is the primary benefit that you get?" <a class="yt-timestamp" data-t="01:15:13">[01:15:13]</a>
    *   Initially, this can be an open-ended question to crowdsource different benefits [01:52:13].
    *   Then, it can be refined into a multiple-choice question for subsequent surveys, forcing users to select one of several distinctive benefit statements [01:25:22, 01:27:26].
    *   A further question could be: "Why is that benefit important to you?" This provides crucial context for effective messaging and product positioning [01:37:37, 01:40:02].
    *   Example: For an email product (Zane), users valued "finding things faster," and the context was "I'm drowning in email." This led to effective marketing hooks [01:55:00, 01:56:00, 01:10:50].
*   **Identifying Alternatives**: Asking "What would you use instead if this product were no longer available?" can reveal if the product offers unique value or if commodity alternatives exist [04:59:00]. A "must-have" product should be both valuable and unique [04:57:00, 05:13:00].

### Strategic Application of Insights
*   **Product Roadmap**: The insights help ensure the product roadmap doubles down on features important to the "must-have" customers [01:13:00].
*   **Onboarding and Messaging**: Streamlining [[the_integration_of_user_research_in_product_development | onboarding]] and adjusting messaging to set the right expectations is key [01:16:00]. For example, a mobile security company with a low initial score found "antivirus" was the "must-have" feature; by repositioning the product around this and optimizing onboarding for antivirus setup, they rapidly increased their score [09:53:00, 01:17:50].
*   **Acquisition**: Campaigns should target people who genuinely have the need the product solves, guided by the understanding of "must-have" users [01:27:00].

> [!CAUTION] Ignoring "Somewhat Disappointed" Users
> Shaun Ellis initially advised ignoring users who say they would be "somewhat disappointed" because paying too much attention to their feedback might dilute the product for "must-have" users, making it "good for everyone but not great for anyone" <a class="yt-timestamp" data-t="00:26:00">[00:26:00]</a>, <a class="yt-timestamp" data-t="04:22:00">[04:22:00]</a>.
>
> **Superhuman's Nuance**: The team at Superhuman evolved this approach. They would identify the core benefit desired by "must-have" users. Then, among the "somewhat disappointed" users, they would look for those *also* focused on that same core benefit. They would then ask what these "on-the-fence" users needed for the product to become a "must-have" for them, without compromising the core experience for the loyal users <a class="yt-timestamp" data-t="04:27:00">[04:27:00]</a>.

## Practical Considerations for Running the Survey

*   **Timing**: The survey should be sent to a random sample of users who have actively used the product (activated) and have been using it for at least a couple of weeks <a class="yt-timestamp" data-t="02:38:00">[02:38:00]</a>. It should not be given to brand new users, those only landing on a homepage, or those who have long churned [02:29:00, 02:40:00].
*   **Sample Size**: While some insights can be gained from small numbers, a minimum of **30 responses** is generally recommended for reliable data [03:08:00, 03:17:00].
*   **Tools**: Simple tools like SurveyMonkey via email can work, as can in-product survey tools like Qualaroo or Intercom (if they offer a good user experience) [03:26:00, 03:36:00].
*   **Limitations**: The test may not be suitable for "one-off" products (e.g., watching a single movie) where continuous usage is not expected. For such cases, an NPS (Net Promoter Score) question might be more appropriate [04:13:00].

## Qualitative Feedback in Growth Strategy

Qualitative feedback is foundational to [[the_impact_of_user_feedback_on_product_development | product growth]]. When a company reaches a good Product-Market Fit score, the focus shifts to getting as many of the right people to experience that "must-have" feeling [04:47:00].

### Growth Prioritization: Activation First
Shaun Ellis emphasizes a specific sequence for growth:
1.  **Understand Must-Have Value**: Deeply comprehend what makes the product indispensable to core users [04:49:00].
2.  **Define North Star Metric**: Establish a metric that captures "units of value being delivered" to the customer. This should correlate with revenue but not *be* revenue, and it should be "up and to the right" over time (e.g., nights booked for Airbnb, weekly rides for Uber, monthly purchases for Amazon) [04:53:00, 04:59:00, 01:19:51].
3.  **Activation**: This is often the most critical initial focus. Many companies struggle because the product team is focused on features, and the marketing team on acquisition, while the crucial first-user experience falls through the cracks [05:11:00, 05:39:00].
    *   **"Problem Well Stated is Half Solved"**: The key to improving activation is deeply understanding *why* users aren't progressing [05:51:00]. This often involves asking users directly about their struggles (e.g., "Why didn't you download the software after registering?") [05:58:00].
    *   **Increase Desire, Reduce Friction**: These are the two primary levers for driving conversion during activation [01:01:36].
    *   **Example (LogMeIn)**: By understanding that 95% of sign-ups never did a remote control session, the company froze other development and focused all efforts on improving the sign-up to usage rate, increasing it by 1000% in three months. This allowed previously unprofitable acquisition channels to scale dramatically [05:41:00, 05:48:00].
4.  **Engagement & Referral Loops**: Once activation is solid, focus on how to keep users coming back and encourage them to bring in new users. Referral programs (like Dropbox's legendary one) work best as accelerators when there's already organic word-of-mouth [01:14:58].
5.  **Revenue Model**: Ensure the product can be monetized profitably [05:39:00].
6.  **Customer Acquisition**: Only once the internal "growth engine" is efficient should a company aggressively pursue scalable customer acquisition, as it's highly competitive [05:11:00, 05:28:00].

### The Blend of Qualitative and Quantitative
Shaun Ellis highlights the importance of combining both qualitative and quantitative research. Initially, he was solely data-driven, but a VC's persistent questioning about talking to customers led him to integrate qualitative insights. He found that combining the two approaches leads to much better experiments and deeper understanding of user behavior [01:11:03, 01:19:16].

> [!QUOTE]
> "It's just really hard to run good experiments when you can't deeply contextualize what's going on." <a class="yt-timestamp" data-t="01:37:35">[01:37:35]</a>

### Asking the Right Questions
A core principle underlying effective [[customer_feedback_and_product_improvement | product improvement]] and growth is learning "how to ask the right question at the right time" <a class="yt-timestamp" data-t="01:33:14">[01:33:14]</a>. This means:
*   Instead of immediately jumping to solutions, first try to deeply understand the problem by asking obvious, direct questions to users (e.g., "Why aren't users downloading the software?") [01:34:04].
*   Understanding the "why" behind user behavior provides critical context that informs better solutions and experiments [01:45:00].

## The Future Role of AI

AI is expected to significantly impact product development and growth strategies, particularly in:
*   **Predicting Outcomes**: AI can help model potential outcomes of experiments and predict probabilities, potentially refining or even replacing prioritization frameworks like ICE [01:29:51].
*   **Identifying Opportunities**: AI can identify areas of underperformance in a business and suggest experiments, making recommendations more dispassionate and potentially overcoming team ego dynamics [01:31:51].
*   **Analysis**: AI can help overcome bottlenecks in data analysis, which often become a challenge when running a high velocity of experiments [01:32:45].