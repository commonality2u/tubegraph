---
title: Interplay of AI and traditional business and technology approaches
videoId: scsW6_2SPC4
---

From: [[lennyspodcast]] <br/> 

The landscape of technology development is undergoing a rapid transformation with the advent of artificial intelligence (AI). A core tenet in this new era is the understanding that the AI models used today are the "worst AI model you will ever use for the rest of your life," highlighting the constant and rapid pace of improvement <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. This necessitates a fundamentally different approach to product development compared to traditional methods <a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a>.

## Contrasting AI and Traditional Technology Development

In traditional technology companies, product development typically relies on a stable technological foundation. Teams spend their time identifying and solving user problems, understanding habits, and improving user lives, knowing the underlying technology is relatively fixed <a class="yt-timestamp" data-t="00:16:28">[00:16:28]</a>. For example, a database used this year might be only 5% better than one used two years prior <a class="yt-timestamp" data-t="00:16:55">[00:16:55]</a>.

However, [[developing_ai_products_and_utilizing_technology | developing AI products and utilizing technology]] is vastly different. "Every two months computers can do something they've never been able to do before" <a class="yt-timestamp" data-t="00:17:01">[00:17:01]</a>. This constant evolution means that product teams must completely rethink their strategies <a class="yt-timestamp" data-t="00:17:07">[00:17:07]</a>. Unlike traditional systems with defined inputs and outputs, Large Language Models (LLMs) excel at processing "fuzzy, subtle inputs" like human language nuances <a class="yt-timestamp" data-t="00:17:46">[00:17:46]</a>. They also don't necessarily provide the exact same output every time, even for the same input <a class="yt-timestamp" data-t="00:17:54">[00:17:54]</a>. The reliability of a model's performance (e.g., 60% vs. 99.5% accuracy) significantly impacts how a product is designed <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>.

## Product Development in an AI Era

The [[impact_of_ai_on_product_development | impact of AI on product development]] introduces unique considerations for teams.

### Agility and Iteration

At OpenAI, the product philosophy embraces constant change. While there's a sense of overall direction, quarterly roadmapping and year-long strategies are not rigid blueprints <a class="yt-timestamp" data-t="00:27:09">[00:27:09]</a>. The approach is likened to Eisenhower's quote: "Plans are useless. Planning is helpful" <a class="yt-timestamp" data-t="00:27:22">[00:27:22]</a>. The planning process itself is valuable for reviewing past work and understanding dependencies, but the rapid technological shifts mean plans will likely be discarded or changed mid-quarter <a class="yt-timestamp" data-t="00:28:03">[00:28:03]</a>.

This environment favors a "bottoms-up" approach, empowering passionate engineers, product managers, and designers who understand the models' capabilities to drive development <a class="yt-timestamp" data-t="00:28:26">[00:28:26]</a>. The company also embraces making mistakes and moving fast <a class="yt-timestamp" data-t="00:29:00">[00:29:00]</a>. A key philosophy is "iterative deployment," where products are shipped early, even with incomplete knowledge of their full capabilities, allowing for co-evolution with society <a class="yt-timestamp" data-t="00:30:44">[00:30:44]</a>.

### The Role of Evals

A critical skill in AI product development is writing "evals," which are essentially quizzes or tests for AI models <a class="yt-timestamp" data-t="00:19:24">[00:19:24]</a>. Evals serve as benchmarks to gauge a model's intelligence or capability in specific domains, much like unit tests for software <a class="yt-timestamp" data-t="00:19:57">[00:19:57]</a>.

Understanding a model's performance through evals is crucial for determining the appropriate product design. A model that's 60% accurate requires a different product design than one that's 99.5% accurate <a class="yt-timestamp" data-t="00:20:30">[00:20:30]</a>. Evals are not static; they are used in a continuous learning process. For example, in building deep research capabilities, evals were designed alongside the product, allowing for "hill climbing" â€“ continuous improvement and fine-tuning of the model based on performance on these specific tests <a class="yt-timestamp" data-t="00:22:05">[00:22:05]</a>. This feedback loop between product needs and model training is essential for building effective [[developing_ai_products_and_utilizing_technology | AI products and utilizing technology]].

### Model Maximalism

A core product philosophy is "model maximalism" <a class="yt-timestamp" data-t="00:31:19">[00:31:19]</a>. While models are not perfect and will make mistakes, the approach is to avoid excessive scaffolding around current limitations <a class="yt-timestamp" data-t="00:31:39">[00:31:39]</a>. The mindset is that "in two months there's going to be a better model and it's going to blow away whatever the current set of limitations are" <a class="yt-timestamp" data-t="00:31:43">[00:31:43]</a>. This encourages developers to build products that are "right on the edge of the capabilities" because future model improvements will make them "sing" <a class="yt-timestamp" data-t="00:31:58">[00:31:58]</a>. This is a key [[tips_for_using_ai_in_product_development | tip for using AI in product development]].

## Organizational Structures and Roles

The rapid pace and unique nature of AI also reshape organizational structures and roles within companies. This contributes to the broader [[adapting_to_ai_driven_changes_in_organizations | adapting to AI driven changes in organizations]].

### Product Management in AI

Product management at OpenAI is characterized by being "PM light," meaning a relatively small number of PMs for the scale of the company <a class="yt-timestamp" data-t="00:48:21">[00:48:21]</a>. This philosophy aims to prevent micromanagement and empower engineers, who are expected to be "product focused" and have "high agency" <a class="yt-timestamp" data-t="00:48:47">[00:48:47]</a>.

Key traits for PMs in this environment include:
*   **High Agency:** Proactively identifying and solving problems without waiting for explicit direction <a class="yt-timestamp" data-t="00:49:56">[00:49:56]</a>.
*   **Comfort with Ambiguity:** The problems are often "ill-formed," requiring individuals to figure things out as they go <a class="yt-timestamp" data-t="00:50:14">[00:50:14]</a>.
*   **Ability to Lead through Influence:** Given that teams don't report directly to PMs, and the presence of self-directed research functions, building strong rapport and influencing without direct authority is crucial <a class="yt-timestamp" data-t="00:50:56">[00:50:56]</a>.
*   **Decisiveness:** In ambiguous situations where no one is making a call, PMs are expected to ensure decisions are made to move forward <a class="yt-timestamp" data-t="00:52:50">[00:52:50]</a>.

The ability to write evals is also seen as a core skill for product managers <a class="yt-timestamp" data-t="00:19:03">[00:19:03]</a>, integrating deep technical understanding with product needs. These aspects highlight unique [[tools_and_techniques_for_ai_product_managers | tools and techniques for AI product managers]].

### Integrating Research and Product

OpenAI's evolution from a pure research company to a product company required closer collaboration between research and product teams <a class="yt-timestamp" data-t="00:46:07">[00:46:07]</a>. Treating these functions separately, where research develops models and then product/engineering teams simply consume them via an API, is not optimal <a class="yt-timestamp" data-t="00:47:11">[00:47:11]</a>. The best products emerge when product design and research work as a single, iterative team, providing feedback to fine-tune models for specific use cases <a class="yt-timestamp" data-t="00:47:20">[00:47:20]</a>. This collaboration is a new "muscle" for the company, but one that consistently leads to "awesome" results <a class="yt-timestamp" data-t="00:47:53">[00:47:53]</a>.

The future of product teams across industries is likely to include "quasi researcher-machine learning engineer types" as a core part of every team, as fine-tuning models will become a standard workflow for building most products <a class="yt-timestamp" data-t="00:58:37">[00:58:37]</a>. This highlights the [[impact_of_ai_on_product_teams | impact of AI on product teams]].

### AI's Impact on Internal Workflows

Internally, AI is heavily utilized for daily tasks like summarizing and writing documents, and even helping to write evals <a class="yt-timestamp" data-t="00:53:54">[00:53:54]</a>. However, there's a recognition that workflows could be even more transformed <a class="yt-timestamp" data-t="00:54:31">[00:54:31]</a>.

A significant shift is "vibe coding," where models assist in rapidly generating code for prototypes and proofs of concept <a class="yt-timestamp" data-t="00:55:01">[00:55:01]</a>. Instead of detailed Figma designs, teams can quickly spin up functional prototypes, even by non-engineers <a class="yt-timestamp" data-t="00:54:57">[00:54:57]</a>. This involves a back-and-forth interaction, allowing the model to "let go of the wheel" and generate code based on prompts and error messages, leading to rapid exploration of ideas <a class="yt-timestamp" data-t="00:56:11">[00:56:11]</a>. This has a significant [[impact_of_ai_on_software_development | impact of AI on software development]].

The concept of "fine-tuned models" and "ensembles of models" is critical for internal operations and [[enterprise_ai_solutions_and_user_adaptation | enterprise AI solutions and user adaptation]] <a class="yt-timestamp" data-t="00:59:57">[00:59:57]</a>. Instead of using a single general model for all tasks, problems are broken down into specific sub-tasks, each handled by a specialized or fine-tuned model <a class="yt-timestamp" data-t="01:00:38">[01:00:38]</a>. For example, customer support leverages various models of different sizes and with custom prompts, allowing for automation of routine queries while escalating complex ones to humans, whose answers then serve as fine-tuning data <a class="yt-timestamp" data-t="01:01:50">[01:01:50]</a>. This parallels how a company (an "ensemble of models") groups humans with diverse skills to solve problems <a class="yt-timestamp" data-t="01:02:56">[01:02:56]</a>.

### Human Analogy in AI Product Design

A counterintuitive learning in [[developing_ai_products_and_utilizing_technology | developing AI products and utilizing technology]] is that one can often reason about AI products and phenomena by drawing analogies to human behavior <a class="yt-timestamp" data-t="00:36:31">[00:36:31]</a>. For instance, when designing the UI for a "reasoning model" that takes time to think, the team considered how a human would behave when pondering a complex question (e.g., occasional updates like "Huh, that's a good question") <a class="yt-timestamp" data-t="00:38:08">[00:38:08]</a>. Similarly, combining multiple models to tackle a problem, with another model integrating their outputs, resembles human brainstorming <a class="yt-timestamp" data-t="00:38:54">[00:38:54]</a>.

The prevalence of chat interfaces for LLMs is also understood through a human analogy. Chat is incredibly versatile and universal, mirroring how humans communicate without rigid interfaces <a class="yt-timestamp" data-t="00:41:35">[00:41:35]</a>. This unstructured communication method allows for maximum bandwidth and understanding of complex nuances, making it an ideal fit for the power of LLMs <a class="yt-timestamp" data-t="00:42:08">[00:42:08]</a>.

## Future Outlook and Societal Impact

Despite [[challenges_and_lessons_in_building_a_business_around_ai_tools | challenges and lessons in building a business around AI tools]], there is a strong optimistic view for the future.

### Key Skills for the AI Era

For future generations, the focus should be on teaching children curiosity, independence, self-confidence, and how to think <a class="yt-timestamp" data-t="01:05:40">[01:05:40]</a>. These skills are deemed crucial regardless of how the future workforce evolves <a class="yt-timestamp" data-t="01:05:50">[01:05:50]</a>.

One of the most significant potential impacts of AI is personalized tutoring, which is free via tools like Chat GPT <a class="yt-timestamp" data-t="01:07:08">[01:07:08]</a>. Research suggests that combining classroom education with personalized tutoring can lead to "multiple standard deviation improvements in learning speed" <a class="yt-timestamp" data-t="01:07:23">[01:07:23]</a>. AI also serves as an excellent reskilling app, capable of teaching a wide array of new subjects <a class="yt-timestamp" data-t="01:09:35">[01:09:35]</a>.

### Optimism for the Future

Technology is seen as a primary driver of societal advancements over the last 200 years, leading to economic and geopolitical progress, improved quality of life, and longevity <a class="yt-timestamp" data-t="01:08:28">[01:08:28]</a>. While acknowledging potential temporary dislocations and individual impacts, the long-term outlook for AI is overwhelmingly optimistic <a class="yt-timestamp" data-t="01:09:02">[01:09:02]</a>. Society must work to ensure a graceful and well-supported transition for all individuals <a class="yt-timestamp" data-t="01:09:50">[01:09:50]</a>.

AI is poised to transform creative work by allowing individuals to explore more possibilities and achieve better final results, as seen with image generation and video models like Sora <a class="yt-timestamp" data-t="01:13:08">[01:13:08]</a>. AI enhances human creativity rather than replacing it <a class="yt-timestamp" data-t="01:13:16">[01:13:16]</a>.

The pace of AI advancement is accelerating; new "O-series" models are released every 3-4 months, each representing a significant step up in capability <a class="yt-timestamp" data-t="01:15:33">[01:15:33]</a>. Concurrently, AI models are becoming cheaper (e.g., 100x cost reduction for GPT-40 Mini compared to earlier models) <a class="yt-timestamp" data-t="01:15:58">[01:15:58]</a>, faster, and safer (less hallucination) <a class="yt-timestamp" data-t="01:16:19">[01:16:19]</a>. This exponential growth, far steeper than Moore's Law, suggests a future profoundly different from today <a class="yt-timestamp" data-t="01:16:31">[01:16:31]</a>.

## Conclusion

The interplay of AI and traditional business approaches means a paradigm shift where agility, iterative deployment, and a deep understanding of evolving model capabilities are paramount. Companies must foster high-agency teams, integrate research and product functions, and continually adapt their internal workflows. While the future holds uncertainty, the prevailing sentiment is one of optimism, with AI poised to drive unprecedented advancements and reshape human potential.