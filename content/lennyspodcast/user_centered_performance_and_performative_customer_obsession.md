---
title: User centered performance and performative customer obsession
videoId: L6RKi9ZvkT4
---

From: [[lennyspodcast]] <br/> 

## What is User-Centered Performance?

User-centered performance refers to customer obsession or user-centered practice that is symbolic rather than focused on learning <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. It is work done to signal how customer-obsessed a team or individual is, not necessarily because they want to make a different decision <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>. This phenomenon is extremely common <a class="yt-timestamp" data-t="00:00:21">[00:00:21]</a>.

**Explicit Examples:**
*   A Product Manager (PM) asking a researcher to run a quick user study at the end of a product process "just to validate assumptions" <a class="yt-timestamp" data-t="00:00:23">[00:00:23]</a>. At this stage, it's often too late to matter, and the PM just wants to "check the box" before shipping <a class="yt-timestamp" data-t="00:00:32">[00:00:32]</a>.
*   "Check the box" style research is a clear example of user-centered performance <a class="yt-timestamp" data-t="00:25:17">[00:25:17]</a>.
*   Executive listening sessions or focus groups, where PMs, founders, product people, or designers want to "get close to the customer" <a class="yt-timestamp" data-t="00:25:25">[00:25:25]</a>. This is often 97% performance, well-intentioned but not focused on learning or driving better outcomes <a class="yt-timestamp" data-t="00:25:39">[00:25:39]</a>.

**Implicit Examples:**
*   A lot of user-centered performance comes down to cognitive biases, confirmation bias, and ego <a class="yt-timestamp" data-t="00:25:52">[00:25:52]</a>. Many PMs and designers are looking to *validate* their ideas rather than being open to being proven wrong <a class="yt-timestamp" data-t="00:00:45">[00:00:45]</a>. The ideal mindset is to "falsify" assumptions, actively looking to be wrong <a class="yt-timestamp" data-t="00:00:39">[00:00:39]</a>.

## The User Research Reckoning and its Connection

The field of user research is currently undergoing a "reckoning," partly evidenced by significant layoffs in user experience (UX) and UX research teams <a class="yt-timestamp" data-t="00:01:27">[00:01:27]</a>, <a class="yt-timestamp" data-t="00:07:43">[00:07:43]</a>. This signals that the system might be broken, and research may not be driving the value or impact it should <a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a>. One core reason is that too much of the "wrong type of research" is being conducted <a class="yt-timestamp" data-t="00:08:50">[00:08:50]</a>.

Historically, the ease of money (zero interest rates phenomenon) allowed companies to hire many researchers without properly integrating them or setting them up for success <a class="yt-timestamp" data-t="00:11:32">[00:11:32]</a>. Research was often treated as a service function, leading to reactive work with less impact <a class="yt-timestamp" data-t="00:11:46">[00:11:46]</a>, <a class="yt-timestamp" data-t="00:16:24">[00:16:24]</a>.

## Distinguishing Research Types (Macro, Middle, Micro)

A framework categorizes research into three types:

*   **Macro Research:** Big-picture, strategic, business-focused, forward-looking, and innovation-driven <a class="yt-timestamp" data-t="00:09:09">[00:09:09]</a>. This includes understanding market and competitors, long-term product direction, strategic planning, and total addressable market (TAM) studies <a class="yt-timestamp" data-t="00:09:13">[00:09:13]</a>, <a class="yt-timestamp" data-t="00:12:23">[00:12:23]</a>. It's often tied to annual planning processes <a class="yt-timestamp" data-t="00:34:52">[00:34:52]</a>.
*   **Micro Research:** Highly technical usability research focused on enabling a high-quality, pixel-perfect product <a class="yt-timestamp" data-t="00:09:22">[00:09:22]</a>. It includes laser-focused research to understand A/B test results <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>. This type of research can go very fast and derive significant business value, such as improving conversion rates by fixing a "multi-million dollar button" <a class="yt-timestamp" data-t="00:35:16">[00:35:16]</a>.
*   **Middle-Range Research:** This "blob place" involves research questions that are "middle altitude," often focused on user understanding <a class="yt-timestamp" data-t="00:09:38">[00:09:38]</a>. It typically involves asking groups of people about their thoughts, feelings, behaviors, or product usage <a class="yt-timestamp" data-t="00:09:54">[00:09:54]</a>.

## The Pitfalls of Middle-Range Research

While often interesting to researchers, middle-range research can be devastatingly unimpactful for the business <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>. This type of research often leads to:
*   Results that are interesting but hard to operationalize <a class="yt-timestamp" data-t="00:10:46">[00:10:46]</a>.
*   Post-hoc bias, where people confidently claim they "knew that already" <a class="yt-timestamp" data-t="00:10:53">[00:10:53]</a>.
*   Fulfilling a need to *feel* customer-obsessed or user-centered without actually changing anything <a class="yt-timestamp" data-t="00:11:03">[00:11:03]</a>.
*   Delays in decision-making, as teams wait for research answers <a class="yt-timestamp" data-t="00:13:42">[00:13:42]</a>.
*   PMs and product teams relying on research to avoid making decisions on their own <a class="yt-timestamp" data-t="00:13:47">[00:13:47]</a>.

Product managers often ask for middle-range research to justify decisions they are reluctant to make themselves <a class="yt-timestamp" data-t="00:26:45">[00:26:45]</a>. Designers may ask for it because it fits their model of what a proper design process should look like <a class="yt-timestamp" data-t="00:26:50">[00:26:50]</a>. Executives may ask for it because they don't fully understand research's purpose, using it for performative user-centeredness <a class="yt-timestamp" data-t="00:26:55">[00:26:55]</a>. Ultimately, decisions may still be based on personal opinions <a class="yt-timestamp" data-t="00:27:03">[00:27:03]</a>.

## Common Tropes and Misconceptions

Researchers often hear common tropes from product teams that highlight misunderstandings about [[Importance of Customer and User Research | user research]]:
*   **"Research just slows us down" / "Research is too slow."** Good research can be done in a day, a week, or a month, depending on the need <a class="yt-timestamp" data-t="00:34:01">[00:34:01]</a>. Getting it wrong and having to fix it is often slower than taking time to get it right initially <a class="yt-timestamp" data-t="00:34:24">[00:34:24]</a>. Quick micro-level research can drive significant business value <a class="yt-timestamp" data-t="00:35:16">[00:35:16]</a>.
*   **"I can do my own research; why do I need researchers?"** While product people should engage with customers, talking to users does not automatically constitute effective research or insights <a class="yt-timestamp" data-t="00:39:13">[00:39:13]</a>. A professional researcher knows how to extract core insights, handle idiosyncrasies, and avoid bias from limited samples <a class="yt-timestamp" data-t="00:39:33">[00:39:33]</a>.
*   **"A/B test everything."** A/B tests are great for making causal claims about products but rarely explain *why* something happened <a class="yt-timestamp" data-t="00:40:12">[00:40:12]</a>, <a class="yt-timestamp" data-t="00:41:33">[00:41:33]</a>. Speculating on reasons after an A/B test can lead to endless cycles <a class="yt-timestamp" data-t="00:40:30">[00:40:30]</a>. [[Effective Customer Interaction and Feedback Gathering | User research]] can quickly provide insights into the "how" and "why," preventing future mistakes <a class="yt-timestamp" data-t="00:40:45">[00:40:45]</a>.
*   **The apocryphal Henry Ford quote about horses:** The quote "If I'd asked my users, they would have said faster horses" is widely used but likely never said by Ford <a class="yt-timestamp" data-t="00:42:27">[00:42:27]</a>. More importantly, it misrepresents research; good researchers do not simply ask customers what they want <a class="yt-timestamp" data-t="00:42:56">[00:42:56]</a>.
*   **"We knew this already" / "That was obvious."** This is related to post-hoc bias and hindsight bias <a class="yt-timestamp" data-t="00:43:18">[00:43:18]</a>. The book *Everything is Obvious If You Already Know the Answer* by Duncan Watts discusses how intuition can lead astray, selectively remembering things and constructing narratives that make us feel like we already knew something <a class="yt-timestamp" data-t="00:43:37">[00:43:37]</a>.

## Cultivating Genuine Customer Obsession

To move beyond performative customer obsession, companies and researchers need to adapt:

**For Researchers:**
*   **Develop diverse research skills:** Great researchers are multi-method, possessing five key tools:
    1.  Formative or generative user experience research (looking ahead, innovation-focused, open-ended, ethnographic) <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>.
    2.  Evaluative research (usability testing, micro-level analysis) <a class="yt-timestamp" data-t="00:18:28">[00:18:28]</a>.
    3.  Rigorous survey design <a class="yt-timestamp" data-t="00:18:35">[00:18:35]</a>.
    4.  Applied statistics (understanding A/B testing, basic stats) <a class="yt-timestamp" data-t="00:18:46">[00:18:46]</a>.
    5.  Technical skills like SQL for querying data, or prompt engineering for interacting with generative AI <a class="yt-timestamp" data-t="00:19:01">[00:19:01]</a>.
*   **Go deep on business knowledge:** Understand company strategy, OKRs, metrics, and conversion funnels <a class="yt-timestamp" data-t="00:22:20">[00:22:20]</a>. Propose research questions aligned with business problems, speaking the language of the business <a class="yt-timestamp" data-t="00:22:30">[00:22:30]</a>.
*   **Build strong relationships:** Researchers need to be consistently engaged in the product process from beginning to end <a class="yt-timestamp" data-t="00:14:40">[00:14:40]</a>. They should be in the room, participating in conversations to help frame the right questions for maximum business impact <a class="yt-timestamp" data-t="00:15:09">[00:15:09]</a>. A strong metric for a researcher's success is when decision-making meetings cannot happen without them <a class="yt-timestamp" data-t="00:32:04">[00:32:04]</a>.
*   **Learn to say no:** Researchers often work on too many projects, leading to burnout and lower quality work <a class="yt-timestamp" data-t="00:48:30">[00:48:30]</a>. Prioritization with partners is crucial <a class="yt-timestamp" data-t="00:48:44">[00:48:44]</a>.
*   **Be excellent communicators:** Communicate effectively, tailoring the message to the audience <a class="yt-timestamp" data-t="01:02:53">[01:02:53]</a>.

**For Companies and Product Managers:**
*   **Integrate research early and consistently:** Avoid treating research as a service function called in at the end <a class="yt-timestamp" data-t="00:15:04">[00:15:04]</a>. Instead, build a process where research is a part of product development from inception to launch <a class="yt-timestamp" data-t="00:14:40">[00:14:40]</a>. This fosters consistent relationships and allows researchers to drive maximum impact <a class="yt-timestamp" data-t="00:14:40">[00:14:40]</a>.
*   **Align success metrics:** Product managers, engineers, designers, and researchers should all share the same set of metrics for success <a class="yt-timestamp" data-t="00:31:51">[00:31:51]</a>.
*   **Foster a "falsify" mindset:** Encourage teams to seek evidence that disproves assumptions, rather than merely validating them <a class="yt-timestamp" data-t="00:26:00">[00:26:00]</a>.
*   **Protect researcher's time:** A researcher's full plate might be two big projects and one small side project <a class="yt-timestamp" data-t="00:51:52">[00:51:52]</a>.
*   **Reduce silos across insights disciplines:** Instead of having separate teams for UX research, market research, data science, customer service feedback, etc., aim to create an integrated insights function <a class="yt-timestamp" data-t="00:49:50">[00:49:50]</a>. This prevents an overwhelming amount of disconnected information from being thrown at product teams <a class="yt-timestamp" data-t="00:49:57">[00:49:57]</a>.
*   **Balance intuition with evidence:** While intuition is valuable, it's also where biases and blind spots lie <a class="yt-timestamp" data-t="00:27:11">[00:27:11]</a>. Engage "System 2" thinking (slow, methodical analysis) to check intuition <a class="yt-timestamp" data-t="00:30:36">[00:30:36]</a>. Leverage the "wisdom of the crowd" by bringing in diverse sources of information and judgment <a class="yt-timestamp" data-t="00:30:58">[00:30:58]</a>.
*   **Partner with researchers on prioritization:** Help researchers focus on the most important things <a class="yt-timestamp" data-t="00:52:02">[00:52:02]</a>.
*   **Invest in [[Effective Customer Engagement and Validation | Effective Customer Engagement and Validation]] from early stages:** Even startups with 10 employees can benefit significantly from a researcher to provide the "Swiss army knife" of tools, helping with major iterations or pivots <a class="yt-timestamp" data-t="00:59:33">[00:59:33]</a>.

## The Flaws of NPS

The Net Promoter Score (NPS) is critiqued as an example of marketing marketing itself <a class="yt-timestamp" data-t="01:03:57">[01:03:57]</a>. According to survey science, NPS makes several mistakes:
*   The "likelihood to recommend" question is flawed <a class="yt-timestamp" data-t="01:04:20">[01:04:20]</a>.
*   It uses a 0-10 scale that is often unlabeled, which is not a gold standard <a class="yt-timestamp" data-t="01:04:28">[01:04:28]</a>.
*   Precision of results decreases on scales with more than five to seven items <a class="yt-timestamp" data-t="01:04:38">[01:04:38]</a>.
*   The question itself might be fundamentally flawed (e.g., "How likely are you to recommend Windows 11 to your friends and family?") <a class="yt-timestamp" data-t="01:05:00">[01:05:00]</a>.
*   Customer satisfaction (CSAT) is a simpler, better metric, with better data properties, more precision, and stronger correlation to business outcomes <a class="yt-timestamp" data-t="01:05:17">[01:05:17]</a>.
*   While NPS is used for benchmarking, research shows it's idiosyncratic and inconsistent, making apples-to-apples comparisons unreliable <a class="yt-timestamp" data-t="01:06:22">[01:06:22]</a>.

## Dogfooding and User Blind Spots

While it's important for product teams to dogfood their own products (use them as a typical user would), there's a significant caveat: product managers are often nothing like their users <a class="yt-timestamp" data-t="01:07:20">[01:07:20]</a>.
*   A PM's own usage can bias their perception of what's good or bad <a class="yt-timestamp" data-t="01:07:44">[01:07:44]</a>.
*   Some product problems require insights into a user's context of use, priorities, and constraints that a PM simply cannot imagine from their own perspective <a class="yt-timestamp" data-t="01:08:03">[01:08:03]</a>.
*   Dogfooding is great for identifying a list of potential issues, but prioritizing that list and understanding *for whom* those issues are problems requires external validation <a class="yt-timestamp" data-t="01:08:24">[01:08:24]</a>. It's crucial to be wary of relying solely on intuition for prioritization <a class="yt-timestamp" data-t="01:08:32">[01:08:32]</a>.

## Advice for Researchers and Companies

The user research discipline is undergoing an evolution <a class="yt-timestamp" data-t="01:07:41">[01:07:41]</a>. It's not about blaming researchers for past challenges, but empowering them and companies to move forward <a class="yt-timestamp" data-t="01:02:10">[01:02:10]</a>.
*   Researchers should own their development, pushing back on unproductive research requests and focusing on high-value, impactful work <a class="yt-timestamp" data-t="01:02:39">[01:02:39]</a>.
*   Companies should prioritize creating a new, inclusive model that deeply integrates researchers into lean, unified product processes <a class="yt-timestamp" data-t="01:03:34">[01:03:34]</a>.
*   The future for the discipline is bright, provided both sides contribute to this evolution <a class="yt-timestamp" data-t="01:03:28">[01:03:28]</a>.