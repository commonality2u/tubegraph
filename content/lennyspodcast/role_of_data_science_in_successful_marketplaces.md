---
title: Role of data science in successful marketplaces
videoId: BVzTfsUMaK8
---

From: [[lennyspodcast]] <br/> 

Ramesh Johari, a professor at Stanford University, conducts research and teaches data science methods focusing specifically on the [[design_and_operation_of_online_marketplaces | design and operation of online marketplaces]] <a class="yt-timestamp" data-t="01:10:59">[01:10:59]</a>. He has advised and worked with major marketplaces globally, including Airbnb, Uber, Stripe, Bumble, Stitch Fix, and Upwork <a class="yt-timestamp" data-t="01:14:00">[01:14:00]</a>.

## Understanding Marketplace Businesses

A common misconception is that companies like Airbnb sell rooms or Uber sells rides <a class="yt-timestamp" data-t="05:56:00">[05:56:00]</a>. While users interact with these platforms to obtain such services, the platforms themselves sell something different: they sell the removal of friction <a class="yt-timestamp" data-t="06:35:00">[06:35:00]</a>. This friction includes the difficulty of finding a place to stay or a driver <a class="yt-timestamp" data-t="06:38:00">[06:38:00]</a>. In economics, this is referred to as taking away "transaction costs" <a class="yt-timestamp" data-t="06:44:00">[06:44:00]</a>.

Marketplaces address "market failures" where potential buyers and sellers cannot easily connect due to lack of information or trust <a class="yt-timestamp" data-t="06:58:00">[06:58:00]</a>. This implies that both sides of a marketplace – buyers (guests, riders) and sellers (hosts, drivers) – are customers of the platform, as both depend on the platform to remove friction and facilitate transactions <a class="yt-timestamp" data-t="07:41:00">[07:41:00]</a>.

## Data Science as the Core of Marketplace Operation

The ability to constantly architect and rearchitect marketplaces using technology means that [[design_and_operation_of_online_marketplaces | data and data science]] are central to their success <a class="yt-timestamp" data-t="09:01:00">[09:01:00]</a>. Data science supports the fundamental [[design_and_operation_of_online_marketplaces | marketplace flywheel of growth]] <a class="yt-timestamp" data-t="01:31:00">[01:31:00]</a> by addressing three core problems:

1.  **Finding Matches**: Helping users (e.g., guests on Airbnb, job seekers on Upwork) find suitable counterparts (e.g., listings, jobs) <a class="yt-timestamp" data-t="09:31:00">[09:31:00]</a>.
2.  **Making Matches**: Assisting in the selection process once potential matches are found (e.g., choosing a freelancer from multiple applicants) <a class="yt-timestamp" data-t="09:51:00">[09:51:00]</a>.
3.  **Learning About Matches**: Collecting feedback and data from completed transactions to improve future matching and platform functionality <a class="yt-timestamp" data-t="10:18:00">[10:18:00]</a>. This includes active data collection (e.g., star ratings) and passive data collection (e.g., early departures from bookings) <a class="yt-timestamp" data-t="10:32:00">[10:32:00]</a>.

These three areas are continuously fed back into the system, enabling better [[design_and_operation_of_online_marketplaces | algorithms and data science]] to take away friction <a class="yt-timestamp" data-t="11:00:00">[11:00:00]</a>.

## Challenges for Marketplace Founders

A common [[challenges_in_starting_and_scaling_marketplace_businesses | challenge in starting and scaling marketplace businesses]] is thinking too much about being a "Marketplace" before actually being one <a class="yt-timestamp" data-t="12:34:00">[12:34:00]</a>. A business is truly a marketplace when it achieves "scaled liquidity" on both sides, meaning it has many buyers and many sellers <a class="yt-timestamp" data-t="23:08:00">[23:08:08]</a>.

If a founder only has scaled liquidity on one side (e.g., many buyers but few sellers), they face a strategic choice:
*   **Lean into growth on the scaled side**: Continue to grow that side of the business without necessarily focusing on building a marketplace <a class="yt-timestamp" data-t="23:51:00">[23:51:00]</a>.
*   **Leverage the scaled side to attract the other**: Use the existing liquidity to subsidize or incentivize the growth of the underserved side, like Uber giving free rides to attract riders when they had many drivers <a class="yt-timestamp" data-t="24:23:00">[24:23:00]</a>.

### The "Founder" Mindset

Johari argues that there shouldn't be a distinct concept of a "Marketplace founder," but rather just "Founders" <a class="yt-timestamp" data-t="17:08:00">[17:08:00]</a>. Virtually any human business endeavor can potentially involve online transactions, making any founder a potential "Marketplace founder" by choice as they grow <a class="yt-timestamp" data-t="17:10:00">[17:10:00]</a>. For example, OpenAI, initially not a marketplace, became one with the introduction of plugins <a class="yt-timestamp" data-t="17:36:00">[17:36:00]</a>.

Founders must consider:
*   **Initial Value Proposition**: When starting without scale, what unique value does the platform offer? UrbanSitter initially solved the friction of babysitters accepting credit card payments, then later shifted to facilitating finding sitters once liquidity was established <a class="yt-timestamp" data-t="13:48:00">[13:48:00]</a>. Upwork (formerly oDesk) initially focused on resolving trust issues for remote work through tracking tools and payment guarantees <a class="yt-timestamp" data-t="15:47:00">[15:47:00]</a>.
*   **Avoiding Over-commitment**: Early business choices, especially regarding monetization models, can tie a company's hands later <a class="yt-timestamp" data-t="18:38:00">[18:38:00]</a>. For example, a constant commission model might lead to "disintermediation" (users bypassing the platform) once trust is established and the platform's value diminishes over long-term relationships <a class="yt-timestamp" data-t="19:17:00">[19:17:17]</a>.

### The Firm vs. Market Question

Sometimes, the best solution to frictions might not be a marketplace model but a "firm" model with tightly controlled labor (employees) <a class="yt-timestamp" data-t="27:02:00">[27:02:00]</a>. This depends on the need for sustained relationships or curation, as seen in Stitch Fix with stylists or healthcare platforms requiring consistent practitioners <a class="yt-timestamp" data-t="27:05:00">[27:05:00]</a>.

## Leveraging Data for Team Efficiency and Impact

A data person's biggest [[leveraging_ai_for_data_team_efficiency | leverage and opportunity]] in a marketplace is to help the business make decisions rooted in causation, not just prediction or correlation <a class="yt-timestamp" data-t="30:02:00">[30:02:00]</a>.

*   **Prediction vs. Causation**: While machine learning models are excellent at predicting patterns from past data (correlation), the real value comes from understanding how interventions cause changes <a class="yt-timestamp" data-t="31:12:00">[31:12:00]</a>. For instance, knowing how much more a customer will spend *because* they received a promotion (causation) is more valuable than just predicting their total lifetime value (correlation) <a class="yt-timestamp" data-t="33:04:00">[33:04:00]</a>.
*   **Focus on Business Metrics**: When evaluating [[design_and_operation_of_online_marketplaces | ranking algorithms]] (e.g., for search or recommendations), the key question is whether one algorithm leads to more bookings or better matches compared to another, not just how well it predicts past user choices <a class="yt-timestamp" data-t="36:46:00">[36:46:00]</a>.

## Experimentation and Learning

Experiments are crucial for understanding causal impacts <a class="yt-timestamp" data-t="40:27:00">[40:27:00]</a>. However, there are common pitfalls:

*   **Micro-optimization**: Over-reliance on experiments can lead to incremental improvements rather than big, transformative opportunities <a class="yt-timestamp" data-t="40:50:00">[40:50:00]</a>.
*   **Risk Aversion**: Companies often test incremental changes and run experiments for too long, partly due to incentives that reward "wins" <a class="yt-timestamp" data-t="41:52:00">[41:52:00]</a>.
*   **"Winners and Losers"**: Many consequential changes in marketplaces create winners and losers, as they reallocate attention and inventory <a class="yt-timestamp" data-t="51:48:00">[51:48:00]</a>. The challenge is recognizing whether the created winners are more important to the business than the losers <a class="yt-timestamp" data-t="51:55:00">[51:55:00]</a>.

To counter these issues, companies should foster a culture where:
*   **Learning is a Win**: Experiments should be hypothesis-driven, focusing on what can be learned about the business, even if the experiment doesn't yield an immediate "win" in metrics <a class="yt-timestamp" data-t="44:03:00">[44:03:00]</a>. This requires leadership to expect more from data scientists than just statistically rigorous reports, encouraging them to discuss business insights <a class="yt-timestamp" data-t="54:47:00">[54:47:00]</a>.
*   **Past Learnings are Incorporated**: Traditional frequentist statistics often disregard past knowledge <a class="yt-timestamp" data-t="55:58:00">[55:58:00]</a>. Bayesian A/B testing can help by integrating "prior beliefs" (from past experiments) with new data to form conclusions, thus rewarding people for contributing information to the collective knowledge <a class="yt-timestamp" data-t="56:25:00">[56:25:00]</a>.
*   **Learning is Costly**: Understanding that "paying to learn" is essential for long-term growth is crucial. For example, holdout groups in marketing campaigns might seem costly in the short term but provide invaluable insights into the team's impact <a class="yt-timestamp" data-t="59:03:00">[59:03:00]</a>.

## Designing Effective Rating Systems

Rating systems face challenges like:
*   **Rating Inflation**: Over time, median ratings tend to inflate due to factors like reciprocity (users don't want to be mean) and norming (a 4-star rating feels bad when the average is 4.8) <a class="yt-timestamp" data-t="01:02:50">[01:02:50]</a>.
    *   **Solution**: Re-norming rating labels (e.g., "exceeded expectations") or asking comparative questions (e.g., "how did this compare to a past highly-rated experience?") can help maintain accuracy <a class="yt-timestamp" data-t="01:03:51">[01:03:51]</a>.
*   **Averaging Issues**: Simply averaging ratings can have significant "distributional consequences" <a class="yt-timestamp" data-t="01:04:45">[01:04:45]</a>. A single negative review can severely impact new sellers, while established sellers are largely unaffected <a class="yt-timestamp" data-t="01:05:05">[01:05:05]</a>.
    *   **Solution**: Incorporating a "prior belief" (e.g., about the general quality of new users) when calculating initial ratings can "pull up" a new user's score, giving them a fairer chance despite early negative feedback <a class="yt-timestamp" data-t="01:06:01">[01:06:01]</a>.

The "Sound of Silence" — the information contained in ratings *not* left — is also highly predictive of future performance <a class="yt-timestamp" data-t="01:07:47">[01:07:47]</a>. Double-blind review systems can increase review rates by incentivizing users to leave a review to see the other party's feedback <a class="yt-timestamp" data-t="01:07:20">[01:07:20]</a>.

## [[Impact_of_AI_on_data_science_and_marketplaces | Impact of AI on Data Science and Marketplaces]]

AI, particularly large language models (LLMs) and generative AI, has expanded the frontier of possible ideas and hypotheses that data scientists can generate and test <a class="yt-timestamp" data-t="01:09:50">[01:09:50]</a>. While AI automates some tasks like coding and visualization, it places *more* pressure on human data scientists, not less <a class="yt-timestamp" data-t="01:10:10">[01:10:10]</a>. Humans become more crucial in funneling down the astronomical explosion of explanations and ideas to identify what truly matters for the business <a class="yt-timestamp" data-t="01:10:18">[01:10:18]</a>. This shift emphasizes the need for increased [[the_role_of_ai_in_shaping_product_management_skills | data literacy]] among all individuals interacting with these tools <a class="yt-timestamp" data-t="01:22:38">[01:22:38]</a>.