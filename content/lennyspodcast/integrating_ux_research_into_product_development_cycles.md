---
title: Integrating UX research into product development cycles
videoId: L6RKi9ZvkT4
---

From: [[lennyspodcast]] <br/> 

User-centered performance describes a practice of "customer obsession" or "user-centered" approaches that are symbolic rather than focused on learning, often signaling how customer-obsessed a team is without aiming to make different decisions [00:00:00]. This phenomenon is extremely common [00:00:21].

## The State of UX Research Today

The user research field is currently undergoing a "reckoning," necessitating significant changes within the field itself and in how companies [[leveraging_user_insights_for_product_development | leverage user research]] moving forward [00:01:22]. Over the last decade, the user research field has made missteps, with Product Managers (PMs) and designers too often relying on user research to answer the wrong questions [00:01:38]. This situation has contributed to widespread layoffs in UX and UX research, indicating a potentially broken system where research isn't delivering the value or impact it should [00:08:00].

Much of the current practice involves the "wrong type of research" [00:08:47]. During the "zero interest rates phenomenon" era, companies hired many researchers with good intentions but often failed to properly integrate them, setting them up as a service function [00:11:32].

### Three Types of Research

Jud Anon categorizes user research into three types based on their focus and altitude [00:08:57]:

*   **Macro Research** <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>: This involves big-picture, strategic, business-focused, and forward-looking work. It includes innovation, market analysis, competitor review, and long-term research to guide product direction. It should be involved in strategic planning and total addressable market (TAM) studies [00:09:09]. This type of research should ideally be tied to annual planning processes, like "concept car projects" that synthesize a year's worth of insights to develop future product visions [00:34:49].
*   **Middle-Range Research** <a class="yt-timestamp" data-t="00:09:38">[00:09:38]</a>: This category occupies a "blob place" where research questions are of "middle altitude" [00:09:41]. It often focuses on understanding user thoughts, feelings, and behaviors related to product usage [00:09:54]. Examples include understanding how users feel about specific features like payment options [00:12:45]. While interesting, this type of research is often not impactful enough for the business, can be hard to operationalize, and triggers post-hoc bias where findings seem obvious in hindsight [00:10:04]. It often fulfills a performative need for teams to appear customer-obsessed without driving actual change [00:11:03]. This "middle research zone" is often what slows down development [00:37:31].
*   **Micro Research** <a class="yt-timestamp" data-t="00:09:19">[00:09:19]</a>: This is highly technical usability research focused on enabling a high-quality, pixel-perfect product [00:09:22]. It includes laser-focused research to understand A/B test results [00:09:30]. Micro research can provide significant business value quickly, sometimes yielding results in 48 hours [00:35:16]. An example is changing a button's text based on research to significantly improve conversion [00:35:30]. This type of research, which identifies and solves problems with functionality to improve business metrics, should be much more common and is not "scut work" for junior researchers [00:37:57].

## Integrating User Research for Impact

The solution to the current challenges involves restructuring how products are made, [[integrating_customer_feedback_loops_in_product_development | integrating user research]] much more fully from beginning to end [00:14:32]. This means fostering consistent relationships where researchers and their insights are an integral part of the process [00:14:40]. When research is treated as a service function, called in reactively at the end of a product process, it leads to less impact because researchers have less input on the questions asked and are unable to build direct relationships or participate in decisions [00:15:04].

A vicious cycle has emerged: companies hire researchers with good intentions, but don't integrate them well, leading to reactive and less impactful research. This causes executives to conclude that researchers are not impactful, leading to sidelining or layoffs [00:15:59]. To break this cycle, constant engagement of researchers within the product process is crucial [00:17:09]. When a skilled researcher is consistently involved, they can drive product improvement, metrics impact, and growth [00:17:14].

### Qualities of Effective UX Researchers

The best researchers are multi-method, possessing a "Swiss army knife" of skills [00:17:44]:

1.  **Formative or Generative User Experience Research** <a class="yt-timestamp" data-t="00:18:11">[00:18:11]</a>: Forward-looking, innovation-focused, open-ended, and ethnographic methods (e.g., observing users in their environment) [00:18:13].
2.  **Evaluative Research** <a class="yt-timestamp" data-t="00:18:28">[00:18:28]</a>: Focused on usability testing and evaluating existing products, typically at the micro-level [00:18:30].
3.  **Rigorous Survey Design** <a class="yt-timestamp" data-t="00:18:35">[00:18:35]</a>: The best scaled method for gathering responses from communities of any size [00:18:37].
4.  **Applied Statistics** <a class="yt-timestamp" data-t="00:18:46">[00:18:46]</a>: Essential for understanding A/B testing and interacting with quantitative data [00:18:49].
5.  **Technical Skills (SQL/Prompt Engineering)** <a class="yt-timestamp" data-t="00:19:01">[00:19:01]</a>: Ability to run queries, understand data, and interact with generative AI [00:19:01].

When [[how_to_evaluate_and_hire_effective_ux_researchers | interviewing candidates]], look for those who propose multi-method approaches to open-ended research questions, demonstrating a versatile toolkit rather than a single approach [00:20:21]. While individuals may specialize, a strong team should collectively cover all these areas [00:20:50].

### Business Acumen for Researchers

Researchers need to be much more business-oriented, focusing on the overlap between user needs and business goals (profit) [00:21:13]. This means understanding business language, reading quarterly reports and shareholder calls, and scouring internal documents for strategy, OKRs, metrics, and conversion funnels [00:22:00]. By understanding the business deeply, researchers can propose relevant research questions that drive maximum business and product improvement [00:22:33].

### User-Centered Performance: A Damaging Phenomenon

[[Customer engagement and product development | User-centered performance]] is a phenomenon where individuals act like they care about the user but are doing it "for show," having already decided what they want to do [00:02:04].

*   **Explicit Examples:**
    *   PMs asking for a "quick user study" at the end of a product process "just to validate our assumptions." This is too late for learning; the PM isn't interested in being wrong [00:24:53]. Any "check the box" research falls into this category [00:25:15].
    *   Executive listening sessions: While well-intentioned, these are often 97% performance and not focused on learning or driving better outcomes [00:25:27].
*   **Implicit Examples:**
    *   Cognitive biases and ego, leading to confirmation bias [00:25:52].
    *   The desire to "validate" rather than "falsify" hypotheses. A good mindset is to actively seek to be wrong in research [00:26:00].
*   **Impact:** This performative user-centeredness is damaging because it sidesteps genuine learning and makes research easily sidelined [00:28:48].

PMs, designers, and executives can all engage in user-centered performance [00:26:43]. Product Managers may ask for middle-range research to justify decisions they are reluctant to make themselves [00:26:45]. Designers might request it because it aligns with their model of a "proper design process" [00:26:50]. Executives, often not understanding the purpose of research, may ask for it to perform user-centeredness, ultimately deciding based on their own opinions [00:26:55].

### Countering Biases and Improving Decisions

While intuition is important in product development, it's also where biases and blind spots lie [00:27:08]. Good researchers expose these biases and help expand horizons, constantly improving intuition [00:27:29].

To check intuition, engage in "System Two" thinking â€“ a slow, methodical analytical process [00:30:36]. Additionally, leverage the "wisdom of the crowd" by bringing in diverse sources of information and judgment from different individuals, such as other PMs, designers, and researchers [00:30:58].

### Common Tropes and Misconceptions about Research

Jud Anon addresses several common misconceptions PMs and others have about research:

*   **"Research just slows us down" / "Research is too slow."** <a class="yt-timestamp" data-t="00:33:52">[00:33:52]</a>: A good research team can deliver results in a day, week, or month, depending on the need [00:34:01]. Good research actually speeds up the process by preventing mistakes and rework later [00:34:32]. Micro-level research, for example, can be very fast and yield significant business value [00:35:16].
*   **"I can do my own research; why do I need researchers?"** <a class="yt-timestamp" data-t="00:39:03">[00:39:03]</a>: While anyone can talk to a user, that doesn't constitute research or insights work. One user can be idiosyncratic, and a researcher knows how to extract meaningful insights, avoid bias, and properly situate conversations within a broader context [00:39:22].
*   **"A/B test everything."** <a class="yt-timestamp" data-t="00:40:08">[00:40:08]</a>: A/B tests are great for making causal claims but rarely explain *why* something happened [00:40:12]. Without understanding the *why*, teams can fall into an endless cycle of speculation and further A/B tests [00:40:30]. Research provides the "how and why," which is essential for building better products and avoiding future mistakes [00:41:40]. Strong partnerships between data scientists and researchers are crucial for both causal relationships and understanding underlying reasons [00:41:56].
*   **The Henry Ford quote: "If I'd asked my users, they would have said faster horses."** <a class="yt-timestamp" data-t="00:42:25">[00:42:25]</a>: This quote is apocryphal [00:42:31] and fundamentally misrepresents what researchers do. Good researchers do not simply ask customers what they want [00:42:56]; instead, they uncover underlying needs and problems.
*   **"We knew this already; that was obvious." (Post-hoc bias)** <a class="yt-timestamp" data-t="00:43:18">[00:43:18]</a>: This relates to hindsight bias, where people selectively remember things and construct narratives that make findings seem obvious after the fact [00:43:55]. This "narrative fallacy" is a form of self-gaslighting that prevents genuine learning [00:44:07].

### Optimal Research Integration and Team Structure

For maximum impact, research teams should not have separate OKRs. Instead, the entire product team (PMs, engineers, designers, researchers) should share the same set of success metrics [00:31:51]. A key metric for a researcher's success is when the team "cannot have that decision-making meeting without the researcher there" [00:32:09], indicating strong trust, influence, and active participation.

The product-research relationship is often challenging because researchers are not consistently included in the PM's process [00:33:00]. This leads to product managers asking middle-range questions when they haven't deeply engaged with researchers [00:14:15].

Companies should stop siloing different insights disciplines (e.g., UX research, consumer insights, market research, data science, customer service feedback) [00:49:31]. Integrating these insights into a unified "insights machine" provides a more comprehensive understanding and prevents overwhelming product teams with disparate data [00:50:00].

Companies should also integrate researchers into a unified, lean process [00:50:40]. If researchers are not arm-in-arm with product teams from the beginning, they will remain a service discipline, leading to less value and delayed impact [00:51:01].

### How Product Managers Can Be Better Partners

PMs can be better partners by:

*   Creating a product development process that [[incorporating_user_feedback_into_product_development | integrates user researchers]] and insights from beginning to end [00:51:35].
*   Partnering with researchers on "ruthless prioritization" [00:51:44]. A researcher's "full plate" is usually two big projects and one small project [00:51:52].
*   Taking the time to engage with researchers, even going into the field for studies [00:52:09].
*   Understanding that they are "nothing like the user" [01:07:41]. While dogfooding products and conducting walkthroughs to identify potential issues is valuable, PMs should be wary of relying on their own intuition to prioritize problems or understand user contexts and constraints [01:07:51].

### The Future of User Research

The future of research is bright, but it requires an evolution [01:02:27]. Researchers need to develop diverse skills, deepen their business knowledge, and learn to communicate insights like a scalpel [01:04:47]. They must also build strong relationships with partners and learn to say "no" to focus on the most important work [01:02:20]. Companies, in turn, need to create more inclusive models that fully integrate researchers [01:03:36].

At startups, hiring an early researcher with a "Swiss army knife" of tools can provide immense value by helping avoid missteps, validate assumptions, or facilitate pivots, rather than relying solely on founder intuition [00:59:14]. A good researcher can make a company go faster and drive impact by answering questions that are impossible to answer otherwise [00:59:18].

### The Flawed Nature of NPS

Net Promoter Score (NPS) is considered a flawed metric by survey scientists [01:04:14]. Its "likelihood to recommend" question is problematic due to its 0-10 scale, often unlabeled points, and 11-item range (precision decreases after five to seven items) [01:04:20]. The question itself is fundamentally flawed as people rarely go around recommending operating systems or similar products [01:05:00].

Instead, a simple customer satisfaction (CSAT) metric (e.g., "Overall, how satisfied are you with your experience?") is better. It has superior data properties, is more precise, and is more correlated to business outcomes [01:05:17]. While many use NPS for benchmarking, research shows it is idiosyncratic and inconsistent, making cross-company comparisons unreliable [01:06:19].