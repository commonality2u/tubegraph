---
title: Pitfalls of usercentered performance and symbolic practices
videoId: L6RKi9ZvkT4
---

From: [[lennyspodcast]] <br/> 

User-centered performance is defined as a practice of "customer obsession or user-centered" approaches that are symbolic rather than genuinely focused on learning [00:00:00]. This type of work is often done to signal to others how customer-obsessed a team or individual is, rather than to genuinely inform different decisions [00:00:09]. This phenomenon is extremely common in product development [00:00:21].

## Manifestations of User-Centered Performance

User-centered performance can appear in both explicit and implicit ways:

### Explicit Examples
*   **Late-Stage Validation Studies**
    *   A common example is when a Product Manager (PM) approaches a researcher at the very end of a product development process, asking for a "quick user study" to "validate assumptions" [00:00:23]. At this point, it's typically too late to genuinely matter or change course, serving merely as a "check the box" exercise [00:00:32].
    *   Any "check the box" style research falls into this category [00:25:17].
*   **Executive Listening Sessions**
    *   Often, executives, founders, PMs, and designers desire to "get close to the customer" [00:25:30]. This leads to requests for activities like focus groups, which, while often well-intentioned, are largely performance-driven and not focused on driving better outcomes or impact [00:25:39].

### Implicit Examples
User-centered performance is often driven by internal factors such as:
*   **Cognitive Biases and Ego**
    *   Confirmation bias plays a significant role, where individuals seek to validate their existing ideas rather than genuinely explore being wrong [00:25:54].
    *   Many PMs and designers are not in a mindset where they want to be proven wrong; instead, they are looking to validate their initial hypotheses [00:26:22].
*   **Perceived Requirements**
    *   The practice of "performing customer centricity" or "performing user centeredness" often occurs when teams are not genuinely interested in learning, but believe it's what they "are supposed to do" [00:23:31]. This stems from popularized methodologies like user-centered design or design thinking [00:28:32], or directives to be "customer obsessed" [00:28:44].

## Pitfalls and Consequences
The prevalence of user-centered performance and symbolic practices leads to several [[challenges_in_strategy_implementation | challenges in strategy implementation]] and overall in product organizations:

*   **Lack of Impactful Learning**
    *   Research conducted for symbolic purposes often yields insights that are "interesting but sometimes hard to operationalize" [00:10:46]. It does not significantly contribute to the business [00:10:09].
    *   It allows teams to "feel and be customer obsessed user centered without changing anything" [00:11:03].
*   **Delay and Inefficiency**
    *   This type of research can "delay everything" as teams wait for answers to make decisions, creating an issue where product teams are reluctant to trust their own judgment [00:13:42].
*   **Misguided Use of Research**
    *   PMs often ask for "middle range research" — questions that are "middle altitude" and focus on general user understanding — primarily to justify decisions they are reluctant to make on their own [00:09:41].
    *   This "blob place" of research often ends up "not driving impact" for the business [00:10:00].
*   **Erosion of Research Value**
    *   When research is utilized as a "service function" and called in reactively at the end of a process, it has less input on crucial questions and cannot build direct relationships to drive impact [00:14:50]. This leads to it being perceived as "less impactful" and contributes to researchers being sidelined or laid off [00:16:56].
*   **Over-reliance on Intuition**
    *   While intuition is important in product development, it is also "where all of those biases lie" [00:27:10]. Relying solely on intuition without evidence from research can lead to blind spots and suboptimal decisions [00:27:22].
    *   The belief that "we knew this already" or that an insight is "obvious" (post-hoc bias) is a form of self-gaslighting that prevents genuine learning and adaptation [00:43:18].
*   **Misconceptions about AB Testing**
    *   Teams may exclusively pursue AB testing, speculating endlessly about *why* results occurred because the tests rarely provide causal explanations [00:40:12]. This can lead to a "endless flywheel of AB testing" without deep understanding [00:40:38].

## Moving Forward
To overcome these pitfalls and move past the "Reckoning" in user research, a shift in mindset and approach is necessary:

*   **Integrated Research**
    *   Researchers should be consistently involved in the product development process from beginning to end [00:14:40].
    *   This allows researchers to help frame the right questions that will drive maximum business and product improvement [00:15:16].
    *   Successful companies should foster "consistent engaged processes" where researchers are protected and empowered, leading to the desire for more research partners due to visible impact [00:57:47].
*   **Business Acumen for Researchers**
    *   Researchers need to be much more business-oriented, focusing on how their work helps the business succeed, not just what users need [00:21:13]. This includes understanding financial reports, company strategies, OKRs, and conversion funnels [00:22:00].
*   **Multi-Method Expertise**
    *   Great researchers possess diverse skills, including formative/generative research, evaluative/usability testing, rigorous survey design, applied statistics, and technical skills like SQL or prompt engineering [00:18:03].
*   **Falsification Mindset**
    *   Instead of seeking to validate assumptions, the mindset should be to "falsify" — actively looking for ways to be wrong in order to improve [00:26:00].
*   **Collaboration and Diverse Perspectives**
    *   Product managers should partner with researchers to ruthlessly prioritize research efforts, ensuring focus on the most impactful questions [00:52:03].
    *   Bringing diverse sources of information and judgment to the table, including researchers, allows for checking intuition and expanding horizons [00:30:11].
    *   The ideal is "beautiful partnerships between data scientists and research and insights people" [00:41:56].
*   **Avoiding Silos**
    *   Companies should integrate all insights disciplines (UX research, market research, data science, customer service feedback) into a unified function to avoid fragmented and overwhelming information for product teams [00:49:57].
*   **Understanding User Uniqueness**
    *   PMs and designers dogfooding their own products is valuable, but they must be "extremely wary of relying on your own sort of opinion expertise or intuition" because they are inherently different from the average user [01:08:32]. Recognizing that "some problems with a product... require like context of use priorities constraints that you just don't have" is crucial [01:08:03].