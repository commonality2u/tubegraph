---
title: Engineering productivity and strategy evaluation
videoId: Z9ftpRhRiJE
---

From: [[lennyspodcast]] <br/> 

The landscape of engineering has significantly transformed, particularly in the shift from the "zero interest rate era" to today's market, where efficiency and strategic focus are paramount <a class="yt-timestamp" data-t="04:13">[04:13]</a>.

## Current Landscape of Engineering

Historically, a large focus for engineering managers was on hiring, with some spending half their time or more on interviews <a class="yt-timestamp" data-t="05:06">[05:06]</a>. This led to learning how to build large teams and hire extensively <a class="yt-timestamp" data-t="05:00">[05:00]</a>. In contrast, the current market sees engineering managers conducting significantly fewer interviews, sometimes as little as two per month or even none <a class="yt-timestamp" data-t="05:27">[05:27]</a>.

This shift means that competencies beyond just hiring have become critical <a class="yt-timestamp" data-t="05:37">[05:37]</a>. An engineering director who was once a top performer primarily due to their hiring prowess may now be perceived as a low performer if they cannot lead the team, delve into details, or help determine the right sizing and allocation of engineering teams <a class="yt-timestamp" data-t="05:47">[05:47]</a>. Teams are now facing consolidation, cuts, and even disappearance, a stark contrast to the previous era of continuous growth <a class="yt-timestamp" data-t="06:15">[06:15]</a>.

## Treating Engineers as Peers

Traditionally, engineers have sometimes been "coddled" or "sheltered" from the real problems of the business, treated "a little bit like children" rather than adults with responsibilities <a class="yt-timestamp" data-t="06:40">[06:40]</a>. This approach was partly due to the emphasis on retention in previous eras, where losing team members was a "huge issue" <a class="yt-timestamp" data-t="07:36">[07:36]</a>.

However, a positive shift is occurring where engineers can now be treated as peers and placed in senior leadership roles, without the baseline assumption that they need to be protected from "real problems" <a class="yt-timestamp" data-t="07:00">[07:00]</a>. This allows for greater accountability and provides opportunities for engineers to grow <a class="yt-timestamp" data-t="07:11">[07:11]</a>. Holding engineers accountable allows them to take on more senior roles, which aligns with their career aspirations <a class="yt-timestamp" data-t="08:21">[08:21]</a>.

## Understanding Systems Thinking in Engineering

[[engineering_leadership_and_management_strategies | Systems thinking]] is a valuable approach for analyzing and improving processes. It involves thinking in terms of "stocks" (things that accumulate, like the number of fish in a lake or potential job candidates) and "flows" (movement from one stock to another, like fish being caught or candidates moving through hiring stages) <a class="yt-timestamp" data-t="11:43">[11:43]</a>.

### Application: The Hiring Pipeline Example
In a hiring pipeline, "stocks" could include potential candidates, sourced candidates, and candidates at various interview stages <a class="yt-timestamp" data-t="13:27">[13:27]</a>. "Flows" represent conversion rates between these stages, such as candidates passing a recruiter screen or a hiring manager screen <a class="yt-timestamp" data-t="14:01">[14:01]</a>.

By modeling a process like this, one can identify where bottlenecks or issues occur. For example:
*   **Hiring Manager Hesitation:** Many candidates reach the offer stage, but few convert due to hiring managers' inability to gain confidence <a class="yt-timestamp" data-t="14:31">[14:31]</a>.
*   **Offer Acceptance:** Many offers are extended, but few are accepted, indicating issues with closing candidates <a class="yt-timestamp" data-t="15:01">[15:01]</a>.
*   **Insufficient Candidates:** A good conversion and closing rate, but not enough candidates entering the pipeline <a class="yt-timestamp" data-t="15:09">[15:09]</a>.

Comparing this model with historical data from applicant tracking systems helps pinpoint where to focus improvement efforts, preventing changes based on "feelings" rather than data <a class="yt-timestamp" data-t="15:20">[15:20]</a>.

### The Importance of Reality
A crucial caution in systems thinking is to recognize that "reality is never wrong, reality is always right" <a class="yt-timestamp" data-t="10:37">[10:37]</a>. If your model conflicts with reality, your model is flawed <a class="yt-timestamp" data-t="10:40">[10:40]</a>. The gap between your model and reality is where true learning and improvement occur <a class="yt-timestamp" data-t="10:44">[10:44]</a>. The goal is to learn and then *act*, not just to measure indefinitely <a class="yt-timestamp" data-t="10:15">[10:15]</a>.

## Developing Engineering Strategy

Many companies, including engineering departments, often operate without a clearly written strategy <a class="yt-timestamp" data-t="16:53">[16:53]</a>. However, a strategy always exists implicitly, even if it's "bad" or inconsistently applied <a class="yt-timestamp" data-t="18:01">[18:01]</a>. Writing down the strategy is the first step toward improving it, allowing for debugging and clarity across the organization <a class="yt-timestamp" data-t="18:22">[18:22]</a>.

### Components of Strategy (Richard Rumelt's Definition)
Richard Rumelt's definition of strategy includes three components <a class="yt-timestamp" data-t="21:23">[21:23]</a>:
1.  **Diagnosis:** Understanding the current status quo and identifying real problems <a class="yt-timestamp" data-t="21:25">[21:25]</a>.
2.  **Guiding Policies:** How to address the problems based on the diagnosis <a class="yt-timestamp" data-t="21:31">[21:31]</a>.
3.  **Actions:** Concrete steps to implement those guiding policies <a class="yt-timestamp" data-t="21:37">[21:37]</a>.

### "Boring" Strategies and Constraints
Often, good strategies are "boring" because they involve deliberate constraints that focus the organization's energy <a class="yt-timestamp" data-t="19:07">[19:07]</a>. Examples include:
*   **Standardized Tooling:** Only using existing tools and not introducing new programming languages, databases, or cloud providers <a class="yt-timestamp" data-t="19:20">[19:20]</a>. This can be frustrating for engineers but focuses their energy on building innovative features rather than new tooling <a class="yt-timestamp" data-t="19:57">[19:57]</a>.
*   **In-house Data Centers (Uber):** Uber's strict "no cloud" policy meant building and running everything themselves. While challenging, it enabled rapid global expansion, such as spinning up in China in three months <a class="yt-timestamp" data-t="22:09">[22:09]</a>. This strategy provided flexibility in geopolitical constraints <a class="yt-timestamp" data-t="23:06">[23:06]</a>.
*   **Ruby Monolith (Stripe):** Stripe's focus on a Ruby monolith, despite engineers' desires for other languages, directed efforts towards building innovative features for users <a class="yt-timestamp" data-t="23:25">[23:25]</a>.

These strategies, though sometimes unpopular with engineers, dictate how limited capabilities are invested into prioritized problems <a class="yt-timestamp" data-t="24:06">[24:06]</a>. The common theme is deciding to constrain options to move faster and focus on what truly matters <a class="yt-timestamp" data-t="24:20">[24:20]</a>. Bad strategies often stem from a "willful disbelief" of an accurate diagnosis, leading to incoherent guiding policies <a class="yt-timestamp" data-t="24:58">[24:58]</a>.

## Measuring Engineering Productivity and Effectiveness

Evaluating [[influence_of_ai_on_engineering_productivity | engineering productivity]] is a persistent challenge, especially in the current market climate where efficiency is under scrutiny from venture capitalists and boards <a class="yt-timestamp" data-t="48:47">[48:47]</a>.

### Approaches to Measurement
1.  **Benchmarking:** A mechanical exercise of comparing R&D, engineering, and infrastructure spending against industry benchmarks provided by VCs. While it offers a "defensible answer" to stakeholders, it doesn't provide insight into running the organization effectively <a class="yt-timestamp" data-t="49:13">[49:13]</a>.
2.  **Qualitative Insights:** Directly talking to engineers is highly effective. Engineers often know if their teams are effective and can identify problems. Their diagnoses might be flawed, but they provide "crumbs" that a leader can follow to uncover contributing causes <a class="yt-timestamp" data-t="50:28">[50:28]</a>.
3.  **Quantitative Insights & Alignment:**
    *   **Aligning with Business/Product Goals:** Engineering evaluation should be "wholly accountable to the product goals" <a class="yt-timestamp" data-t="51:30">[51:30]</a>. Engineering's purpose is to support the product and customers, not to build novel systems for their own sake <a class="yt-timestamp" data-t="51:50">[51:50]</a>.
    *   **Showing the Roadmap:** Presenting a roadmap of "meaningful, meaty things that have impact" over the last six months helps demonstrate value. If this list is robust, stakeholders will grant space; if not, they will rightly have concerns <a class="yt-timestamp" data-t="52:03">[52:03]</a>.

### [[DORA metrics]]
The book "Accelerate" by Nicole Forsgren, Jean Kim, and others introduces four key metrics for software engineering performance: lead time, incident remediation time, and failure rate <a class="yt-timestamp" data-t="52:51">[52:51]</a>. These metrics are excellent for **diagnosis** (e.g., "our deployments are slow, why is that?") but are not direct measures of a company's overall success <a class="yt-timestamp" data-t="53:30">[53:30]</a>.

It's crucial to be comfortable measuring imperfect data <a class="yt-timestamp" data-t="54:41">[54:41]</a>. Engineers often resist measurement by pointing out every inaccuracy. However, starting with "something mediocre" and reporting on it allows for education and sophistication <a class="yt-timestamp" data-t="55:07">[55:07]</a>. Metrics are about educating stakeholders about the "rich data underneath," not about presenting a perfect dataset <a class="yt-timestamp" data-t="55:58">[55:58]</a>.

## Fostering Productive Engineer-Product Relationships

Challenges in the relationship between engineering managers (EMs) and product managers (PMs) often stem from two core issues <a class="yt-timestamp" data-t="41:36">[41:36]</a>:
1.  **Misaligned Incentives:** EMs and PMs may have conflicting goals (e.g., PM focused on sales commitments for promotion vs. EM prioritizing stability) <a class="yt-timestamp" data-t="41:44">[41:44]</a>. While complex, honesty about incentives can sometimes lead to compromise <a class="yt-timestamp" data-t="41:49">[41:49]</a>.
2.  **Lack of Understanding:** More commonly, EMs and PMs fail to understand each other's needs before attempting to solve conflicts <a class="yt-timestamp" data-t="42:55">[42:55]</a>. Deeply understanding each party's true needs often reveals compromise solutions that don't require more time <a class="yt-timestamp" data-t="43:27">[43:27]</a>.

### Solution: Shared Performance Ratings
A powerful approach to align incentives and foster better [[engineering_and_product_management_integration | EM-PM collaboration]] is to link their performance ratings <a class="yt-timestamp" data-t="44:06">[44:06]</a>. When EMs and PMs generally receive the same performance rating, it drives a shared perspective and encourages them to solve for the entire set of constraints, rather than just their functional ones <a class="yt-timestamp" data-t="44:48">[44:48]</a>. This "trifecta" approach can also extend to business leadership <a class="yt-timestamp" data-t="45:03">[45:03]</a>.

### Understanding Engineering Manager Concerns
A significant challenge EMs face is the expectation to provide their teams with "interesting work" <a class="yt-timestamp" data-t="47:06">[47:06]</a>. This can create friction when product teams require many "boring" experiments (e.g., in growth teams) while engineers desire to build something new <a class="yt-timestamp" data-t="47:13">[47:13]</a>. These "invisible constraints" can make EMs seem unreliable to PMs <a class="yt-timestamp" data-t="47:50">[47:50]</a>. Pushing to understand *why* an EM is prioritizing something that seems "idiotic" (e.g., a rewrite into a new language) can lead to honest conversations about navigating these constraints <a class="yt-timestamp" data-t="47:53">[47:53]</a>.

## Defining Company Values

Effective company values serve as a guide for decision-making and reflect the true nature of the organization.
Key principles for good values:
1.  **Honesty:** Values must genuinely reflect what the company *actually does* and the decisions it makes, rather than what it aspires to be <a class="yt-timestamp" data-t="57:07">[57:07]</a>. Copying values from another company (e.g., Facebook's values for another firm) is ineffective <a class="yt-timestamp" data-t="56:19">[56:19]</a>.
2.  **Applicability:** Values should be clearly usable in real-world situations, guiding decisions on how to navigate dilemmas (e.g., whether to optimize for a specific team or the overall organization) <a class="yt-timestamp" data-t="57:33">[57:33]</a>. Uber's implicit value of "do what's good for your team and ignore everyone else" allowed them to move fast, contrasting with Stripe's "optimize globally" <a class="yt-timestamp" data-t="58:07">[58:07]</a>.
3.  **Reversibility:** A good value should have a clear opposite that another company *could* plausibly hold <a class="yt-timestamp" data-t="59:01">[59:01]</a>. Values like "we build good software" or "we solve customer problems that matter" are not useful because no company would claim the opposite; these are "identity values" that feel good but don't aid decision-making <a class="yt-timestamp" data-t="59:05">[59:05]</a>. Values should also implicitly define who doesn't fit within the company culture, acting as a hiring filter <a class="yt-timestamp" data-t="01:00:39">[01:00:39]</a>.

## Failure Corner: The Dig v4 Rewrite

The Dig v4 rewrite, which shipped about six months after Will Larson joined the company, was a "complete rewrite" aimed at incorporating social functionality, a decision that "never works out for anyone" <a class="yt-timestamp" data-t="01:03:49">[01:03:49]</a>. The previous version couldn't support social features, and the company was losing to social networks like Twitter and Facebook, as well as Reddit <a class="yt-timestamp" data-t="01:03:12">[01:03:12]</a>.

Upon launch, Dig basically "didn't work properly for much of the month" <a class="yt-timestamp" data-t="01:04:46">[01:04:46]</a>. The team had to wipe and re-image servers, and the site kept crashing <a class="yt-timestamp" data-t="01:04:41">[01:04:41]</a>. It took a month to get it fully functional again <a class="yt-timestamp" data-t="01:04:52">[01:04:52]</a>. The site was only partially up for weeks, requiring server restarts every 12 hours <a class="yt-timestamp" data-t="01:05:39">[01:05:39]</a>. The core bug causing crashes was an "incredibly simple issue" related to how Python initiates variables as default parameters, a mistake made by someone new to Python that went uncaught in review <a class="yt-timestamp" data-t="01:05:51">[01:05:51]</a>.

Despite the heroic efforts to get the site working, the company ultimately "still went to zero" <a class="yt-timestamp" data-t="01:06:35">[01:06:35]</a>. A new CEO arrived weeks after the launch, followed by layoffs. Within nine months, the team shrunk from 100 people to 30 <a class="yt-timestamp" data-t="01:06:45">[01:06:45]</a>. The company ultimately "sold for parts" <a class="yt-timestamp" data-t="01:09:29">[01:09:29]</a>.

The root cause of Dig's demise was an SEO change that caused traffic to its "permalink pages" (where most monetization came from ads) to plummet <a class="yt-timestamp" data-t="01:10:13">[01:10:13]</a>. The migration was launched when the company was "already on fire" <a class="yt-timestamp" data-t="01:10:27">[01:10:27]</a>.

Despite the outcome, this difficult experience provided immense learning. Larson, early in his career, found himself "basically running the entire engineering team" because many experienced engineers left <a class="yt-timestamp" data-t="01:07:21">[01:07:21]</a>. This "kernel" experience shaped his entire career <a class="yt-timestamp" data-t="01:07:40">[01:07:40]</a>. Challenging situations, though not voluntarily chosen, can lead to powerful bonding experiences and significant growth <a class="yt-timestamp" data-t="01:16:04">[01:16:04]</a>.