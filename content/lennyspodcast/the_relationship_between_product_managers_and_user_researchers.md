---
title: The relationship between product managers and user researchers
videoId: L6RKi9ZvkT4
---

From: [[lennyspodcast]] <br/> 

The relationship between [[role_of_product_managers | Product Managers]] (PMs) and user researchers is often challenged, stemming from the fundamental way researchers are included—or excluded—from the product development process <a class="yt-timestamp" data-t="00:33:00">[00:33:00]</a>. This dynamic often leads to what Jud Anon, a former head of research at Airbnb and Facebook, calls "user-centered performance" <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.

## Jud Anon's Background and the "User Research Reckoning"

Jud Anon helped build the user research practice at Facebook and was a longtime head of research at Airbnb <a class="yt-timestamp" data-t="00:56:00">[00:56:00]</a>. His direct reports have gone on to lead research teams at companies like Figma, Notion, Slack, Robinhood, Duolingo, and others <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>.

Anon believes the user research field is undergoing a "reckoning" <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>. He argues that the user research discipline as it has existed for the last 15 years is "dying" and needs to adapt quickly to survive and thrive <a class="yt-timestamp" data-t="05:46:00">[05:46:00]</a>. This reckoning is partly driven by recent layoffs in tech, where user experience (UX) and UX research teams were particularly hard hit <a class="yt-timestamp" data-t="07:43:00">[07:43:00]</a>. This suggests that research is not driving the value or impact it should or could be <a class="yt-timestamp" data-t="08:32:00">[08:32:00]</a>.

## User-Centered Performance

User-centered performance is a common phenomenon where individuals signal customer obsession or user-centered practice for symbolic reasons rather than a genuine focus on learning or making different decisions <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>, <a class="yt-timestamp" data-t="00:09:00">[00:09:00]</a>, <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>.

Anon provides examples:
*   A PM asking a researcher to "just run a quick user study to validate our assumptions" at the end of a product process is user-centered performance <a class="yt-timestamp" data-t="00:23:00">[00:23:00]</a>, <a class="yt-timestamp" data-t="02:53:00">[02:53:00]</a>. This is often too late to matter, as the goal is to "check the box" for shipping the product <a class="yt-timestamp" data-t="00:34:00">[00:34:00]</a>, <a class="yt-timestamp" data-t="02:53:00">[02:53:00]</a>.
*   Executive listening sessions, while well-intentioned, can be 97% performance, not focused on learning or driving better outcomes <a class="yt-timestamp" data-t="02:52:00">[02:52:00]</a>.

This phenomenon is widespread and often stems from cognitive biases, confirmation bias, and ego <a class="yt-timestamp" data-t="02:52:00">[02:52:00]</a>. Many PMs and designers are looking to *validate* their ideas rather than *falsify* them, a mindset that hinders genuine learning <a class="yt-timestamp" data-t="00:45:00">[00:45:00]</a>, <a class="yt-timestamp" data-t="02:22:00">[02:22:00]</a>, <a class="yt-timestamp" data-t="02:49:00">[02:49:00]</a>.

## The Right and Wrong Kinds of Research

Anon categorizes user research into three types <a class="yt-timestamp" data-t="08:57:00">[08:57:00]</a>:

1.  **Macro Research:** Big-picture, strategic, business-focused, forward-looking, innovation-driven <a class="yt-timestamp" data-t="09:06:00">[09:06:00]</a>. This includes understanding the market, competitors, and long-term product direction <a class="yt-timestamp" data-t="09:09:00">[09:09:00]</a>, <a class="yt-timestamp" data-t="12:23:00">[12:23:00]</a>.
2.  **Micro Research:** Laser-focused research enabling high-quality, pixel-perfect product execution <a class="yt-timestamp" data-t="09:22:00">[09:22:00]</a>. This includes technical usability and understanding A/B test results <a class="yt-timestamp" data-t="09:23:00">[09:23:00]</a>, <a class="yt-timestamp" data-t="35:16:00">[35:16:00]</a>. An example is the "multi-million dollar button" story at Airbnb, where a simple text change on a button, based on quick micro-research, significantly increased conversion and generated millions of dollars <a class="yt-timestamp" data-t="35:37:00">[35:37:00]</a>.
3.  **Middle Range Research:** This is the "blob place" where many user understanding questions fall <a class="yt-timestamp" data-t="09:38:00">[09:38:00]</a>. Researchers often do this because it's interesting and what they are most often asked to do <a class="yt-timestamp" data-t="10:14:00">[10:14:00]</a>, <a class="yt-timestamp" data-t="10:17:00">[10:17:00]</a>.
    *   **Problems with Middle Range Research:** It yields interesting but often hard-to-operationalize results <a class="yt-timestamp" data-t="10:46:00">[10:46:00]</a>. It triggers "post hoc bias" (e.g., "that was obvious, we knew that already") <a class="yt-timestamp" data-t="10:53:00">[10:53:00]</a>. It fulfills the need to feel user-centered without requiring actual change <a class="yt-timestamp" data-t="11:03:00">[11:03:00]</a>. This type of research contributes to the stereotype that research is slow and delays decisions <a class="yt-timestamp" data-t="13:31:00">[13:31:00]</a>, <a class="yt-timestamp" data-t="34:21:00">[34:21:00]</a>.

Anon argues that doing too much middle-range research is a symptom of a broken system where research isn't driving sufficient value or impact <a class="yt-timestamp" data-t="11:11:00">[11:11:00]</a>, <a class="yt-timestamp" data-t="08:47:00">[08:47:00]</a>.

## The Challenged Relationship

The problem often arises when [[role_of_product_managers | PMs]] ask for middle-range questions because they haven't deeply engaged with researchers to leverage their full potential <a class="yt-timestamp" data-t="14:15:00">[14:15:00]</a>. When research is treated as a "service function" that gets called in only at the end, it becomes reactive and less impactful <a class="yt-timestamp" data-t="15:04:00">[15:04:00]</a>, <a class="yt-timestamp" data-t="16:24:00">[16:24:00]</a>.

### Common Tropes PMs Have About Research:

1.  **"Research just slows us down" / "Research is too slow."** <a class="yt-timestamp" data-t="33:52:00">[33:52:00]</a>
    *   **Rebuttal:** A great research team can conduct research in a day, week, or month, depending on the need <a class="yt-timestamp" data-t="34:01:00">[34:01:00]</a>. It's slower to get it wrong and then fix it than to take time to get it right initially <a class="yt-timestamp" data-t="34:24:00">[34:24:00]</a>. Effective micro-research can be very fast and drive huge business value <a class="yt-timestamp" data-t="35:21:00">[35:21:00]</a>.
2.  **"I can do my own research; why do I need researchers?"** <a class="yt-timestamp" data-t="39:03:00">[39:03:00]</a>
    *   **Rebuttal:** While anyone can talk to a user, that doesn't constitute research or insights work <a class="yt-timestamp" data-t="39:22:00">[39:22:00]</a>. A single user can be powerful, but also idiosyncratic <a class="yt-timestamp" data-t="39:27:00">[39:27:00]</a>. Researchers know how to quickly get to the heart of an issue, contextualize conversations, and avoid biases from informal feedback <a class="yt-timestamp" data-t="39:33:00">[39:33:00]</a>.
3.  **"A/B test everything."** <a class="yt-timestamp" data-t="40:08:00">[40:08:00]</a>
    *   **Rebuttal:** A/B tests are great for causal claims (what happened), but they rarely tell you *how* and *why* things happened <a class="yt-timestamp" data-t="40:33:00">[40:33:00]</a>, <a class="yt-timestamp" data-t="41:40:00">[41:40:00]</a>. Speculating about A/B test results without understanding the "why" leads to an endless, inefficient flywheel of testing <a class="yt-timestamp" data-t="40:38:00">[40:38:00]</a>. Effective [[collaboration_between_research_and_product_teams | collaboration between data scientists and researchers]] is crucial to understand both the "what" and the "how/why" <a class="yt-timestamp" data-t="41:56:00">[41:56:00]</a>.
4.  **The (Apocryphal) Henry Ford Quote:** "If I'd asked my users, they would have said faster horses." <a class="yt-timestamp" data-t="42:25:00">[42:25:00]</a>
    *   **Rebuttal:** This quote is likely false <a class="yt-timestamp" data-t="42:31:00">[42:31:00]</a>. More importantly, researchers don't ask users what they want; a researcher who does this is a "bad researcher" <a class="yt-timestamp" data-t="42:59:00">[42:59:00]</a>.
5.  **"We knew this already" / "That was obvious" (Post Hoc Bias/Hindsight Bias).** <a class="yt-timestamp" data-t="43:18:00">[43:18:00]</a>
    *   **Rebuttal:** This is a common cognitive bias where people selectively remember things and construct narratives that make them feel they already knew an outcome <a class="yt-timestamp" data-t="43:55:00">[43:55:00]</a>. Insights and research are designed to expose these biases and expand intuition <a class="yt-timestamp" data-t="27:33:00">[27:33:00]</a>, <a class="yt-timestamp" data-t="27:48:00">[27:48:00]</a>.

## Qualities of a Great Researcher for PMs

The best researchers are **multi-method**, possessing a "Swiss army knife" of tools <a class="yt-timestamp" data-t="17:44:00">[17:44:00]</a>, <a class="yt-timestamp" data-t="20:13:00">[20:13:00]</a>. These include:

1.  **Formative or Generative User Experience Research:** Looking ahead, innovation-focused, open-ended, ethnographic (e.g., observing users in their environment) <a class="yt-timestamp" data-t="18:08:00">[18:08:00]</a>.
2.  **Evaluative Research:** Usability testing to ensure a high-quality product <a class="yt-timestamp" data-t="18:28:00">[18:28:00]</a>, <a class="yt-timestamp" data-t="38:00:00">[38:00:00]</a>.
3.  **Rigorous Survey Design:** The best-scaled way to gather responses from communities <a class="yt-timestamp" data-t="18:35:00">[18:35:00]</a>.
4.  **Applied Statistics:** Essential for interacting with A/B testing and understanding data <a class="yt-timestamp" data-t="18:46:00">[18:46:00]</a>.
5.  **Technical Skills:** Historically SQL for running queries; now potentially prompt engineering for [[ai_tools_and_resources_for_product_managers | generative AI]] <a class="yt-timestamp" data-t="19:01:00">[19:01:00]</a>, <a class="yt-timestamp" data-t="19:05:00">[19:05:00]</a>.

## Advice for PMs and Companies for Better Collaboration

To move beyond the "reckoning," [[integrating_user_research_effectively_into_product_development | integrating user research effectively into product development]] is crucial <a class="yt-timestamp" data-t="01:32:00">[01:32:00]</a>.

### For PMs:
*   **Integrate Research Early and Consistently:** The "number one root of the problem" is when research is a service function <a class="yt-timestamp" data-t="15:04:00">[15:04:00]</a>, <a class="yt-timestamp" data-t="33:52:00">[33:52:00]</a>. Researchers should be involved from beginning to end to help frame the right questions for maximum business impact <a class="yt-timestamp" data-t="14:48:00">[14:48:00]</a>, <a class="yt-timestamp" data-t="15:10:00">[15:10:00]</a>, <a class="yt-timestamp" data-t="15:57:00">[15:57:00]</a>, <a class="yt-timestamp" data-t="50:40:00">[50:40:00]</a>.
*   **Seek Falsification, Not Just Validation:** Rather than seeking to validate assumptions, PMs should embrace a mindset of looking to be wrong and identifying areas for improvement <a class="yt-timestamp" data-t="00:45:00">[00:45:00]</a>, <a class="yt-timestamp" data-t="02:59:00">[02:59:00]</a>.
*   **Balance Intuition with Evidence:** While intuition is valuable, it's prone to biases and blind spots <a class="yt-timestamp" data-t="27:22:00">[27:22:00]</a>, <a class="yt-timestamp" data-t="29:58:00">[29:58:00]</a>. Engage "system two" (slow, methodical analytic thinking) to check your gut <a class="yt-timestamp" data-t="30:36:00">[30:36:00]</a>. Bring in diverse perspectives ("wisdom of the crowd") to challenge assumptions <a class="yt-timestamp" data-t="30:58:00">[30:58:00]</a>.
*   **Prioritize Ruthlessly with Researchers:** Help researchers focus on the most important projects. A researcher typically handles two big projects and one small side project at a time <a class="yt-timestamp" data-t="51:44:00">[51:44:00]</a>.
*   **Actively Participate in Research:** PMs should take the time to go into the field and observe research firsthand <a class="yt-timestamp" data-t="52:09:00">[52:09:00]</a>. Experiencing research directly, even small examples, can "burst their own bubble" and lead to significant insights <a class="yt-timestamp" data-t="55:31:00">[55:31:00]</a>.
*   **Beware of Dogfooding Bias:** While "dogfooding" (using your own product) is important, PMs are "nothing like the user" and can't imagine all user contexts or constraints <a class="yt-timestamp" data-t="01:07:41">[01:07:41]</a>. Relying solely on personal usage for prioritizing issues can be misleading <a class="yt-timestamp" data-t="01:08:26">[01:08:26]</a>.

### For Companies:
*   **Unify Insights Functions:** Avoid siloing different insights disciplines (UX research, consumer insights, market research, data science, customer service feedback) <a class="yt-timestamp" data-t="49:07:00">[49:07:00]</a>. An integrated insights function can provide a clearer, more complete picture <a class="yt-timestamp" data-t="50:03:00">[50:03:00]</a>.
*   **Align Metrics for Success:** All team members—PMs, engineers, designers, and researchers—should share the same metrics for success (e.g., OKRs) <a class="yt-timestamp" data-t="01:01:51">[01:01:51]</a>.
*   **Cultivate Influence, Not Just Input:** The goal is for teams to not want to have decision-making meetings without the researcher present, indicating strong, trusting relationships and active participation <a class="yt-timestamp" data-t="01:02:07">[01:02:07]</a>.
*   **Rethink Researcher Ratios:** Instead of a fixed ratio, companies should ensure that key product areas have a consistent research partner <a class="yt-timestamp" data-t="57:29:00">[57:29:00]</a>. Protecting their time and allowing them to demonstrate impact will create demand for more researchers <a class="yt-timestamp" data-t="57:56:00">[57:56:00]</a>. Even early-stage startups can benefit significantly from an insights person with a "Swiss army knife" of skills to guide iterations or pivots <a class="yt-timestamp" data-t="01:00:20">[01:00:20]</a>.

## Empowering Researchers to Drive [[importance_of_user_feedback_in_product_development | Business Value]]

Anon emphasizes that while the system can be challenging, researchers also have a role in their own empowerment <a class="yt-timestamp" data-t="01:01:12">[01:01:12]</a>, <a class="yt-timestamp" data-t="01:02:01">[01:02:01]</a>.

Researchers should:
*   **Develop Diverse Research Skills:** Master the "five (or five and a half) tools" <a class="yt-timestamp" data-t="01:08:01">[01:08:01]</a>.
*   **Deepen Business Knowledge:** Learn the language of product, business, and metrics <a class="yt-timestamp" data-t="01:08:12">[01:08:12]</a>. Understand the conversion funnel and how insights can be used like a scalpel to address business problems <a class="yt-timestamp" data-t="01:08:16">[01:08:16]</a>, <a class="yt-timestamp" data-t="01:08:20">[01:08:20]</a>.
*   **Build Strong Relationships:** Actively work with PMs and other partners <a class="yt-timestamp" data-t="01:08:20">[01:08:20]</a>.
*   **Say No and Prioritize:** Focus on fewer things done better <a class="yt-timestamp" data-t="01:08:28">[01:08:28]</a>.
*   **Become Excellent Communicators:** Effectively convey research findings, adapting the message to different audiences (e.g., PMs vs. executives) <a class="yt-timestamp" data-t="01:02:53">[01:02:53]</a>.

## The Problem with NPS

Jud Anon has a strong opinion against Net Promoter Score (NPS) <a class="yt-timestamp" data-t="01:03:44">[01:03:44]</a>:
*   He calls it "the best example of the marketing industry marketing itself" <a class="yt-timestamp" data-t="01:03:57">[01:03:57]</a>.
*   The consensus in the survey science community is that NPS makes fundamental mistakes in survey design <a class="yt-timestamp" data-t="01:04:14">[01:04:14]</a>.
*   The "likelihood to recommend" question is flawed for various reasons: it uses a 0-10 scale that is often unlabeled, and 11 items on a scale often lead to lower precision, especially on mobile devices where options might be "below the fold" <a class="yt-timestamp" data-t="01:04:20">[01:04:20]</a>.
*   The question assumes people actively recommend products like operating systems, which isn't always true <a class="yt-timestamp" data-t="01:05:04">[01:05:04]</a>.
*   **Solution:** A simple customer satisfaction (CSAT) metric (e.g., "Overall, how satisfied are you with your experience?") has better data properties, is more precise, and is more correlated to business outcomes <a class="yt-timestamp" data-t="01:05:17">[01:05:17]</a>.
*   NPS scores are often idiosyncratic and inconsistent in how they are collected, making meaningful comparisons or benchmarking unreliable <a class="yt-timestamp" data-t="01:06:19">[01:06:19]</a>.

The future for the user research discipline is bright if both researchers and companies commit to an evolution that embraces diverse skills, business acumen, and genuine [[the_role_of_empathy_and_user_feedback_in_product_management | collaboration between research and product teams]] <a class="yt-timestamp" data-t="01:02:22">[01:02:22]</a>, <a class="yt-timestamp" data-t="01:03:26">[01:03:26]</a>.