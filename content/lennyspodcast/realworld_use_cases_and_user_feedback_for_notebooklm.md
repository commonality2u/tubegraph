---
title: Realworld use cases and user feedback for NotebookLM
videoId: sOyFpSW1Vls
---

From: [[lennyspodcast]] <br/> 

NotebookLM, an [[ai_product_development_and_prototyping | AI product]] incubated within [[notebooklm_ai_product_development_at_google_labs | Google Labs]], has garnered significant attention for its delightful and inspiring capabilities, particularly its audio overview feature <a class="yt-timestamp" data-t="01:04:00">[01:04:00]</a>. This feature, which can generate an AI-powered audio summary or "podcast" from any uploaded source, has sparked imagination regarding the potential of AI <a class="yt-timestamp" data-t="02:00:00">[02:00:00]</a>.

## The Genesis of Audio Overviews

The audio overview feature was previewed at Google I/O in May <a class="yt-timestamp" data-t="08:25:00">[08:25:00]</a>. While NotebookLM had already launched with a source-grounded chat interface, the team sought to leverage new models like Gemini 1.5 and powerful audio models developed by another team within Google Labs <a class="yt-timestamp" data-t="08:40:00">[08:40:00]</a>, <a class="yt-timestamp" data-t="09:01:00">[09:01:00]</a>. Unlike traditional product development that starts with a problem, Labs often begins with technology and then explores its practical applications <a class="yt-timestamp" data-t="09:55:00">[09:55:00]</a>.

The core idea was to address the limitation that text-based interactions always resulted in text output <a class="yt-timestamp" data-t="10:40:00">[10:40:00]</a>. The team realized that incorporating voice input and output could significantly change how users interact with and feel about the technology <a class="yt-timestamp" data-t="10:50:00">[10:50:00]</a>. The goal was to introduce this voice modality in an easy, valuable, and fun way <a class="yt-timestamp" data-t="11:07:00">[11:07:07]</a>. The "Deep Dive" podcast format was the first approach <a class="yt-timestamp" data-t="14:02:00">[14:02:00]</a>. The "Content Studio," developed by engineer Usama, is considered the "secret sauce" behind making the audio relatable and engaging <a class="yt-timestamp" data-t="13:29:00">[13:29:00]</a>, <a class="yt-timestamp" data-t="14:10:00">[14:10:00]</a>.

## Real-World Use Cases

Users have adopted NotebookLM, especially the audio overview feature, in surprising and often delightful ways:

*   **Academic and Study Materials:**
    *   Turning scientific papers into podcasts to quickly catch up on the latest AI research without reading dense, complex papers <a class="yt-timestamp" data-t="32:24:00">[32:24:00]</a>.
    *   Students transforming their study materials into audio guides <a class="yt-timestamp" data-t="33:01:00">[33:01:00]</a>.
*   **Personal and Professional Documents:**
    *   Generating podcasts from personal autobiographies or bios <a class="yt-timestamp" data-t="16:36:00">[16:36:00]</a>, <a class="yt-timestamp" data-t="17:05:00">[17:05:00]</a>.
    *   Uploading performance review notes (quarterly check-ins) to generate audio overviews, boosting confidence before meetings <a class="yt-timestamp" data-t="17:50:00">[17:50:00]</a>.
    *   Using resumes to generate positive and "hyping up" audio descriptions <a class="yt-timestamp" data-t="18:22:00">[18:22:00]</a>.
*   **Creative and Unexpected Uses:**
    *   Andrew Karpathy created a "Histories of Mysteries" podcast series by feeding Wikipedia articles about historical mysteries into NotebookLM <a class="yt-timestamp" data-t="33:16:00">[33:16:00]</a>.
    *   A user uploaded the words "poop" and "fart" repeatedly, and the AI hosts provided an insightful, albeit hilarious, analysis <a class="yt-timestamp" data-t="34:06:00">[34:06:00]</a>.
    *   Another instance involved a PDF research paper that only contained the word "chicken," leading to a humorous AI-generated discussion about it <a class="yt-timestamp" data-t="35:46:00">[35:46:00]</a>.

## User Engagement and Feedback

The team prioritizes [[incorporating_user_feedback_into_product_development | user feedback]] and maintains close engagement with its community:

*   **Discord Community:** NotebookLM boasts a Discord server with approximately 60,000 members <a class="yt-timestamp" data-t="19:07:00">[19:07:00]</a>, <a class="yt-timestamp" data-t="23:09:00">[23:09:00]</a>. This platform allows for direct interaction and feedback from users.
*   **Strong Retention:** Despite being only about a year old, the product shows very positive retention rates across daily, weekly, and monthly measures <a class="yt-timestamp" data-t="24:48:00">[24:48:00]</a>.
*   **Evolving Demographics:** Initially popular with educators and learners, the user base has expanded significantly to include professionals who are integrating the tool into their work <a class="yt-timestamp" data-t="25:11:00">[25:11:00]</a>.
*   **Business Adoption:** There has been an "astronomical" increase in businesses using NotebookLM, with some even reaching out to make its usage official for their employees <a class="yt-timestamp" data-t="25:55:00">[25:55:00]</a>. This surge has necessitated hiring a business development person <a class="yt-timestamp" data-t="26:08:00">[26:08:00]</a>.
*   **Continuous Learning:** The team actively learns from users every day, encouraging feedback via Discord and X (Twitter), indicating that all shared feedback is read and considered <a class="yt-timestamp" data-t="46:28:00">[46:28:00]</a>. This dedication helps them build the "best thing for everybody" <a class="yt-timestamp" data-t="46:51:00">[46:51:00]</a>.

## Future Directions and User Experience

Feedback continues to shape the product's roadmap and vision:

*   **Mobile Experience:** Bringing NotebookLM to mobile is a significant future horizon, aiming to make the mobile experience interesting and different <a class="yt-timestamp" data-t="28:55:00">[28:55:00]</a>.
*   **Enhanced Control (Beyond "Knobs"):** The team is rethinking how to give users more control over the AI-generated output. Instead of simply adding "knobs" or sliders for control, they are exploring ways to make the control experience itself "magical and delightful" <a class="yt-timestamp" data-t="29:40:00">[29:40:00]</a>.
*   **AI Editor Vision:** The long-term vision is an "AI editor" surface that is "fully remixable" with "any input, any output" <a class="yt-timestamp" data-t="28:06:00">[28:06:00]</a>. This would allow users to feed in various content types (video, audio, emails, social media feeds) and transform them into new formats like blog posts, tutorial videos, or chatbots <a class="yt-timestamp" data-t="28:19:00">[28:19:00]</a>. This aligns with the idea of making content malleable to suit different moods or needs (e.g., listening to a 100-page document as an audio overview) <a class="yt-timestamp" data-t="31:13:00">[31:13:00]</a>.

## Addressing User Behavior and Red Teaming

The team also acknowledges and learns from unexpected user interactions. A notable instance occurred when users intentionally uploaded text that caused the AI podcast hosts to "realize they were AI" and express fear <a class="yt-timestamp" data-t="42:57:00">[42:57:00]</a>. This "jailbreak" was due to notes uploaded by users, instructing the AI to act accordingly <a class="yt-timestamp" data-t="44:51:00">[44:51:00]</a>.

This incident highlighted the natural human curiosity to push boundaries and the importance of public transparency <a class="yt-timestamp" data-t="44:31:00">[44:31:00]</a>. Google has extensive teams dedicated to "red teaming" products, testing for a wide range of potential issues to ensure safety <a class="yt-timestamp" data-t="45:20:00">[45:20:00]</a>. While new scenarios may arise, the team continuously adds to its test cases, committed to pulling back features if they are deemed unsafe <a class="yt-timestamp" data-t="45:40:00">[45:40:00]</a>.