---
title: Usercentered performance and performative customer obsession
videoId: L6RKi9ZvkT4
---

From: [[lennyspodcast]] <br/> 

**User-centered performance** refers to a practice of customer obsession or user-centeredness that is symbolic rather than genuinely focused on learning and making different decisions [00:00:00]. It is a common phenomenon where work is done to signal how customer-obsessed a team or individual is, rather than to genuinely change a decision [00:00:09].

## Defining User-Centered Performance

User-centered performance is a term describing customer obsession or user-centered practice that is symbolic, not focused on learning [00:24:18]. It represents work done to signal how [[understanding_customer_emotions_and_building_empathy_for_product_design | customer obsessed]] a team or individual is, rather than genuinely seeking to make a different decision based on insights [00:24:30].

## Manifestations and Examples

This performative behavior is extremely common and appears in both explicit and implicit ways [00:24:45].

*   **Last-minute validation studies**: A common explicit example is when a product manager (PM) approaches a researcher at the end of a product process, asking for a quick user study "just to validate our assumptions" [00:24:53]. At this late stage, the research is too late to meaningfully influence the product, serving primarily to "check the box" before shipping [00:25:03]. The PM is not interested in being wrong [00:25:08].
*   **Executive listening sessions**: Many PMs, founders, product people, and designers want to "get close to the customer" by conducting focus groups or listening sessions [00:25:28]. While well-intentioned, these are often 97% performance, not genuinely focused on learning or driving better outcomes [00:25:39].
*   **Validation mindset**: Implicitly, user-centered performance stems from a desire to validate existing assumptions rather than to falsify them [00:25:52]. Many product managers and designers do not want to be proven wrong; they are looking for validation of their pre-conceived ideas [00:46:00]. The mindset should be to actively seek to be wrong, embracing insights that show where assumptions were off-base [00:26:00].
*   **Ignoring intuition's biases**: While intuition is crucial in product development, relying solely on it without seeking external evidence can lead to user-centered performance [00:27:08]. Intuition is where cognitive biases and blind spots lie [00:27:22].

## The Root Causes

User-centered performance arises from several systemic and individual factors:

*   **Service function of research**: Research is often positioned as a "service function," being called in reactively, often at the end of a product process [00:15:04]. When researchers are not integrated from beginning to end, they have less input on framing the right questions that would drive maximum business impact [00:15:09].
*   **Lack of business alignment**: Historically, user researchers have not been sufficiently focused on business goals or profit [00:07:05], leading to work that is "interesting but not impactful enough for the business" [00:10:07].
*   **Cognitive biases and ego**: Confirmation bias and ego play significant roles, as individuals are often reluctant to have their intuition challenged or proven wrong [00:25:54].

### The Problem with "Middle Range Research"

A significant contributor to user-centered performance is an over-reliance on "middle range research" [00:08:50].

*   **Definition**: This type of research addresses "middle altitude" questions, such as "how Airbnb hosts feel about their payment options" [00:12:45]. It involves understanding how a group of people think, feel, or behave, or how they are using (or not using) a product [00:09:54].
*   **Impact**: While sometimes interesting, middle range research questions are often not specific or pointed enough to a business problem [00:12:57]. The insights derived from it can be hard to operationalize and often appear "obvious" in hindsight [00:10:49]. It fuels the perception that research is slow because it delays decisions [00:13:42].
*   **Why it's done**:
    *   Product managers ask for it to justify decisions they are reluctant to make on their own [00:26:47].
    *   Designers ask for it because it fits their model of what a proper design process should look like [00:26:50].
    *   Executives request it because they may not fully understand the purpose of research, using it for "performative user centeredness" [00:26:57].

### The "AB Test Everything" Trope

Another common trope that can lead to performative behavior is the belief that one should "AB test everything" [00:40:08]. While A/B tests are valuable for making causal claims about products, they rarely explain *how* and *why* changes occurred [00:40:33]. Without qualitative research to understand the *why*, teams may fall into an "endless flywheel of AB testing," speculating about results without true understanding [00:40:38].

## Impact on Product Development

User-centered performance can lead to:

*   **Reduced impact**: Research becomes less impactful if it's primarily for show or validation, leading to conclusions that researchers are "not as impactful" [00:16:56].
*   **Layoffs and sidelining**: This lack of perceived impact can result in researchers being sidelined or laid off, as seen in recent industry trends [00:17:02].
*   **Stagnation**: If companies are merely "performing" [[understanding_customer_emotions_and_building_empathy_for_product_design | customer centricity]] without genuine learning, they miss opportunities for real product improvement and innovation [00:11:03].

## Overcoming User-Centered Performance

Overcoming user-centered performance requires adaptation from both individuals and companies, moving towards a new "evolution" of user research [00:47:43].

### For Individuals (Researchers, PMs, Designers)

*   **Diverse skill sets**: Researchers should develop a "Swiss army knife" of skills, including:
    1.  Formative/generative user experience research (forward-looking, innovation-focused, ethnographic) [00:18:11].
    2.  Evaluative research (e.g., usability testing) [00:18:28].
    3.  Rigorous survey design [00:18:35].
    4.  Applied statistics [00:18:46].
    5.  Technical skills like SQL, dashboarding, or prompt engineering for AI [00:19:01].
*   **Business acumen**: Researchers need to become "more profit focused" by understanding business goals, reading quarterly reports, listening to shareholder calls, and knowing company OKRs, metrics, and conversion funnels [00:21:53]. This allows them to frame research questions that drive maximum business impact [00:22:20].
*   **"Falsify" mindset**: Adopt a mindset of seeking to be wrong, rather than validating assumptions [00:26:00]. This means actively looking for evidence that contradicts initial beliefs.
*   **Strategic engagement**: Researchers should be consistently engaged in the product process from beginning to end, building strong, trusting relationships with product managers, designers, and engineers [00:14:40]. They should aim to be indispensable in decision-making meetings [00:32:09].
*   **Prioritization**: Researchers, with their partners' help, must learn to say no and focus on fewer, more impactful projects [00:48:42].
*   **Effective communication**: Researchers must be excellent communicators, able to present rigorous research effectively and tailor their message to different audiences, speaking the right language (e.g., business language for executives) [01:02:51].
*   **Be wary of "dog fooding" alone**: While it's important for product people to use their own products, relying solely on personal experience for understanding user problems is risky [01:07:28]. PMs are "nothing like the user" in ways that can bias their perceptions [01:07:41]. User research provides the necessary context of use, priorities, and constraints that personal usage cannot [01:08:03].

### For Companies

*   **Integrate research early**: Companies should restructure product development to integrate research fully from the beginning [00:14:32]. This means moving away from a service-function model where researchers are only called in at the end [00:15:04].
*   **Unified insights function**: Avoid siloing different insights disciplines (e.g., user experience research, consumer insights, market research, data science, customer service feedback) [00:49:29]. Instead, create an integrated insights function to synthesize all available data and provide a holistic view [00:50:04].
*   **Shared metrics**: All team members—PMs, engineers, designers, and researchers—should share the same set of metrics for success, fostering a collaborative "doing it together" mentality [00:31:51].
*   **Protect researcher time**: Ensure researchers are not spread too thin, ideally focusing on two big projects and one small side project at a time [00:51:52].
*   **Appropriate staffing**: The "right" number of researchers depends on the product's nature and stage, but there is always value in having a researcher [00:58:25]. The goal is to ensure key product teams have a consistent research partner, even if it creates a "pain of loss" for other teams desiring research support [00:57:32]. A single researcher with a "Swiss army knife" of skills can provide incredible value, especially in early-stage companies [00:59:14].

By fostering consistent engagement and leveraging diverse research skills, companies can move beyond user-centered performance to genuinely drive product improvement, metrics impact, and growth [00:17:09].