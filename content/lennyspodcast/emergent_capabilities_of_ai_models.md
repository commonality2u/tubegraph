---
title: Emergent capabilities of AI models
videoId: IxkvVZua28k
---

From: [[lennyspodcast]] <br/> 

The development of AI models is characterized by rapid, often unpredictable, advancements, leading to "emergent capabilities" – new functionalities that were not explicitly programmed but arise from the model's training <a class="yt-timestamp" data-t="00:06:23">[00:06:23]</a>. This dynamic landscape presents both challenges and exciting opportunities for product development <a class="yt-timestamp" data-t="00:02:02">[00:02:02]</a>.

## Unpredictable Nature of AI Capabilities

Unlike traditional product development based on fixed technology, AI product development operates on a constantly shifting technological base <a class="yt-timestamp" data-t="00:01:46">[00:01:46]</a>. Every couple of months, computers can perform actions previously impossible, requiring product teams to constantly re-evaluate how these new capabilities can be integrated <a class="yt-timestamp" data-t="00:01:56">[00:01:56]</a>.

Kevin noted that as new models are trained, there's often only a vague sense of potential new capabilities <a class="yt-timestamp" data-t="00:06:31">[00:06:31]</a>. These capabilities are "emergent properties" of the model, meaning their exact functionality and reliability (e.g., 60% good, 90% good, or 99% good) are unknown until they manifest <a class="yt-timestamp" data-t="00:06:52">[00:06:52]</a>. This unpredictability means product roadmaps can be disrupted from within the company itself <a class="yt-timestamp" data-t="00:07:51">[00:07:51]</a>.

## Discovery and Integration of Capabilities

Discovery of new capabilities can happen in several ways:
*   **Observing Intelligence Advancements**: Product teams can anticipate general directions of AI advancement and begin to build products around those expected model behaviors <a class="yt-timestamp" data-t="00:08:20">[00:08:20]</a>.
*   **Co-Design and Fine-Tuning**: For specific features, product and research teams engage in collaborative design, research, and fine-tuning to develop desired capabilities <a class="yt-timestamp" data-t="00:08:47">[00:08:47]</a>. This process prioritizes learning and generating informative demos over immediate perfect product shipments <a class="yt-timestamp" data-t="00:09:14">[00:09:14]</a>.
*   **Unexpected Discoveries**: Sometimes, existing capabilities within the research realm are not immediately known or deemed important by product teams, leading to "magic happening" when they are finally discovered and applied <a class="yt-timestamp" data-t="00:09:55">[00:09:55]</a>.

## Designing for Imperfect Capabilities

A key challenge is designing products around models that are not yet 99% accurate <a class="yt-timestamp" data-t="00:10:18">[00:10:18]</a>. Even a 60% success rate can be valuable if the product is designed to accommodate human involvement <a class="yt-timestamp" data-t="00:10:50">[00:10:50]</a>.

For example, [[leveraging_ai_in_product_development | GitHub Co-pilot]], an early AI product, proved useful even when the underlying model wasn't perfect at coding, because it provided significant assistance that users could then edit <a class="yt-timestamp" data-t="00:11:02">[00:11:02]</a>. Similarly, future AI agents performing longer tasks may not be perfect, but if they save users time or can identify areas where they lack confidence and seek human input, they remain valuable <a class="yt-timestamp" data-t="00:11:45">[00:11:45]</a>.

AI model performance can be "lumpy," meaning it excels in some tasks but not others <a class="yt-timestamp" data-t="00:12:21">[00:12:21]</a>. Real-world pilot programs with customers often reveal varied results, with some finding the model fully solving their problems while others find it completely off <a class="yt-timestamp" data-t="00:12:27">[00:12:27]</a>. This highlights that models are often "intelligence limited" but "eval limited" – they could do more if properly evaluated and taught <a class="yt-timestamp" data-t="00:13:13">[00:13:13]</a>.

## The Future of AI Capabilities

The future of AI is expected to involve models that are:

*   **Proactive**: Models will become more proactive, capable of monitoring information (with user authorization) and offering assistance without direct prompts, such as summarizing emails, preparing for meetings, or drafting presentations <a class="yt-timestamp" data-t="00:33:50">[00:33:50]</a>.
*   **Asynchronous**: Tasks will become more asynchronous, allowing models to "think" for extended periods (minutes to days) while users engage in other activities, then returning with vetted answers or completed projects <a class="yt-timestamp" data-t="00:34:21">[00:34:21]</a>. This will enable handling more complex, longer-horizon tasks <a class="yt-timestamp" data-t="00:35:04">[00:35:04]</a>.
*   **Multimodal Interaction**: Models will increasingly interact in human-like ways, beyond just typing, to include speech, vision, and other modalities <a class="yt-timestamp" data-t="00:35:40">[00:35:40]</a>. An example is a universal translator that enables real-time conversations across language barriers <a class="yt-timestamp" data-t="00:36:16">[00:36:16]</a>.
*   **Orchestration of Models**: The most sophisticated applications will likely involve combining multiple models in workflows, using each for its specific strengths <a class="yt-timestamp" data-t="00:32:56">[00:32:56]</a>. For example, one model might be good at reasoning (like "system two thinking" where it pauses to form hypotheses and refute them) while another is precise at inputs/outputs, allowing for complex tasks like cybersecurity <a class="yt-timestamp" data-t="00:30:09">[00:30:09]</a>. This mimics human teams with diverse skill sets working together <a class="yt-timestamp" data-t="00:33:07">[00:33:07]</a>.

## Adapting to New Behaviors

The rapid evolution of AI means users and developers must adapt quickly to non-deterministic systems <a class="yt-timestamp" data-t="00:20:24">[00:20:24]</a>. The traditional expectation of consistent outputs from consistent inputs no longer holds true with AI <a class="yt-timestamp" data-t="00:21:32">[00:21:32]</a>. Users, particularly younger generations, are showing an innate ability to interact with AI in novel ways, treating them almost as persons or entities with distinct personalities <a class="yt-timestamp" data-t="00:37:09">[00:37:09]</a>. This suggests that the "model behavior" itself is becoming a critical aspect of product design <a class="yt-timestamp" data-t="00:39:43">[00:39:43]</a>.

Indeed, Mike notes an emerging "two-way empathy" where users not only interact with models but also understand their nuances and evolving intelligence <a class="yt-timestamp" data-t="00:39:00">[00:39:00]</a>. The product needs to be educational, informing users about how to best use new features and helping them overcome confusion <a class="yt-timestamp" data-t="00:24:52">[00:24:52]</a>. In enterprise settings, internal power users often become evangelists, helping to educate non-technical colleagues on how to leverage these new tools <a class="yt-timestamp" data-t="00:26:43">[00:26:43]</a>.

For instance, Anthropic's "computer use" feature, still in early stages, allows AI to perform tasks like UI testing and repetitive data manipulation, automating "drudgery" and freeing up human creativity <a class="yt-timestamp" data-t="00:28:11">[00:28:11]</a>. An early beta test even saw the AI successfully order a pizza <a class="yt-timestamp" data-t="00:27:46">[00:27:46]</a>.