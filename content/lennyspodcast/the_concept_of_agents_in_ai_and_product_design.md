---
title: The concept of agents in AI and product design
videoId: HbbfXAWcuUo
---

From: [[lennyspodcast]] <br/> 

## Introduction to AI Agents
Aparna Shanapraada, Chief Product Officer at Microsoft, oversees AI product strategy for their productivity tools and work on agents <a class="yt-timestamp" data-t="01:10:00">[01:10:00]</a>. She considers AI agents to be tools, albeit based on stochastic models rather than deterministic programming <a class="yt-timestamp" data-t="01:32:00">[01:32:00]</a>.

## Key Characteristics of AI Agents
The evolution of AI has led to the "assistants era," where humans maintain control but receive significant help from AI, such as with Copilot <a class="yt-timestamp" data-t="01:54:00">[01:54:00]</a>. This then moves towards agents, which operate with increased autonomy and delegation <a class="yt-timestamp" data-t="01:11:00">[01:11:00]</a>.

Aparna identifies three core characteristics of AI agents <a class="yt-timestamp" data-t="01:26:00">[01:26:00]</a>:
1.  **Autonomy/Delegation**: Agents possess an increasing level of independence, allowing users to delegate higher-order tasks rather than just fine motor hand-holding <a class="yt-timestamp" data-t="01:32:00">[01:32:00]</a> <a class="yt-timestamp" data-t="01:17:00">[01:17:00]</a>. For example, a researcher agent for work can be tasked with preparing a persuasion pitch for a meeting, analyzing participants' views and providing new insights, effectively granting "superpowers" <a class="yt-timestamp" data-t="01:39:00">[01:39:00]</a>.
2.  **Complexity**: Agents can handle complex tasks beyond simple one-shot actions like summarizing documents or generating images. They can, for instance, build a prototype for an augmented reality app <a class="yt-timestamp" data-t="01:40:00">[01:40:00]</a> <a class="yt-timestamp" data-t="01:48:00">[01:48:00]</a>.
3.  **Asynchronous Operation**: Agents can perform tasks even when the user is not actively working, operating asynchronously <a class="yt-timestamp" data-t="01:57:00">[01:57:00]</a>. This means users do not need to be constantly in front of the agent <a class="yt-timestamp" data-t="01:59:00">[01:59:00]</a>.

## NLX: The New UX
Aparna emphasizes that Natural Language Interface (NLX) is the "new UX" <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a> <a class="yt-timestamp" data-t="01:15:00">[01:15:00]</a>.

While graphical user interfaces (GUI) are rigid and require explicit design, natural language interfaces are more elastic <a class="yt-timestamp" data-t="01:32:00">[01:32:00]</a>. However, this elasticity does not mean they are undesigned; conversations, like podcasts or meetings, have grammars, structures, and invisible UI elements <a class="yt-timestamp" data-t="01:35:00">[01:35:00]</a>.

New design principles and constructs are emerging for natural language as an interface:
*   **Prompts**: The prompt itself is a new UI element, akin to a dropdown or menu <a class="yt-timestamp" data-t="01:22:00">[01:22:00]</a>.
*   **Plans**: For high-level goals, an agent returning with a preferable editable plan is a new construct <a class="yt-timestamp" data-t="01:37:00">[01:37:00]</a>.
*   **Showing the Work**: Products like Co-pilot and DeepC demonstrate the concept of "thinking aloud" or showing the work being done <a class="yt-timestamp" data-t="01:49:00">[01:49:00]</a>. The challenge is balancing verbosity with conciseness to maintain user confidence <a class="yt-timestamp" data-t="02:03:00">[02:03:00]</a>. This transparency helps users understand what's happening, especially given the "black box" nature of current AI models and inference times <a class="yt-timestamp" data-t="02:44:00">[02:44:00]</a>.
*   **Follow-ups**: Designing explicit proactive follow-up suggestions is crucial for guiding users to a successful outcome without being annoying <a class="yt-timestamp" data-t="02:07:00">[02:07:00]</a>.

## [[impact_of_ai_on_product_development | Impact of AI on Product Development]] and Design
The [[impact_of_ai_on_product_development | future of product development]] is significantly different with AI <a class="yt-timestamp" data-t="02:48:00">[02:48:00]</a>:
*   **Prototyping and "Prompt Sets"**: If one is not prototyping and building to see what they want to build, they are likely doing it wrong <a class="yt-timestamp" data-t="02:08:00">[02:08:00]</a>. "Prompt sets" are the new Product Requirements Documents (PRDs) <a class="yt-timestamp" data-t="02:17:00">[02:17:00]</a>. This allows for a much faster, high-bandwidth way of communication â€“ "demos before memos" <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a>.
*   **Uneven Cadence**: The time to the first demo is much shorter, but the time to full deployment is longer <a class="yt-timestamp" data-t="02:08:00">[02:08:00]</a>. This inner loop of prototyping, iterating, and even user research through AI conversations is shortened, but the bar for scale becomes much higher <a class="yt-timestamp" data-t="02:31:00">[02:31:00]</a>.
*   **[[role_of_product_managers_in_ai | Taste-making and Editing Function]]**: While the supply of ideas and prototypes will increase significantly, the "editing function" or "taste-making" at the heart of [[impact_of_ai_on_product_management | product management]] becomes even more critical to avoid "Frankenstein products" <a class="yt-timestamp" data-t="02:51:00">[02:51:00]</a> <a class="yt-timestamp" data-t="02:17:00">[02:17:00]</a>.
*   **[[impact_of_ai_on_product_roles | Role of Coding]]**: The idea that coding is dead is fundamentally disagreed with. While layers of abstraction will increase, enabling "software operators" (SO) instead of Software Engineers (SWE), understanding computer science and its mental models remains crucial <a class="yt-timestamp" data-t="02:50:00">[02:50:00]</a> <a class="yt-timestamp" data-t="02:17:00">[02:17:00]</a>.
*   **Internal AI Usage**: Aparna uses a Chrome extension that prompts "How can you use AI to do what you're going to do right now?" on every new tab to encourage "reflexive AI usage" and challenge ingrained habits <a class="yt-timestamp" data-t="03:41:00">[03:41:00]</a>. She built this extension herself using GitHub Copilot <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a>.
*   **Updating Priors**: It is challenging to update one's understanding of what AI models can do, as their capabilities evolve very rapidly. Product builders should demand more from AI and not be limited by past limitations <a class="yt-timestamp" data-t="03:02:00">[03:02:00]</a>.

## Agent Collaboration and Future Outlook
A significant area of excitement is how humans and agents will collaborate. Aparna envisions a "co-working space" where humans and agents work together to produce significantly more than either could alone <a class="yt-timestamp" data-t="05:11:00">[05:11:00]</a>. This involves delegating tasks, inspecting agent work, and mediating information flow between people <a class="yt-timestamp" data-t="05:41:00">[05:41:00]</a>. Current experiences are largely single-player, and there's an opportunity to reimagine collaborative products and experiences with agents <a class="yt-timestamp" data-t="05:57:00">[05:57:00]</a>.

[!NOTE]
Aparna uses a "Frontier program" at Microsoft to operationalize "living one year in the future." This involves creating an environment where employees can experiment with cutting-edge AI tools and deep research agents to understand how they change individual and team workflows <a class="yt-timestamp" data-t="01:07:00">[01:07:00]</a>. This allows early adopters to engage with experimental features without insisting on company-wide adoption, fostering new muscles and understanding of compressed AI cycles <a class="yt-timestamp" data-t="01:10:00">[01:10:00]</a>.