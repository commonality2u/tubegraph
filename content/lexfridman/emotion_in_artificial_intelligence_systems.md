---
title: Emotion in artificial intelligence systems
videoId: qwsft6tmvBA
---

From: [[lexfridman]] <br/> 

The discussion surrounding emotion in artificial intelligence (AI) systems is an intricate one, involving various scientific and philosophical considerations. [[humans_and_artificial_intelligence | Lisa Feldman Barrett]], a distinguished professor of psychology at Northeastern University and an expert in human emotion, provides valuable insights into how emotions could be integrated into future AI systems. 

## Misconceptions About Emotion

> [!info] Common Misconception
> 
> A prevalent misconception is that emotions can be accurately discerned from facial expressions alone. Many believe that specific facial expressions are universally indicative of certain emotions: scowling means anger, smiling means happiness, and so on <a class="yt-timestamp" data-t="05:00">[05:00]</a>. However, Barrett argues that emotions are more complex and cannot be reduced to mere facial movements. AI systems built to detect emotions from facial expressions only offer systems to read facial movements, which do not intrinsically carry emotional meanings <a class="yt-timestamp" data-t="05:40">[05:40]</a>.

## Basics of Emotion Creation

Barrett suggests two conflicting views on how emotion is created: 

1. **Pre-wired Emotion Circuits**: The belief in inherent circuits predetermined for specific emotions, such as anger or happiness <a class="yt-timestamp" data-t="09:19">[09:19]</a>.
2. **Constructed Emotion**: The notion that emotions are not pre-wired but are constructed by the brain in response to certain ingredients or building blocks associated with physical and social contexts <a class="yt-timestamp" data-t="11:02">[11:02]</a>.

Artificial Intelligence systems might benefit by adopting the latter approach, where systems use basic ingredients to construct emotional responses dynamically <a class="yt-timestamp" data-t="14:23">[14:23]</a>.

## Challenges in Grafting Emotion in AI

[[challenges_in_aibased_emotion_recognition | Building emotion recognition systems in AI]] is a complex endeavor due to several factors:

- **Absence of Body**: Since much of human emotion arises from physiological changes within the body, AI systems without bodies lack an essential component of human emotional experience <a class="yt-timestamp" data-t="53:01">[53:01]</a>.

- **Learning from Experience**: Human emotions are shaped by cultural and experiential factors. Infants learn emotional expressions through interactions, which is not a straightforward process to replicate in AI systems <a class="yt-timestamp" data-t="30:00">[30:00]</a>.

## Emotional Expression as a Cultural Construct

Barrett posits that emotional expression can be viewed as a kind of language or social construct that is learned rather than innate< a class="yt-timestamp" data-t="25:29">[25:29]</a>. Emotional expressions serve as a socially agreed-upon means of communication that assigns meaning beyond the facial movements themselves <a class="yt-timestamp" data-t="27:59">[27:59]</a>.

## Implications for AI Development

Creating emotionally intelligent AI involves endowing systems with the ability to navigate human-like experiences through simulations of physiological and biological responses, often needing something akin to a physical body <a class="yt-timestamp" data-t="41:33">[41:33]</a>. The challenge lies in developing systems that can mimic the complex interplay of social and biological factors that drive human emotion.

## Conclusion

The integration of emotional intelligence into AI systems remains an area of active research with significant philosophical and technical implications. As Barrett elaborates, it involves understanding the fundamental nature of emotions and how they are constructed, rather than merely assuming universally-recognized physical expressions. The journey towards emotionally intelligent AI will necessitate interdisciplinary approaches, embracing insights from neurosciences, psychology, and engineering.