---
title: potential solutions to AI challenges
videoId: yYr1-qkgjMo
---

From: [[limitless-ft]] <br/> 

The "Intelligence Curse" is defined as the set of incentives that may arise upon unlocking artificial general intelligence (AGI), which is the ability to automate most or all human labor <a class="yt-timestamp" data-t="00:00:03">[00:00:03]</a>. In such a world, there is concern that governments, powerful actors, and corporations may lose their incentive to care for regular people, severing the economic incentive that has existed throughout human history <a class="yt-timestamp" data-t="00:00:17">[00:00:17]</a>. This scenario mirrors the "resource curse" seen in economies afflicted by abundant natural resources, where powerful actors may neglect the general populace as their wealth no longer depends on human labor <a class="yt-timestamp" data-t="00:00:44">[00:00:44]</a>.

The core argument of the Intelligence Curse is based on three premises:
1.  AGI is accruing incredible capability and power and is on a near-term horizon (potentially within 5 years) <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.
2.  [[ai_and_the_future_of_employment | AI will replace humans for valuable economic labor]], especially through a "pyramid replacement" model starting from entry-level positions and moving upwards <a class="yt-timestamp" data-t="00:09:56">[00:09:56]</a>.
3.  As a result, powerful actors (nation states and companies) will no longer have an incentive to care for regular people, as humans are no longer their primary economic engine <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>.

In this transformed landscape, capital (including physical assets, GPUs, and cash) becomes more important than human labor as a factor of production <a class="yt-timestamp" data-t="00:22:07">[00:22:07]</a>. This shift could lead to decreased social mobility, where capital can be substituted for labor more effectively, potentially creating a "permanent caste system" based on inherited capital <a class="yt-timestamp" data-t="00:24:58">[00:24:58]</a>. The historical analogy is the period before the Industrial Revolution, where human talent was less critical, and social mobility was very low <a class="yt-timestamp" data-t="00:28:06">[00:28:06]</a>. Furthermore, it could erode classical liberalism, as the incentives for states to invest in public goods and human welfare (like education or infrastructure) diminish when their revenue no longer primarily depends on taxing human labor <a class="yt-timestamp" data-t="00:36:59">[00:36:59]</a>.

## Breaking the Intelligence Curse

To address these profound [[economic_and_social_impacts_of_ai | economic and social impacts of AI]], a framework for solutions has been proposed, encapsulated by three key strategies: **Avert**, **Diffuse**, and **Democratize** <a class="yt-timestamp" data-t="01:09:05">[01:09:05]</a>. This approach aims to proactively shape the future of AI rather than merely reacting to its challenges.

### Avert Catastrophes

The first step is to **avert** potential catastrophes that AI might enable, without, critically, requiring centralizing control <a class="yt-timestamp" data-t="01:13:26">[01:13:26]</a>. AI's capacity for misuse, such as enabling bio-weapons or cyber-attacks, is a significant concern <a class="yt-timestamp" data-t="01:14:43">[01:14:43]</a>. Historically, tragedies have justified significant government power grabs and centralization, such as the PATRIOT Act after 9/11, which led to significant restrictions on civil liberties <a class="yt-timestamp" data-t="01:15:13">[01:15:13]</a>. Centralizing the means of production through AI into a few hands carries risks akin to historical totalitarian regimes <a class="yt-timestamp" data-t="01:16:06">[01:16:06]</a>.

A key strategy for averting these outcomes is **differential technology development**, also known as "defensive accelerationism" <a class="yt-timestamp" data-t="01:17:03">[01:17:03]</a>. This involves prioritizing and accelerating the development of technologies that help guard against risks and empower humans, ensuring they arrive before the more dangerous or worrying technologies <a class="yt-timestamp" data-t="01:17:08">[01:17:08]</a>. Examples include:
*   Developing robust cyber defenses before [[the_potential_and_risks_of_ai_in_everyday_life | AI]] can easily perform cyber-attacks <a class="yt-timestamp" data-t="01:17:25">[01:17:25]</a>.
*   Hardening the world against bio-weapons systems before [[the_potential_and_risks_of_ai_in_everyday_life | AI]] can design them <a class="yt-timestamp" data-t="01:17:29">[01:17:29]</a>.
*   Focusing on areas like biosecurity, cybersecurity, and AI alignment <a class="yt-timestamp" data-t="01:17:53">[01:17:53]</a>.

This approach is about making the "safe, good, pro-human thing the winning strategy," shifting the equilibrium without relying on external coordination with other actors <a class="yt-timestamp" data-t="01:25:03">[01:25:03]</a>.

### Diffuse Benefits and Tools

The second strategy is to **diffuse** the benefits of AI by ensuring widespread access to AI tools and economic opportunities <a class="yt-timestamp" data-t="01:18:18">[01:18:18]</a>. The goal is to help as many people as possible benefit economically from [[the_future_of_ai_hardware | AI]] quickly, so that by the time radical AI hits, more people are owners, have built companies, and have access to the technology <a class="yt-timestamp" data-t="01:18:50">[01:18:50]</a>. This means giving "AI superpowers" to everyone <a class="yt-timestamp" data-t="01:19:10">[01:19:10]</a>.

This strategy involves two phases:
1.  **Augmentation Phase:** In the current phase, where AI agency is not fully developed, there is an market opportunity to invest in [[the_future_of_ai_hardware | AI]] augmenting tools <a class="yt-timestamp" data-t="01:20:20">[01:20:20]</a>. These tools, like Cursor for software engineers, empower humans in the driver's seat rather than fully replacing them <a class="yt-timestamp" data-t="01:20:43">[01:20:43]</a>. Extending this "AI human augmentation" window helps access untapped economic potential and focuses on what can be done today <a class="yt-timestamp" data-t="01:21:02">[01:21:02]</a>.
2.  **User-Aligned Models:** In the future, this involves aligning models directly to users, leveraging individual "tacit knowledge" and data <a class="yt-timestamp" data-t="01:21:19">[01:21:19]</a>. This could involve AIs trained on a user's unique knowledge, behaving like them, and representing their judgment, thus ensuring the user gets compensated from their [[economic_and_social_impacts_of_ai | economic activity]], even as the systems become more intelligent <a class="yt-timestamp" data-t="01:21:50">[01:21:50]</a>.

A broad endorsement of open-source models is also considered supportive of diffusion, especially when efforts have been made to secure the world against major disasters <a class="yt-timestamp" data-t="01:20:00">[01:20:00]</a>.

### Democratize Power and Governance

The final and crucial step is to **democratize** power, ensuring that humans can still maintain political agency and hold institutions in check <a class="yt-timestamp" data-t="01:22:27">[01:22:27]</a>. This involves strengthening democratic structures so that they can override capital incentives when necessary <a class="yt-timestamp" data-t="01:22:42">[01:22:42]</a>.

This includes:
*   **Technological assistance for governance:** Leveraging AI to improve governance, verification, coordination, and trust <a class="yt-timestamp" data-t="01:22:50">[01:22:50]</a>. Examples include AI helping policymakers understand voter sentiment, AI advocating on behalf of individuals, and AI auditing information with provable guarantees, potentially offering more incorruptible judgments than humans <a class="yt-timestamp" data-t="01:23:09">[01:23:09]</a>. This can provide building blocks for more effective and representative governance <a class="yt-timestamp" data-t="01:23:55">[01:23:55]</a>.
*   **Strengthening democratic institutions:** Adopting policies like campaign finance reform, strengthening anti-corruption laws, and improving bureaucratic competence <a class="yt-timestamp" data-t="01:25:38">[01:25:38]</a>.
*   **Electing trustworthy leaders:** Voters should prioritize electing politicians with integrity who can make good decisions on behalf of the populace, even if those decisions go against immediate economic incentives <a class="yt-timestamp" data-t="01:25:56">[01:25:56]</a>.

### The Payoff and Call to Action

Solving the Intelligence Curse promises a future of immense potential, offering the greatest technological revolution in human history <a class="yt-timestamp" data-t="01:29:35">[01:29:35]</a>. This includes:
*   Curing unimaginable diseases <a class="yt-timestamp" data-t="01:29:47">[01:29:47]</a>.
*   Achieving total abundance <a class="yt-timestamp" data-t="01:29:52">[01:29:52]</a>.
*   Unlocking vast resources <a class="yt-timestamp" data-t="01:29:54">[01:29:54]</a>.
*   Providing experiences previously limited to the ultra-elite to everyone <a class="yt-timestamp" data-t="01:29:58">[01:29:58]</a>.
*   Abolishing poverty and disease <a class="yt-timestamp" data-t="01:30:05">[01:30:05]</a>.
*   Increasing human agency and control over the world with fewer drawbacks <a class="yt-timestamp" data-t="01:30:14">[01:30:14]</a>.
*   Building technology that ensures that doing the "safe good pro-human thing is the winning strategy" <a class="yt-timestamp" data-t="01:25:15">[01:25:15]</a>.

Listeners are encouraged to explore specific tech ideas, build solutions that align with these goals, and engage with the political process by electing trustworthy leaders <a class="yt-timestamp" data-t="01:27:10">[01:27:10]</a>. Strategic career decisions, focusing on roles that require learning to be one's own actor and commanding agents or augmentative tools, can also prepare individuals for the coming changes <a class="yt-timestamp" data-t="01:28:56">[01:28:56]</a>.

> "If we can get this right, the promise of artificial intelligence is that instead of having less agency and less control over your world, you get more with a whole lot less the drawbacks." <a class="yt-timestamp" data-t="01:30:10">[01:30:10]</a>