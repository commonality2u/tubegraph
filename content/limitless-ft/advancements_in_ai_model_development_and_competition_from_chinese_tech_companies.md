---
title: Advancements in AI model development and competition from Chinese tech companies
videoId: RJin72IysMw
---

From: [[limitless-ft]] <br/> 

The AI landscape is experiencing rapid [[advancements_in_ai_model_development_and_competition_from_chinese_tech_companies | model advancements]] and intense competition, particularly from Chinese tech companies that are increasingly challenging Western dominance in efficiency and cost.

## Global Trends in AI Model Development

The current trends in AI model development show an increase in efficiency, an accelerated rate of progress, and a significant decrease in the cost per query or token [00:46:38](<a class="yt-timestamp" data-t="00:46:38">[00:46:38]</a>. This means more power at a lower cost, which unlocks greater productive output from tokens [00:46:52](<a class="yt-timestamp" data-t="00:46:52">[00:46:52]</a>. The declining cost per query also opens opportunities for scaling up reinforcement learning, potentially leading to smarter models at a cheaper cost [00:49:21](<a class="yt-timestamp" data-t="00:49:21">[00:49:21]</a>.

### Google's Gemini 2.5 Flash

Google's Gemini 2.5 Flash is identified as one of the leading models, even surpassing OpenAI's GPT-4o in many aspects, despite not receiving as much attention [00:34:28](<a class="yt-timestamp" data-t="00:34:28">[00:34:28]</a>. A potential reason for its lower visibility is its current availability primarily via API, rather than through Google's main consumer interface for Gemini [00:34:46](<a class="yt-timestamp" data-t="00:34:46">[00:34:46]</a>. This model demonstrates significant improvements in reasoning compared to its predecessor, Gemini 2.0 Flash [00:34:57](<a class="yt-timestamp" data-t="00:34:57">[00:34:57]</a>. It is also comparatively cheaper than most other models, with only Gemini 2.0 Flash being more economical, while offering a substantial leap in ability [00:35:22](<a class="yt-timestamp" data-t="00:35:22">[00:35:22]</a>. It performs better across various metrics, including reasoning, science, coding, and mathematics [00:35:34](<a class="yt-timestamp" data-t="00:35:34">[00:35:34]</a>.

Despite its capabilities, the stickiness of OpenAI's products, like ChatGPT, means that even powerful new models from competitors like Gemini struggle to gain widespread consumer adoption [00:36:05](<a class="yt-timestamp" data-t="00:36:05">[00:36:05]</a>. The lack of a user-friendly product to leverage these advancements limits public excitement and adoption [00:36:17](<a class="yt-timestamp" data-t="00:36:17">[00:36:17]</a>. This highlights a persistent challenge for Google: while they have incredible software, they struggle to create compelling consumer products and experiences [00:07:00](<a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>.

## Chinese Competition in AI

Chinese AI companies are rapidly advancing, challenging the long-standing dominance of Western firms.

### DeepSeek's New Model

DeepSeek, a Chinese manufacturer, is set to release a new major model update, which is rumored to feature 1.2 trillion parameters [00:42:32](<a class="yt-timestamp" data-t="00:42:32">[00:42:32]</a>. This model is a hybrid mixture-of-experts (MoE) model, meaning only a subset of parameters is queried for each request, making it more efficient [00:42:39](<a class="yt-timestamp" data-t="00:42:39">[00:42:39]</a>. This efficiency significantly drives down cost, with the new model expected to be 97.3% cheaper than GPT-4o [00:43:04](<a class="yt-timestamp" data-t="00:43:04">[00:43:04]</a>. It has been trained on a massive 5.2 petabytes of data and is designed for improved reasoning [00:43:42](<a class="yt-timestamp" data-t="00:43:42">[00:43:42]</a>.

DeepSeek's focus on efficiency and rapid acceleration is a key differentiator [00:45:35](<a class="yt-timestamp" data-t="00:45:35">[00:45:35]</a>. While OpenAI and Google's Gemini are currently leading in frontier models, DeepSeek's efficiency could allow it to quickly surpass leading models in the US [00:45:41](<a class="yt-timestamp" data-t="00:45:41">[00:45:41]</a>.

### Advancements in AI Hardware

A critical aspect of Chinese AI development is their progress in [[the_future_of_ai_hardware | AI hardware]], particularly chips. DeepSeek's new model boasts 82% utilization on the Huawei Ascend 910B, a Chinese-manufactured AI chip [00:43:55](<a class="yt-timestamp" data-t="00:43:55">[00:43:55]</a>. This is significant because Nvidia has historically dominated over 95% of the chip manufacturing industry, including compute and design [00:44:10](<a class="yt-timestamp" data-t="00:44:10">[00:44:10]</a>. Huawei's Ascend 910B is now about 75% as effective as Nvidia's H100, one of their flagship chips [00:44:39](<a class="yt-timestamp" data-t="00:44:39">[00:44:39]</a>. This demonstrates China's rapid catch-up in [[challenges_and_implications_of_ai_hardware_development | AI hardware development]], despite previously being considered a decade behind the Western world [00:44:34](<a class="yt-timestamp" data-t="00:44:34">[00:44:34]</a>.

Huawei also recently launched a 718 billion parameter model, which was trained using 6,000 of their new Ascend chips [00:52:20](<a class="yt-timestamp" data-t="00:52:20">[00:52:20]</a>. This represents a reduction from the 8,000 chips used to train their previous model, which had half the parameter count [00:52:40](<a class="yt-timestamp" data-t="00:52:40">[00:52:40]</a>. This trend of decreasing chip count for increasing model intelligence is a notable and potentially "scary" development [00:52:51](<a class="yt-timestamp" data-t="00:52:51">[00:52:51]</a>.

### Implications of Cost Reduction and Open-Sourcing

The aggressive decrease in cost per query/token by companies like DeepSeek and Huawei unlocks significant opportunities [00:46:41](<a class="yt-timestamp" data-t="00:46:41">[00:46:41]</a>. A 97% cost reduction means that 33 times more compute can be done for the same cost [00:47:27](<a class="yt-timestamp" data-t="00:47:27">[00:47:27]</a>. While this doesn't directly translate to 33 times better outcomes, it significantly increases the accessibility and affordability of intelligence [00:48:42](<a class="yt-timestamp" data-t="00:48:42">[00:48:42]</a>. This lower cost per token can enable more efficient distillation of large models into smaller, hyper-specialized versions, potentially even for local device use like iPhones [00:50:56](<a class="yt-timestamp" data-t="00:50:56">[00:50:56]</a>. This could lead to a modular approach where networks of hyper-trained nodes interact based on query needs [00:51:43](<a class="yt-timestamp" data-t="00:51:43">[00:51:43]</a>.

Chinese companies, including DeepSeek and Meta, are increasingly open-sourcing their models [00:53:03](<a class="yt-timestamp" data-t="00:53:03">[00:53:03]</a>. This allows Western developers to benefit from their innovations for now [00:53:00](<a class="yt-timestamp" data-t="00:53:00">[00:53:00]</a>. However, there's an expectation that they may eventually close access once they achieve or surpass parity with Western models [00:53:10](<a class="yt-timestamp" data-t="00:53:10">[00:53:10]</a>. This strategy not only makes AI more accessible and cheaper but also demonstrates innovation in design and execution, moving beyond mere copying of Western technologies [00:52:03](<a class="yt-timestamp" data-t="00:52:03">[00:52:03]</a>.