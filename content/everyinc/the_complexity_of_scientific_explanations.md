---
title: The complexity of scientific explanations
videoId: tNRMWNfrkxc
---

From: [[everyinc]] <br/> 

Science has historically focused on finding [[the_challenge_of_explaining_advanced_scientific_concepts | clear and parsimonious explanations]] for how the world works, which has been highly successful in fields like physics and chemistry <a class="yt-timestamp" data-t="00:18:41">[00:18:41]</a>. However, in disciplines dealing with highly complex systems, such as psychology or biology, achieving such explanations can be incredibly difficult <a class="yt-timestamp" data-t="00:19:01">[00:19:01]</a>. The increasing volume of scientific literature also makes it challenging for humans to keep up <a class="yt-timestamp" data-t="02:10:00">[02:10:00]</a>.

## Science Beyond Human Comprehension

The concept of explaining quantum mechanics to a dog illustrates that some well-specified theories might simply be beyond human comprehension <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>, <a class="yt-timestamp" data-t="00:24:16">[00:24:16]</a>. Humans already use tools like telescopes to see beyond their eyes and calculators to perform computations they cannot do manually <a class="yt-timestamp" data-t="00:12:00">[00:12:00]</a>. This suggests a future where certain scientific complexities might be beyond human understanding, requiring acceptance of different, more general forms of explanation <a class="yt-timestamp" data-t="00:26:00">[00:26:00]</a>.

### The Predictive World

AI and [[large_language_models_for_scientific_prediction | large language models]] (LLMs) offer a path to achieving accurate predictions without necessarily providing human-understandable explanations <a class="yt-timestamp" data-t="00:19:47">[00:19:47]</a>. This shift could transform science from primarily an explanation-seeking endeavor to an engineering problem focused on prediction <a class="yt-timestamp" data-t="00:20:01">[00:20:01]</a>.

The BrainGPT project, for instance, utilizes LLMs fine-tuned on 20 years of neuroscience literature to predict the outcomes of neuroscience studies more accurately than human experts <a class="yt-timestamp" data-t="03:06:00">[03:06:00]</a>, <a class="yt-timestamp" data-t="03:24:00">[03:24:00]</a>. This predictive capability is crucial for identifying informative studies, avoiding redundant experiments, and addressing reproducibility issues in science <a class="yt-timestamp" data-t="04:46:00">[04:46:00]</a>.

> "Maybe we're just going to be in this predictive world and it's not even dystopian like everything could be better we'll just have stories about how this stuff works so like maybe scientist will be like the new priests just interpreting things and like making it explaining it to how it how it works and providing meaning to the systems" <a class="yt-timestamp" data-t="00:30:00">[00:30:00]</a>, <a class="yt-timestamp" data-t="00:33:00">[00:33:00]</a>

### Why Explanations are Hard in Complex Systems

Biological systems, including the brain, are incredibly messy and involve thousands of interacting variables across multiple levels, from DNA and molecular findings to psychology and behavior <a class="yt-timestamp" data-t="00:40:00">[00:40:00]</a>, <a class="yt-timestamp" data-t="02:10:00">[02:10:00]</a>, <a class="yt-timestamp" data-t="03:17:00">[03:17:00]</a>. These systems feature complex feedback cycles and delays <a class="yt-timestamp" data-t="02:24:00">[02:24:00]</a>. Unlike engineers who design abstraction layers to simplify systems (e.g., hardware to software) <a class="yt-timestamp" data-t="03:03:00">[03:03:00]</a>, nature does not create such neat divisions <a class="yt-timestamp" data-t="03:05:00">[03:05:00]</a>. This inherent complexity means a "clean" human-understandable explanation may not exist <a class="yt-timestamp" data-t="02:35:00">[02:35:00]</a>.

## The Seduction of Simple Narratives

Humans tend to prefer simple, coherent narratives, which are effective in politics, law, and everyday communication <a class="yt-timestamp" data-t="00:41:00">[00:41:00]</a>. This preference for parsimonious explanations can be a heuristic for what makes an appealing scientific explanation <a class="yt-timestamp" data-t="00:42:00">[00:42:00]</a>. However, applying this to highly complex systems like the brain or real-world phenomena can lead to oversimplification or misinterpretation of deeper truths <a class="yt-timestamp" data-t="00:43:00">[00:43:00]</a>.

Furthermore, scientists, once they believe a particular story, may engage in "confirmatory work," collecting data that supports their existing framework, thus prolonging the life of simple explanations beyond their utility <a class="yt-timestamp" data-t="00:44:00">[00:44:00]</a>.

### Case Study: Intuitive Cell Types in Neuroscience

Research, such as the paper "The inevitability and superfluousness of cell types and spatial cognition," highlights the danger of forcing intuitive understandings onto complex systems <a class="yt-timestamp" data-t="03:15:00">[03:15:00]</a>. Major discoveries in neuroscience have often involved recording from a single cell and forming a clear, intuitive explanation for its function, such as "place cells" acting as the brain's GPS system <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>.

However, studies show that in larger deep networks trained in virtual reality environments, similar "intuitive cell types" can emerge even in random networks that don't serve the function of navigation or localization <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>. This suggests that these simple interpretations are often contrived and imposed by the human observer, rather than reflecting the system's true operation <a class="yt-timestamp" data-t="03:45:00">[03:45:00]</a>.

Historically, initial "Eureka" moments about simple cell types are often followed by decades of research revealing their complexity and dependence on numerous factors, such as room distortion, rewards, path history, or viewpoint <a class="yt-timestamp" data-t="03:06:00">[03:06:00]</a>. This ongoing pattern suggests that such simple, attractive explanations are often seductive but ultimately limiting <a class="yt-timestamp" data-t="03:52:00">[03:52:00]</a>.

## Redefining Science in a Complex World

The future of science may involve a shift in emphasis from seeking "clean explanations" to leveraging powerful predictive tools <a class="yt-timestamp" data-t="02:28:00">[02:28:00]</a>.

### The Role of Data and Computational Tools

There is a growing trend towards [[the_role_of_data_in_scientific_research | larger scale studies]] and the integration of massive data sets, including DNA databases, disease databases, and brain recordings <a class="yt-timestamp" data-t="02:22:00">[02:22:00]</a>, <a class="yt-timestamp" data-t="02:48:00">[02:48:00]</a>. This "Sensor Fusion problem" of connecting diverse data types requires advanced computational skills and [[large_language_models_for_scientific_prediction | large language models]] <a class="yt-timestamp" data-t="02:56:00">[02:56:00]</a>. For example, training a model on both psychology and neuroscience data to see if it improves neuroscience predictions offers a form of explanation about the fields' relation, even if it's not a simple equation <a class="yt-timestamp" data-t="02:52:00">[02:52:00]</a>.

In machine learning, advancements like AlexNet in computer vision demonstrated that training models on millions of natural images at scale led to greater progress in object recognition than decades of traditional vision science <a class="yt-timestamp" data-t="04:47:00">[04:47:00]</a>. This suggests that embracing real-world challenges and large-scale data can yield significant breakthroughs <a class="yt-timestamp" data-t="04:57:00">[04:57:00]</a>.

### Changing Expectations of Explanation

What constitutes a "satisfying explanation" may change over time <a class="yt-timestamp" data-t="03:09:00">[03:09:00]</a>. Future generations of scientists might find it satisfying if a trusted, standardized model indicates a relationship between two fields, even without a direct causal explanation <a class="yt-timestamp" data-t="03:45:00">[03:45:00]</a>.

This shift involves:
*   **Philosophical Reflection**: Scientists need to be more thoughtful and philosophical about the enterprise of science, including the nature and limits of explanations <a class="yt-timestamp" data-t="04:24:00">[04:24:00]</a>.
*   **Computational Emphasis**: Greater emphasis on computational skills, large-scale simulations, and understanding naturalistic environments and their inherent complexity <a class="yt-timestamp" data-t="04:36:00">[04:36:00]</a>.
*   **Human-Machine Teaming**: Using confidence metrics from models, like perplexity in LLMs, can enable effective human-machine collaboration, leading to better results than either alone <a class="yt-timestamp" data-t="00:15:13">[00:15:13]</a>.
*   **[[mechanistic_interpretability_of_language_models | Mechanistic interpretability]]**: While current LLMs are complex, efforts to interpret their internal workings may reveal hidden theories of phenomena like depression <a class="yt-timestamp" data-t="02:27:00">[02:27:00]</a>.

### Science and Subjectivity

Science, particularly the "view from nowhere" perspective, strives for objectivity and disembodied calculation, which is powerful for predicting outcomes like a probe reaching Mars <a class="yt-timestamp" data-t="05:08:00">[05:08:00]</a>. However, much of valuable human experience is subjective, and science, in its current form, may have limits in explaining phenomena like "qualia" (the subjective quality of experience) <a class="yt-timestamp" data-t="05:15:00">[05:15:00]</a>.

In fields like psychology, researchers must "operationalize" concepts like depression, which involves abstracting and quantifying them, implicitly ignoring other nuances <a class="yt-timestamp" data-t="05:27:00">[05:27:00]</a>. While science can offer correlates of experiences or predict outcomes like waking from anesthesia, it may not provide deep insights into first-person subjective experiences <a class="yt-timestamp" data-t="05:32:00">[05:32:00]</a>. This is why other forms of human knowledge, such as literature, religion, and music, remain vital for exploring and providing meaning to human experience <a class="yt-timestamp" data-t="05:39:00">[05:39:00]</a>. The [[interconnection_of_science_and_intuition | interplay of science and intuition]] may highlight that some phenomena are better understood through intuitive means, such as the skill of a great baseball player or a clinician <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a>, <a class="yt-timestamp" data-t="02:59:00">[02:59:00]</a>.