---
title: Interconnection of science and intuition
videoId: tNRMWNfrkxc
---

From: [[everyinc]] <br/> 

Traditional scientific methods have long prioritized finding clear, causal explanations for phenomena <a class="yt-timestamp" data-t="18:33:00">[18:33:00]</a>. However, with the advent of advanced AI, particularly large language models, the very nature of scientific inquiry may be shifting, emphasizing prediction over human-understandable explanation and re-evaluating the role of [[balancing_personal_intuition_with_external_feedback | intuition]].

## The Shift from Explanation to Prediction

For centuries, science has been "obsessed with explanations" because they are powerful for making predictions and offer a beautiful understanding of how the world works <a class="yt-timestamp" data-t="18:41:00">[18:41:00]</a>. This approach has been highly successful in fields like physics and chemistry <a class="yt-timestamp" data-t="18:52:00">[18:52:00]</a>.

However, in complex areas like psychology and other "soft sciences," finding "causal, parsimonious scientific explanations" is exceedingly difficult <a class="yt-timestamp" data-t="19:07:00">[19:07:07]</a>. This difficulty contributes to issues like the low reproducibility of findings <a class="yt-timestamp" data-t="19:12:00">[19:12:00]</a>. For instance, after 150 years, there's no "germ theory of mental illness"; many competing ideas exist for conditions like depression, but no single, clear explanation <a class="yt-timestamp" data-t="19:18:00">[19:18:00]</a>.

### Unbundling Prediction from Explanation
AI and machine learning (ML) approaches offer a new paradigm by allowing the "unbundling [of] explanations from predictions" <a class="yt-timestamp" data-t="19:47:00">[19:47:00]</a>. This means achieving accurate predictions without requiring explicit, human-understandable theories <a class="yt-timestamp" data-t="19:52:00">[19:52:00]</a>. For example, a system like BrainGPT, a large language model focused on neuroscience research, can predict the outcomes of neuroscience studies better than human experts <a class="yt-timestamp" data-t="02:50:00">[02:50:00]</a>, <a class="yt-timestamp" data-t="03:06:00">[03:06:00]</a>.

If a sufficiently predictive model is developed, the underlying theory "theoretically...exists in the neural network somewhere" <a class="yt-timestamp" data-t="20:21:00">[20:21:00]</a>. While neural networks may be more interpretable than human brains, the resulting theories for higher-level phenomena might be "so big that they don't fit in our rational brains" <a class="yt-timestamp" data-t="20:53:00">[20:53:00]</a>.

## Human Cognitive Limitations and the Power of Intuition

A core challenge is that human cognitive abilities might be inherently limited in grasping the true complexity of many real-world systems. This concept is illustrated by the analogy of "explaining quantum mechanics to a dog" <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>, <a class="yt-timestamp" data-t="24:16:00">[24:16:00]</a>. Just as quantum mechanics is beyond a dog's comprehension, many complex systems, particularly in biology and human behavior, might be beyond human understanding <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>, <a class="yt-timestamp" data-t="24:25:00">[24:25:00]</a>.

### The Rise of Intuition and "Stories"
If systems are too complex for "clean explanations" <a class="yt-timestamp" data-t="23:31:00">[23:31:00]</a>, then [[balancing_rationality_and_imagination_in_business_and_personal_development | intuition]] may become increasingly valuable. A good clinician, for example, often relies on an "intuitive sense of what's wrong with someone" to help them, even if they can't fully articulate a causal explanation <a class="yt-timestamp" data-t="21:01:00">[21:01:00]</a>. Similarly, a great baseball player's explanation of how they hit the ball is often "useless" because their actions are based on intuitive processing <a class="yt-timestamp" data-t="22:29:00">[22:29:00]</a>.

AI could help us "re-realize the power of intuition" by making it "usable" in a way that parallels how logic is used <a class="yt-timestamp" data-t="21:31:00">[21:31:00]</a>. Instead of finding precise causal chains, science might increasingly rely on predictive models, with humans providing "stories about how this stuff works" <a class="yt-timestamp" data-t="25:29:00">[25:29:00]</a>. In this future, scientists might act as "new priests," interpreting and providing meaning to complex systems without necessarily having a full, human-comprehensible explanation <a class="yt-timestamp" data-t="00:37:00">[00:37:00]</a>, <a class="yt-timestamp" data-t="25:31:00">[25:31:00]</a>.

### The Seduction of Simple Explanations
Humans have a natural preference for "simple story, coherent narrative" explanations <a class="yt-timestamp" data-t="41:07:00">[41:07:00]</a>. This is because such narratives have the "best information transmission value" and are easily understood and remembered <a class="yt-timestamp" data-t="41:14:00">[41:14:00]</a>. However, this preference can be problematic when dealing with complex systems where the underlying reality involves "10,000 variables and they're all interacting" at different levels <a class="yt-timestamp" data-t="23:17:00">[23:17:00]</a>, <a class="yt-timestamp" data-t="33:51:00">[33:51:00]</a>.

Forcing an "intuitive understanding" on a complex system can lead to misinterpretations <a class="yt-timestamp" data-t="38:45:00">[38:45:00]</a>. For example, some "intuitive cell types" identified in neuroscience, like "place cells," might appear to offer simple explanations (e.g., "the brain's GPS system") <a class="yt-timestamp" data-t="37:58:00">[37:58:00]</a>. However, research using deep networks in virtual reality environments showed that these "cell types" can "pop up even in random networks that don't serve the function of navigation or localization" <a class="yt-timestamp" data-t="38:35:00">[38:35:00]</a>. Such simple explanations, while "seductive," can be "ultimately limiting" <a class="yt-timestamp" data-t="40:49:00">[40:49:00]</a>.

## The Future of Science and Explanation

It is possible that in the future, "explanation and prediction unfortunately diverge" <a class="yt-timestamp" data-t="25:49:00">[25:49:00]</a>. This is not due to scientific error, but because "the world's really complex systems are complex" and human brains "aren't built to make sense of this kind of stuff" <a class="yt-timestamp" data-t="25:55:00">[25:55:00]</a>.

### Changing Forms of Explanation
Future explanations might take different forms. Instead of simple equations, they could involve broad characterizations, such as demonstrating that training a model on both psychology and neuroscience data leads to better predictions in neuroscience, indicating a relationship between the fields <a class="yt-timestamp" data-t="24:55:00">[24:55:00]</a>. This kind of "explanation" focuses on systemic behavior rather than granular causal chains <a class="yt-timestamp" data-t="25:08:00">[25:08:00]</a>.

The definition of a "satisfying" explanation might also change over time <a class="yt-timestamp" data-t="31:09:00">[31:09:00]</a>. As models become highly standardized and trusted, new results derived from them might be seen as equally fascinating as discovering underlying causal networks <a class="yt-timestamp" data-t="31:51:00">[31:51:00]</a>.

### Science's "View from Nowhere" vs. Subjective Experience
Science operates from a "view from nowhere"â€”an objective, disembodied perspective that aims to be universally true regardless of the observer <a class="yt-timestamp" data-t="50:48:00">[50:48:00]</a>. This is its strength, as seen in accurate predictions like launching a probe to Mars <a class="yt-timestamp" data-t="51:03:00">[51:03:00]</a>. However, a lot of valuable human experience is subjective, which is where "meaning comes in our lives" <a class="yt-timestamp" data-t="51:15:00">[51:15:00]</a>.

In fields like psychology, which attempts to be scientific but also deals with human experience, there can be an "overstep" <a class="yt-timestamp" data-t="51:46:00">[51:46:00]</a>. Psychology relies on operationalizing concepts (e.g., defining depression with measurable criteria) <a class="yt-timestamp" data-t="52:27:00">[52:27:00]</a>. However, it can become problematic when psychologists confuse objective insights with "deep insights into our subjective experiences" or "qualia" <a class="yt-timestamp" data-t="53:09:00">[53:09:00]</a>. Science may excel at predicting outcomes (e.g., whether a patient wakes up from anesthesia), but it likely has little to say "beyond correlates of these experiences" when it comes to subjective, first-person perspectives <a class="yt-timestamp" data-t="53:20:00">[53:20:00]</a>. This is why fields like [[the_interplay_between_scientific_explanations_and_spiritual_experiences | literature]], religion, and music continue to be vital explorations of human experience <a class="yt-timestamp" data-t="53:55:00">[53:55:00]</a>.

Ultimately, the future of science might involve a greater embrace of [[the_complexity_of_scientific_explanations | computational skills]], large-scale simulations, and consideration of the inherent complexity of naturalistic environments <a class="yt-timestamp" data-t="45:34:00">[45:34:00]</a>. It will require a shift in mindset, acknowledging that some things may simply be beyond human-level explanation, while still leveraging powerful tools for prediction and application <a class="yt-timestamp" data-t="46:08:00">[46:08:00]</a>.