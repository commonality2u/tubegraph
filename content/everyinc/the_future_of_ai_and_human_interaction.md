---
title: The future of AI and human interaction
videoId: E5EgUuzzH5I
---

From: [[everyinc]] <br/> 

The landscape of software and human interaction is undergoing a significant transformation due to [[potential_future_developments_and_implications_of_ai_technologies | AI]]. The shift is from deterministic software to something more "squishy" and stochastic, presenting new challenges and opportunities for design and interaction <a class="yt-timestamp" data-t="00:00:23">[00:00:23]</a>.

## Reimagining Software with [[potential_future_developments_and_implications_of_ai_technologies | AI]]
A core principle for rebuilding software with [[potential_future_developments_and_implications_of_ai_technologies | AI]] is to reduce human interaction with the database <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>. Ideally, the [[potential_future_developments_and_implications_of_ai_technologies | AI]] should manage the database, eliminating the need for manual field updates <a class="yt-timestamp" data-t="00:00:12">[00:00:12]</a>. For instance, in a CRM, the [[potential_future_developments_and_implications_of_ai_technologies | AI]] should automatically update deal amounts from emails or capture risk information from Slack conversations, making the database an implementation detail rather than a direct user interface <a class="yt-timestamp" data-t="00:14:24">[00:14:24]</a>. Users would interact more with processed outputs, such as daily progress bars or productivity metrics, rather than the raw database itself <a class="yt-timestamp" data-t="00:14:46">[00:14:46]</a>. This approach aims to make internal company information more legible and up-to-date without constant human intervention <a class="yt-timestamp" data-t="00:15:29">[00:15:29]</a>.

## New Primitives for Thinking with [[potential_future_developments_and_implications_of_ai_technologies | AI]]
The emergence of [[potential_future_developments_and_implications_of_ai_technologies | AI]] introduces new primitives for software design, alongside existing fundamental concepts like relational databases <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>. These new primitives include:
*   **Foundation Models (Thinking Boxes)**: These models act as "thinking boxes" that can take context and a task, then reason, format, and perform actions <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>. They automate cumbersome tasks that humans previously had to do <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>.
*   **Embeddings**: Essential for highly effective semantic search <a class="yt-timestamp" data-t="00:03:27">[00:03:27]</a>. Embeddings can capture many dimensions of information, making them useful for storing data even when its future use is unknown, contrasting with relational databases that benefit from a known schema <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a>. Both embeddings and deterministic querying (like SQL) are tools in the toolbox, with the choice depending on the specific question and performance needs <a class="yt-timestamp" data-t="00:11:39">[00:11:39]</a>. For example, precise numerical queries require deterministic methods, while flexible semantic searches benefit from embeddings <a class="yt-timestamp" data-t="00:12:24">[00:12:24]</a>.

Other crucial elements for [[the_future_of_ai_agents_and_user_interaction | AI]]-driven systems include:
*   **Databases with UI**: A human-understandable UI around the database that the [[potential_future_developments_and_implications_of_ai_technologies | AI]] can also use <a class="yt-timestamp" data-t="00:04:12">[00:04:12]</a>.
*   **Permission Models**: A clear and controllable permission model for what the [[potential_future_developments_and_implications_of_ai_technologies | AI]] can read or write is vital, especially with coding [[the_future_of_ai_agents_and_user_interaction | agent]] tools <a class="yt-timestamp" data-t="00:04:17">[00:04:17]</a>.

## The Evolution of User Interfaces

### Chat Interfaces
Chat interfaces are likely to remain a form of [[humanlike_interaction_with_ai | human-AI interaction]] due to their intuitive nature <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>. However, a major issue is the "empty text box" problem, where users don't know what to type <a class="yt-timestamp" data-t="00:05:27">[00:05:27]</a>. While good for exploration, chat is less effective for users who simply want a task done <a class="yt-timestamp" data-t="00:05:37">[00:05:37]</a>. Most users prefer solutions to problems presented directly, rather than exploring complex tools <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a>. This suggests a future where users leverage pre-defined workflows found by "toolmakers" (exploratory users) <a class="yt-timestamp" data-t="00:06:43">[00:06:43]</a>.

### Discrete vs. Continuous Interaction
Traditional UIs involve discrete updates (e.g., checking a radio box), typically along one dimension <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a>. With chat, [[humanlike_interaction_with_ai | interaction]] can be fuzzier and more continuous across multiple dimensions simultaneously <a class="yt-timestamp" data-t="00:07:17">[00:07:17]</a>. [[potential_future_developments_and_implications_of_ai_technologies | AI]] can execute a sequence of commands based on high-level instructions, effectively "turning many knobs" at once <a class="yt-timestamp" data-t="00:07:54">[00:07:54]</a>. This introduces the challenge of explaining to the user what complex changes have occurred <a class="yt-timestamp" data-t="00:08:22">[00:08:22]</a>. Summaries often remain too high-level, making it difficult to be concrete enough without being overly detailed <a class="yt-timestamp" data-t="00:09:12">[00:09:12]</a>.

### Designing [[future_of_ai_and_agi_development | LLM]] Interfaces
Effective [[future_of_ai_and_agi_development | LLM]] interfaces should:
*   **Align with Training Data**: Speak the language the model was trained on as much as possible (e.g., Markdown over complex XML) <a class="yt-timestamp" data-t="00:23:51">[00:23:51]</a>. Overly complex formatting instructions can harm the model's ability to perform other tasks <a class="yt-timestamp" data-t="00:24:41">[00:24:41]</a>.
*   **Simplify Output Structure**: Keep the output structure as simple as possible while still accomplishing the task <a class="yt-timestamp" data-t="00:25:31">[00:25:31]</a>.
*   **Prevent Errors**: Prioritize making classes of issues impossible within the system, using validation, rather than relying solely on prompt improvements <a class="yt-timestamp" data-t="00:26:36">[00:26:36]</a>. Forcing the model to output specific intermediate values (like estimated record counts) can help align its understanding and allow for early error detection <a class="yt-timestamp" data-t="00:27:27">[00:27:27]</a>. This is akin to a "Chain of Thought" approach <a class="yt-timestamp" data-t="00:28:08">[00:28:08]</a>.

## Challenges of "Squishy Software"

Developing and scaling [[potential_future_developments_and_implications_of_ai_technologies | AI]] applications presents unique challenges due to their stochastic nature <a class="yt-timestamp" data-t="00:28:33">[00:28:33]</a>:
*   **Unknown Failure Cases**: Unlike deterministic software, it's hard to know all the cases where [[potential_future_developments_and_implications_of_ai_technologies | AI]] might fail <a class="yt-timestamp" data-t="00:29:14">[00:29:14]</a>. New classes of errors often emerge during prompt refinement <a class="yt-timestamp" data-t="00:29:20">[00:29:20]</a>.
*   **Evaluation**:
    *   **Deterministic Evals**: Ideal when possible, especially for classifier elements that produce enum values <a class="yt-timestamp" data-t="00:29:47">[00:29:47]</a>. These allow for easy data collection and scoring <a class="yt-timestamp" data-t="00:30:01">[00:30:01]</a>.
    *   **Non-deterministic Evals (Model-Graded Evals)**: Using an [[potential_future_developments_and_implications_of_ai_technologies | AI]] to evaluate another [[potential_future_developments_and_implications_of_ai_technologies | AI]] is challenging because you need to evaluate the eval itself <a class="yt-timestamp" data-t="00:30:21">[00:30:21]</a>. These work best when the evaluation task is targeted and clearly described, ensuring the grading model is highly reliable <a class="yt-timestamp" data-t="00:30:50">[00:30:50]</a>.
*   **Continuous Improvement Loop**: A robust loop for logging, collecting, and labeling issues is essential for optimizing prompts and preventing regressions <a class="yt-timestamp" data-t="00:31:23">[00:31:23]</a>. This relies on good evals and data sets that capture error distributions <a class="yt-timestamp" data-t="00:31:56">[00:31:56]</a>.
*   **Context Management**: Limiting and carefully selecting context remains crucial, even with larger context windows in modern models <a class="yt-timestamp" data-t="00:34:39">[00:34:39]</a>. Removing irrelevant information still yields returns due to latency, attention, and quality concerns <a class="yt-timestamp" data-t="00:34:44">[00:34:44]</a>.

## [[the_future_of_ai_agents_and_user_interaction | AI Agents]] and Tools
The concept of [[the_future_of_ai_agents_and_user_interaction | AI agents]] interacting with computers is evolving <a class="yt-timestamp" data-t="00:18:01">[00:18:01]</a>. While implicit tool understanding (where the model infers tools like a browser) is emerging, explicit, specialized tools often provide better quality and lower latency <a class="yt-timestamp" data-t="00:19:15">[00:19:15]</a>. For tasks where specific APIs exist, they are preferable for speed and determinism <a class="yt-timestamp" data-t="00:20:25">[00:20:25]</a>. However, the ability for [[the_future_of_ai_agents_and_user_interaction | AI]] to "do stuff on a computer" acts as a useful escape hatch when no specific API is available <a class="yt-timestamp" data-t="00:20:30">[00:20:30]</a>.

A key concern is the market dynamic of [[the_future_of_ai_agents_and_user_interaction | AI agents]] accessing third-party tools <a class="yt-timestamp" data-t="00:21:06">[00:21:06]</a>. Users will want [[the_future_of_ai_agents_and_user_interaction | AI]] to access their applications, leading to potential conflicts with companies that might not want such access <a class="yt-timestamp" data-t="00:21:18">[00:21:18]</a>. The ideal outcome would involve a system where everyone allows access, and value accrues to the creators of the software being used <a class="yt-timestamp" data-t="00:22:00">[00:22:00]</a>. This might lead to dedicated "[[future_of_ai_and_agi_development | LLM]]-friendly" interfaces, perhaps simplified HTML versions of websites, designed specifically for [[future_of_ai_and_agi_development | LLM]] interaction <a class="yt-timestamp" data-t="00:22:50">[00:22:50]</a>.

The ultimate goal for [[the_future_of_ai_agents_and_user_interaction | AI agents]] is to seamlessly integrate tool use into a Chain of Thought process, allowing the [[potential_future_developments_and_implications_of_ai_technologies | AI]] to enter a loop of thinking, using tools, observing outputs, and continuing to think <a class="yt-timestamp" data-t="00:39:58">[00:39:58]</a>. This long-horizon reinforcement learning over tool use is seen as a key unlock for [[the_future_of_ai_agents_and_user_interaction | agents]] to truly work <a class="yt-timestamp" data-t="00:40:08">[00:40:08]</a>.

## The Changing Role of Humanity

### What Humans Are "Good At"
The traditional view of what humans are good at compared to machines is constantly shifting <a class="yt-timestamp" data-t="00:49:20">[00:49:20]</a>. With the potential for [[future_of_ai_and_agi_development | AGI]], it's posited that machines will eventually be better at nearly everything <a class="yt-timestamp" data-t="00:49:40">[00:49:40]</a>. The most important human role then becomes ensuring the future aligns with human values and desires <a class="yt-timestamp" data-t="00:49:52">[00:49:52]</a>. This boils down to **wanting**—defining high-level goals and orchestrating [[potential_future_developments_and_implications_of_ai_technologies | AI]] tasks, as well as observing and verifying that the [[potential_future_developments_and_implications_of_ai_technologies | AI]] is doing the right thing <a class="yt-timestamp" data-t="00:50:07">[00:50:07]</a>.

### Creativity and Intuition
The idea that human creativity and intuition hold a special, unreplicable value is challenged <a class="yt-timestamp" data-t="00:53:31">[00:53:31]</a>. [[potential_future_developments_and_implications_of_ai_technologies | AI]] has already shown capabilities in generating beautiful art and performing complex reasoning <a class="yt-timestamp" data-t="00:53:46">[00:53:46]</a>. The focus should shift from what humans can *do* uniquely to what humans *will* and *desire* to be done <a class="yt-timestamp" data-t="00:54:05">[00:54:05]</a>. It's expected that [[potential_future_developments_and_implications_of_ai_technologies | AI]] will eventually surpass humans in creativity and intuition <a class="yt-timestamp" data-t="00:54:15">[00:54:15]</a>.

From this perspective, the key human attributes in an [[potential_future_developments_and_implications_of_ai_technologies | AI]]-driven world are:
*   **Openness**: To new experiences and the rapid changes brought by [[potential_future_developments_and_implications_of_ai_technologies | AI]] <a class="yt-timestamp" data-t="00:54:25">[00:54:25]</a>.
*   **Ambition**: To redefine what humanity can achieve, unencumbered by past limitations <a class="yt-timestamp" data-t="00:54:33">[00:54:33]</a>.
*   **Optimism**: About the possibilities that [[potential_future_developments_and_implications_of_ai_technologies | AI]] unlocks <a class="yt-timestamp" data-t="00:54:50">[00:54:50]</a>.

## The Horizon of [[future_of_ai_and_agi_development | AGI]]
The prospect of [[future_of_ai_and_agi_development | AGI]] (Artificial General Intelligence) within the next decade is considered a strong possibility, potentially without requiring major paradigm shifts <a class="yt-timestamp" data-t="00:50:30">[00:50:30]</a>. [[future_of_ai_and_agi_development | AGI]] is defined as [[potential_future_developments_and_implications_of_ai_technologies | AI]] that can perform all economically useful tasks <a class="yt-timestamp" data-t="00:50:42">[00:50:42]</a>.

A critical aspect of [[future_of_ai_and_agi_development | AGI]] development is the intelligence explosion, where [[potential_future_developments_and_implications_of_ai_technologies | AI]] becomes good enough at [[future_of_ai_and_agi_development | AI]] research tasks to significantly contribute to making itself better <a class="yt-timestamp" data-t="00:50:50">[00:50:50]</a>. The process of [[potential_future_developments_and_implications_of_ai_technologies | AI]] research—reading literature, gathering context, developing ideas, designing and running experiments, analyzing results, and deciding next steps—all seem amenable to automation by a sufficiently advanced foundation model <a class="yt-timestamp" data-t="00:51:10">[00:51:10]</a>.

A key factor in scaling [[future_of_ai_and_agi_development | AI]] training is the ability to verify results <a class="yt-timestamp" data-t="00:41:06">[00:41:06]</a>. This applies to areas like coding (passing unit tests) or math problems (correct answers), enabling large-scale reinforcement learning <a class="yt-timestamp" data-t="00:41:20">[00:41:20]</a>. While this focus on verifiable tasks might seem to limit "aesthetic creativity" or intuition, it's suggested that if an aesthetic points to truth (e.g., simpler theories being more likely correct), the model could learn that aesthetic over time through exposure to vast amounts of verifiable data <a class="yt-timestamp" data-t="00:43:58">[00:43:58]</a>. Humans may use aesthetic "shortcuts" due to cognitive limits, but [[future_of_ai_and_agi_development | LLMs]] can combine these intuitive shortcuts with brute-force exploration in a way humans cannot <a class="yt-timestamp" data-t="00:44:20">[00:44:20]</a>.

The concept of [[future_of_ai_and_agi_development | AGI]] is a "moving target" because [[potential_future_developments_and_implications_of_ai_technologies | AI]] itself changes what economically valuable tasks are <a class="yt-timestamp" data-t="00:51:57">[00:51:57]</a>. The economy is expected to transform, leading to completely new types of jobs and significantly more economic value, driven by the elastic scalability of [[potential_future_developments_and_implications_of_ai_technologies | AI]] compared to human labor <a class="yt-timestamp" data-t="00:52:40">[00:52:40]</a>.