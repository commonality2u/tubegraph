---
title: Future of AI and AGI development
videoId: exzPO4hAD9s
---

From: [[everyinc]] <br/> 

The [[the_evolution_of_artificial_intelligence|evolution of artificial intelligence]] (AI) and [[potential_future_developments_and_implications_of_ai_technologies|AGI]] (Artificial General Intelligence) development is characterized by a "pluralistic framework" with multiple models, stakeholders, and approaches to any given problem <a class="yt-timestamp" data-t="00:09:32">[00:09:32]</a>. The core of current AI applications involves mapping inputs to desired outputs, and achieving these outputs is often a "skill issue" <a class="yt-timestamp" data-t="00:44:06">[00:44:06]</a>.

## Prompt Engineering in the Age of AI

Prompt engineering is described as an iterative process, akin to the scientific method, focusing on trying different approaches and iterating based on a good dataset and framework <a class="yt-timestamp" data-t="00:00:08">[00:00:08]</a>. The idea that there's one "new prompting strategy" from research papers is viewed with skepticism; it's more about operationalizing prompt edits than discovering a single correct prompt <a class="yt-timestamp" data-t="00:23:00">[00:23:00]</a>.

Reports of the "death of the prompt engineer" have been exaggerated <a class="yt-timestamp" data-t="00:01:41">[00:01:41]</a>. The core thesis is that prompt engineering is fundamentally about embedding domain knowledge into an [[the_evolution_of_artificial_intelligence|LM]] system <a class="yt-timestamp" data-t="00:02:29">[00:02:29]</a>. While superficial aspects like "please and thank you" in prompts may disappear, the need to iterate on this "core source code" will remain <a class="yt-timestamp" data-t="00:02:39">[00:02:39]</a>.

### The Three Primitives of Prompt Engineering
The prompt engineering workflow centers on three key primitives:
*   **The Prompt:** The instructions given to the [[the_evolution_of_artificial_intelligence|AI]].
*   **The Eval:** Methods for testing and evaluating the [[the_evolution_of_artificial_intelligence|AI]]'s responses.
*   **The Dataset:** The sample data used for testing and iteration <a class="yt-timestamp" data-t="00:02:09">[00:02:09]</a>.

It is argued that while one of these elements might be automated, the others still need to be built and managed <a class="yt-timestamp" data-t="00:02:20">[00:02:20]</a>.

### The Role of Domain Experts
For most companies, winning in the age of generative [[the_evolution_of_artificial_intelligence|AI]] will not come from hiring the best machine learning engineers or building defensibility through machine learning <a class="yt-timestamp" data-t="00:27:27">[00:27:27]</a>. Instead, success will be achieved by collaborating with domain experts who can accurately define the problem and its specifications <a class="yt-timestamp" data-t="00:31:03">[00:31:03]</a>.

> "You're going to win by working with the domain experts who can write down that problem... who could define the specs of what you're solving." <a class="yt-timestamp" data-t="00:31:03">[00:31:03]</a>

An example of this is a non-technical teacher acting as a prompt engineer for an [[the_future_of_ai_and_human_interaction|AI]] parenting coach app <a class="yt-timestamp" data-t="00:12:13">[00:12:13]</a>. This teacher edits prompts and sees the changes immediately in the app <a class="yt-timestamp" data-t="00:12:30">[00:12:30]</a>. This highlights that engineers may not be the best people to define how an [[the_evolution_of_artificial_intelligence|AI]] should respond in specialized fields like education, therapy, or law <a class="yt-timestamp" data-t="00:13:10">[00:13:10]</a>.

### Computational Irreducibility and AI
The concept of computational irreducibility, as discussed by Stephen Wolfram, suggests that in solving a problem, certain parts can be collapsed or sped up, but there will always be an "irreducible" part that cannot be simplified or factored <a class="yt-timestamp" data-t="00:08:25">[00:08:25]</a>. In the context of [[the_future_of_ai_and_human_interaction|AI]], even with the best [[the_evolution_of_artificial_intelligence|AI]] tools, the hardest part remains defining *what* problem to solve <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>.

*   This means there is no "one prompt to rule them all" or "one dataset to rule them all" for complex problems <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>.
*   The definition of "best" is highly contextual, leading to many different approaches and solutions for a single problem, like building an [[the_future_of_ai_and_human_interaction|AI]] math tutor <a class="yt-timestamp" data-t="00:05:27">[00:05:27]</a>.
*   This also implies that there won't be one [[the_evolution_of_artificial_intelligence|AI]] model that rules them all, as different answers and approaches are required <a class="yt-timestamp" data-t="00:18:31">[00:18:31]</a>.

## Perspectives on AGI and AI Development

### AGI Skepticism
A strong opinion is expressed against the common discourse around AGI taking over the world or killing humans <a class="yt-timestamp" data-t="00:09:58">[00:09:58]</a>. The focus should be on how to build with [[the_evolution_of_artificial_intelligence|AI]] as a tool <a class="yt-timestamp" data-t="00:10:39">[00:10:39]</a>. [[the_evolution_of_artificial_intelligence|AI]] is viewed primarily as a means to translate language to data and data to language, which opens up many possibilities <a class="yt-timestamp" data-t="00:10:53">[00:10:53]</a>.

The definition of [[potential_future_developments_and_implications_of_ai_technologies|AGI]] as an [[the_future_of_ai_and_human_interaction|AI]] that can do most human tasks is considered achievable through sufficient prompt engineering and building systems with existing [[the_evolution_of_artificial_intelligence|AI]] toolboxes <a class="yt-timestamp" data-t="00:55:51">[00:55:51]</a>.

### Current Challenges in AI/AGI
*   **Defining the Problem:** The most significant challenge in [[potential_future_developments_and_implications_of_ai_technologies|AI]] development is identifying the right problem to solve, as building is becoming less expensive <a class="yt-timestamp" data-t="00:06:56">[00:06:56]</a>. This requires real-world interaction, creativity, and a specific viewpoint <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>.
*   **Lack of Ground Truth in Evals:** Many real-world problems, such as summarizing calls or emails, lack a clear "ground truth" for evaluation <a class="yt-timestamp" data-t="00:30:51">[00:30:51]</a>. This makes generic [[potential_future_developments_and_implications_of_ai_technologies|eval]] benchmarks less reliable <a class="yt-timestamp" data-t="00:33:06">[00:33:06]</a>. The difficulty lies in codifying human judgment and breaking it down into measurable heuristics <a class="yt-timestamp" data-t="00:34:25">[00:34:25]</a>.
*   **Overfitting in General Purpose Prompts:** Large general-purpose [[the_evolution_of_artificial_intelligence|AI]]s like [[the_evolution_of_artificial_intelligence|ChatGPT]] or Anthropic's systems often have "bad" and "run-on" system prompts, which accumulate "prompt debt" by continuously adding conditions ("do this if they say this, don't say this") <a class="yt-timestamp" data-t="00:42:27">[00:42:27]</a>. This approach can lead to overfitting and a lack of conciseness <a class="yt-timestamp" data-t="00:43:00">[00:43:00]</a>.
*   **Implicit vs. Explicit Routing:** There's a trade-off between explicit routing (where the [[the_evolution_of_artificial_intelligence|AI]] explicitly chooses a tool or model) and implicit routing (where the model internally routes requests). While explicit routing can lead to better user experience (as seen in [[the_evolution_of_artificial_intelligence|ChatGPT]]'s plugin evolution), the optimal choice depends on specific use cases, latency, and cost trade-offs <a class="yt-timestamp" data-t="00:44:53">[00:44:53]</a>.

### Architectural Approaches for Effective Prompts
Instead of stacking messages into a single prompt, a better approach is to build a workflow, a directed acyclic graph (DAG), or a graph to route user requests to the appropriate prompt <a class="yt-timestamp" data-t="00:27:04">[00:27:04]</a>. This "prompt router" approach enables prompts to do "one thing and do one thing really well," making them easier to test, collaborate on, and more robust <a class="yt-timestamp" data-t="00:27:14">[00:27:14]</a>. This also helps with "jailbreaking" prevention by limiting the scope of individual prompts <a class="yt-timestamp" data-t="00:28:57">[00:28:57]</a>.

While models improve, reducing the need for such discrete prompting, there's always a trade-off: highly specialized prompts are more reliable but less flexible, while general prompts can answer anything but may not always be accurate <a class="yt-timestamp" data-t="00:27:40">[00:27:40]</a>. This approach is particularly useful in the early stages of a prompt's lifecycle when the distribution of user questions is less known <a class="yt-timestamp" data-t="00:28:20">[00:28:20]</a>.

### The Future of AI Agents and User Interaction
The future of [[the_future_of_ai_agents_and_user_interaction|AI agents and user interaction]] involves leveraging domain experts to distribute knowledge through [[the_evolution_of_artificial_intelligence|AI]] applications <a class="yt-timestamp" data-t="00:32:41">[00:32:41]</a>. This can manifest as:
*   A domain expert crafting prompts for all users (e.g., the teacher for the parenting app) <a class="yt-timestamp" data-t="00:37:04">[00:37:04]</a>.
*   Users becoming their own "prompt engineers" by constructing or modifying existing prompts (e.g., custom "spirals" for converting podcast transcripts to tweets) <a class="yt-timestamp" data-t="00:38:19">[00:38:19]</a>.

Ultimately, these approaches share the common goal of taking expert knowledge and distributing it, whether across a workflow, data, or directly to a user base <a class="yt-timestamp" data-t="00:38:40">[00:38:40]</a>.

### The Hacker Energy and Single-Use Software
The current era of [[the_evolution_of_artificial_intelligence|AI]] allows for a return of "hacker energy," where individuals can build custom tools for themselves without significant investment <a class="yt-timestamp" data-t="00:38:41">[00:38:41]</a>. This leads to the development of "single-use software" – tools that might not be commercially viable but are easy enough to create for personal use, such as a natural language to SQL translator for a specific database schema <a class="yt-timestamp" data-t="00:39:30">[00:39:30]</a>.

This trend extends beyond software, as [[the_evolution_of_artificial_intelligence|AI]] lowers the cost of telling stories <a class="yt-timestamp" data-t="00:40:00">[00:40:00]</a>. It enables storytelling about niche topics that were previously too expensive to cover, allowing for a diverse range of content from an "NPR-style talk show about something that NPR would never cover" <a class="yt-timestamp" data-t="00:40:29">[00:40:29]</a>. This implies a future where [[future_possibilities_and_implications_of_ai_in_gaming|AI]]-generated content might be "junk food" – widely consumed and enjoyed – while human-made "organic" content will still exist and serve different purposes <a class="yt-timestamp" data-t="00:41:22">[00:41:22]</a>.