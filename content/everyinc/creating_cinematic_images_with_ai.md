---
title: Creating cinematic images with AI
videoId: 1Vl3_KwrSiE
---

From: [[everyinc]] <br/> 
[[AI in filmmaking | AI]] tools are transforming the process of creating dynamic, cinematic imagery from static pictures. One prominent platform for this purpose is Runway, which allows users to animate images and add subtle or dramatic motion effects.

## Runway: An AI-Powered Tool for Video Generation
Runway is a versatile [[AI in film making | AI tool]] that offers "text-to-image-to-video" capabilities within a single application <a class="yt-timestamp" data-t="00:00:26">[00:00:26]</a>. It is particularly useful for users working under time constraints <a class="yt-timestamp" data-t="00:00:32">[00:00:32]</a>. Users can import images, including those generated by other [[using_ai_tools_for_creative_projects | AI tools]] like Midjourney or ChatGPT <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>.

## The Motion Brush Tool
Runway's "Motion Brush" is a key feature for [[creating_cinematic_experiences_with_ai_tools | animating cinematic images]] <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>. This tool provides a high level of control, allowing users to define specific areas of an image that should move and the degree of that movement <a class="yt-timestamp" data-t="00:00:41">[00:00:41]</a>.

### How to Use the Motion Brush
1.  **Select Areas for Movement:** Users choose a brush tool to "color over" areas of the image they wish to animate <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. It's not overly delicate, meaning minor inaccuracies can often be corrected or tolerated <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.
2.  **Define Movement Parameters:** After selecting an area, users can specify the type and intensity of movement. Different "brushes" can be used for different elements within the same image <a class="yt-timestamp" data-t="00:01:29">[00:01:29]</a>.
    *   **Ambient Movement:** This creates subtle motion, like rustling clothes or hair <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>. For instance, a 0.5 ambient movement can be applied to a character <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>.
    *   **Vertical Brush:** This setting can make elements like smoke appear to move upwards <a class="yt-timestamp" data-t="00:02:47">[00:02:47]</a>.
    *   **Proximity:** This can be used to make elements appear to come closer to the viewer, such as light rays <a class="yt-timestamp" data-t="00:03:11">[00:03:11]</a>.
3.  **Generate Output:** Once parameters are set, the user clicks "done" and can generate multiple video outputs simultaneously <a class="yt-timestamp" data-t="00:03:26">[00:03:26]</a>. Generating five versions at once is recommended as the outcome can vary <a class="yt-timestamp" data-t="00:03:34">[00:03:34]</a>. The generation process for a single image can take around a minute <a class="yt-timestamp" data-t="00:04:30">[00:04:30]</a>.
4.  **Optional Camera Movement:** Beyond animating specific elements, Runway also allows for camera movements like zooming out <a class="yt-timestamp" data-t="00:04:11">[00:04:11]</a>.

### Example: Animating a "Nicholas Cage" Image
In a demonstration, an image featuring Nicholas Cage surrounded by spirits and looking at a "Book of the Dead" was used <a class="yt-timestamp" data-t="00:00:52">[00:00:52]</a>.
*   **Nicholas Cage:** Given a small ambient movement (0.5) to suggest subtle motion <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>.
*   **Spirits (Ghosts):** Vertical movement (e.g., a "two ambience") was applied to make smoke rise <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>.
*   **Light from God (Rays):** Proximity was used to make the light rays appear to move towards the viewer <a class="yt-timestamp" data-t="00:03:14">[00:03:14]</a>.
*   **Candles:** Simple ambient noise was applied to simulate flickering <a class="yt-timestamp" data-t="00:03:18">[00:03:18]</a>.

The generated videos showed subtle movements, such as Nicholas Cage leaning in or tilting his head, and the light dimming <a class="yt-timestamp" data-t="00:05:03">[00:05:03]</a>, <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>, <a class="yt-timestamp" data-t="00:06:16">[00:06:16]</a>. Different generations might produce varying effects, such as a character's appearance changing <a class="yt-timestamp" data-t="00:05:51">[00:05:51]</a>.

### Post-Production
Users can take multiple generated clips and layer them in editing software like Adobe Premiere. This allows for combining preferred elements from different generations, such as taking the best smoke effect from one clip and the best character movement from another, and masking them together <a class="yt-timestamp" data-t="00:05:28">[00:05:28]</a>. This demonstrates the [[intersection_of_traditional_and_ai_filmmaking | intersection of traditional and AI filmmaking]] techniques.