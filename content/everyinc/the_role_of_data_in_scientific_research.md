---
title: The role of data in scientific research
videoId: D5jABTx-_3s
---

From: [[everyinc]] <br/> 

Scientific research is undergoing a fundamental shift, driven by increased access to data and computational power <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>. This evolution challenges traditional formats for disseminating scientific findings and re-evaluates the role of data itself.

## The Evolution of Scientific Publication

Traditionally, the scientific paper has been the primary substrate for releasing scientific information <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. However, this format has inherent limitations, notably the selective publication of results. This means that information regarding failed experiments or attempted methods is often not shared, leading to a skewed understanding of scientific progress <a class="yt-timestamp" data-t="00:00:16">[00:00:16]</a>, and hindering reproducibility.

Historically, the "story" (the narrative of the research and its conclusions) and the underlying data were often bundled together, creating problems in fields from machine learning to journalism <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>. The solution isn't to abandon stories, as they remain crucial for conveying information, but to recognize that the underlying data is now equally, if not more, important <a class="yt-timestamp" data-t="00:40:40">[00:40:40]</a>, especially as it becomes more discoverable and legible <a class="yt-timestamp" data-t="00:51:30">[00:51:30]</a>.

## Data-Centric Science

There's a growing emphasis on open data initiatives <a class="yt-timestamp" data-t="00:40:39">[00:40:39]</a>. Instead of solely focusing on producing papers, the scientific endeavor should prioritize gathering and aggregating high-quality datasets. This approach allows any scientist to build models on these datasets, fostering broader collaboration and new discoveries <a class="yt-timestamp" data-t="00:40:51">[00:40:51]</a>.

The "data asymmetry" between entities like large language models (which are trained on vast amounts of internet text) and researchers is significant. If more data sets across various domains were openly released, it could lead to non-linear improvements in research through combinatorial power <a class="yt-timestamp" data-t="00:43:48">[00:43:48]</a>. Scientists are becoming more computational by nature, equipped with new tools to answer complex questions <a class="yt-timestamp" data-t="00:44:29">[00:44:29]</a>.

### The Value of "N of One" Experiments

In fields like psychology or psychiatry, where causal explanations are extremely complex <a class="yt-timestamp" data-t="00:41:46">[00:41:46]</a>, a shift towards prioritizing predictions is proposed. "N of one" experiments, which focus on individual cases rather than generalized findings, can be incredibly useful and are now feasible with modern [[experiments_and_tools_in_ai_research | tools]] <a class="yt-timestamp" data-t="00:26:33">[00:26:33]</a>. For example, predicting an individual's OCD symptoms or depression can be life-changing, even without a complete causal explanation <a class="yt-timestamp" data-t="00:41:50">[00:41:50]</a>.

This approach acknowledges the contextual nature of many scientific findings, especially in cognitive science and psychology, where grand generalizations are often weaker or less reliable than initially thought <a class="yt-timestamp" data-t="00:45:57">[00:45:57]</a>.

## [[ai_and_its_impact_on_science | AI and its Impact on Science]]

[[advantages_of_ai_in_data_analysis | AI and its impact on science]] is already fundamentally changing science:
*   **Knowledge Acquisition** [[advantages_of_ai_in_data_analysis | AI]] can efficiently comb through vast amounts of information, saving researchers countless years in literature review and data extraction <a class="yt-timestamp" data-t="00:38:43">[00:38:43]</a>.
*   **Simulation** [[large_language_models_for_scientific_prediction | Large language models for scientific prediction]] are becoming adept at simulating data. Given a solid existing dataset, they can generate more data, which is invaluable for scientists exploring the possibility space and narrowing down research avenues <a class="yt-timestamp" data-t="00:39:05">[00:39:05]</a>.
*   **Data Transformation** AI models can transduce diverse data inputs (like video, audio, or biometric data) into meaningful signals for other models. For instance, emotion embedding from video can be used in predictive models <a class="yt-timestamp" data-t="00:31:11">[00:31:11]</a>.

However, humans remain crucial for hypothesis generation and critical thinking about what kind of data to collect <a class="yt-timestamp" data-t="00:39:56">[00:39:56]</a>.

## Unbundling Story and Data

The concept of "unbundling" the story or conclusion from the underlying data is significant. In journalism, for instance, platforms that provide access to sources and raw interviews alongside an article allow readers to form their own opinions <a class="yt-timestamp" data-t="00:49:19">[00:49:19]</a>. This approach can be applied to academic papers as well, allowing deeper understanding, alternative hypothesis generation, and testing based on direct access to the data <a class="yt-timestamp" data-t="00:48:43">[00:48:43]</a>.

This shift helps address the problem of papers that don't bear out their hypotheses not being published; if only the data set is published, its quality is the primary criterion, regardless of the initial hypothesis <a class="yt-timestamp" data-t="00:46:50">[00:46:50]</a>.

## [[future_of_science_with_ai | The Future of Science with AI]]

[[future_of_science_with_ai | The future of science with AI]] may look more like engineering, focusing on data gathering and model building <a class="yt-timestamp" data-t="00:42:08">[00:42:08]</a>. This mirrors the shift from symbolic AI, which sought rules and logical formulas to define intelligence, to subsymbolic AI, which involves throwing large amounts of data at models to let them figure things out <a class="yt-timestamp" data-t="00:42:27">[00:42:27]</a>.

There is a need for more data trusts, where large tech companies with vast datasets could donate their data to qualified researchers, enabling answers to critical questions that are currently out of reach for academic studies <a class="yt-timestamp" data-t="00:47:36">[00:47:36]</a>. This openness, alongside open-source models, is crucial for academic progress <a class="yt-timestamp" data-t="00:47:55">[00:47:55]</a>.

Ultimately, science is moving towards a model where access to data is paramount, enabling new forms of research, collaboration, and deeper understanding beyond traditional publication methods.