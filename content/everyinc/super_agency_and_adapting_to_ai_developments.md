---
title: Super agency and adapting to AI developments
videoId: lQF0RuddS4g
---

From: [[everyinc]] <br/> 

"Superagency" is a concept that explores how individuals and societies can enhance their capabilities and control when faced with new technologies like artificial intelligence (AI) <a class="yt-timestamp" data-t="01:02:03">[01:02:03]</a>. Rather than viewing new technologies as a threat that diminishes human control, the perspective is that they can be leveraged to transform, extend, and enhance human agency <a class="yt-timestamp" data-t="00:09:09">[00:09:09]</a>.

## Historical Parallels of Technological Change

A common historical pattern emerges when new technologies are introduced: initial public dialogue often centers on fear and skepticism <a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>. This fear is rooted in the perception that new technology will reduce human agency <a class="yt-timestamp" data-t="00:07:44">[00:07:44]</a>.

Examples from history include:
*   **The Printing Press** When the printing press was introduced, public dialogue was similar to that around [[future_of_ai_and_agi_development | artificial intelligence]] today <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>. Concerns included the collapse of trust in human cognition, widespread misinformation, erosion of knowledge, and societal instability <a class="yt-timestamp" data-t="00:03:15">[00:03:15]</a>. Despite these fears, the printing press became indispensable for science, widespread literacy, education, and the progress of knowledge, underpinning modern institutions like universities <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a>. However, the transition period was challenging, leading to nearly a century of religious war <a class="yt-timestamp" data-t="00:04:15">[00:04:15]</a>.
*   **Smartphones** Initially, some people at forums like Davos argued that smartphones were "humanity-reducing" and akin to "cybernetic control of human beings" <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>. Yet, billions of people now use them because they offer a "massive increase in agency" <a class="yt-timestamp" data-t="00:09:54">[00:09:54]</a>. This collective elevation of individual agency can lead to "superagency" at a societal level <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>.

The ability to steer transitions with new technologies in a better way than previous generations, leveraging historical lessons, is a key opportunity for minimizing difficulties and maximizing benefits <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>.

## Understanding Agency: Internal vs. External Factors

Agency is not solely a product of external factors but also an internal, aesthetic experience or a "stance" one has towards the world <a class="yt-timestamp" data-t="00:24:00">[00:24:00]</a>. When encountering external circumstances, such as new technologies, approaching them as diminishing one's agency can be self-defeating <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. Instead, the focus should be on how to use the circumstance to transform, extend, and enhance one's agency <a class="yt-timestamp" data-t="00:12:10">[00:12:10]</a>.

This perspective is akin to the catechism: "the strength to change the things I can, the tolerance to live with the things I can't, and the wisdom to know the difference" <a class="yt-timestamp" data-t="00:32:51">[00:32:51]</a>. Recognizing what is within one's control and what is not is crucial for navigating the world <a class="yt-timestamp" data-t="00:40:00">[00:40:00]</a>. Over-focusing on things out of one's control can lead to misery and reduces effectiveness <a class="yt-timestamp" data-t="00:18:08">[00:18:08]</a>.

The idea of "high agency" in tech circles often implies having a high internal locus of control <a class="yt-timestamp" data-t="00:18:03">[00:18:03]</a>. However, it's also important to recognize situations where giving up control—such as in friendships, romantic relationships, team sports, or religious experiences—leads to meaningful personal growth and shared agency <a class="yt-timestamp" data-t="00:18:46">[00:18:46]</a>.

## Navigating Uncertainty with a Compass

Rather than rigid blueprints or plans, which break easily, a "compass" approach is more effective for navigating uncertain environments <a class="yt-timestamp" data-t="00:30:30">[00:30:30]</a>. A compass provides a sense of direction while allowing for flexibility and adjustment based on new information and changing conditions <a class="yt-timestamp" data-t="00:31:16">[00:31:16]</a>. This is particularly relevant for [[future_of_ai_and_agi_development | AI]], where a chatbot acts as an "informational GPS" <a class="yt-timestamp" data-t="00:31:47">[00:31:47]</a>.

This "techno-humanist compass" emphasizes embracing uncertainty as a feature, not a bug <a class="yt-timestamp" data-t="00:28:44">[00:28:44]</a>. The default Western stance of trying to eliminate uncertainty through philosophy, science, or religion can lead to trouble when dealing with technology <a class="yt-timestamp" data-t="00:22:50">[00:22:50]</a>. Instead, managing uncertainty through heuristics and adapting strategies, much like entrepreneurs and artists do, is crucial <a class="yt-timestamp" data-t="00:24:49">[00:24:49]</a>. Life is not deterministic like chess or Go; it involves randomness and epistemic uncertainty <a class="yt-timestamp" data-t="00:17:09">[00:17:09]</a>.

## Practical Adaptation for Professionals

Professionals must [[applying_agency_in_ai_development | deploy AI]] and engage with [[the_role_and_capabilities_of_ai_agents | AI agents]] to do their work <a class="yt-timestamp" data-t="00:37:06">[00:37:06]</a>. This isn't just about reading a book; it's about actively engaging with AI tools in serious ways, not just for trivial tasks <a class="yt-timestamp" data-t="00:37:22">[00:37:22]</a>.

*   **Experimentation:** Start using AI for tasks that are genuinely important to you <a class="yt-timestamp" data-t="00:37:45">[00:37:45]</a>. Even if AI isn't perfect, it can offer useful insights or accelerate processes. For instance, while ChatGPT might fail at providing venture capital investment advice, it can be useful for generating due diligence questions on a business plan <a class="yt-timestamp" data-t="00:38:07">[00:38:07]</a>.
*   **Job Transformation:** Many jobs will transform rather than disappear <a class="yt-timestamp" data-t="00:39:51">[00:39:51]</a>. The goal is for humans to become "humans with the [[future_of_ai_and_agi_development | AI]]" <a class="yt-timestamp" data-t="00:39:19">[00:39:19]</a>. AI can assist in learning new skills, identifying career paths, and executing tasks more efficiently, as in marketing <a class="yt-timestamp" data-t="00:40:03">[00:40:03]</a>.
*   **Co-pilot Approach:** Focus on AI as a "co-pilot" for human amplification, rather than solely for human replacement <a class="yt-timestamp" data-t="01:06:17">[01:06:17]</a>. This approach makes sense for [[impact_of_ai_on_media_and_product_development | media and product development]], for instance, where AI can assist with headlines or descriptions, lowering costs for those who couldn't previously afford human services <a class="yt-timestamp" data-t="01:06:58">[01:06:58]</a>. AI amplifies capabilities across the board, benefiting both those with less access and those who are already highly skilled <a class="yt-timestamp" data-t="01:07:38">[01:07:38]</a>.

## Societal Implications: Equitable Access and Private Commons

For [[managing_agency_in_the_age_of_ai | managing agency in the age of AI]] and maximizing societal benefit, [[shaping_ai_agents_to_meet_diverse_developer_needs | equitable access]] to [[future_of_ai_and_agi_development | AI]] is crucial <a class="yt-timestamp" data-t="00:41:52">[00:41:52]</a>. When more people can access and utilize AI, it unlocks broader talent and creates fairer participation in new jobs and career paths <a class="yt-timestamp" data-t="00:42:10">[00:42:10]</a>.

The concept of "private commons" refers to the personal data accumulated by individuals through platforms like Facebook and Google <a class="yt-timestamp" data-t="00:45:14">[00:45:14]</a>. With AI, this data becomes tremendously more valuable to the individual for insights and predictions <a class="yt-timestamp" data-t="00:45:37">[00:45:37]</a>. Allowing individuals the right to move and utilize their data as they wish is essential for enabling this private commons and creating "superagency" <a class="yt-timestamp" data-t="00:47:00">[00:47:00]</a>.

This also ties into the "Quantified Self" movement, where personal health data from devices (like Whoop) combined with AI can provide insights into conditions like OCD or even predict illnesses like COVID-19 <a class="yt-timestamp" data-t="00:49:37">[00:49:37]</a>. The ability to query and index personal data streams is vital for future medical and self-understanding advancements <a class="yt-timestamp" data-t="00:50:36">[00:50:36]</a>.

## The Future of AI and Cognitive Models

The evolution of AI mirrors shifts in philosophy, moving from a search for universal truths (symbolic AI) to a more pragmatic, pattern-matching approach (subsymbolic AI) <a class="yt-timestamp" data-t="00:52:12">[00:52:12]</a>. Symbolic AI, which attempts to define intelligence through discrete symbols and their relations, is often brittle and computationally expensive <a class="yt-timestamp" data-t="00:53:00">[00:53:00]</a>. Subsymbolic AI, like current large language models (LLMs), excels at fuzzy matching patterns and applying thousands of rules based on context <a class="yt-timestamp" data-t="00:53:38">[00:53:38]</a>.

The future of [[future_of_ai_and_agi_development | AI development]] will likely involve a combination of probabilistic models and symbols, leveraging the strengths of both <a class="yt-timestamp" data-t="00:55:26">[00:55:26]</a>. This approach acknowledges that while symbols are important, they often arise from a subsymbolic architecture <a class="yt-timestamp" data-t="00:58:00">[00:58:00]</a>. This shift in thinking, moving from deduction to induction and abduction (developing the best theory to model evidence), is crucial for [[combining_ai_interfaces_with_human_agency | combining AI interfaces with human agency]] and navigating the complexities of the world <a class="yt-timestamp" data-t="01:00:33">[01:00:33]</a>.

## Designing for Superagency

For technologists, "human agency" should be a core design principle <a class="yt-timestamp" data-t="01:04:30">[01:04:30]</a>. This means designing for:
*   **Iterative Engagement:** Making technologies easy for people to engage with in an iterative pattern, fostering a sense of control and participation <a class="yt-timestamp" data-t="01:05:36">[01:05:36]</a>.
*   **Human Amplification:** Prioritizing designs that act as "co-pilots" to amplify human capabilities, rather than solely focusing on human replacement <a class="yt-timestamp" data-t="01:06:15">[01:06:15]</a>. This creates "impromptu amplification intelligence" <a class="yt-timestamp" data-t="01:06:23">[01:06:23]</a>.

By fostering these principles, the goal is to raise the capability across all levels of society, from individuals with less access to highly skilled professionals, leading to a net positive impact <a class="yt-timestamp" data-t="01:07:37">[01:07:37]</a>.