---
title: Managing agency in the age of AI
videoId: lQF0RuddS4g
---

From: [[everyinc]] <br/> 

The concept of agency, defined as an internal, aesthetic experience or a "stance that we have towards the world" <a class="yt-timestamp" data-t="10:29:30">[10:29:30]</a>, is central to understanding human interaction with new technologies, particularly artificial intelligence. Initially, encountering external circumstances or new technologies can feel like a reduction of agency, leading to fear and resistance <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>. However, a more productive approach involves asking how these new tools can be used to transform, extend, and enhance one's [[super_agency_and_adapting_to_ai_developments | agency]] <a class="yt-timestamp" data-t="00:09:08">[00:09:08]</a>.

## Historical Precedent of Technological Transitions

Throughout history, significant technological changes have often been met with fear that they would lead to a collapse of societal norms, trust, and knowledge <a class="yt-timestamp" data-t="03:09:12">[03:09:12]</a>.

### The Printing Press
When the printing press was introduced, public dialogue expressed concerns about the collapse of trust in human cognition, widespread misinformation, and the erosion of knowledge and society <a class="yt-timestamp" data-t="03:07:07">[03:07:07]</a>. Despite these fears, the printing press became indispensable for science, widespread literacy, education, and the progress of knowledge, enabling the growth of institutions like universities <a class="yt-timestamp" data-t="03:43:40">[03:43:40]</a>. However, the transition period was not without challenges, leading to nearly a century of religious war <a class="yt-timestamp" data-t="04:17:09">[04:17:09]</a>. The lesson from history is that while transitions can be challenging, humanity can learn from past tragedies to navigate new technological leaps more compassionately and humanely, maximizing benefits <a class="yt-timestamp" data-t="06:00:54">[06:00:54]</a>.

### Modern Technologies
Examples like Uber and smartphones illustrate how technologies initially perceived as a loss of agency (e.g., not driving oneself <a class="yt-timestamp" data-t="08:32:00">[08:32:00]</a> or feeling controlled by devices <a class="yt-timestamp" data-t="09:30:00">[09:30:00]</a>) quickly become seen as massive increases in [[super_agency_and_adapting_to_ai_developments | agency]] for millions of people, leading to collective [[super_agency_and_adapting_to_ai_developments | super agency]] <a class="yt-timestamp" data-t="09:56:00">[09:56:00]</a>.

## The Psychology of Agency and Uncertainty

Fear of new technology often stems from a perception that it reduces individual, group, or societal agency <a class="yt-timestamp" data-t="07:29:00">[07:29:00]</a>. This reaction is based on the idea that agency changes, and some prior forms of agency may indeed be lost <a class="yt-timestamp" data-t="08:10:00">[08:10:00]</a>.

A key aspect of [[what_it_means_to_be_human_in_the_age_of_ai | human agency]] is the ability to choose how we approach external circumstances <a class="yt-timestamp" data-t="09:08:00">[09:08:00]</a>. If one approaches a new technology as "taking my agency," it can be self-defeating <a class="yt-timestamp" data-t="11:58:00">[11:58:00]</a>. Conversely, approaching it as an opportunity to transform, extend, and enhance one's agency leads to better outcomes <a class="yt-timestamp" data-t="12:09:00">[12:09:09]</a>.

> "The strength to change the things I can, the tolerance to live with the things I can't, and the wisdom to know the difference." <a class="yt-timestamp" data-t="00:34:00">[00:34:00]</a> <a class="yt-timestamp" data-t="13:37:00">[13:37:00]</a>

This catechism, adopted early in life, emphasizes distinguishing between what is under one's control and what is not <a class="yt-timestamp" data-t="14:16:00">[14:16:00]</a>. Playing board games with elements of randomness, like Avalon Hill games or Starfleet Battles, helped in understanding how to navigate a world with uncertainty, unlike deterministic games like chess or Go <a class="yt-timestamp" data-t="17:03:00">[17:03:00]</a>.

While a "high agency" mindset is generally beneficial, applying an internal locus of control to things entirely out of one's control can lead to misery and ineffectiveness <a class="yt-timestamp" data-t="18:08:00">[18:08:08]</a>. Important life experiences, such as friendships, romantic relationships, team sports, or religious experiences, often involve giving up complete control <a class="yt-timestamp" data-t="18:46:00">[18:46:00]</a>.

### Embracing Uncertainty
Western philosophy and science have often aimed to eliminate uncertainty, seeking universal truths and explicit, fundamental laws <a class="yt-timestamp" data-t="22:53:00">[22:53:00]</a>. However, life inherently involves risk and uncertainty, such as driving on a highway <a class="yt-timestamp" data-t="24:21:00">[24:21:00]</a>.

A better approach is to manage uncertainty, understanding that some things are out of our control <a class="yt-timestamp" data-t="24:50:00">[24:50:00]</a>. Entrepreneurship, for instance, inherently involves navigating a world of risk <a class="yt-timestamp" data-t="25:28:00">[25:28:00]</a>. Embracing uncertainty, like "surfing" a wave, allows one to work with the dynamic context rather than trying to stop it <a class="yt-timestamp" data-t="29:20:00">[29:20:00]</a>. This "artistic entrepreneurial stance" <a class="yt-timestamp" data-t="27:47:00">[27:47:00]</a> toward uncertainty is crucial for working with new technologies <a class="yt-timestamp" data-t="27:52:00">[27:52:00]</a>.

Instead of rigid blueprints or plans, a "techno-humanist compass" or "cognitive GPS" <a class="yt-timestamp" data-t="30:22:00">[30:22:00]</a> allows for flexible navigation, adjusting one's path as new information and conditions arise <a class="yt-timestamp" data-t="31:16:00">[31:16:00]</a>. This approach can align with first principles by defining broad "navigational truths" rather than rigid, predetermined routes <a class="yt-timestamp" data-t="33:41:00">[33:41:00]</a>.

## Practical Approaches to AI and Agency

### Iterative Engagement
For individuals in tech (engineers, product managers, designers) or any profession, the best way to prepare for the [[super_agency_and_adapting_to_ai_developments | cognitive Industrial Revolution]] is to start engaging with AI tools seriously <a class="yt-timestamp" data-t="36:36:00">[36:36:00]</a>. This means going beyond casual use to applying AI to earnest tasks, identifying its current capabilities and limitations <a class="yt-timestamp" data-t="37:43:00">[37:43:00]</a>.

For example, while ChatGPT might not yet provide accurate venture capital investment strategies, it can be highly effective for tasks like generating due diligence questions for a business plan <a class="yt-timestamp" data-t="38:51:00">[38:51:00]</a>.

### Job Transformation vs. Replacement
Many jobs will transform rather than disappear entirely <a class="yt-timestamp" data-t="39:51:00">[39:51:00]</a>. The goal is for humans to become "humans with AI" <a class="yt-timestamp" data-t="39:19:00">[39:19:00]</a> <a class="yt-timestamp" data-t="39:23:00">[39:23:00]</a>. AI can assist in this transformation by helping individuals understand how their skills can accelerate new processes (e.g., marketing tasks) and identify new career paths if their current role is replaced (e.g., customer service agents transitioning to account management or sales) <a class="yt-timestamp" data-t="40:03:00">[40:03:00]</a>. This emphasizes [[using_ai_to_offload_cognitive_work | using AI to offload cognitive work]] and [[applying_agency_in_ai_development | applying agency in AI development]].

### Equitable Access
To ensure AI benefits society broadly, not just the wealthy, it must be put into as many people's hands as possible <a class="yt-timestamp" data-t="42:06:00">[42:06:00]</a>. [[applying_agency_in_ai_development | Equitable access]] fosters fair participation in new jobs and career paths, and unlocks talent from a broad range, benefiting all of society through increased creativity and maximum benefit <a class="yt-timestamp" data-t="42:25:00">[42:25:00]</a>.

### [[private_commons | Private Commons]] and Data Ownership
While generally cautious about regulation, the idea of [[private_commons | private commons]] is an area where intervention might be considered <a class="yt-timestamp" data-t="43:54:00">[43:54:00]</a>. The data accumulated by individuals on platforms like Google or Facebook, while sometimes criticized as "surveillance capitalism," also serves as a "private common" that benefits the individual (e.g., Google Maps helping friends find one's house <a class="yt-timestamp" data-t="45:41:00">[45:41:00]</a>).

With AI, this personal data becomes tremendously more valuable for individual insights (e.g., analyzing personal health data like Whoop, facial, and vocal tone to predict OCD symptoms <a class="yt-timestamp" data-t="48:00:00">[48:00:00]</a>). To enable this, individuals should have the right to move and utilize their data as they wish, facilitated by corporations <a class="yt-timestamp" data-t="47:07:00">[47:07:07]</a>. This shift empowers individuals to gain profound insights into their own lives, leading to a "Quantified Self" movement on a grand scale <a class="yt-timestamp" data-t="50:00:00">[50:00:00]</a>.

## Philosophical and Cognitive Shifts with AI

The history of AI mirrors a shift seen in philosophy, moving from a search for universal truths (symbolic AI) to a more pragmatic, pattern-matching approach (sub-symbolic AI) <a class="yt-timestamp" data-t="52:18:00">[52:18:00]</a>. Early symbolic AI tried to define intelligence as a set of explicit symbols and their relations, which proved brittle and computationally expensive <a class="yt-timestamp" data-t="53:07:00">[53:07:00]</a>. Connectionism and sub-symbolic AI, by contrast, focus on fuzzy matching patterns and bringing thousands of rules to bear based on context, recognizing that intelligence arises from complex, often implicit, interactions <a class="yt-timestamp" data-t="53:34:00">[53:34:00]</a>.

The future of AI will likely involve a combination of probabilistic models and symbols <a class="yt-timestamp" data-t="55:24:00">[55:24:00]</a>. This approach moves away from solely deductive reasoning towards embracing induction (modeling curves from data) and abduction (generating the best theory to explain evidence, involving creativity) <a class="yt-timestamp" data-t="01:00:33">[01:00:33]</a>. [[the_role_and_capabilities_of_ai_agents | AI agents]] can apply many different approaches simultaneously, which is a strength that contrasts with the limitations of purely explicit philosophical systems <a class="yt-timestamp" data-t="01:01:28">[01:01:28]</a>. This enables [[combining_ai_interfaces_with_human_agency | combining AI interfaces with human agency]].

## AI as an Amplification Tool

AI raises the capabilities across the board <a class="yt-timestamp" data-t="01:07:38">[01:07:38]</a>. For individuals without access to expensive resources (e.g., top schools, ghostwriters), AI can provide similar leverage, lowering costs and increasing access to "intelligence services" <a class="yt-timestamp" data-t="01:06:43">[01:06:43]</a>. For those who already have access, AI further amplifies their capabilities <a class="yt-timestamp" data-t="01:07:57">[01:07:57]</a>. This "human amplification" through AI, often envisioned as a "co-pilot," is a crucial design principle for technologists <a class="yt-timestamp" data-t="01:06:17">[01:06:17]</a>. This vision for [[the_future_of_ai_agents_and_user_interaction | the future of AI agents and user interaction]] and [[building_and_managing_a_multifaceted_business_with_ai | building and managing a multifaceted business with AI]] is vital.