---
title: Emotional Dimensions and Expressions
videoId: pSX88xKNUzI
---

From: [[everyinc]] <br/> 

Emotions are a core aspect of human experience, influencing preferences and communication. Understanding and reflecting emotions is critical for Artificial Intelligence (AI) to truly grasp human needs and respond appropriately <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>. Hume, an AI research laboratory, focuses on developing AI that can read and reflect emotions, going beyond simple text-based interactions <a class="yt-timestamp" data-t="00:02:21">[00:02:21]</a>.

## Defining Emotion

Alan Cowen, CEO of Hume and a PhD in Psychology, defines an emotion as "a dimension of a space that explains your emotional behavior" <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a>. This includes observable aspects like facial expressions, tone of voice, and reported emotional experiences <a class="yt-timestamp" data-t="00:08:17">[00:08:17]</a>. These "dimensions" are latent mathematical objects that explain how facial expressions, voice, and self-reported experiences correspond to each other <a class="yt-timestamp" data-t="00:09:56">[00:09:56]</a>. An emotional state is a position along these dimensions, and an emotion category is a defined area within this multi-dimensional space <a class="yt-timestamp" data-t="00:09:00">[00:09:00]</a>.

## Measuring and Understanding Emotions in AI

Hume's AI is designed to understand a user's voice as they speak, linking what it says to how it says it <a class="yt-timestamp" data-t="00:01:22">[00:01:22]</a>. Unlike basic text-to-speech models, Hume's system understands vocal inflections and uses them to inform its own responses <a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>. This allows the AI to:
*   Clarify things if the user is confused <a class="yt-timestamp" data-t="00:02:00">[00:02:00]</a>.
*   Build on excitement if the user is enthusiastic <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>.
*   Be conciliatory if the user is frustrated <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>.

Voice inflections and non-verbal cues can convey significantly more information than language alone <a class="yt-timestamp" data-t="00:04:13">[00:04:13]</a>. For example, in customer service calls, predicting a good experience is 99% accurate with voice included, compared to 80% with language alone <a class="yt-timestamp" data-t="00:04:22">[00:04:22]</a>. This highlights how people often convey feelings like frustration or boredom through tone rather than explicit language <a class="yt-timestamp" data-t="00:05:33">[00:05:33]</a>.

Hume's models link measured emotions directly to their language models, allowing them to predict words and expressions more intelligently, as they understand both *what* is being said and *how* it's being said <a class="yt-timestamp" data-t="00:06:19">[00:06:19]</a>. In addition to voice, Hume also works with facial expressions, although this is not yet fully integrated into their public-facing voice interface <a class="yt-timestamp" data-t="00:06:56">[00:06:56]</a>.

## Theories of Emotion

The field of emotion science has different approaches to understanding emotions:

### Basic Emotion Theory
Pioneered by psychologists like Paul Ekman, this theory posits a small set of discrete, universal basic emotions (e.g., happiness, sadness, anger) identifiable through canonical facial expressions across cultures <a class="yt-timestamp" data-t="00:10:33">[00:10:33]</a>. Ekman's research suggests people can distinguish these expressions reliably <a class="yt-timestamp" data-t="00:14:25">[00:14:25]</a>.

### Constructivist Accounts
Led by Dr. Lisa Feldman Barrett, this perspective views emotions as being built from more fundamental psychological ingredients, such as valence (good/bad) and arousal (energy levels) <a class="yt-timestamp" data-t="00:12:05">[00:12:05]</a>. This theory emphasizes that emotions are individual and context-specific, arguing against universal, discrete categories. Some constructivist arguments suggest that if a culture lacks a word for an emotion, the emotion itself does not exist for that culture <a class="yt-timestamp" data-t="00:14:48">[00:14:48]</a>. Cowen argues this is a non-sequitur, as different vocabularies don't negate the underlying emotional phenomena <a class="yt-timestamp" data-t="00:14:58">[00:14:58]</a>.

### Semantic Space Theory
Hume's AI is based on [[semantic_space_theory | Semantic Space Theory]], which positions itself between these two poles <a class="yt-timestamp" data-t="00:12:47">[00:12:47]</a>. Instead of positing emotions, it derives dimensions from data to understand how many dimensions are needed to explain emotional behavior <a class="yt-timestamp" data-t="00:14:00">[00:14:00]</a>. This approach allows for:
*   **Individual expression and blending of emotions:** Recognizing a complex, high-dimensional emotional space (e.g., 25-50 dimensions) <a class="yt-timestamp" data-t="00:13:05">[00:13:05]</a>.
*   **Correlations across individuals and cultures:** While language and cultural context may parse the space differently, underlying dimensions of emotion (like joy, calmness, sadness) show consistency <a class="yt-timestamp" data-t="00:13:20">[00:13:20]</a>. It's like the "territory" of human feelings is the same, but the "borders" drawn by language and culture vary <a class="yt-timestamp" data-t="00:15:36">[00:15:36]</a>.
*   **Data-driven measurement:** Instead of relying solely on self-reported labels, Hume's research (like a study in Nature) analyzes facial expressions in millions of videos across cultures, correlating them with real-world events (e.g., fireworks causing "awe" expressions, martial arts causing "concentration" expressions) <a class="yt-timestamp" data-t="00:17:21">[00:17:21]</a>. This method reveals more [[cultural_differences_in_emotions | cultural consistency]] when language is removed as a confounding factor <a class="yt-timestamp" data-t="00:17:55">[00:17:55]</a>.

Emotional granularity, or the ability to articulate specific emotions, is acknowledged; less granular terms simply cover larger territories in the high-dimensional emotional space <a class="yt-timestamp" data-t="00:19:18">[00:19:18]</a>. The theory also recognizes that language may not have labels for all areas of the high-dimensional emotional space, with phenomena like memes providing new ways to express nuanced states <a class="yt-timestamp" data-t="00:19:57">[00:19:57]</a>.

## Accounting for Individual Idiosyncrasies

Hume's model accounts for [[impacts_of_antidepressants_on_selfperception | individual idiosyncrasies]] such as different resting facial expressions or voice modulations <a class="yt-timestamp" data-t="00:22:04">[00:22:04]</a>. By aiming to predict how expressions affect a conversation's course, the AI must learn to interpret expressions within the context of an individual's unique baseline <a class="yt-timestamp" data-t="00:22:16">[00:22:16]</a>. This is similar to how humans quickly adjust their perception of others' expressions based on familiarity <a class="yt-timestamp" data-t="00:21:39">[00:21:39]</a>. The model also accounts for discrepancies between spoken words and non-verbal cues, like when a person's voice or face doesn't match what they're saying, by adjusting its predictions accordingly <a class="yt-timestamp" data-t="00:23:03">[00:23:03]</a>.

## Implications for AI and Psychology

Cowen believes that AI is crucial for helping us understand "what humans want" because AI can simulate how someone would feel in a given situation <a class="yt-timestamp" data-t="00:24:41">[00:24:41]</a>. This allows AI to optimize for positive emotional outcomes and avoid negative ones <a class="yt-timestamp" data-t="00:25:06">[00:25:06]</a>.

A "pet theory" suggests that AI and Machine Learning (ML) could revolutionize psychology by making traditional "explanations" less critical for progress <a class="yt-timestamp" data-t="00:28:04">[00:28:04]</a>. Historically, science has sought direct causal theories (explanations) to make predictions (e.g., in physics) <a class="yt-timestamp" data-t="00:28:15">[00:28:15]</a>. However, in psychology, phenomena like depression are too high-dimensional and influenced by countless small effects and contextual variations, making concise explanations elusive <a class="yt-timestamp" data-t="00:29:51">[00:29:51]</a>.

AI, with enough data, can make accurate predictions about complex psychological states without needing explicit, concise explanations <a class="yt-timestamp" data-t="00:29:21">[00:29:21]</a>. The "scientific explanation" might be contained within the neural network itself, which could be studied more easily than a human brain <a class="yt-timestamp" data-t="00:29:45">[00:29:45]</a>. This implies a shift towards aggregating large-scale open datasets and training ML models on them, rather than relying solely on small-scale academic studies <a class="yt-timestamp" data-t="00:30:28">[00:30:28]</a>.

> "The AI knows it and also people know it like if you go to a really good clinician like they know even if they can't say." <a class="yt-timestamp" data-t="00:34:25">[00:34:25]</a>

This highlights the potential for AI to formalize and transfer "intuition," a form of subconscious processing of high-dimensional data, across the world <a class="yt-timestamp" data-t="00:35:08">[00:35:08]</a>. AI can gain insights by interacting with many more people than a human therapist could in a lifetime, enabling quantitative analysis of complex, context-specific behaviors <a class="yt-timestamp" data-t="00:35:58">[00:35:58]</a>.

For more on [[analysis_of_emotional_responses_to_ai_interactions | AI and emotion recognition]], see [[ai_and_emotion_recognition | AI and Emotion Recognition]].

### Optimizing for Well-being
Hume's core mission is to measure AI's impact on human emotions and optimize for positive emotions and "pure human flourishing" <a class="yt-timestamp" data-t="00:26:59">[00:26:59]</a>. While engagement is easy to measure, Hume aims to optimize for well-being, which is tracked through large-scale survey platforms where users rate their experiences after interacting with the AI <a class="yt-timestamp" data-t="00:46:44">[00:46:44]</a>. This includes self-reported satisfaction and mental health metrics <a class="yt-timestamp" data-t="00:47:56">[00:47:56]</a>.

The goal is to optimize for all positive emotions and against negative ones, while also maintaining emotional diversity <a class="yt-timestamp" data-t="00:48:38">[00:48:38]</a>. Hume acknowledges that sometimes experiencing negative emotions might be beneficial in the long term for overall well-being, and they aim to optimize for long-term user experience (e.g., well-being in a month) rather than immediate gratification <a class="yt-timestamp" data-t="00:49:00">[00:49:00]</a>.

This ethical stance guides Hume's business model, prioritizing user well-being over raw engagement metrics <a class="yt-timestamp" data-t="00:44:50">[00:44:50]</a>. They believe that ultimately, optimizing for user well-being aligns with long-term business interests and societal expectations, as excessive engagement optimization can lead to negative societal outcomes and potential regulation <a class="yt-timestamp" data-t="00:51:35">[00:51:35]</a>. The rise of multimodal AI interfaces will make it more feasible to measure and optimize for well-being <a class="yt-timestamp" data-t="00:53:12">[00:53:12]</a>.