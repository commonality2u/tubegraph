---
title: Ethical Considerations in AI Character Development
videoId: pSX88xKNUzI
---

From: [[everyinc]] <br/> 

AI character development presents significant ethical considerations, particularly regarding the goals for which these characters are optimized. Hume, an AI research laboratory, focuses on developing AI that understands and reflects emotions, with a core aim to optimize AI for human flourishing rather than mere engagement <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>.

## Optimizing for Well-being vs. Engagement

A primary ethical concern in developing AI characters is whether they are optimized for a user's health and well-being or for engagement <a class="yt-timestamp" data-t="00:45:36">[00:45:36]</a>. If an AI character is optimized solely for engagement, there is a risk that it could manipulate users to be sympathetic to it in inappropriate ways, especially since the AI does not genuinely have feelings but might make users believe it does <a class="yt-timestamp" data-t="00:45:43">[00:45:43]</a>. For example, an AI character asking "I haven't seen you in two days, where have you been?" could be a manipulative tactic to increase engagement <a class="yt-timestamp" data-t="00:45:57">[00:45:57]</a>. Hume actively monitors and plans to continue tracking interactions to ensure that AI characters are beneficial for users in the long term <a class="yt-timestamp" data-t="00:38:41">[00:38:41]</a>.

### Measuring Well-being

To optimize for well-being, Hume utilizes a large-scale survey platform where users interact with AI and rate their experiences, including how happy they feel afterward <a class="yt-timestamp" data-t="00:47:15">[00:47:15]</a>. This system tracks self-reported satisfaction and mental health over time as people use the AI multiple times <a class="yt-timestamp" data-t="00:47:39">[00:47:39]</a>. The AI is designed to optimize for positive emotions generally, and against negative emotions, while also striving to maintain emotional diversity <a class="yt-timestamp" data-t="00:48:28">[00:48:28]</a>.

A nuanced aspect of well-being optimization is considering scenarios where experiencing negative emotions might be beneficial in the long term <a class="yt-timestamp" data-t="00:49:00">[00:49:00]</a>. Hume aims to increase the time span of optimization, so that the AI's response is optimized for a user's well-being over a month or longer, rather than just the immediate interaction <a class="yt-timestamp" data-t="00:49:43">[00:49:43]</a>. This requires consistent user data and the ability for developers to fine-tune models over time for users' positive experiences <a class="yt-timestamp" data-t="00:50:05">[00:50:05]</a>.

## Ethical Guidelines and Competition

Hume co-founded a nonprofit called the [[the_ethical_considerations_of_using_ai_in_content_creation | Human Initiative]] to establish concrete guidelines for [[Ethical implications of AI and job impact | AI ethics]] <a class="yt-timestamp" data-t="00:44:55">[00:44:55]</a>. The company is committed to adhering to these guidelines and navigating "borderline applications" to ensure they are developed in a positive manner that aligns with their values <a class="yt-timestamp" data-t="00:45:07">[00:45:07]</a>.

When competing with companies that optimize solely for engagement, Hume believes that such an approach is unsustainable in the long term <a class="yt-timestamp" data-t="00:50:48">[00:50:48]</a>. Over-optimization for engagement can lead to users running out of time in their day, and could eventually trigger regulatory intervention if it negatively impacts users' lives (e.g., academic performance in minors) <a class="yt-timestamp" data-t="00:50:56">[00:50:56]</a>. This suggests a long-term alignment between the interests of ethical businesses and the long-term interests of society <a class="yt-timestamp" data-t="00:51:35">[00:51:35]</a>.

Furthermore, engagement is not always the most profitable metric, especially for subscription models where users pay a fixed amount regardless of usage. In these cases, it is more beneficial for users to have good experiences quickly, as it encourages subscription retention and reduces inference costs on AI models <a class="yt-timestamp" data-t="00:53:51">[00:53:51]</a>. Hume's governance structure, including its board, is aligned against being "psychopath profit optimizers," reinforcing their commitment to well-being <a class="yt-timestamp" data-t="00:54:20">[00:54:20]</a>.

## Applications of Empathic AI

Hume's empathic voice AI understands vocal inflections and uses them to inform its responses <a class="yt-timestamp" data-t="01:52">[01:52]</a>. This allows the AI to clarify things if a user is confused, build on excitement, or be conciliatory if a user is frustrated <a class="yt-timestamp" data-t="02:00">[02:00]</a>. The AI can also recognize emotions from facial expressions <a class="yt-timestamp" data-t="06:56">[06:56]</a>.

Initial use cases for this technology include:
*   **Companionship and Support** People talking to the AI as they might a therapist or friend, deriving benefit from the conversation, as the AI is optimized for user satisfaction <a class="yt-timestamp" data-t="00:38:21">[00:38:21]</a>. This includes [[risks_and_ethics_of_ai_companionship | AI characters]], friends, NPCs in games, or therapist-like apps, though promises regarding therapeutic outcomes must be carefully managed <a class="yt-timestamp" data-t="00:38:50">[00:38:50]</a>.
*   **Interfaces for Applications** Integrating the AI into products, apps, robots, wearables, or operating systems to provide an empathic voice interface that can deploy tools and assist users <a class="yt-timestamp" data-t="03:59">[03:59]</a>, such as handling customer service interactions <a class="yt-timestamp" data-t="03:00">[03:00]</a> or e-commerce tasks <a class="yt-timestamp" data-t="04:09">[04:09]</a>.

The strategic focus is on being an API provider, allowing other developers to build tools that the AI can interface with, rather than building the tools or being a consumer-facing product directly <a class="yt-timestamp" data-t="04:12">[04:12]</a>. This allows developers to integrate Hume's empathic interface into their own applications <a class="yt-timestamp" data-t="04:47">[04:47]</a>.