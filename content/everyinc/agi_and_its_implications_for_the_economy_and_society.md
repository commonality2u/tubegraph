---
title: AGI and its implications for the economy and society
videoId: E5EgUuzzH5I
---

From: [[everyinc]] <br/> 

The concept of Artificial General Intelligence (AGI) and its potential impact on the economy and society is a significant area of discussion. AGI is generally defined as the ability of an AI to perform "all the economically useful tasks" <a class="yt-timestamp" data-t="00:50:44">[00:50:44]</a>. There is a "pretty decent probability" of AGI developing within the next 10 years, potentially without requiring major paradigm shifts <a class="yt-timestamp" data-t="00:50:32">[00:50:32]</a>.

## Economic Implications of AGI

The emergence of AGI is expected to bring about profound [[economic_predictions_and_ai_in_the_labor_market | changes in the economy]] and [[impact_of_ai_on_future_work_and_the_economy | labor market]]:

*   **Automation of Knowledge Work** Knowledge work tasks that humans "don't really want to be doing" or are "too expensive for them to do" <a class="yt-timestamp" data-t="00:14:09">[00:14:09]</a> are prime candidates for automation. This includes maintaining documentation, manual data entry in databases, and summarizing information <a class="yt-timestamp" data-t="00:46:45">[00:46:45]</a>.
*   **Reduced Human Interaction with Databases** A core principle of rebuilding systems with [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] would be "less humans touching the database" <a class="yt-timestamp" data-t="00:14:18">[00:14:18]</a>. The [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] should manage data automatically, deriving information from sources like emails or internal communications <a class="yt-timestamp" data-t="00:14:28">[00:14:28]</a>. This means users would interact more with the "processed outputs" <a class="yt-timestamp" data-t="00:14:49">[00:14:49]</a> rather than the raw database.
*   **Increased Legibility in Organizations** Companies can operate better when more information is "legible" and "written down" <a class="yt-timestamp" data-t="00:15:30">[00:15:30]</a>. [[impact_of_ai_and_chatgpt_on_productivity_and_jobs | AI]] offers an opportunity to record and update information that would ordinarily not be documented, without human intervention <a class="yt-timestamp" data-t="00:16:19">[00:16:19]</a>.
*   **Elastic Scaling of Economic Value** Once an "economically useful task" is discovered using [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] models, it can be scaled up more elastically by buying more compute, unlike humans who require training and paying <a class="yt-timestamp" data-t="00:53:02">[00:53:02]</a>. This could lead to a "100x more economic value" than currently exists <a class="yt-timestamp" data-t="00:52:48">[00:52:48]</a>.

## Societal Implications of AGI

The advent of AGI will also bring significant societal shifts:

*   **Changing Nature of Jobs** Similar to how farming was largely automated in South Korea over a few decades, completely transforming the economy, jobs are expected to "completely change" with [[potential_future_developments_and_implications_of_ai_technologies | AI]] <a class="yt-timestamp" data-t="00:52:43">[00:52:43]</a>. New tasks and industries will emerge, creating substantial new economic value <a class="yt-timestamp" data-t="00:52:45">[00:52:45]</a>.
*   **The Intelligence Explosion** A critical concern is the potential for an "intelligence explosion," where [[future_of_ai_and_agi_development | AIs]] become proficient enough at [[ai_and_its_impact_on_science | AI research tasks]] to significantly improve themselves <a class="yt-timestamp" data-t="00:51:01">[00:51:01]</a>. The components of [[ai_and_its_impact_on_science | AI research]], such as reading literature, generating ideas, designing experiments, writing code, and analyzing results, appear to be tasks that sufficiently advanced foundation models could handle <a class="yt-timestamp" data-t="00:51:13">[00:51:13]</a>.
*   **Human Role: "Wanting" and Orchestration** As [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AIs]] become more capable, the crucial role for humans will shift from execution to "wanting" <a class="yt-timestamp" data-t="00:50:11">[00:50:11]</a>. This means defining the "high level goal" <a class="yt-timestamp" data-t="00:50:16">[00:50:16]</a> and ensuring the [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] is doing the "right thing" through observation and control <a class="yt-timestamp" data-t="00:50:02">[00:50:02]</a>.
*   **Redefining Creativity and Intuition** The idea that humans possess a special value in creativity or intuition may be a "category error" <a class="yt-timestamp" data-t="00:53:56">[00:53:56]</a>. Instances like [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] generating beautiful images suggest that [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] can perform what was once considered creative or intuitive work <a class="yt-timestamp" data-t="00:53:51">[00:53:51]</a>. The core of human value will be in determining "what we want to be done" <a class="yt-timestamp" data-t="00:54:08">[00:54:08]</a>.
*   **Importance of Ambition and Openness** In this era of powerful [[potential_future_developments_and_implications_of_ai_technologies | AI]], it is important for humanity to "ratchet up our ambition" <a class="yt-timestamp" data-t="00:54:37">[00:54:37]</a> and be open to new experiences, not being encumbered by past failures <a class="yt-timestamp" data-t="00:54:45">[00:54:45]</a>.

> "I feel like the most important thing there is making sure that the shape of the future is align with what we care about and we agree and consent to it and support it and a lot of it is around like us orchestrating the tasks that the AI are doing" <a class="yt-timestamp" data-t="00:54:42">[00:54:42]</a>

## Challenges and Considerations

*   **Understanding and Explaining AI Actions** When [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] performs complex tasks, explaining "what happened" <a class="yt-timestamp" data-t="00:08:25">[00:08:25]</a> to the user is a difficult problem <a class="yt-timestamp" data-t="00:09:02">[00:09:02]</a>. Summaries provided by [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] can be too high-level, lacking concrete detail <a class="yt-timestamp" data-t="00:09:17">[00:09:17]</a>.
*   **Verifiability in Training Loops** There's a focus on training [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] models where results can be "verified in some way" <a class="yt-timestamp" data-t="00:41:12">[00:41:12]</a>, such as passing unit tests in coding or having correct answers in math problems <a class="yt-timestamp" data-t="00:41:20">[00:41:20]</a>. While this enables scaling training, it raises concerns about whether it limits the [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI's]] ability to develop new, unverifiable theories or aesthetic creativity, which often drives human scientific discovery <a class="yt-timestamp" data-t="00:42:48">[00:42:48]</a>. However, it's hypothesized that [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] might learn an "aesthetic" for truth or beauty if trained on a distribution of correct theorems <a class="yt-timestamp" data-t="00:43:55">[00:43:55]</a>.
*   **Security and Permissions** As [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] agents gain the ability to interact with computers, the "permission model" is crucial to control what they can "read or write to" <a class="yt-timestamp" data-t="00:04:19">[00:04:19]</a>. The future may see specific interfaces for verified humans and distinct, [[application_and_implications_of_ai_in_the_context_of_human_intelligence | LLM]]-friendly interfaces for [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] <a class="yt-timestamp" data-t="00:22:25">[00:22:25]</a>. This also raises market dynamics questions, as companies might want to prevent [[application_and_implications_of_ai_in_the_context_of_human_intelligence | AI]] agents from accessing their tools without compensation <a class="yt-timestamp" data-t="00:21:23">[00:21:23]</a>.