---
title: Storytelling and language models
videoId: 3ChNkbULAH8
---

From: [[everyinc]] <br/> 

Author Robin Sloan, known for works like *Mr. Penumbra's 24-Hour Bookstore* and *Sourdough*, discusses his latest book, *Moonbound*, and its deep connections to [[nature_of_language_models_and_language | language models]] <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>. His journey into writing *about* AI rather than *with* AI offers unique perspectives on the nature of language, creativity, and the human condition in the age of artificial intelligence <a class="yt-timestamp" data-t="00:04:01">[00:04:01]</a>.

## From Writing *With* AI to Writing *About* AI

Sloan's engagement with [[nature_of_language_models_and_language | language models]] began early, around 2016-2017, when forms of this technology were still primitive <a class="yt-timestamp" data-t="00:04:27">[00:04:27]</a>. At the time, feeding an entire corpus of Shakespeare to generate "cruddy fake Shakespeare" was considered impressive <a class="yt-timestamp" data-t="00:04:52">[00:04:52]</a>. He found early models appealing for two main reasons:
1.  **Weird Output:** Their output was "really weird," "messed up," and "broken weird inhuman," which was aesthetically and poetically interesting because a human would "never imagine to write" that way <a class="yt-timestamp" data-t="00:05:20">[00:05:20]</a>.
2.  **Custom Training Data:** The smaller scale of these models allowed individuals to consider "what will I train this on," unlike today's multi-jillion dollar labs that download the entire internet <a class="yt-timestamp" data-t="00:05:43">[00:05:43]</a>. Sloan's early experiments involved training models on "huge swaths of classic public domain fantasy and science fiction" <a class="yt-timestamp" data-t="00:06:12">[00:06:12]</a>.

This led him to create one of the first text editors where a user could write alongside an AI model <a class="yt-timestamp" data-t="00:06:37">[00:06:37]</a>. His initial goal was to "develop and then use these tools to write in a new way" <a class="yt-timestamp" data-t="00:07:16">[00:07:16]</a>. However, after several years, he made two discoveries:
*   **Creative Writing Frustration:** The experience of [[creative_storytelling_and_ai | writing fiction creatively with the machine]] was "not very much fun" and didn't produce results "up to spec" <a class="yt-timestamp" data-t="00:07:38">[00:07:38]</a>.
*   **Fascination with the Machine Itself:** The underlying "math that made them go" and the "code that kind of wove them all together" were "super duper interesting" <a class="yt-timestamp" data-t="00:07:56">[00:07:56]</a>. This led to a shift from creative writing to compulsive tinkering <a class="yt-timestamp" data-t="00:08:05">[00:08:05]</a>.

*Moonbound*, as a result, contains "not a scrap of AI written text" but is "packed full of these ideas and actually some of these feelings" gleaned from time spent with the technology <a class="yt-timestamp" data-t="00:08:18">[00:08:18]</a>.

## Embedding Spaces and the Nature of Language

Sloan was particularly influenced by a Stanford project that mapped sentences into an "embedding space" <a class="yt-timestamp" data-t="00:08:57">[00:08:57]</a>. This concept allows sentences to be "packed into the space" so that one can "move between the sentences in a way that was sort of sensible" <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>. He found the idea that "language could get mapped into math in this way was just so freaking cool" <a class="yt-timestamp" data-t="00:10:19">[00:10:19]</a>.

> [!INFO] Embedding Spaces
> [[Understanding language models and agency | Embedding spaces]] map text or other data into a multi-dimensional space where items with similar meanings are closer together <a class="yt-timestamp" data-t="00:10:53">[00:10:53]</a>. In *Moonbound*, characters "swim through a many-dimensional space," with one dimension even representing "Bagel" <a class="yt-timestamp" data-t="00:11:10">[00:11:10]</a>. This is a real concept, with labs like Anthropic identifying "features" such as the "Golden Gate Bridge feature" that can be activated within [[nature_of_language_models_and_language | language models]] <a class="yt-timestamp" data-t="00:11:31">[00:11:31]</a>.

Sloan attempted to identify the meaning of different dimensions in his own sentence space but found it difficult <a class="yt-timestamp" data-t="00:12:37">[00:12:37]</a>. He finds it "reassuring or satisfying that it took until now... for like the leading AI labs to find ways to interpret these these features and these dimensions" <a class="yt-timestamp" data-t="00:13:08">[00:13:08]</a>.

## Challenges of [[creative_storytelling_through_ai_technologies | Creative Storytelling through AI Technologies]]

Sloan's decision to stop using AI for creative writing stems from a key observation: while [[nature_of_language_models_and_language | language models]] are "really impressive" at fitting into a style or mode (e.g., murder mystery, high fantasy), their output is "always close but never quite exactly right" for "fairly high-end fictional composition" <a class="yt-timestamp" data-t="00:16:02">[00:16:02]</a>.

> [!IMPORTANT] The "Probability Cloud" of Language Models
> Sloan theorizes that [[nature_of_language_models_and_language | language models]] generate text from "inside a distribution" or "probability cloud" of content <a class="yt-timestamp" data-t="00:17:28">[00:17:28]</a>. Really good writing, however, exists "way out at the edge" of this cloud, or even "pushes a bit beyond it" <a class="yt-timestamp" data-t="00:17:47">[00:17:47]</a>. This is precisely where [[nature_of_language_models_and_language | language models]] are weakest, as their goal is to statistically cover the terrain of existing content <a class="yt-timestamp" data-t="00:18:03">[00:18:03]</a>.

He expresses reservations about fine-tuning current large models due to the immense, human-unreadable "corpuses" they are trained on <a class="yt-timestamp" data-t="00:19:32">[00:19:32]</a>. The fact that even the makers "don't know what's in there" makes him "quite uneasy" about using such models for fiction that conveys "thoughts and feelings and ideas" <a class="yt-timestamp" data-t="00:20:01">[00:20:01]</a>.

This leads to a discussion of the "container" of content <a class="yt-timestamp" data-t="00:20:26">[00:20:26]</a>. Sloan would be more comfortable with an "AI powered thing" like a "hyperbook" if he knew "what went in" <a class="yt-timestamp" data-t="00:21:35">[00:21:35]</a>. The current uncertainty about output from models like Claude or GPT-4, where "nobody knows what's in" their training data, makes him reluctant to "put my name on the thing that... shoots that output at unsuspecting people" <a class="yt-timestamp" data-t="00:24:08">[00:24:08]</a>. He anticipates a future where "nutrition facts" or "ethically raised organic AI" labels might emerge, indicating transparency about training data <a class="yt-timestamp" data-t="00:24:26">[00:24:26]</a>.

## Stories, Predictions, and the Human "I"

*Moonbound* explores how stories shape reality and how individuals can author their own narratives rather than merely following "prescriptions" <a class="yt-timestamp" data-t="00:25:31">[00:25:31]</a>. Sloan notes that this theme, though not consciously linked to "next token prediction" during writing, "totally checks out" <a class="yt-timestamp" data-t="00:26:27">[00:26:27]</a>. These "patterns and templates" are deeply "woven into the systems" of [[nature_of_language_models_and_language | language models]] because they are "repeated so often and so powerfully throughout... their training corpora" <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>.

Early [[nature_of_language_models_and_language | language models]], trained on narratives like fairy tales, myths, and news articles, developed a "bias... towards if then, cause and effect and the rhythm of a story" <a class="yt-timestamp" data-t="00:29:35">[00:29:35]</a>. However, the recent inclusion of vast amounts of code in training data for models like GPT-3 might have influenced their "reasoning" abilities, as code is "so structured and so consequential" <a class="yt-timestamp" data-t="00:28:41">[00:28:41]</a>.

> [!NOTE] The Central Question: "What Happens Next"
> *Moonbound* posits that "the central question of the human race is what happens next" <a class="yt-timestamp" data-t="00:30:57">[00:30:57]</a>. Sloan feels this question deeply and connects it to the nature of [[understanding_language_models_and_agency | language models]], which "bootstrap all the knowledge that they have" by repeatedly answering "what comes next" <a class="yt-timestamp" data-t="00:35:05">[00:35:05]</a>. This simple challenge, when repeated trillions of times, requires "a lot of complexity and... a rich picture of the world" <a class="yt-timestamp" data-t="00:35:49">[00:35:49]</a>.

Sloan also explores the concept of the "I" (the self) in *Moonbound*, featuring a "chronicler" who is a "hybrid organic technological creation" and a character named Clovis, whose multiple instances globally share a single personality <a class="yt-timestamp" data-t="00:41:19">[00:41:19]</a>. He highlights how different languages, like Japanese, have multiple forms of "I," each with nuanced meanings <a class="yt-timestamp" data-t="00:42:58">[00:42:58]</a>. The internet age has further complicated the singular "I," as human presences and attention are increasingly distributed across contexts <a class="yt-timestamp" data-t="00:44:17">[00:44:17]</a>. This relates to [[understanding_language_models_and_agency | language models]]' ability to identify "hundreds of thousands or millions of different robins" (versions of a name) based on context, creating a "dictionary of these very very very specific words" <a class="yt-timestamp" data-t="00:46:26">[00:46:26]</a>.

## Language as Autonomy and the Analogy of Dreams

Sloan finds the claim that "what [[nature_of_language_models_and_language | language models]] are is language itself... given its first dose of autonomy" to be aesthetically compelling <a class="yt-timestamp" data-t="00:39:09">[00:39:09]</a>. It's as if "you rip language out of our head... and it starts walking around like wind up toys" <a class="yt-timestamp" data-t="00:39:24">[00:39:24]</a>. The apparent "reasoning or thinking or deducing" of [[nature_of_language_models_and_language | language models]] might be the inherent qualities of language itself, now visible through this new technology <a class="yt-timestamp" data-t="00:39:44">[00:39:44]</a>.

He proposes a "pet theory" that anyone interested in [[nature_of_language_models_and_language | language models]] should study dreams <a class="yt-timestamp" data-t="00:49:50">[00:49:50]</a>. He believes the "mechanism of dreaming is very similar to the mechanism of a language model" trying to complete a sequence, even if "weird" <a class="yt-timestamp" data-t="00:50:01">[00:50:01]</a>. For Sloan, novels are "packaged dreams" that allow readers to "load a waking dream into your head" <a class="yt-timestamp" data-t="00:50:21">[00:50:21]</a>. This suggests a "trilateral connection between books and dreams and [[nature_of_language_models_and_language | language models]]" <a class="yt-timestamp" data-t="00:50:40">[00:50:40]</a>.

The fundamental biological necessity of sleep for all living things makes him wonder if "AI really ought to do" something analogous for their "own long-term success or health" <a class="yt-timestamp" data-t="00:52:08">[00:52:08]</a>. Sloan encourages philosophers, cognitive scientists, and linguists to deeply engage with the profound questions raised by [[nature_of_language_models_and_language | language models]], as they "raise questions about long-standing projects" and can "redirect streams of inquiry" <a class="yt-timestamp" data-t="00:47:44">[00:47:44]</a>.