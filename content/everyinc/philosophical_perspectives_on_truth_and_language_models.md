---
title: Philosophical perspectives on truth and language models
videoId: n4PVZ_fxaFU
---

From: [[everyinc]] <br/> 

Philosophy provides critical insights into the development and impact of artificial intelligence (AI), particularly concerning [[nature_of_language_models_and_language | language models]] and their relationship with truth <a class="yt-timestamp" data-t="00:00:32">[00:00:32]</a>. Understanding how AI might change [[human_identity_and_language | what it means to be human]] involves deep philosophical questions <a class="yt-timestamp" data-t="00:00:32">[00:00:32]</a>.

## The Importance of Philosophy in a Technological Age
A background in philosophy is considered more important for entrepreneurship than an MBA, as it teaches clear thinking about possibilities and theories of human nature <a class="yt-timestamp" data-t="00:00:06">[00:00:06]</a>. Entrepreneurs envision "what the world could be" and how human nature might be reshaped by new products and technologies <a class="yt-timestamp" data-t="00:04:59">[00:04:59]</a>. This [[the_role_of_philosophical_thinking_in_ai_development | philosophical approach]] is essential for navigating change and understanding the underlying theories of human behavior as circumstances and ecosystems evolve <a class="yt-timestamp" data-t="00:05:26">[00:05:26]</a>.

Philosophical questions, often deemed "unanswerable" (like the nature of truth or how language works), are crucial for advancing science and technology <a class="yt-timestamp" data-t="00:06:05">[00:06:05]</a>. Science itself is full of unanswerable questions, progressing through dynamically improving working theories <a class="yt-timestamp" data-t="00:06:36">[00:06:36]</a>. This dynamic evolution of questions applies equally to building technology and products <a class="yt-timestamp" data-t="00:07:07">[00:07:07]</a>.

### Limitations of Thought Experiments
Philosophical thought experiments, such as trolley problems, can be misused when they artificially simplify complex environments or posit perfect knowledge, leading to unrealistic scenarios <a class="yt-timestamp" data-t="00:07:43">[00:07:43]</a>. The fundamental issue is that these problems often force binary choices without accounting for real-world complexities or alternative actions <a class="yt-timestamp" data-t="00:08:22">[00:08:22]</a>.

## Truth and [[nature_of_language_models_and_language | Language Models]]
The debate between essentialism (objective, knowable reality) and nominalism (truth as relative, social convention) gains new perspectives with the advent of [[nature_of_language_models_and_language | language models]] <a class="yt-timestamp" data-t="00:15:07">[00:15:07]</a>.

### Wittgenstein's Influence
[[nature_of_language_models_and_language | Language models]] function more like later Wittgenstein's nominalist view, focusing on the relationships between words in a sentence rather than mapping to pre-defined "atomic facts" of the world <a class="yt-timestamp" data-t="00:19:21">[00:19:21]</a>. Early AI approaches that tried to list every object in the world (more essentialist) largely failed <a class="yt-timestamp" data-t="00:19:39">[00:19:39]</a>.

However, the development of [[nature_of_language_models_and_language | language models]] can be seen as a Hegelian synthesis:
*   **Thesis:** Essentialist view of truth.
*   **Antithesis:** Nominalist view, emphasizing language games and social conventions <a class="yt-timestamp" data-t="00:16:11">[00:16:11]</a>.
*   **Synthesis:** Modern [[nature_of_language_models_and_language | language models]] are built on a pragmatic base, but there's an ongoing effort to ground them more firmly in truth and reality, reducing "hallucinations" <a class="yt-timestamp" data-t="00:15:46">[00:15:46]</a>.

Later Wittgenstein's philosophy suggests that language is grounded in how humans, as biological beings, navigate the world. The "truth" is discovered through a dynamic process of engaging in "language games" <a class="yt-timestamp" data-t="00:22:50">[00:22:50]</a>. This raises questions for [[nature_of_language_models_and_language | language models]]:
*   Are [[nature_of_language_models_and_language | language models]] part of the "same biological form of life" as humans <a class="yt-timestamp" data-t="00:23:17">[00:23:17]</a>?
*   While trained on the human corpus of knowledge, their learning methods differ, potentially leading to different "truth functions" <a class="yt-timestamp" data-t="00:23:41">[00:23:41]</a>.
*   The goal is to make LLMs more reliable on a truth basis, valuing creativity and generativity but demanding accuracy <a class="yt-timestamp" data-t="00:24:22">[00:24:22]</a>.

### Embeddings and Truth
The use of embeddings in LLMs, which map words into high-dimensional spaces representing contextual meanings, appears to align with the later Wittgensteinian view <a class="yt-timestamp" data-t="00:33:11">[00:33:11]</a>. This is because the arrangement within these spaces is determined by how words are used in practice and their utility for humans, rather than an underlying logical ordering that would prevent falsehoods <a class="yt-timestamp" data-t="00:33:34">[00:33:34]</a>.

## Reasoning and Truth Discovery in [[nature_of_language_models_and_language | Language Models]]
Current efforts to instill reasoning into [[nature_of_language_models_and_language | language models]] involve training them on data sources with crisp reasoning patterns:
*   **Computer Code:** Training on code helps models learn reasoning patterns beyond just programming <a class="yt-timestamp" data-t="00:35:02">[00:35:02]</a>.
*   **Textbooks:** Using textbooks allows for the creation of smaller but effective models by encapsulating structured knowledge <a class="yt-timestamp" data-t="00:35:39">[00:35:39]</a>.

Philosophical concepts, particularly logic and theories of science, could inform the creation of synthetic data to further enhance reasoning <a class="yt-timestamp" data-t="00:36:06">[00:36:06]</a>.

### Gödel's Incompleteness Theorem
Gödel's Incompleteness Theorem posits that in any sufficiently robust language system, there are truths that cannot be expressed within that system <a class="yt-timestamp" data-t="00:39:23">[00:39:23]</a>. This "shadow of at least one truth not captured" raises profound questions about truth discovery in both human and LLM contexts <a class="yt-timestamp" data-t="00:40:08">[00:40:08]</a>. The dynamic process of new discoveries suggests that truth is an ongoing synthesis, not a static entity <a class="yt-timestamp" data-t="00:43:22">[00:43:22]</a>.

## The Evolution of Human Cognition and Technology
[[human_identity_and_language | Humans are not static beings]]; their identity and cognitive abilities are shaped by the technology they engage with <a class="yt-timestamp" data-t="00:44:54">[00:44:54]</a>. Examples like eyeglasses, microscopes, and telescopes demonstrate how technology changes our perception of truth and reality <a class="yt-timestamp" data-t="00:45:06">[00:45:06]</a>.

Reading, as a technology, fundamentally alters the human brain and psychology <a class="yt-timestamp" data-t="00:46:54">[00:46:54]</a>. It changes how people perceive their environment and enables complex societal structures <a class="yt-timestamp" data-t="00:47:03">[00:47:03]</a>. This highlights how humans have continuously augmented and replaced aspects of themselves across generations <a class="yt-timestamp" data-t="00:48:23">[00:48:23]</a>.

This process reflects cultural evolution, a faster clock of change compared to biological or geological evolution <a class="yt-timestamp" data-t="00:50:37">[00:50:37]</a>. [[nature_of_language_models_and_language | Language models]] are tools that accelerate this cultural and digital evolution <a class="yt-timestamp" data-t="00:50:57">[00:50:57]</a>. They function as on-demand personal research assistants, making the vast [[historical_perspectives_on_human_intellect | human corpus of knowledge]] accessible and contextualized, thereby overcoming bottlenecks in cultural transmission <a class="yt-timestamp" data-t="00:51:51">[00:51:51]</a>.

## Why Philosophers Didn't Invent AI
The development of AI emerged from computer science and engineering rather than philosophy due to academia's "disciplinarianism" <a class="yt-timestamp" data-t="00:53:15">[00:53:15]</a>. Philosophers historically focused on cogitation without fully integrating the role of technology in shaping language, truth, and reasoning <a class="yt-timestamp" data-t="00:53:57">[00:53:57]</a>. While cogitation is valuable, engaging with technology is crucial for modern philosophical inquiry <a class="yt-timestamp" data-t="00:54:10">[00:54:10]</a>. Computer scientists, on the other hand, focused on the practical question of "what can I make with this technology?" <a class="yt-timestamp" data-t="00:55:02">[00:55:02]</a>.

## Engaging with Philosophical Thinking
To develop the ability to think crisply about possibilities, engagement and interaction are key <a class="yt-timestamp" data-t="00:57:19">[00:57:19]</a>. [[role_of_language_models_in_knowledge_work | ChatGPT]] can be a valuable tool for this, allowing users to:
*   Propose an argument and ask for more supporting arguments <a class="yt-timestamp" data-t="00:57:40">[00:57:40]</a>.
*   Request counterarguments to challenge one's own thinking, fostering a thesis-antithesis-synthesis dynamic <a class="yt-timestamp" data-t="00:57:51">[00:57:51]</a>.
*   Ask for explanations of complex concepts (e.g., Gödel's Theorem, Einstein's relativity) tailored to one's understanding <a class="yt-timestamp" data-t="00:58:51">[00:58:51]</a>.

This interactive process helps internalize [[historical_perspectives_on_human_intellect | great human thought]] and accelerates cultural evolution <a class="yt-timestamp" data-t="00:59:16">[00:59:16]</a>. Engaging with canonical pieces of thinking and being curious about great ideas are fundamental steps <a class="yt-timestamp" data-t="00:59:42">[00:59:42]</a>.