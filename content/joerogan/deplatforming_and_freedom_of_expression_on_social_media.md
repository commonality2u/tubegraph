---
title: Deplatforming and freedom of expression on social media
videoId: sCD9zjf_YRU
---

From: [[joerogan]] <br/> 

Deplatforming in the realm of social media has become a significant and contentious issue, particularly concerning the balance between [[free_speech_and_deplatforming_on_social_media | freedom of expression]] and content moderation. This debate raises questions about the role and responsibility of social media platforms like YouTube, Facebook, and Twitter in moderating content, and how these actions impact the landscape of public discourse.

## The Debate Over Deplatforming

Deplatforming typically refers to the removal of individuals or groups from social media platforms due to violations of community guidelines or terms of service. It often sparks debate about censorship and the limitation of speech. Critics argue that deplatforming tactics can be disproportionately applied, sometimes focusing more on particular political expressions or creators rather than uniformly adhering to platform policies.

### Concerns Over Free Speech

Prominent voices in the public sphere, such as Ben Shapiro, have expressed concerns over the deplatforming activities of big tech companies. They argue that a handful of people, often located in tech hubs like Silicon Valley, have substantial control over public discourse:

> **Ben Shapiro's Perspective:** "If my view of discipline is not the same as yours, good on you. Do what you want as long as it's not bothering me" <a class="yt-timestamp" data-t="02:17:44">[02:17:44]</a>.

Shapiro further critiques the approach that some platforms take in effectively acting as the "moral police" by deciding which conversations should take place, who should be censored, and debating [[free_speech_and_censorship_on_social_media_platforms | free speech and censorship]] on these platforms.

## Platform Responsibility and Content Moderation

Social media companies face the challenge of balancing their role as open platforms for communication against the need to moderate harmful content. This leads to differing views on whether these companies should be treated like public utilities (where they would be required to allow any speech that isn't illegal), versus publishers (where they would have greater leeway to moderate speech as they see fit).

### The Issue of Accountability

Another dimension of the debate is the accountability of these platforms in their content decisions. If they are responsible for moderating content, should they then be held accountable for the speech they allow? Shapiro raises an important point about this:

> **Shapiro on Accountability:** "I run a publication. If we say something defamatory, we will be sued. But if a falsehood is on Facebook, Facebook doesn't get sued, yet it acts as an editor by banning or censoring content it deems inappropriate" <a class="yt-timestamp" data-t="13:03">[13:03]</a>.

## Effects on Public Discourse

The decision to deplatform or not can have wide-reaching effects on public discourse. It can affect who gets to be heard and shape the conversation by excluding certain viewpoints, which can foster echo chambers rather than open dialogue. The issue is where to draw the line between moderation to prevent harm and censorship that stifles debate:

> [!info] The Challenge
> 
> The challenge lies in finding a balance between allowing freedom of expression and ensuring that speech doesn't lead to real-world harm. As platforms choose to moderate content, they face the risk of being viewed as biased, especially when the moderation aligns more with certain political ideologies.

## Conclusion

In conclusion, the debate over deplatforming on social media platforms is complex, involving questions about free speech, moderation, and the role of tech companies in shaping discourse. As social media becomes an increasingly central part of public life, the impact of deplatforming will continue to generate discussion and controversy, especially concerning the balance between keeping online environments safe and allowing for open, diverse dialogues.