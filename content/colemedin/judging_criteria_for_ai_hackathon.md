---
title: Judging criteria for AI Hackathon
videoId: 29pxyXAk_lU
---

From: [[colemedin]] <br/> 

The Automator AI Agent Hackathon includes specific criteria for judging submitted AI agents, particularly during the initial round of evaluation by the Automator team <a class="yt-timestamp" data-t="00:05:08">[00:05:08]</a>. The objective is to select the top agents, likely around the top 25%, to be featured on the Live Agent Studio for community voting <a class="yt-timestamp" data-t="00:05:13">[00:05:13]</a>.

The criteria are as follows:

*   **Innovation** How novel is the idea behind the AI agent? <a class="yt-timestamp" data-t="00:05:46">[00:05:46]</a>
*   **Functionality** How well does the AI agent actually work? <a class="yt-timestamp" data-t="00:05:48">[00:05:48]</a>
*   **Usability** This assesses the ease of use and implementation of the agent <a class="yt-timestamp" data-t="00:05:50">[00:05:50]</a>.
*   **Impact** Does the AI agent solve a real-world problem? <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>
*   **Presentation** This considers how well the agent is presented, including extensive documentation and the option for a video <a class="yt-timestamp" data-t="00:06:00">[00:06:00]</a>.

Competitors are encouraged to bring their best to the [[ai_hackathon_competition_details | competition]] and can seek help by joining the Automator Think Tank Community, which has a dedicated section for the hackathon <a class="yt-timestamp" data-t="00:06:14">[00:06:14]</a>.