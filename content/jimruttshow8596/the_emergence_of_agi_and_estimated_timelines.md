---
title: The emergence of AGI and estimated timelines
videoId: -LKF_wYAQDQ
---

From: [[jimruttshow8596]] <br/> 

## Defining Artificial General Intelligence (AGI)

[[Ben Goertzels views on artificial general intelligence AGI | Ben Goertzel]] coined the term "[[Artificial General Intelligence AGI challenges and possibilities | Artificial General Intelligence]]" (AGI) around 15 years ago <a class="yt-timestamp" data-t="00:02:49">[00:02:49]</a>, defining it as [[Artificial General Intelligence AGI vs Narrow AI | AI]] at a fully human level and beyond <a class="yt-timestamp" data-t="00:00:35">[00:00:35]</a>.

Initially, in the middle of the last century, the goal of the [[Artificial General Intelligence AGI challenges and possibilities | AI]] field was informally understood to be the creation of intelligence of the same type that people possessed <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. However, over subsequent decades, it was discovered that software and hardware systems could perform specific tasks that seemed intelligent when humans did them, but they accomplished these tasks in a very different and more narrowly defined way than humans <a class="yt-timestamp" data-t="00:01:33">[00:01:33]</a>. This led to the development of "[[comparison of narrow AI and AGI | narrow AI]]" <a class="yt-timestamp" data-t="00:02:07">[00:02:07]</a>.

### AGI vs. Narrow AI

Narrow [[comparison of narrow AI and AGI | AI]] systems are proficient at particular, intelligence-seeming tasks within narrowly defined contexts <a class="yt-timestamp" data-t="00:02:07">[00:02:07]</a>. For example, a chess program in the 1950s could play chess at a grandmaster level but couldn't play Scrabble or checkers without reprogramming <a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>. A key limitation of [[comparison of narrow AI and AGI | narrow AI]] is its inability to generalize intelligent functions beyond its very specific context <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>.

In contrast, [[Artificial General Intelligence AGI vs Narrow AI | AGI]] is capable of achieving intelligence with at least the same generality of contexts that people can <a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a>. Concepts like "transfer learning" and "lifelong learning" are closely related, as achieving general intelligence requires the ability to transfer knowledge from one domain to a qualitatively different one <a class="yt-timestamp" data-t="00:03:13">[00:03:13]</a>.

Humans are not maximally generally intelligent systems; for instance, they perform poorly in environments with 275 dimensions, indicating limitations in generalizing beyond the dimensionality of the physical universe they inhabit <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>. However, humans are very general compared to current commercial [[comparison of narrow AI and AGI | AI]] systems <a class="yt-timestamp" data-t="00:04:14">[00:04:14]</a>. The research goal for [[Artificial General Intelligence AGI challenges and possibilities | AGI]] is to create [[Artificial General Intelligence AGI vs Narrow AI | AI]]s that are at least as generally intelligent as humans, and ultimately, more generally intelligent <a class="yt-timestamp" data-t="00:04:21">[00:04:21]</a>.

## Estimated Timelines for AGI Emergence

Estimates for when human-level [[Artificial General Intelligence AGI challenges and possibilities | AGI]] might emerge vary widely within the [[Artificial General Intelligence AGI challenges and possibilities | AI]] community. [[Ben Goertzels views on artificial general intelligence AGI | Ben Goertzel]]'s personal estimate has been five to thirty years from the time of the discussion <a class="yt-timestamp" data-t="00:04:59">[00:04:59]</a>.

Within the broader [[Artificial General Intelligence AGI challenges and possibilities | AI]] community:
*   A fair percentage of people agree with the 5-30 year timeline <a class="yt-timestamp" data-t="00:05:09">[00:05:09]</a>.
*   Estimates range from five or ten years up through hundreds of years <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>.
*   Very few serious [[Artificial General Intelligence AGI challenges and possibilities | AI]] researchers believe it will never happen <a class="yt-timestamp" data-t="00:05:17">[00:05:17]</a>. A small minority suggest a digital computer cannot achieve human-level general intelligence, perhaps due to the human brain being a quantum computer <a class="yt-timestamp" data-t="00:05:24">[00:05:24]</a>.
*   Over the last 10 years, the mean and variance of these estimates have significantly decreased, with a substantial plurality, possibly a majority, believing it will arrive in the next century <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>. [[Ben Goertzels views on artificial general intelligence AGI | Goertzel]] notes that the trend in predictions has moved towards his more optimistic end of the spectrum <a class="yt-timestamp" data-t="00:06:23">[00:06:23]</a>.

### Approaches and Their Impact on Timelines

The question of whether [[Artificial General Intelligence AGI challenges and possibilities | AGI]] will emerge by incrementally improving current style [[comparison of narrow AI and AGI | narrow AI]] systems or by needing a substantially new approach remains open <a class="yt-timestamp" data-t="00:04:28">[00:04:28]</a>.

Two broad approaches to [[Artificial General Intelligence AGI challenges and possibilities | AGI]] include:
1.  **Uploads/Emulations of the Human Brain**: This approach is currently "just an idea" <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>. While scientifically feasible by known laws of physics, direct work on this is limited due to the lack of necessary brain scanning and reconstructive technology <a class="yt-timestamp" data-t="00:07:22">[00:07:22]</a>. Breakthroughs in imaging or extrapolating brain dynamics from static snapshots are needed <a class="yt-timestamp" data-t="00:10:58">[00:10:58]</a>.
2.  **Software Approaches**: This involves creating [[Artificial General Intelligence AGI vs Narrow AI | AGI]] via loosely brain-inspired software (like current deep neural nets) or more math and cognitive science-inspired software (like OpenCog) <a class="yt-timestamp" data-t="00:08:08">[00:08:08]</a>. This is the subject of concrete research projects currently underway <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>. This path allows for incremental benefits and progress <a class="yt-timestamp" data-t="00:09:03">[00:09:03]</a>.

The software approach does not obviously require radically different technology than what currently exists, unlike brain emulation <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>. The human brain serves as a "proof of principle" for a flying machine built of molecules (intelligence), but the best proof of principle is not always the best way to build something <a class="yt-timestamp" data-t="00:11:31">[00:11:31]</a>. Current hardware, though very different from the brain, is highly efficient at tasks like theorem proving or database lookup <a class="yt-timestamp" data-t="00:13:08">[00:13:08]</a>. An "opportunistic approach" to [[Artificial General Intelligence AGI challenges and possibilities | AGI]] leverages existing hardware and knowledge while also incorporating insights from how the brain works <a class="yt-timestamp" data-t="00:13:47">[00:13:47]</a>.

![[progress_and_direction_towards_developing_agi]]
![[artificial_general_intelligence_agi_challenges_and_possibilities]]
![[ben_goertzels_views_on_artificial_general_intelligence_agi]]
![[artificial_general_intelligence_agi_risks]]
![[different_approaches_to_agi_development_beyond_mainstream_methods]]
![[comparison_of_narrow_ai_and_agi]]
![[artificial_general_intelligence_agi_vs_narrow_ai]]
![[efforts_in_creating_a_scalable_infrastructure_for_agi]]
![[cognitive_synergy_in_agi_systems]]