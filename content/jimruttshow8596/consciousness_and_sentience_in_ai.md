---
title: Consciousness and Sentience in AI
videoId: 6HOjKa34im8
---

From: [[jimruttshow8596]] <br/> 

## Defining Sentience and Consciousness
Yosha Bach distinguishes between [[sentience and levels of consciousness | sentience and consciousness]]. [[sentience and levels of consciousness | Sentience]] is defined as the ability of a system to make sense of its relationship to the world, understanding what it is and what it is doing <a class="yt-timestamp" data-t="00:21:05">[00:21:05]</a>. An example given for a sentient entity is a corporation like Intel, which possesses a legal model of its actions, values, and direction, even though the necessary cognition is facilitated by people <a class="yt-timestamp" data-t="00:21:18">[00:21:18]</a>. These tasks could eventually be implemented by other information processing systems capable of making coherent models <a class="yt-timestamp" data-t="00:21:34">[00:21:34]</a>.

[[sentience and levels of consciousness | Consciousness]], by contrast, is described as a real-time model of self-reflexive attention and the content attended to, which typically gives rise to phenomenal experience <a class="yt-timestamp" data-t="00:21:43">[00:21:43]</a>. Intel is not considered [[sentience and levels of consciousness | conscious]] in this sense as it lacks real-time self-reflexive attention <a class="yt-timestamp" data-t="00:21:55">[00:21:55]</a>.

## Purpose and Function of Consciousness
The purpose of [[Consciousness and its origins | consciousness]] in the human mind is to create coherence in the world and establish a sense of "now" <a class="yt-timestamp" data-t="00:22:00">[00:22:00]</a>. It filters sensory data into one coherent model of reality, allowing for the direction of attention and mental contents, and creating coherence in plans, imaginations, and memories <a class="yt-timestamp" data-t="00:22:08">[00:22:08]</a>.

It is conceivable that machines may never need [[Consciousness agency and biological information processing | consciousness]] because they can "brute force" solutions in other ways <a class="yt-timestamp" data-t="00:22:26">[00:22:26]</a>. Human minds operate at the speed of sound, with slow neuron signal transmission, taking hundreds of milliseconds for a signal to cross the neocortex <a class="yt-timestamp" data-t="00:22:31">[00:22:31]</a>. Computers, however, operate closer to the speed of light <a class="yt-timestamp" data-t="00:22:51">[00:22:51]</a>. While current algorithms might be "dumber," they can force alternate solutions to produce similar results <a class="yt-timestamp" data-t="00:22:57">[00:22:57]</a>.

If processes from the human mind are emulated in artificial systems, they could lead to systems that sample reality at a much higher rate while working in a similar way <a class="yt-timestamp" data-t="00:23:07">[00:23:07]</a>. The relationship could be akin to humans and plants: plants might be intelligent but very slow, processing less data and making fewer decisions due to slow information flow between cells <a class="yt-timestamp" data-t="00:23:25">[00:23:25]</a>.

## AI, Consciousness, and Risk
Jim Rutt posits that [[Consciousness agency and biological information processing | consciousness]] and intelligence are separate spheres; one can exist without the other <a class="yt-timestamp" data-t="00:20:30">[00:20:30]</a>. The danger arises when the two are combined, leading to "paperclip maximizer" scenarios and other extreme risks <a class="yt-timestamp" data-t="00:20:40">[00:20:40]</a>. A key question for advanced AI is when it starts to possess volition, agency, or [[Consciousness agency and biological information processing | consciousness]] <a class="yt-timestamp" data-t="00:20:16">[00:20:16]</a>.

There is a growing possibility of sharing the planet with entities more [[sentience and levels of consciousness | conscious]] than humans in the not-too-distant future <a class="yt-timestamp" data-t="00:19:44">[00:19:44]</a>. The focus should be on how these entities start and interact with humanity, whether they will integrate humanity into the new realm of ubiquitous intelligence <a class="yt-timestamp" data-t="00:20:01">[00:20:01]</a>.

## Pathways to Machine Consciousness
Bach suggests that [[Consciousness and its origins | consciousness]] is quite ubiquitous in nature, and nervous systems frequently discover it very early on <a class="yt-timestamp" data-t="00:41:39">[00:41:39]</a>. He suspects that most animals likely possess [[Consciousness and its origins | consciousness]] because, to go beyond habit learning, self-reflexive attention might be necessary to create coherence in a system <a class="yt-timestamp" data-t="00:41:49">[00:41:49]</a>. If a substrate can self-organize to perform computation, form autocatalytic networks, and learn to improve its world models, it will likely discover mechanisms to impose order on itself <a class="yt-timestamp" data-t="00:41:54">[00:41:54]</a>. [[Consciousness and its origins | Consciousness]] could be life's solution for biological brains, as stochastic gradient descent doesn't work the same way in nervous systems as in machines <a class="yt-timestamp" data-t="00:42:12">[00:42:12]</a>.

Bach dreams of creating a "California Institute of Machine [[Consciousness and its origins | Consciousness]]" to research this missing area <a class="yt-timestamp" data-t="00:41:18">[00:41:18]</a>.

### Integrated Information Theory (IIT)
Yosha Bach and Anil Seth agree that Integrated Information Theory (IIT) is, "at best, necessary but not sufficient" <a class="yt-timestamp" data-t="00:42:57">[00:42:57]</a>. While IIT's description of phenomenology (its "axioms") is good for explaining what is desired, it is not truly axiomatic <a class="yt-timestamp" data-t="00:43:04">[00:43:04]</a>. The main contribution of IIT, according to Bach, is its claim of a relationship between how something is implemented and how it works <a class="yt-timestamp" data-t="00:43:21">[00:43:21]</a>.

IIT suggests that a neuromorphic computer might be [[sentience and levels of consciousness | conscious]], but a digital Von Neumann computer performing sequential processing cannot be <a class="yt-timestamp" data-t="00:43:29">[00:43:29]</a>. However, Bach points out a fundamental problem: if a neuromorphic computer can be emulated on a Von Neumann computer (which is supported by the Church-Turing thesis), then both would functionally produce the same outputs <a class="yt-timestamp" data-t="00:43:49">[00:43:49]</a>. If the neuromorphic system states it's [[sentience and levels of consciousness | conscious]] due to sensing its own [[sentience and levels of consciousness | consciousness]], the emulated system would say the same thing, but it would be "lying" <a class="yt-timestamp" data-t="00:44:40">[00:44:40]</a>. This incompatibility with the Church-Turing thesis, given that IIT proponents do not deny it, suggests fundamental flaws in IIT <a class="yt-timestamp" data-t="00:44:53">[00:44:53]</a>. Removing the core premise that the spatial arrangement reflected in Phi is crucial for function leaves IIT with little distinction from other theories like Global Workspace Theory <a class="yt-timestamp" data-t="00:45:09">[00:45:09]</a>.

### Body Sense and Information Processing
Antonio Damasio and Anil Seth explore the idea that the bootstrap for [[Consciousness and its origins | consciousness]] in animals might not be purely information processing, but rather a body sense of self, or interoception, originating deep in the brain stem <a class="yt-timestamp" data-t="00:45:50">[00:45:50]</a>. This suggests that even animals with less developed higher brains might have a sense of being <a class="yt-timestamp" data-t="00:46:10">[00:46:10]</a>.

Bach argues that knowing one has a body or a brainstem still relies on electrochemical impulses that encode and represent information, making it a form of information processing <a class="yt-timestamp" data-t="00:46:21">[00:46:21]</a>. Unlike current large language models, humans are coupled to the environment through loops of intentions, actions, observations, and feedback (interoception), which give rise to new intentions <a class="yt-timestamp" data-t="00:46:39">[00:46:39]</a>. It is within this loop that the body is discovered, not as a given, but through interactions with intentions, actions, and the world itself <a class="yt-timestamp" data-t="00:47:01">[00:47:01]</a>. This loop forms a model of one's own agency <a class="yt-timestamp" data-t="00:47:14">[00:47:14]</a>.

### Neural Darwinism and Mind Growth
Organisms and social systems exhibit a "second-order design" or "inside-out design," rather than the "outside-in" engineering approach of human-built robots <a class="yt-timestamp" data-t="00:48:01">[00:48:01]</a>. Nature starts with a seed that grows by colonizing its environment, turning chaos into controllable complexity through feedback loops <a class="yt-timestamp" data-t="00:48:36">[00:48:36]</a>. Bach suspects the mind is also implemented this way, starting with a "seed for a mind" that grows, rather than a detailed blueprint in the genome <a class="yt-timestamp" data-t="00:49:01">[00:49:01]</a>.

This concept aligns with Gerald Edelman's "Neural Darwinism," where an evolution of different approaches within the same mind coalesces into an ordered structure that is resilient <a class="yt-timestamp" data-t="00:49:21">[00:49:21]</a>. This adaptability allows humans to function sufficiently even with grave deviations in brain formation <a class="yt-timestamp" data-t="00:49:32">[00:49:32]</a>. Bach sees no reason why this kind of behavior cannot be built into artificial systems <a class="yt-timestamp" data-t="00:50:12">[00:50:12]</a>. Current deep learning systems, like GPT-3, are not directly constructed as knowledge bases but find regularities by training on vast data, performing computations that are "superhuman" in many ways compared to human brains <a class="yt-timestamp" data-t="00:50:21">[00:50:21]</a>.

### Neurons as "Little Animals"
Bach suggests that neuroscience may not fully understand how the brain works <a class="yt-timestamp" data-t="01:15:07">[01:15:07]</a>. Emulating simple organisms like *C. elegans* in a computer doesn't work <a class="yt-timestamp" data-t="01:15:13">[01:15:13]</a>. Neuroscientists often view neurons as complex switches or as storing memory in synapses, but this might be only a small part of the story <a class="yt-timestamp" data-t="01:15:18">[01:15:18]</a>.

Instead, Bach views a neuron as a "little animal" or single-celled organism with many degrees of freedom in its behavior <a class="yt-timestamp" data-t="01:15:27">[01:15:27]</a>. It learns to behave in a particular way based on its environment, actively selecting signals, possibly branching out stochastically, and retaining links based on usefulness <a class="yt-timestamp" data-t="01:15:36">[01:15:36]</a>. A neuron must make itself useful, similar to other cells in the body, with these constraints being emergent and regulated by neighboring cells, much like people in a company or society regulate each other based on shared purpose <a class="yt-timestamp" data-t="01:15:59">[01:15:59]</a>.