---
title: Ben Goertzels views on artificial general intelligence AGI
videoId: isIrLmYTdvU
---

From: [[jimruttshow8596]] <br/> 

[[Ben Goertzels perspective on AI architectures and projects | Ben Goertzel]], a leading authority on [[Artificial General Intelligence AGI challenges and possibilities | Artificial General Intelligence (AGI)]], is credited with coining the term "artificial general intelligence" <a class="yt-timestamp" data-t="00:00:48">[00:00:48]</a>. He is also the instigator of the OpenCog project, an [[Progress and direction towards developing AGI | AGI]] open-source software project, and SingularityNET, a decentralized network for developing and deploying AI services <a class="yt-timestamp" data-t="00:00:56">[00:00:56]</a>.

## Defining Artificial General Intelligence (AGI)

[[Artificial General Intelligence AGI vs Narrow AI | AGI]] is an imprecise and informal term that refers to computer systems capable of performing tasks considered intelligent when done by humans, including those they were not specifically programmed or trained for <a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>. This contrasts with [[comparison_of_narrow_ai_and_agi | narrow AI]], which excels at highly particular tasks based on programming or data-driven training <a class="yt-timestamp" data-t="00:02:35">[00:02:35]</a>.

A key distinction of [[Artificial General Intelligence AGI challenges and possibilities | AGI]] is its ability to "take a leap" into domains only loosely connected to previous experiences <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>. Humans exhibit this, for instance, in learning to use the internet without explicit genetic or curriculum-based programming, through improvisation and experimentation <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>. While humans are not infinitely generally intelligent (e.g., struggling with mazes in 977 dimensions), their generality is far superior to any current AI software <a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>.

### Examples of AGI Hard Problems

*   **AlphaFold Limitations**: While impressive, AlphaFold predicts protein folding based on training data. It struggles with "floppy proteins" or new molecular classes (e.g., alien chemistry) because it cannot generalize beyond its training data without manual intervention or algorithm changes <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>. A human expert, given alien molecules, would likely enjoy the challenge and improvise <a class="yt-timestamp" data-t="00:05:22">[00:05:22]</a>.
*   **Wozniak's Ax Test**: An [[Artificial general intelligence AGI challenges and possibilities | AGI]] robot placed in a random kitchen should be able to attempt to make coffee <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a>. No current robot or AI can solve this problem today <a class="yt-timestamp" data-t="00:06:38">[00:06:38]</a>.
*   **Self-Driving Cars**: It is unclear if achieving average human-level self-driving is [[Artificial general intelligence AGI challenges and possibilities | AGI]]-hard <a class="yt-timestamp" data-t="00:07:13">[00:07:13]</a>. The challenge lies in generalization to "weird things" that happen on the road, where current narrow AI training data is insufficient <a class="yt-timestamp" data-t="00:07:38">[00:07:38]</a>.
*   **Turing Test**: Passing a casual 10-minute conversation with an average person is likely achievable with current chatbot technology in a few years <a class="yt-timestamp" data-t="00:09:00">[00:09:00]</a>. However, tricking an expert like [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] or Jim Rutt in a two-hour conversation is considered [[Artificial general intelligence AGI challenges and possibilities | AGI]]-hard, requiring genuine human-level general intelligence <a class="yt-timestamp" data-t="00:09:17">[00:09:17]</a>.
*   **Outlier Innovation**: The creativity of individuals like Richard Feynman, Albert Einstein, Jimi Hendrix, or Henri Matisse involves significant leaps into the unknown, going beyond surface-level patterns in previous accomplishments. This level of innovation cannot be achieved by simply looking at patterns in existing data <a class="yt-timestamp" data-t="01:10:38">[01:10:38]</a>.

## Criticism of Current AI Approaches (Deep Neural Networks)

[[Criticism of deep neural networks in achieving AGI | Goertzel]] believes that deep neural networks (DNNs) and other machine learning algorithms, which dominate the AI world's attention, are "fundamentally unsuited for the creation of human level AGI" <a class="yt-timestamp" data-t="01:10:01">[01:10:01]</a>. While he views them as a significant component of an [[Ben Goertzels perspective on AI architectures and projects | AGI]] architecture, he asserts they are missing many key aspects required for human-level intelligence <a class="yt-timestamp" data-t="01:15:41">[01:15:41]</a>.

He likens current DNNs to "very large lookup tables" that cleverly record and index what they have seen, using relevant historical data to supply responses <a class="yt-timestamp" data-t="01:16:27">[01:16:27]</a>. Despite their "deep" label, these networks primarily identify "shallow patterns" in data <a class="yt-timestamp" data-t="01:17:43">[01:17:43]</a>. For example, in natural language processing, they focus on sequences of words rather than building an underlying model of the conceived world <a class="yt-timestamp" data-t="01:18:00">[01:18:00]</a>. This limitation is exemplified by a transformer neural net suggesting a "table saw" to fit a large table through a small door, assuming it's a saw *for* tables, despite having carpentry manuals in its training data that explain its true function <a class="yt-timestamp" data-t="01:18:23">[01:18:23]</a>. This indicates that these systems do not build models of reality underlying the text <a class="yt-timestamp" data-t="02:00:00">[02:00:00]</a>.

Current systems leverage vast amounts of data and processing power to recognize highly particular patterns and extrapolate from them <a class="yt-timestamp" data-t="02:09:59">[02:09:59]</a>. This approach struggles to generalize to domains of reality that do not exhibit those specific patterns <a class="yt-timestamp" data-t="02:17:17">[02:17:17]</a>. This is a "knowledge representation issue," where knowledge is cataloged as contextualized particulars without abstraction <a class="yt-timestamp" data-t="02:29:13">[02:29:13]</a>. The inability to form concise abstractions of experience directly hinders the ability to generalize to different domains <a class="yt-timestamp" data-t="02:29:50">[02:29:50]</a>.

[[Differences between Generative AI and AGI | Generative AI]] models like GPT-3 and DALL-E 2, while impressive, give the sense of being "astoundingly clever sets of statistical relationships" without true grounding <a class="yt-timestamp" data-t="02:22:20">[02:22:20]</a>. This contrasts sharply with human learning, where a person can play only a few thousand war games across hundreds of titles, yet pull out broad generalizations applicable to new, different games, operating at a higher level of abstraction <a class="yt-timestamp" data-t="02:29:58">[02:29:58]</a>. Humans (and even smart dogs) demonstrate "one-shot learning" by filling in knowledge gaps and improvising based on few clues <a class="yt-timestamp" data-t="02:47:19">[02:47:19]</a>.

The AI industry's focus on DNNs is largely driven by commercial viability. These architectures excel at tasks that involve repeating well-understood operations to maximize defined metrics, such as making people click on web ads or obeying doctrine in military applications <a class="yt-timestamp" data-t="02:47:40">[02:47:40]</a>. This allows for milking commercial value from applications that don't require creative or imaginative AI <a class="yt-timestamp" data-t="02:49:50">[02:49:50]</a>.

## Three Viable Paths to True AGI

Based on his essay, "Three Viable Paths to True AGI," [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] outlines three promising directions for developing [[Artificial General Intelligence AGI challenges and possibilities | AGI]]:

### 1. Cognitive Level Approach: Hybrid Neural Symbolic, Evolutionary Metagraph Based AGI

This approach, exemplified by the OpenCog Hyperon system, aims to emulate the human mind's high-level functions using advanced computer science algorithms, rather than attempting to replicate biology at a low level <a class="yt-timestamp" data-t="03:30:30">[03:30:30]</a>. Similar to how airplanes were inspired by birds but didn't replicate flapping wings, this method takes inspiration from natural intelligence at a higher abstraction level <a class="yt-timestamp" data-t="03:46:58">[03:46:58]</a>.

Key aspects include:
*   **Modular Design**: Identifying distinct cognitive functions (perception, action, planning, working memory, long-term memory, social reasoning) and developing effective computer science algorithms for each <a class="yt-timestamp" data-t="03:50:58">[03:50:58]</a>.
*   **Cognitive Synergy**: Ensuring these algorithms can interoperate deeply, with transparency into each other's internal processing, rather than being isolated "black boxes" <a class="yt-timestamp" data-t="03:57:12">[03:57:12]</a>.
*   **Distributed Knowledge Graph**: Centering the system on a large distributed knowledge graph (hypergraph or metagraph) with typed, weighted nodes and links <a class="yt-timestamp" data-t="03:57:50">[03:57:50]</a>. Various [[Artificial general intelligence AGI challenges and possibilities | AI]] algorithms operate on this common graph <a class="yt-timestamp" data-t="03:38:08">[03:38:08]</a>.
*   **Modernizing GOFAI**: This approach addresses criticisms of "good old-fashioned AI" (GOFAI).
    *   **Logic**: Uses more advanced, fuzzy, probabilistic, paraconsistent, and intuitionist logic, allowing for uncertainty and contradictions <a class="yt-timestamp" data-t="04:27:50">[04:27:50]</a>.
    *   **Learning**: Not reliant on hand-coding common sense knowledge. It incorporates learning, including from low-level sensory data, using logical theorem provers or unsupervised learning <a class="yt-timestamp" data-t="04:44:45">[04:44:45]</a>.
*   **Role of Evolution**:
    *   **Implicit Evolution**: In a distributed knowledge base like OpenCog's Atomspace, economic attention allocation (spreading importance values) and preferential action of logical reasoning on important items can be mathematically described by population genetics <a class="yt-timestamp" data-t="04:47:48">[04:47:48]</a>. The system inherently performs evolutionary learning without explicit genetic algorithms <a class="yt-timestamp" data-t="04:52:00">[04:52:00]</a>.
    *   **Explicit Genetic Algorithms**: Used for procedure learning (e.g., learning program codelets) and creativity (e.g., evolving new logical predicates) <a class="yt-timestamp" data-t="04:59:00">[04:59:00]</a>.
    *   [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] views evolution and autopoiesis (self-organization/reconstruction) as fundamental meta-dynamics underlying complex systems, akin to "being and becoming" <a class="yt-timestamp" data-t="05:11:00">[05:11:00]</a>.

### 2. Brain Level Approach: Large-Scale Non-linear Dynamical Brain Simulation

This path involves simulating the brain at a detailed biological level, which is distinct from current DNNs that use simplified neuron models <a class="yt-timestamp" data-t="05:31:00">[05:31:00]</a>.

*   **Challenges in Computational Neuroscience**:
    *   **Measurement Limitations**: Current brain imaging instruments (PET, fMRI, MEG) cannot yet provide the necessary time-series data of neural activity across large swaths of cortex to reverse-engineer complex processes like abstraction formation <a class="yt-timestamp" data-t="05:27:00">[05:27:00]</a>.
    *   **Biological Complexity**: Beyond neurons, the brain involves glia, astrocytes, cellular/charge diffusion, and potentially "wet quantum biology," which are not fully understood <a class="yt-timestamp" data-t="05:41:00">[05:41:00]</a>.
    *   **Lack of Holistic Models**: Most computational neuroscientists focus on modeling small brain subsystems rather than creating integrated, holistic brain models due to cost and complexity <a class="yt-timestamp" data-t="05:52:00">[05:52:00]</a>.
*   **Promising Directions**:
    *   **Alex Ororbia's Work**: [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] is collaborating with Alex Ororbia, who has developed a predictive coding-based learning mechanism for deep neural networks that appears to outperform backpropagation <a class="yt-timestamp" data-t="05:46:00">[05:46:00]</a>. This method can work with more biologically realistic neuron models (e.g., Hodgkin-Huxley or chaotic neurons) and incorporate glia, which standard backpropagation cannot <a class="yt-timestamp" data-t="05:51:00">[05:51:00]</a>.
    *   **Structured Semantic Representations**: The hypothesis is that replacing backpropagation with predictive coding in networks with biologically realistic neurons (like Izhikevich neurons with sub-threshold spreading of activation) could lead to better generalization and more compact neural networks that automatically learn structured semantic representations, allowing for cleaner interfacing with logic-based systems like OpenCog <a class="yt-timestamp" data-t="05:57:00">[05:57:00]</a>.
*   **Hardware Challenges**:
    *   **Parallel Computing**: Brain simulations are inherently parallel, while most current computers are fundamentally serial (Von Neumann architecture) <a class="yt-timestamp" data-t="01:01:34">[01:01:34]</a>. The success of current DNNs relied on "hijacking GPU processors" for parallelization <a class="yt-timestamp" data-t="01:02:01">[01:02:01]</a>.
    *   **Specialized Chips**: [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] anticipates a proliferation of specialized AI chip architectures beyond GPUs in the next 3-5 years, optimized for different AI algorithms <a class="yt-timestamp" data-t="01:03:50">[01:03:50]</a>. He is involved in designing a MIMD parallel processor-in-RAM architecture for OpenCog's graph and hypergraph pattern matching, suitable for stable knowledge graphs <a class="yt-timestamp" data-t="01:05:15">[01:05:15]</a>. The decreasing cost of designing new chips makes it viable to create AGI boards integrating different specialized chips (deep learning, Izhikevich neuron, hypervector, pattern matching) with fast interconnects <a class="yt-timestamp" data-t="01:07:21">[01:07:21]</a>.

### 3. Chemistry Level Approach: Massively Distributed AI Optimized Artificial Chemistry Simulation

This approach stems from [[Ben Goertzels perspective on AI architectures and projects | Goertzel]]'s background in artificial life, which aims to build artificial organisms with simulated metabolisms and genomes within a simulated world <a class="yt-timestamp" data-t="01:16:32">[01:16:32]</a>. The core idea is that evolution in biology is intricately linked with self-organization and complex, self-forcing dynamics within organisms and their environments, ultimately boiling down to biochemistry <a class="yt-timestamp" data-t="01:18:00">[01:18:00]</a>.

*   **Abstracting Chemistry**: Inspired by Walter Fontana's "algorithmic chemistry," this involves abstracting the spirit of chemistry by using "list codelets" (small programs) that act on other programs to produce new ones in complex chains of reactions, simulating a chemical soup <a class="yt-timestamp" data-t="01:18:40">[01:18:40]</a>.
    *   The motivation is to explore if evolving an underlying "chemistry" (or gene expression machinery) could lead to a more expressive representation for producing intelligent phenotypes than natural evolution's arbitrary chemistry <a class="yt-timestamp" data-t="01:19:48">[01:19:48]</a>.
    *   This approach might be more amenable to play with, easier to understand, require less compute, and avoid the peculiarities of real chemistry <a class="yt-timestamp" data-t="01:24:39">[01:24:39]</a>.
    *   OpenCog Hyperon's new programming language, Meta (M-E-T-T-A), could facilitate this by enabling abstract and modern programming for algorithmic chemistry <a class="yt-timestamp" data-t="01:27:40">[01:27:40]</a>.
*   **Realistic Chemistry Simulation**: An alternative within this approach is to simulate real chemistry/biochemistry, as explored by Bruce Damer's EvoGrid project, which uses grid computing to run computational chemistry simulators to solve the origin of life <a class="yt-timestamp" data-t="01:22:49">[01:22:49]</a>. While intellectually fascinating, this requires immense compute resources <a class="yt-timestamp" data-t="01:26:21">[01:26:21]</a>.
*   **AI-Optimized Artificial Chemistry**: To address the compute challenge, [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] proposes a hybrid approach: using machine learning to study the evolving chemical soup <a class="yt-timestamp" data-t="01:29:10">[01:29:10]</a>. For instance, in a simulation with 10,000 "vats of chemicals," an [[Artificial general intelligence AGI challenges and possibilities | AI]] could identify the most promising vats, kill the least promising, and refill them with mutations or crossovers from the best ones <a class="yt-timestamp" data-t="01:29:20">[01:29:20]</a>. This forms a "directed chemical evolution" using machine learning and even proto-AGI to guide the process <a class="yt-timestamp" data-t="01:30:41">[01:30:41]</a>.
*   **Decentralized Implementation**: This approach lends itself to decentralized platforms like SingularityNET's NuNet, where millions of people could run small virtual algorithmic chemistry simulations on their machines. An OpenCog system in the cloud could analyze the progress and refresh the "soups" periodically <a class="yt-timestamp" data-t="01:31:53">[01:31:53]</a>.
*   **Parallelism Challenge**: Like brain simulations, chemistry is an inherently parallel process. The current serial nature of most computing systems remains a barrier to fully realizing this approach, highlighting the need for massively parallel, "more lifelike" computing infrastructures <a class="yt-timestamp" data-t="01:33:16">[01:33:16]</a>.

## The Need for Portfolio Diversification and Funding

[[Ben Goertzels perspective on AI architectures and projects | Goertzel]] emphasizes that humanity needs to "open up its portfolio bets" in AGI research and invest more significantly in these less mainstream approaches <a class="yt-timestamp" data-t="01:39:41">[01:39:41]</a>. While the [[the_emergence_of_agi_and_estimated_timelines | emergence of AGI]] is now widely accepted to be decades away (e.g., 20-30 years), the lack of investment is due to financial discount rates and a focus on short-term returns <a class="yt-timestamp" data-t="01:38:00">[01:38:00]</a>.

*   **Funding Priorities**: A few hundred billion dollars could massively accelerate [[progress and direction towards developing AGI | AGI R&D]], enabling thousands of projects. This amount is trivial compared to government expenditures like defense budgets or stimulus packages <a class="yt-timestamp" data-t="01:40:52">[01:40:52]</a>.
*   **Industry vs. Research**: The AI industry prioritizes "fine-tuning narrow AIs" for incremental gains, as it leverages existing large datasets and provides predictable commercial value <a class="yt-timestamp" data-t="02:50:00">[02:50:00]</a>. Pursuing [[Artificial General Intelligence AGI challenges and possibilities | AGI]] is seen as a longer-term, uncertain endeavor that doesn't yield immediate "incremental goodies" <a class="yt-timestamp" data-t="01:39:26">[01:39:26]</a>.
*   **Lack of Patience**: [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] notes a cultural shift in younger researchers who are "addicted to running a learning algorithm a data set and getting a cool result right away" <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a>. This discourages the sustained, long-term effort required for [[Artificial general intelligence AGI challenges and possibilities | AGI]] research, which may not provide immediate feedback <a class="yt-timestamp" data-t="01:53:00">[01:53:00]</a>.
*   **Potential Avenues for Funding**:
    *   **Government Funding**: While often conservative, entities like the US NIH and DARPA have shown success in transforming fields through research funding <a class="yt-timestamp" data-t="01:54:00">[01:54:00]</a>.
    *   **Cultural Shift/Citizen Science**: A shift akin to the open-source software movement could see more people dedicating time to [[Artificial general intelligence AGI challenges and possibilities | AGI R&D]] without government funding, especially as more individuals have disposable time and recognize the viability of [[Artificial General Intelligence AGI challenges and possibilities | AGI]] within their lifetimes <a class="yt-timestamp" data-t="01:47:00">[01:47:00]</a>.
*   **The First Path**: [[Ben Goertzels perspective on AI architectures and projects | Goertzel]] maintains his primary bet on the cognitive level, hybrid approach (like OpenCog Hyperon) as the most likely path to [[Artificial General Intelligence AGI challenges and possibilities | AGI]] first <a class="yt-timestamp" data-t="01:38:25">[01:38:25]</a>. This approach's hybrid nature allows it to integrate ideas and modules from other paradigms (e.g., biologically realistic neural nets for perception, algorithmic chemistry for creativity) <a class="yt-timestamp" data-t="01:43:50">[01:43:50]</a>.

[[Artificial general intelligence AGI risks | Goertzel]] concludes that while there will be many paths to [[Artificial General Intelligence AGI challenges and possibilities | AGI]], humans may only pursue the first one, with subsequent paths explored by the AGI itself <a class="yt-timestamp" data-t="01:38:00">[01:38:00]</a>.