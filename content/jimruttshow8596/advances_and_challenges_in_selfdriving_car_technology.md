---
title: Advances and challenges in selfdriving car technology
videoId: 2WmczROXzco
---

From: [[jimruttshow8596]] <br/> 

George Hotz, a notable figure in the tech world known for his early hacking exploits and work with Google's Project Zero, is currently the president of Comma.ai, a company focused on [[development_of_opensource_selfdriving_technology | open-source self-driving car systems]] <a class="yt-timestamp" data-t="00:32:00">[00:32:00]</a>. This field has seen significant interest, with previous discussions on the Jim Rut Show featuring figures like Shaheen Farry and Jim Hackett <a class="yt-timestamp" data-t="00:04:08">[00:04:08]</a>.

## Motivation and Initial Hurdles

Hotz's journey into self-driving technology began with a potential contract to build software for Tesla to replace the Mobileye chip <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>. Although the contract didn't materialize, it inspired him to build an "autopilot clone" to sell to car companies <a class="yt-timestamp" data-t="00:05:12">[00:05:12]</a>. Mobileye chips perform proprietary perception algorithms, assisting with ADAS (Advanced Driver-Assistance Systems) features like perceiving lane lines and cars <a class="yt-timestamp" data-t="00:05:33">[00:05:33]</a>.

An initial attempt to use a camera to directly predict steering wheel angles via supervised learning (image as input, steering angle as output) failed <a class="yt-timestamp" data-t="00:10:49">[00:10:49]</a>. Despite achieving low loss on training and test sets, the model couldn't drive straight on the highway <a class="yt-timestamp" data-t="00:11:11">[00:11:11]</a>. This is because the model wasn't acting in the world during training; the data reflected human policy, not machine policy <a class="yt-timestamp" data-t="00:11:23">[00:11:23]</a>. The "Epsilon error" accumulates over time, making it impossible to generalize from static data to real-world driving where the machine's actions influence subsequent inputs <a class="yt-timestamp" data-t="00:11:50">[00:11:50]</a>.

## [[comparison_between_camera_and_lidarbased_selfdriving_systems | Camera vs. Lidar-Based Systems]]

A significant debate in self-driving technology revolves around sensor reliance <a class="yt-timestamp" data-t="00:06:05">[00:06:05]</a>. Hotz firmly believes that humans, who only have two cameras (eyes), are the only system truly capable of Level 5 self-driving, aligning with Elon Musk's stance against Lidar <a class="yt-timestamp" data-t="00:06:20">[00:06:20]</a>. He argues that Lidar is not necessary for self-driving <a class="yt-timestamp" data-t="00:06:48">[00:06:48]</a>.

## Levels of Self-Driving Automation

The six levels of self-driving automation (Level 0 through Level 5) often relate more to liability than actual capability <a class="yt-timestamp" data-t="00:07:11">[00:07:11]</a>:
*   **Level 2**: The human driver remains fully liable for decisions <a class="yt-timestamp" data-t="00:07:25">[00:07:25]</a>.
*   **Level 3**: Human liability applies in certain scenarios <a class="yt-timestamp" data-t="00:07:39">[00:07:39]</a>.
*   **Level 4**: Human liability is removed in specific areas (e.g., cities) <a class="yt-timestamp" data-t="00:07:43">[00:07:43]</a>.
*   **Level 5**: The human is never liable <a class="yt-timestamp" data-t="00:07:47">[00:07:47]</a>, implying full automation where one could sleep in the back seat <a class="yt-timestamp" data-t="00:08:10">[00:08:10]</a>.

Predictions of full self-driving by 2018-2019 were "total hubris," exemplified by Google's early prototypes without steering wheels <a class="yt-timestamp" data-t="00:08:05">[00:08:05]</a>.

## The Human Benchmark

It's a common misconception that humans are poor drivers <a class="yt-timestamp" data-t="00:08:48">[00:08:48]</a>. Most civilized countries experience about one fatality per 100 million miles driven, a significant achievement not yet matched by self-driving companies <a class="yt-timestamp" data-t="00:08:56">[00:08:56]</a>. Humans are "absurdly good drivers" <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>, having driven thousands of times to work with zero or one crash <a class="yt-timestamp" data-t="00:09:57">[00:09:57]</a>.

Gary Marcus's critique about a "zillion corner cases" in self-driving cars is dismissed by Hotz <a class="yt-timestamp" data-t="00:12:43">[00:12:43]</a>. Human drivers experience far less data than modern systems are trained on <a class="yt-timestamp" data-t="00:13:08">[00:13:08]</a>. The problem is not an inability to handle rare events, but rather the inability of *narrow AIs* to generalize like humans <a class="yt-timestamp" data-t="00:13:27">[00:13:27]</a>. Hotz argues that the Uber accident, where the car failed to recognize a pedestrian with a bicycle and bags, was more akin to a classical software bug than a failing of deep learning <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>.

## Comma.ai's Approach to [[development_of_opensource_selfdriving_technology | Self-Driving Technology]]

Comma.ai's core philosophy is to emulate human driving behavior <a class="yt-timestamp" data-t="00:17:05">[00:17:05]</a>.
*   **Corrective Pressure**: After initial failures with pure supervised learning, Comma.ai introduced a small amount of "corrective pressure" <a class="yt-timestamp" data-t="00:15:15">[00:15:15]</a>. This involved training an algorithm to detect lane lines, find the center, and apply corrective steering torque <a class="yt-timestamp" data-t="00:15:20">[00:15:20]</a>.
*   **Evolution from Lane Lines**: Initially, the reliance on lane lines was considered an "original sin" as they lack a physics-based definition and human labeling is inconsistent <a class="yt-timestamp" data-t="00:15:37">[00:15:37]</a>. Comma.ai eventually removed this dependency, focusing on "where a human would drive the car" on a given road <a class="yt-timestamp" data-t="00:16:04">[00:16:04]</a>.
*   **Simulation for Correction**: To combat the "behavioral cloning" problem where errors accumulate, Comma.ai uses simulation <a class="yt-timestamp" data-t="00:17:25">[00:17:25]</a>. Unlike Waymo's hand-coded game engine simulators, Comma.ai's "small offset simulator" uses real human driving video and applies geometric perturbations to create varied scenarios <a class="yt-timestamp" data-t="00:19:47">[00:19:47]</a>. This allows the model to learn corrective actions and converge, as tested by their "hugging test" which measures how quickly the car returns to the lane center when offset <a class="yt-timestamp" data-t="00:18:20">[00:18:20]</a>.
*   **Data Collection**: Comma.ai boasts the second-largest driving dataset globally after Tesla, with 10,000 weekly active users uploading data <a class="yt-timestamp" data-t="00:19:12">[00:19:12]</a>. This provides tens of millions of miles of "massively diverse" data from various locations worldwide <a class="yt-timestamp" data-t="00:19:21">[00:19:21]</a>.
*   **Installation and Functionality**: The Comma 3X device costs $1250 <a class="yt-timestamp" data-t="00:23:06">[00:23:06]</a> and takes about 15 minutes to install <a class="yt-timestamp" data-t="00:21:39">[00:21:39]</a>. It connects to the car's existing camera behind the rearview mirror, intercepting and improving lane-keep assist messages <a class="yt-timestamp" data-t="00:21:37">[00:21:37]</a>. It selectively blocks or passes through messages, not disabling emergency braking by default <a class="yt-timestamp" data-t="00:22:17">[00:22:17]</a>. The system helps with lateral control, keeping the car centered or where a human would place it, even on unmarked roads <a class="yt-timestamp" data-t="00:24:40">[00:24:40]</a>. It allows for hours of hands-off driving on interstate highways <a class="yt-timestamp" data-t="00:24:51">[00:24:51]</a> and has an experimental mode for city driving (stop signs, lights, turns) <a class="yt-timestamp" data-t="00:25:07">[00:25:07]</a>.
*   **No High-Precision Maps**: Comma.ai does not use high-resolution mapping like Waymo <a class="yt-timestamp" data-t="00:25:56">[00:25:56]</a>, believing that relying on centimeter precision on a global scale is "absurd" and non-robust <a class="yt-timestamp" data-t="00:26:22">[00:26:22]</a>. They use standard definition maps, similar to what humans use <a class="yt-timestamp" data-t="00:26:09">[00:26:09]</a>.

## Comparison with Competitors

*   **Waymo**: Hotz characterizes Waymo's self-driving cars as "fancy remote control cars" or "trackless monorails" <a class="yt-timestamp" data-t="00:26:26">[00:26:26]</a>. Their approach, operating in defined, carefully mapped regions, is Level 4 <a class="yt-timestamp" data-t="00:26:54">[00:26:54]</a>. Waymo's vehicles cost around $500,000 each and rely on extensive remote human operators, with cars stopping if the cell phone network goes down <a class="yt-timestamp" data-t="00:29:36">[00:29:36]</a>. Hotz criticizes their "hilariously negative unit economics" <a class="yt-timestamp" data-t="00:32:29">[00:32:29]</a> and their assumption of a static world without competition <a class="yt-timestamp" data-t="00:32:51">[00:32:51]</a>.
*   **Tesla**: Both Comma.ai and Tesla train models in data centers and then upload them to the car for local processing <a class="yt-timestamp" data-t="00:39:14">[00:39:14]</a>. Tesla has positive unit economics, selling cars profitably today <a class="yt-timestamp" data-t="00:33:37">[00:33:37]</a>. Tesla's CPU power applied to the real-time problem is about 100x that of Comma.ai's <a class="yt-timestamp" data-t="00:35:27">[00:35:27]</a>.
    *   **Similarities**: Both use camera-only approaches and operate anywhere, not just geo-fenced areas <a class="yt-timestamp" data-t="00:37:39">[00:37:39]</a>.
    *   **Differences**: Tesla views driving as a "fiscus problem" with a "modernist perspective," using rigid maneuvers and displaying virtual 3D cars <a class="yt-timestamp" data-t="00:34:26">[00:34:26]</a>. Comma.ai has a more "holistic" approach, focusing on what a human would do ("just tell me the action, don't tell me the state") <a class="yt-timestamp" data-t="00:34:49">[00:34:49]</a>. While Tesla has greater high-end capabilities (e.g., navigating complex turns in experimental FSD) <a class="yt-timestamp" data-t="00:37:01">[00:37:01]</a>, Comma.ai claims superiority in usability and "chill" driving <a class="yt-timestamp" data-t="00:36:14">[00:36:14]</a>. Tesla's system can make "sketchy mistakes" like sudden braking or mis-tracking lanes, leading to jarring experiences <a class="yt-timestamp" data-t="00:36:22">[00:36:22]</a>. Comma.ai's system, with lower torque limits, is smoother and less jarring when overwhelmed <a class="yt-timestamp" data-t="00:36:43">[00:36:43]</a>, its "failure modes" being more human-like <a class="yt-timestamp" data-t="00:38:55">[00:38:55]</a>.

## [[legal_and_regulatory_issues_for_selfdriving_tech | Legal and Regulatory Environment]]

Comma.ai operates as a Level 2 system <a class="yt-timestamp" data-t="00:43:00">[00:43:00]</a>, where the human is always in control and liable <a class="yt-timestamp" data-t="00:43:17">[00:43:17]</a>. They self-certify compliance with automotive standards like ISO 26262 <a class="yt-timestamp" data-t="00:42:41">[00:42:41]</a>. Key aspects of their regulatory compliance and liability stance include:
*   **Control**: The system limits torque and can always be overridden by two fingers <a class="yt-timestamp" data-t="00:43:30">[00:43:30]</a>. The car never becomes uncontrollable <a class="yt-timestamp" data-t="00:43:24">[00:43:24]</a>.
*   **Driver Monitoring**: Comma.ai has "the best driver monitoring in the world" <a class="yt-timestamp" data-t="00:44:42">[00:44:42]</a>, using a camera to ensure the driver keeps eyes on the road <a class="yt-timestamp" data-t="00:44:03">[00:44:03]</a>. This system is designed to be helpful, not intrusive, alerting drivers only when truly necessary to prevent alert fatigue <a class="yt-timestamp" data-t="00:44:53">[00:44:53]</a>.
*   **Liability**: If a crash occurs, liability rests with the human driver <a class="yt-timestamp" data-t="00:43:38">[00:43:38]</a>. Comma.ai's stance is that "the human is in control of the car at all times" <a class="yt-timestamp" data-t="00:50:21">[00:50:21]</a>. They distinguish between functional safety (where a product malfunction, like brake failure, would be their liability) and judgment calls (where the driver is responsible) <a class="yt-timestamp" data-t="00:53:22">[00:53:22]</a>. They have not faced claims for software bugs causing problems, only successfully defended against a patent troll <a class="yt-timestamp" data-t="00:50:52">[00:50:52]</a>.
*   **Data Upload**: Driving telemetry is opt-out, encouraged as a "common good" to improve the system <a class="yt-timestamp" data-t="00:45:37">[00:45:37]</a>. Driver monitoring data (pictures) is not uploaded unless specifically opted in <a class="yt-timestamp" data-t="00:45:28">[00:45:28]</a>.

## Future Vision

Hotz views self-driving cars as a "stepping stone" to [[artificial_general_intelligence_agi_challenges_and_possibilities | general purpose robotics]] and "artificial life" <a class="yt-timestamp" data-t="00:39:54">[00:39:54]</a>. Driving is considered a "big narrow piece of AI" <a class="yt-timestamp" data-t="00:40:14">[00:40:14]</a>, with lessons learned applicable to other robotics challenges. The driving problem is "low dimensional" (steering and acceleration) compared to the high dimensionality of a human hand <a class="yt-timestamp" data-t="00:46:59">[00:46:59]</a>.

Comma.ai's long-term goal is to sell a "Comma Body," a $25,000 robot companion capable of cooking and cleaning <a class="yt-timestamp" data-t="00:47:34">[00:47:34]</a>.

### Tinygrad: A Foundational Project
Hotz is also the CEO of Tinygrad, a machine learning framework that competes with TensorFlow, PyTorch, and JAX <a class="yt-timestamp" data-t="00:55:55">[00:55:55]</a>. Its key distinction is its simplicity, with a codebase of only 5200 lines <a class="yt-timestamp" data-t="00:56:11">[00:56:11]</a>. Tinygrad can run models like Stable Diffusion and Llama, and train various networks <a class="yt-timestamp" data-t="00:56:22">[00:56:22]</a>. It supports devices and data types generically, preventing "combinatorial explosion" common in other frameworks <a class="yt-timestamp" data-t="00:56:47">[00:56:47]</a>. Tinygrad is used in Comma.ai's Openpilot system to run models on devices <a class="yt-timestamp" data-t="00:57:29">[00:57:29]</a>. The long-term goal for Tinygrad is to build machine learning ASICs, starting with software <a class="yt-timestamp" data-t="00:57:11">[00:57:11]</a>.

### Future of Self-Driving Levels
Comma.ai has "no interest in ever going past Level 2" or taking on liability <a class="yt-timestamp" data-t="00:48:39">[00:48:39]</a>, aiming instead to build software that is "a better driver than a human," perhaps 10x better <a class="yt-timestamp" data-t="00:48:50">[00:48:50]</a>. They believe Level 4 is not viable as a business model, as Level 5 cars will arrive too quickly <a class="yt-timestamp" data-t="00:49:18">[00:49:18]</a>. The focus remains on making driving "chill" for users <a class="yt-timestamp" data-t="00:37:10">[00:37:10]</a>.