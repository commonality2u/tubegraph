---
title: Cognitive Architectures
videoId: x0bHMn68kL8
---

From: [[jimruttshow8596]] <br/> 

Joshua Bach, Vice President of Research at the AI Foundation and author of "Principles of Synthetic Intelligence: Psi, an Architecture of Motivated Cognition," views artificial intelligence (AI) as a crucial link between philosophy and mathematics <a class="yt-timestamp" data-t="01:34:00">[01:34:00]</a>. His work seeks to understand the nature of AI to better comprehend human existence <a class="yt-timestamp" data-t="01:25:00">[01:25:00]</a>.

## The Philosophical Project of AI
Bach believes that AI, particularly [[Cognitive synergy in AGI systems | artificial general intelligence]] (AGI), represents the "capstone" of philosophical inquiry into human nature and our relationship with the mechanical universe <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>. He argues that the universe is not magic, but rather operates based on understandable, non-conspiratorial processes <a class="yt-timestamp" data-t="02:07:00">[02:07:00]</a>. AI is an attempt to build a testable theory of what a non-conspiratorial system capable of reflecting on its environment and its own nature might be <a class="yt-timestamp" data-t="02:29:00">[02:29:00]</a>.

### AGI vs. Narrow AI
The field of AI initially began with great optimism among computer scientists, information theorists, and psychologists, aiming to "teach computers how to think" based on constructive mathematics (computation) <a class="yt-timestamp" data-t="04:06:00">[04:06:00]</a>. Early progress was significant, leading to capabilities like decent chess-playing and simple language understanding <a class="yt-timestamp" data-t="04:58:00">[04:58:00]</a>. Many programming languages used today originated from these early AI efforts <a class="yt-timestamp" data-t="05:21:00">[05:21:00]</a>.

However, the daunting nature of building a thinking machine led most researchers to focus on more achievable, short-term goals, resulting in a shift towards "narrow AI" which focused on improving statistical automation <a class="yt-timestamp" data-t="06:05:00">[06:05:00]</a>. This practical approach, driven by funding and tenure incentives, sidelined the philosophical project of AGI <a class="yt-timestamp" data-t="06:08:00">[06:08:00]</a>.

A historical division within AI also occurred, partly due to Marvin Minsky's claim that [[Scaffolding and its function within cognitive and dynamic systems | cognitive AI]] was synonymous with symbolic AI, and his active discouragement of cybernetics and neural network research <a class="yt-timestamp" data-t="06:54:00">[06:54:00]</a>. This delayed the development of [[Developmental perspectives in cognitive neuroscience | dynamical systems models of cognition]] and machine learning systems for over a decade, creating a rift between cognitive AI and other approaches <a class="yt-timestamp" data-t="07:11:00">[07:11:00]</a>. Despite this, many individuals, including those at major tech companies, secretly remain interested in AGI <a class="yt-timestamp" data-t="08:28:00">[08:28:00]</a>.

### Optimism for Superhuman AI
Bach is optimistic about creating computer intelligences that are at or beyond human level <a class="yt-timestamp" data-t="10:33:00">[10:33:00]</a>. He doesn't believe there are "deep open philosophical questions" that need answering, but rather "a lot of technical details" <a class="yt-timestamp" data-t="10:46:00">[10:46:00]</a>. He suggests that humans might be the "stupidest possible general intelligence," given the limitations of the human brain in areas like working memory size and memory fidelity <a class="yt-timestamp" data-t="12:01:00">[12:01:00]</a>.

The possibility of creating superhuman AI depends heavily on finding the "appropriate level of representation" <a class="yt-timestamp" data-t="14:55:00">[14:55:00]</a>. If the unit of computation is a neuron, it might be very expensive, but if it's mini-columns (groups of 300-400 neurons), it could be more feasible, perhaps within the cost of a few powerful GPUs <a class="yt-timestamp" data-t="23:38:00">[23:38:00]</a>.

## Large Language Models: GPT-2 and GPT-3
Bach discusses the capabilities of models like GPT-2 and GPT-3, which are trained on massive amounts of filtered internet text <a class="yt-timestamp" data-t="16:37:00">[16:37:00]</a>. These models can extract meaningful correlations from enormous datasets in days or weeks, a task far beyond human capabilities <a class="yt-timestamp" data-t="17:15:00">[17:15:00]</a>.

While not sentient, GPT models demonstrate remarkable coherence in text and image generation, often passing a Turing test for human-like output <a class="yt-timestamp" data-t="17:52:00">[17:52:00]</a>. Their "self-attention" mechanism allows them to bind features across dimensions into a relational graph, enabling long-range associations within text or images <a class="yt-timestamp" data-t="35:40:00">[35:40:00]</a>. This capability suggests a door opening to embeddings across all modalities <a class="yt-timestamp" data-t="01:36:47">[01:36:47]</a>.

## The Nature of Mind and Reality
Bach delves into the concept of "matter" as a way to describe information and measurable change in a mechanical universe <a class="yt-timestamp" data-t="31:17:00">[31:17:00]</a>. Physics, in this view, describes how adjacent states of the universe are correlated, seeking a "causally closed lowest layer" <a class="yt-timestamp" data-t="32:11:00">[32:11:00]</a>.

He contrasts this with idealism, where conscious experience is primary. While conscious experience is immediately given, he argues that even if we are "dreamt by a mind on a higher plane of existence," that higher plane could still be modeled by the ideas of physics <a class="yt-timestamp" data-t="34:26:00">[34:26:00]</a>.

### Emergence and Virtual Systems
Drawing from [[Complex adaptive systems and the Cynefin framework | complexity science]], Bach explains that "reductionist science" focuses on "dancers," while the complexity perspective includes the "dance" <a class="yt-timestamp" data-t="39:32:00">[39:32:00]</a>. Concepts like a business company are virtual entities—standing waves of coordinated action on signals within boundaries—yet they are "real" because they have traction in the physical world <a class="yt-timestamp" data-t="45:00:00">[45:00:00]</a>.

[[Role of ecological practices in managing complex mental processes | Feedback loops]] are seen as critical in creating higher levels of complexity in systems <a class="yt-timestamp" data-t="40:08:00">[40:08:00]</a>. Bach notes that while dynamical systems models are useful, they are "just models" of the behavior of too many parts to count, rather than being "real" in the sense of the underlying physical layer <a class="yt-timestamp" data-t="42:22:00">[42:22:00]</a>.

He applies this to the mind-body problem: it's not about two different physical substances, but about making two disparate categories of models (body map and mental states) congruent <a class="yt-timestamp" data-t="44:17:00">[44:17:00]</a>. Higher-level emergent structural entities often build from relatively well-defined lower-level units, like neurons, which are relatively fungible units of construction for the mind <a class="yt-timestamp" data-t="47:46:00">[47:46:00]</a>.

### Memetic Viruses
Bach uses the analogy of viruses to explain how ideas operate in society <a class="yt-timestamp" data-t="51:03:00">[51:03:00]</a>. A virus, like a text a cell cannot help but read, represents a flaw exploited by "dead chemistry" <a class="yt-timestamp" data-t="49:48:00">[49:48:00]</a>. Similarly, "memetic viruses" are radical ideas that challenge the status quo, like the scientific revolution or Darwinism <a class="yt-timestamp" data-t="52:19:00">[52:19:00]</a>. While these can increase a group's fitness and competitive advantage, they don't necessarily lead to long-term improvements <a class="yt-timestamp" data-t="52:38:00">[52:38:00]</a>. Homogeneous societies, particularly those reliant on shared [[Media Influence and Cognitive Science | news sources]] or social media, can be highly susceptible to such "mind viruses" <a class="yt-timestamp" data-t="53:37:00">[53:37:00]</a>.

## The Gap Between Humans and Other Animals
Bach speculates on the factors contributing to the cognitive gap between humans and other animals <a class="yt-timestamp" data-t="01:13:22">[01:13:22]</a>. He suggests that the length of human childhood, which is a very expensive period focused on exploration rather than exploitation, allows for "more training data per day" <a class="yt-timestamp" data-t="01:17:09">[01:17:09]</a>. This extended maturation period enables the brain to build more layers and better abstractions <a class="yt-timestamp" data-t="01:17:51">[01:17:51]</a>.

Another key factor might be the ability to do grammatical decomposition, which distinguishes human language use from that of other apes <a class="yt-timestamp" data-t="01:22:46">[01:22:46]</a>. This ability, linked to the use of symbols, allows for greater compression and more effective manipulation of information, making the brain exponentially more effective <a class="yt-timestamp" data-t="01:24:20">[01:24:20]</a>.

## Cognitive Architectures
[[Scaffolding and its function within cognitive and dynamic systems | Cognitive architectures]] are a tradition originating mostly in psychology, influenced by cybernetics and AI <a class="yt-timestamp" data-t="01:29:35">[01:29:35]</a>. They aim to identify the underlying structure and principles of the human mind to replicate feats like language learning, social interaction, and symbolic reflection <a class="yt-timestamp" data-t="01:29:48">[01:29:48]</a>. Unlike current machine learning approaches that often focus on layered structures, cognitive architectures acknowledge the brain's complex, interconnected regions, more akin to a city with diverse transport networks <a class="yt-timestamp" data-t="01:31:12">[01:31:12]</a>. Examples include SOAR and ACT-R <a class="yt-timestamp" data-t="01:29:22">[01:29:22]</a>.

### The `μ` (Micro) PSI Architecture
Joshua Bach's `μ`PSI (MicroPsi) architecture is based on the ideas of German psychologist and cybernetician Dietrich Dorner <a class="yt-timestamp" data-t="01:39:00">[01:39:00]</a>. Dorner, initially optimistic about solving human psychology with computers by the late 1970s, independently developed many concepts that became central to AI, including situated and agent architectures with autonomous motivation based on [[Role of ecological practices in managing complex mental processes | feedback loops]] <a class="yt-timestamp" data-t="01:40:03">[01:40:03]</a>.

Bach systematized and translated Dorner's work into an implementable form, detailed in his book "Principles of Synthetic Intelligence." The book summarizes Dorner's ideas, contrasts them with existing fields, and outlines the implementation, before offering critiques and directions for future research <a class="yt-timestamp" data-t="01:43:00">[01:43:00]</a>.

The first MicroPsi was implemented in Java, while MicroPsi 2 was written in Python <a class="yt-timestamp" data-t="01:44:27">[01:44:27]</a>. MicroPsi 2 has been used in AI planning startups and by MicroPsi Industries for controlling industrial robots and basic research <a class="yt-timestamp" data-t="01:45:01">[01:45:01]</a>. Bach continues to use MicroPsi internally to experiment with models like spreading activation networks interacting with cellular automata representations <a class="yt-timestamp" data-t="01:45:40">[01:45:40]</a>.

Looking ahead, future cognitive architectures might leverage [[Ben Goertzels perspective on AI architectures and projects | very large-scale data processing architectures]] like Apache Ignite, Flink, and Spark, rather than being confined to single machines <a class="yt-timestamp" data-t="01:46:51">[01:46:51]</a>. The focus should shift from monolithic, homogenous representations to understanding how different parts of the architecture implement general principles that allow them to learn to interact, using existing tools like shader programs and graphics engines <a class="yt-timestamp" data-t="01:47:19">[01:47:19]</a>.