---
title: Existential risks and opportunities of AI
videoId: QsRG91HUTyE
---

From: [[jimruttshow8596]] <br/> 

The discussion surrounding the [[artificial_intelligence_risk | existential risk]] of [[artificial_intelligence_risk | AI]] is often seen as undisciplined, although significant risks are acknowledged <a class="yt-timestamp" data-t="01:17:29">[01:17:29]</a>. While outright existential threats, such as the Eliezer Yudkowsky "paperclip maximizer" scenario, are not considered imminent, the possibility of machine intelligence vastly exceeding human capabilities is acknowledged as a future likelihood unless consciously halted <a class="yt-timestamp" data-t="01:18:02">[01:18:02]</a>. The current "overheated speculations" about the state of [[artificial_intelligence_risk | AI]] are viewed by some as marketing ploys to secure more resources for addressing long-term issues <a class="yt-timestamp" data-t="01:18:46">[01:18:46]</a>.

## Significant Risks of AI

Beyond theoretical [[ai_risk_and_existential_threats_to_humanity | existential threats to humanity]], several other significant risks are identified:

*   **Misuse of Narrow AI** <a class="yt-timestamp" data-t="01:19:03">[01:19:03]</a>: This includes the development of sophisticated police states, exemplified by China's use of [[impact_of_algorithms_and_ai_on_society | AI]] for real-time tracking and facial recognition of populations <a class="yt-timestamp" data-t="01:19:05">[01:19:05]</a>. While not existential, such applications pose a risk to the world's structure <a class="yt-timestamp" data-t="01:19:28">[01:19:28]</a>.
*   **"Idiocracy" Risk** <a class="yt-timestamp" data-t="01:19:34">[01:19:34]</a>: If narrow [[impact_of_algorithms_and_ai_on_society | AI]] continues to improve at more tasks, humans may stop investing in developing intellectual skills <a class="yt-timestamp" data-t="01:19:57">[01:19:57]</a>. This could lead to a societal devolution where people forget how to perform basic functions, leaving them vulnerable if technology fails, such as during a severe solar flare event that could destroy the electrical grid for years <a class="yt-timestamp" data-t="01:20:06">[01:20:06]</a>.
*   **Acceleration of "Game A"** <a class="yt-timestamp" data-t="01:21:20">[01:21:20]</a>: The current societal status quo, referred to as "game A," is seen as accelerating towards a crisis point <a class="yt-timestamp" data-t="01:21:20">[01:21:20]</a>. Enabling [[the_development_and_influence_of_technology_and_ai_on_society | technologies]], including [[impact_of_ai_advancements_on_various_industries | AI]], can accelerate this trajectory by making manufacturing cheaper and resource extraction easier <a class="yt-timestamp" data-t="01:21:44">[01:21:44]</a>. This might reduce the time available to address major global challenges from 80 years to 40 <a class="yt-timestamp" data-t="01:21:49">[01:21:49]</a>.

### Historical Precedent for Risk Management
Historically, humanity has managed risks associated with powerful technologies:

*   **Genetic Engineering (Recombinant DNA and CRISPR)** <a class="yt-timestamp" data-t="01:22:28">[01:22:28]</a>: Despite the invention of recombinant DNA in the 1970s and CRISPR in the late 1980s, voluntary moratoriums and existing regulatory frameworks (like FDA approval for drugs) have managed risks <a class="yt-timestamp" data-t="01:22:50">[01:22:50]</a>. CRISPR, for example, is legal and accessible, but society has largely learned to self-regulate <a class="yt-timestamp" data-t="01:23:08">[01:23:08]</a>.
*   **Nuclear Weapons** <a class="yt-timestamp" data-t="01:22:39">[01:22:39]</a>: Following the first nuclear test in 1945, ideas for managing nuclear materials emerged quickly, leading to non-proliferation treaties after the Cuban Missile Crisis <a class="yt-timestamp" data-t="01:23:24">[01:23:24]</a>.
*   **Automobiles** <a class="yt-timestamp" data-t="01:23:41">[01:23:41]</a>: Over 100 years, fatalities per mile have seen a 95% reduction due to small [[regulation_and_impact_of_ai_on_society | regulatory interventions]] like traffic lights, drunk driving laws, seatbelts, airbags, and driving tests <a class="yt-timestamp" data-t="01:23:47">[01:23:47]</a>.

This historical record suggests that empirically informed discussions, rather than "science fiction prognostication," should guide the [[regulation_and_impact_of_ai_on_society | regulation and impact of AI on society]] <a class="yt-timestamp" data-t="01:24:32">[01:24:32]</a>.

## Opportunities and Positive Trajectories of AI

Despite the risks, there are significant [[economic_and_social_implications_of_ai | opportunities]] and positive trajectories for [[potential_trajectories_of_ai_advancements | AI advancements]].

### Info Agents as a Solution to Information Overload
The proliferation of low-quality information ("flood of sludge") from [[impact_of_algorithms_and_ai_on_society | AI]]-generated content on the internet, such as fake news sites and spam, is a noticeable negative <a class="yt-timestamp" data-t="01:28:11">[01:28:11]</a>. However, this phenomenon could naturally lead to the development of "info agents" <a class="yt-timestamp" data-t="01:28:50">[01:28:50]</a>.

These info agents, powered by [[the_development_and_influence_of_technology_and_ai_on_society | AI]], would act as personal filters, curating content on behalf of users and buffering them from overwhelming information <a class="yt-timestamp" data-t="01:29:03">[01:29:03]</a>. They could connect with other info agents, building networks of mutual curation <a class="yt-timestamp" data-t="01:29:07">[01:29:07]</a>. This concept is analogous to the breakthrough in spam filters that prevented email from "melting down" in the mid-1990s <a class="yt-timestamp" data-t="01:31:09">[01:31:09]</a>.

Such a system could leverage existing [[the_development_and_influence_of_technology_and_ai_on_society | technologies]] like latent semantic vector space databases and large language models for summarization and "rough and dirty curation" <a class="yt-timestamp" data-t="01:30:42">[01:30:42]</a>. This could create a "magnificent opportunity" to use [[the_development_and_influence_of_technology_and_ai_on_society | AI]] to improve our experience with digital information <a class="yt-timestamp" data-t="01:30:39">[01:30:39]</a>.

### AI as a Catalyst for New Science
The current capabilities of large language models (LLMs) can be viewed similarly to the steam engines of the 19th century <a class="yt-timestamp" data-t="01:46:16">[01:46:16]</a>. Just as heat engines led to the science of statistical mechanics and thermodynamics, LLMs and related [[the_development_and_influence_of_technology_and_ai_on_society | technologies]] could lead to entirely new scientific fields <a class="yt-timestamp" data-t="01:46:21">[01:46:21]</a>.

There is speculation that [[impact_of_ai_advancements_on_various_industries | AI]] could enable:
*   **Cognitive Phenomena Studies** <a class="yt-timestamp" data-t="01:46:48">[01:46:48]</a>: Using [[the_development_and_influence_of_technology_and_ai_on_society | AI]] to interpret brain scans and reduce complex data could lead to new principles for explaining adaptive reality <a class="yt-timestamp" data-t="01:46:50">[01:46:50]</a>.
*   **Economic Theory** <a class="yt-timestamp" data-t="01:47:19">[01:47:19]</a>: [[Impact of algorithms and AI on society | AI]] might enable the derivation of a "truly working economic theory" that provides a real understanding of how markets operate, beyond mere quantitative improvements in market prediction <a class="yt-timestamp" data-t="01:47:22">[01:47:22]</a>.

## The Nature of Current AI Models and Future Potential

Current [[impact_of_algorithms_and_ai_on_society | AI]] models, like GPT-4, are "superhuman models" with trillions of parameters, far beyond human comprehension <a class="yt-timestamp" data-t="01:13:05">[01:13:05]</a>. They excel at "prediction" and can solve problems like protein folding (AlphaFold) and language generation with incredible accuracy, but often without providing "zero theoretical insight" into *why* they work <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>. This contrasts with traditional "theory-driven science" which seeks coarse-grained understanding <a class="yt-timestamp" data-t="00:03:03">[00:03:03]</a>.

### Limitations of Current AI
Despite their power, current models have significant limitations:

*   **Arithmetic Incapacity** <a class="yt-timestamp" data-t="00:34:10">[00:34:10]</a>: Large language models like GPT-4, despite their massive size, struggle with basic arithmetic, performing worse than a 50-year-old HP-35 calculator with only 1K of memory <a class="yt-timestamp" data-t="00:35:10">[00:35:10]</a>. This suggests they are "certainly not sentient" <a class="yt-timestamp" data-t="00:35:25">[00:35:25]</a>.
*   **Data Hunger** <a class="yt-timestamp" data-t="00:23:24">[00:23:24]</a>: Current deep learning paradigms typically require five or six orders of magnitude more data to achieve results comparable to human learning <a class="yt-timestamp" data-t="00:23:31">[00:23:31]</a>. Human language acquisition, for instance, occurs with a memory footprint vastly smaller than what LLMs require <a class="yt-timestamp" data-t="00:21:40">[00:21:40]</a>.
*   **Lack of Internalized Functions** <a class="yt-timestamp" data-t="00:37:51">[00:37:51]</a>: Unlike human intelligence, which can internalize functions (like arithmetic), current [[the_development_and_influence_of_technology_and_ai_on_society | AI]] models often "outsource capabilities to tools" <a class="yt-timestamp" data-t="00:37:38">[00:37:38]</a>.
*   **Herd Mentality** <a class="yt-timestamp" data-t="00:54:47">[00:54:47]</a>: Current models are "pure herd," trained on established knowledge, making them excellent reference material but "not discovery engines" for truly novel ideas <a class="yt-timestamp" data-t="00:55:00">[00:55:00]</a>. True scientific breakthroughs often come from deviating from conventional wisdom <a class="yt-timestamp" data-t="00:54:38">[00:54:38]</a>.

### Future Directions and Integration
The future of [[future_directions_and_challenges_for_ai_and_agi | AI advancements]] likely involves "cognitive synergy," combining different [[potential_trajectories_of_ai_advancements | AI advancements]] and techniques like deep learning, genetic algorithms, and symbolic [[impact of algorithms and AI on society | AI]] <a class="yt-timestamp" data-t="00:35:36">[00:35:36]</a>. This allows for addressing problems where perceptual power (deep learning) can interact with mathematical skills and simulations <a class="yt-timestamp" data-t="00:36:21">[00:36:21]</a>.

The development of "superhuman models" suggests that high-dimensionality can aid in solving the problem of induction, as regularities exist even in complex, high-dimensional data <a class="yt-timestamp" data-t="01:15:21">[01:15:21]</a>. This indicates that [[potential_trajectories_of_ai_advancements | AI advancements]] can reveal new insights into the nature of complexity itself <a class="yt-timestamp" data-t="01:15:27">[01:15:27]</a>.

The current rate of [[the_development_and_influence_of_technology_and_ai_on_society | AI]] development is rapid, with future models like GPT-5 potentially being trained on video, which could lead to a "qualitative phase change" in their ability to "induce physics" and understand reality in new ways <a class="yt-timestamp" data-t="01:26:00">[01:26:00]</a>. This rapid pace and low cost of development mean that [[the_development_and_influence_of_technology_and_ai_on_society | AI]] could be "qualitatively different" from previous technological advancements <a class="yt-timestamp" data-t="01:27:17">[01:27:17]</a>.