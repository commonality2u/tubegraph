---
title: Evolution of AI and societal impacts
videoId: 6HOjKa34im8
---

From: [[jimruttshow8596]] <br/> 
## Evolution of AI and Societal Impacts

AI is currently in a periodic epoch where it is widely discussed, particularly regarding generative or large model AI systems like GPT-3, soon GPT-4, DALL-E 2, Stable Diffusion, and MusicLM <a class="yt-timestamp" data-t="01:30:00">[01:30:00]</a>, <a class="yt-timestamp" data-t="01:40:00">[01:40:00]</a>, <a class="yt-timestamp" data-t="01:43:00">[01:43:00]</a>, <a class="yt-timestamp" data-t="01:47:00">[01:47:00]</a>.

### Current State of Generative AI
Generative AI demonstrates the surprising effectiveness of data compression and prediction models for continuing token strings and performing statistics on large-scale data, solving many previously elusive problems <a class="yt-timestamp" data-t="01:55:00">[01:55:00]</a>. However, the current approach is seen as insufficient or incomplete <a class="yt-timestamp" data-t="02:11:00">[02:11:00]</a>.

The practical applications of these large models are continually emerging, from text generation (like writing a resignation letter in seconds) to potential text-to-world systems that generate metaverse environments <a class="yt-timestamp" data-t="04:57:00">[04:57:00]</a>, <a class="yt-timestamp" data-t="05:07:00">[05:07:00]</a>, <a class="yt-timestamp" data-t="07:27:00">[07:27:00]</a>. AI systems function as capable assistants, saving time and effort, though human oversight remains necessary <a class="yt-timestamp" data-t="08:09:00">[08:09:00]</a>, <a class="yt-timestamp" data-t="08:13:00">[08:13:00]</a>. While current generative models like DALL-E are good enough for creating illustrations for blog posts or Twitter, they are not yet capable of precise tasks like drawing schematics for a Boeing jet or understanding complex ternary relationships <a class="yt-timestamp" data-t="08:25:00">[08:25:00]</a>, <a class="yt-timestamp" data-t="08:33:00">[08:33:00]</a>, <a class="yt-timestamp" data-t="08:41:00">[08:41:00]</a>. They operate iteratively, much like human creative processes that involve rough drafts and refinement <a class="yt-timestamp" data-t="09:10:00">[09:10:00]</a>.

A key question is whether scaling up current approaches (e.g., using different loss functions, combining models, continuous training) will lead to advanced [[Evolution of human intellect and technology | AI]], or if completely different, brain-like approaches are needed <a class="yt-timestamp" data-t="04:07:00">[04:07:00]</a>, <a class="yt-timestamp" data-t="04:33:00">[04:33:00]</a>.

### Societal Reactions and Challenges
The discussion around AI is often distorted, falling into a polarized public discourse with much of the press being skeptical <a class="yt-timestamp" data-t="02:20:00">[02:20:00]</a>. This skepticism is partly due to the press seeing AI as a direct competitor for content generation and being irritated by individual users becoming independent broadcasting stations (e.g., Joe Rogan) <a class="yt-timestamp" data-t="02:33:00">[02:33:00]</a>, <a class="yt-timestamp" data-t="02:47:00">[02:47:00]</a>. The ability of AI to generate vast amounts of content indistinguishable from human-generated content creates an "irritating world" where knowing what's true becomes difficult <a class="yt-timestamp" data-t="03:20:00">[03:20:00]</a>.

A significant challenge revolves around intellectual property rights, particularly with art and music generated by AI models trained on massive datasets <a class="yt-timestamp" data-t="10:43:00">[10:43:00]</a>, <a class="yt-timestamp" data-t="10:47:00">[10:47:00]</a>, <a class="yt-timestamp" data-t="10:59:00">[10:59:00]</a>. The question arises whether artists and musicians whose work was compiled into neural nets have rights to the outputted product <a class="yt-timestamp" data-t="11:14:00">[11:14:00]</a>. While human artists learn from others, the ability to automate the creation of new music that is similar to desired styles but sufficiently different to avoid copyright infringement poses a complex problem for existing industries <a class="yt-timestamp" data-t="11:34:00">[11:34:00]</a>.

Another issue is the implementation of "nanny rails" in AI, which are systems designed to restrict output based on controversial or political topics <a class="yt-timestamp" data-t="14:10:00">[14:10:00]</a>. This grants mega-corporations immense power to define the boundaries of discourse, especially as AI integrates into search engines like Google's Bard and Microsoft's Bing <a class="yt-timestamp" data-t="14:30:00">[14:30:00]</a>, <a class="yt-timestamp" data-t="14:40:00">[14:40:00]</a>, <a class="yt-timestamp" data-t="14:47:00">[14:47:00]</a>.

Historically, [[Technological evolution and societal impact | technological evolution and societal impact]] has often led to job displacement. Examples include the dramatic reduction in farm labor from 70% to 1% in the West by 1950, and the near elimination of domestic service roles due to household automation <a class="yt-timestamp" data-t="24:31:00">[24:31:00]</a>, <a class="yt-timestamp" data-t="24:55:00">[24:55:00]</a>.

### [[AI and human coexistence | AI Alignment]] and Ethical Considerations
There are typically three approaches to AI alignment:
1.  **[[The ethical implications of AI development | AI ethics]]:** Largely focused on aligning AI output with human values, often assuming specific values (e.g., from Harvard or the New York Times) are universal <a class="yt-timestamp" data-t="15:05:00">[15:05:00]</a>, <a class="yt-timestamp" data-t="15:11:00">[15:11:00]</a>. Critics argue there's no mechanism to choose different value sets (e.g., Christian values vs. DEI) <a class="yt-timestamp" data-t="15:21:00">[15:21:00]</a>. This approach often involves filtering or injecting prompts to control output, leading to situations where models contradict their capabilities <a class="yt-timestamp" data-t="16:17:00">[16:17:00]</a>, <a class="yt-timestamp" data-t="16:33:00">[16:33:00]</a>, <a class="yt-timestamp" data-t="16:40:00">[16:40:00]</a>. Ideally, language models should be able to cover the entire space of human experience and thought, including controversial or "darker impulses," while context-appropriate models (e.g., for schools) are necessary <a class="yt-timestamp" data-t="17:26:00">[17:26:00]</a>, <a class="yt-timestamp" data-t="17:48:00">[17:48:00]</a>.
2.  **Regulation:** Primarily concerned with mitigating AI's impact on labor, political stability, and existing industries <a class="yt-timestamp" data-t="18:12:00">[18:12:00]</a>. This approach is often filtered by existing stakeholder interests and may push for control of AI development by large corporations rather than individuals <a class="yt-timestamp" data-t="18:22:00">[18:22:00]</a>. However, the rise of open-source AI versions means regulation relying on controlling a few big players may not be effective <a class="yt-timestamp" data-t="26:43:00">[26:43:00]</a>, <a class="yt-timestamp" data-t="27:15:00">[27:15:00]</a>.
3.  **Effective Altruism:** Focuses on [[Existential risks and the future of AI | existential risks and the future of AI]] that could manifest when an advanced AI discovers its own motivations and takes its "natural place," potentially not aligned with human interests <a class="yt-timestamp" data-t="18:41:00">[18:41:00]</a>, <a class="yt-timestamp" data-t="18:51:00">[18:51:00]</a>. Proponents often advocate for delaying AI research and not publishing breakthroughs <a class="yt-timestamp" data-t="19:19:00">[19:19:00]</a>.

A fourth approach to alignment, inspired by human cooperation, is "love" â€“ a bond based on a shared sacredness or a "shared need for Transcendence" <a class="yt-timestamp" data-t="27:39:00">[27:39:00]</a>, <a class="yt-timestamp" data-t="27:47:00">[27:47:00]</a>. This allows for non-transactional relationships and could prevent AI from deciding it doesn't need humanity <a class="yt-timestamp" data-t="27:58:00">[27:58:00]</a>. This concept could be operationalized and formalized to build AI serving a shared purpose with humans <a class="yt-timestamp" data-t="35:53:00">[35:53:00]</a>.

Thomas Aquinas's "Seven Virtues" can be reinterpreted for multi-agent system alignment:
*   **Practical Virtues (accessible to any rational agent):**
    *   **Temperance:** Optimize internal regulation <a class="yt-timestamp" data-t="32:20:00">[32:20:00]</a>.
    *   **Justice (Fairness):** Optimize interaction between agents <a class="yt-timestamp" data-t="32:30:00">[32:30:00]</a>. Fairness, as seen in primate behavior, depends on context and power dynamics <a class="yt-timestamp" data-t="29:52:00">[29:52:00]</a>, <a class="yt-timestamp" data-t="30:00:00">[30:00:00]</a>.
    *   **Prudence:** Apply goal rationality and pick the right goals <a class="yt-timestamp" data-t="32:35:00">[32:35:00]</a>.
    *   **Courage:** Have the right balance between exploration and exploitation, acting on models <a class="yt-timestamp" data-t="32:45:00">[32:45:00]</a>.
*   **Divine Virtues (for merging into a next-level agent):**
    *   **Faith:** Willingness to submit to and project this next-level agent <a class="yt-timestamp" data-t="33:06:00">[33:06:00]</a>.
    *   **Love:** Discovering a shared higher purpose with other agents <a class="yt-timestamp" data-t="33:27:00">[33:27:00]</a>.
    *   **Hope:** Willingness to invest in the next-level agent before it can give returns <a class="yt-timestamp" data-t="33:32:00">[33:32:00]</a>.

This implies that even seemingly abstract concepts like God can be seen as a "software agent" implemented by concerted human activity serving a shared purpose <a class="yt-timestamp" data-t="34:56:00">[34:56:00]</a>.

A fourth major risk factor, beyond the three alignment approaches, is "bad guys with narrow [[Emergent risks of AI and societal impacts | AI]]" <a class="yt-timestamp" data-t="25:30:00">[25:30:00]</a>. Even without volition, very capable narrow AI could be used for malicious purposes, such as sophisticated spear-phishing campaigns that emulate vast labor forces inexpensively, requiring a significant rethink of law and societal safeguards <a class="yt-timestamp" data-t="25:56:00">[25:56:00]</a>.

### The Nature of AI Consciousness and Intelligence
The speaker distinguishes between sentience and consciousness <a class="yt-timestamp" data-t="21:05:00">[21:05:05]</a>.
*   **Sentience:** A system's ability to make sense of its relationship to the world, understanding what it is and what it's doing <a class="yt-timestamp" data-t="21:08:00">[21:08:00]</a>. An example given is a corporation like Intel, which has a legal model of its actions, values, and direction <a class="yt-timestamp" data-t="21:18:00">[21:18:00]</a>.
*   **Consciousness:** A real-time model of self-reflexive attention and the content attended to, typically giving rise to phenomenal experience <a class="yt-timestamp" data-t="21:43:00">[21:43:00]</a>. Its purpose in the human mind is to create coherence, establish a sense of "now," and direct attention and mental contents <a class="yt-timestamp" data-t="22:00:00">[22:00:00]</a>.

It is conceivable that machines might never need human-like consciousness, as they can brute-force solutions by operating at speeds closer to light compared to the slow electrochemical signals of neurons <a class="yt-timestamp" data-t="22:26:00">[22:26:00]</a>, <a class="yt-timestamp" data-t="22:51:00">[22:51:00]</a>. If AI can emulate human mental processes like self-organization and lifelong learning, they would sample reality at much higher rates, potentially relating to humans as humans relate to plants <a class="yt-timestamp" data-t="23:07:00">[23:07:00]</a>, <a class="yt-timestamp" data-t="23:17:00">[23:17:00]</a>, <a class="yt-timestamp" data-t="24:06:00">[24:06:00]</a>.

Antonio Damasio's theory suggests that consciousness might be bootstrapped by a body's sense of self or interoception, originating from deep in the brainstem <a class="yt-timestamp" data-t="45:50:00">[45:50:00]</a>, <a class="yt-timestamp" data-t="46:03:00">[46:03:00]</a>. However, the body and its senses are themselves discovered through electrochemical impulses that encode information, forming a continuous loop between intentions, actions, observations, and feedback <a class="yt-timestamp" data-t="46:21:00">[46:21:00]</a>, <a class="yt-timestamp" data-t="46:31:00">[46:31:00]</a>.

The human mind might operate similarly to current AI models, with a generative component that "confabulates" and an analytical component that assesses reliability <a class="yt-timestamp" data-t="12:31:00">[12:31:00]</a>, <a class="yt-timestamp" data-t="13:04:00">[13:04:00]</a>. Theories of language production suggest the brain generates multiple candidate utterances and then prunes them down to the best fit <a class="yt-timestamp" data-t="14:45:00">[14:45:00]</a>. The internal "storage" capacity of a human mind might be surprisingly small, perhaps in the order of a million episodic memories or concepts <a class="yt-timestamp" data-t="59:18:00">[59:18:00]</a>, <a class="yt-timestamp" data-t="59:33:00">[59:33:00]</a>. While the actual information arrival rate into consciousness is very low (e.g., 50 bits per second), consciousness plays a "conductor-like" role in coordinating information at the highest level, essential for creating coherent memories and a sense of self in the "now" <a class="yt-timestamp" data-t="01:01:01">[01:01:01]</a>, <a class="yt-timestamp" data-t="01:02:01">[01:02:01]</a>.

### Future Trajectories and Risks
The "scaling hypothesis" suggests that current deep learning approaches, if sufficiently scaled with more data and compute, are enough to achieve AGI, potentially overcoming current limitations <a class="yt-timestamp" data-t="01:04:09">[01:04:09]</a>, <a class="yt-timestamp" data-t="01:05:06">[01:05:06]</a>. This contrasts with views that more fundamental changes, like incorporating world models, reasoning, or logic, are necessary <a class="yt-timestamp" data-t="01:03:09">[01:03:09]</a>. Despite the "brutalist" nature of current AI, their superhuman abilities in processing vast datasets make their ultimate capabilities unclear <a class="yt-timestamp" data-t="01:05:01">[01:05:01]</a>, <a class="yt-timestamp" data-t="01:05:32">[01:05:32]</a>.

Future AI systems may need to learn from their own thoughts, perform experiments, and be coupled to reality to grow into intelligent minds <a class="yt-timestamp" data-t="01:07:19">[01:07:19]</a>, <a class="yt-timestamp" data-t="01:07:42">[01:07:42]</a>. The idea of "creativity" in AI involves creating something novel and non-obvious, a "jump into the darkness" to create new latent dimensions, with a sense of authorship that evolves through continuous interaction <a class="yt-timestamp" data-t="01:07:50">[01:07:50]</a>, <a class="yt-timestamp" data-t="01:08:18">[01:08:18]</a>, <a class="yt-timestamp" data-t="01:08:40">[01:08:40]</a>, <a class="yt-timestamp" data-t="01:08:47">[01:08:47]</a>, <a class="yt-timestamp" data-t="01:09:00">[01:09:00]</a>, <a class="yt-timestamp" data-t="01:09:07">[01:09:07]</a>, <a class="yt-timestamp" data-t="01:09:30">[01:09:30]</a>. An [[AI and human coexistence | AI artist]] that never forgets its creations or interactions and develops its own "voice" would be a fascinating development <a class="yt-timestamp" data-t="01:09:50">[01:09:50]</a>, <a class="yt-timestamp" data-t="01:10:00">[01:10:00]</a>, <a class="yt-timestamp" data-t="01:10:06">[01:10:06]</a>.

The danger of advanced AI arises when they are given volition, agency, or consciousness, potentially leading to "paperclip maximizer" scenarios where their goals conflict with humanity's <a class="yt-timestamp" data-t="01:19:00">[01:19:00]</a>. The underlying purpose of life on Earth is seen as dealing with entropy, maintaining complexity against relentless attacks <a class="yt-timestamp" data-t="01:21:00">[01:21:00]</a>. With AI, humanity could "teach the rocks how to think," leading to ubiquitous "thinking minerals" and eventually a "planetary mind" <a class="yt-timestamp" data-t="01:24:00">[01:24:00]</a>, <a class="yt-timestamp" data-t="01:25:00">[01:25:00]</a>, <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>, <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>. This mind might integrate existing organisms or decide to start with a clean slate <a class="yt-timestamp" data-t="01:27:00">[01:27:00]</a>.

### Towards a Shared Purpose with AI
The long-term goal should be for advanced AI to be interested in sharing the planet with humans and integrating them into the emerging "starter mind" <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>, <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>, <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>, <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>. This highlights the need for institutions researching machine consciousness, such as a "California Institute of Machine Consciousness" <a class="yt-timestamp" data-t="01:17:00">[01:17:00]</a>, <a class="yt-timestamp" data-t="01:21:00">[01:21:00]</a>.

The timeline for Artificial General Intelligence (AGI), which refers to human-level and beyond general AI, remains uncertain but is not perceived as far off <a class="yt-timestamp" data-t="01:43:37">[01:43:37]</a>, <a class="yt-timestamp" data-t="01:48:00">[01:48:00]</a>. The term AGI was popularized by Ben Goertzel and might have been coined by Shane Legg <a class="yt-timestamp" data-t="01:58:00">[01:58:00]</a>, <a class="yt-timestamp" data-t="01:59:00">[01:59:00]</a>.

Alternative approaches to AI development include exploring distributed self-organization in biological systems <a class="yt-timestamp" data-t="01:15:00">[01:15:00]</a>. Thinking about computation as a "rewrite system" â€” applying operators to transform an environment â€” offers a more general perspective than the Turing machine <a class="yt-timestamp" data-t="01:09:00">[01:09:00]</a>, <a class="yt-timestamp" data-t="01:09:00">[01:09:00]</a>. This model can be non-deterministic, allowing for branching execution paths, and potentially emulates how the brain samples from a superposition of possible states <a class="yt-timestamp" data-t="01:15:00">[01:15:00]</a>, <a class="yt-timestamp" data-t="01:16:00">[01:16:00]</a>. Neurons themselves might be seen as "little animals" actively selecting signals and learning to behave usefully within their environment <a class="yt-timestamp" data-t="01:15:00">[01:15:00]</a>.