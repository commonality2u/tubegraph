---
title: Generative AI vs AGI
videoId: Z5dompWURVo
---

From: [[jimruttshow8596]] <br/> 

This article explores the distinction between current [[generative_artificial_intelligence | Generative Artificial Intelligence]] (AI), particularly large language models (LLMs), and [[artificial_general_intelligence_agi | Artificial General Intelligence (AGI)]], based on insights from leading [[artificial_general_intelligence_agi | AGI]] authority Ben Goertzel <a class="yt-timestamp" data-t="00:35:55">[00:35:55]</a>. The discussion highlights the rapid advancements in the AI space, which Goertzel compares to the personal computer revolution but at ten times the speed <a class="yt-timestamp" data-t="01:23:00">[01:23:00]</a>. This exponential acceleration, as projected by Ray Kurzweil, is occurring differentially across various domains <a class="yt-timestamp" data-t="01:53:00">[01:53:00]</a>.

## Ben Goertzel's Core Thesis on LLMs and [[artificial_general_intelligence_agi | AGI]]

Ben Goertzel's fundamental thesis, as outlined in his paper "[[generative_artificial_intelligence | Generative AI]] versus [[artificial_general_intelligence_agi | AGI]]: the cognitive strengths and weaknesses of modern LLMs," states that current LLMs (Transformer Nets trained to predict the next token) will likely not lead to full human-level [[artificial_general_intelligence_agi | AGI]] on their own <a class="yt-timestamp" data-t="04:34:00">[04:34:00]</a>. However, he is bullish that these systems can perform many amazing and useful functions, potentially even passing the Turing test <a class="yt-timestamp" data-t="04:58:00">[04:58:00]</a>. More importantly, LLMs can serve as valuable components within systems designed to achieve [[artificial_general_intelligence_agi | AGI]] <a class="yt-timestamp" data-t="05:08:00">[05:08:00]</a>.

A key distinction is whether LLMs serve as the "hub" or a "supporting role" in a hybrid [[artificial_general_intelligence_agi | AGI]] system <a class="yt-timestamp" data-t="05:55:00">[05:55:00]</a>. For instance, OpenAI's [[artificial_general_intelligence_agi | AGI]] architecture might use multiple LLMs as an integration hub, calling upon other non-LLM systems like DALL-E or Wolfram Alpha <a class="yt-timestamp" data-t="05:22:00">[05:22:00]</a>. In contrast, Goertzel's own approach with [[opencog_hyperon | OpenCog Hyperon]] positions a weighted labeled metagraph (AtomSpace) as the central hub, with LLMs interacting on the periphery <a class="yt-timestamp" data-t="05:57:00">[05:57:00]</a>. This highlights a finer-grained distinction often overlooked in the polarized [[artificial_general_intelligence_agi | AGI]] field <a class="yt-timestamp" data-t="06:35:00">[06:35:00]</a>.

Goertzel predicts a 60/40 chance of achieving [[artificial_general_intelligence_agi | AGI]] within five years <a class="yt-timestamp" data-t="03:19:00">[03:19:00]</a>. He emphasizes that "LLM plus plus" (LLM with external tools) will likely not lead to human-level [[artificial_general_intelligence_agi | AGI]], but "something plus LLM" might achieve [[artificial_general_intelligence_agi | AGI]] faster than ignoring LLMs entirely <a class="yt-timestamp" data-t="08:01:00">[08:01:00]</a>.

## Current Limitations of LLMs

Despite their capabilities, LLMs exhibit several fundamental limitations that differentiate them from human-level [[artificial_general_intelligence_agi | AGI]]:

### Hallucination Problem
LLMs are known to "hallucinate" or make up facts, especially for obscure queries <a class="yt-timestamp" data-t="09:39:42">[09:39:42]</a>. While improvements are being made, such as using probes to detect hallucination signatures within the network, this doesn't signify true understanding or "reality discrimination" like humans possess <a class="yt-timestamp" data-t="11:12:00">[11:12:00]</a>. Human reality discrimination involves reflective self-modeling and understanding, a capability LLMs lack <a class="yt-timestamp" data-t="12:12:00">[12:12:00]</a>. One brute-force method to reduce hallucinations is to run queries multiple times, as correct answers tend to have different entropy than incorrect ones <a class="yt-timestamp" data-t="13:52:00">[13:52:00]</a>.

### Banality and Lack of True Creativity
The natural output of LLMs often exhibits "banality" <a class="yt-timestamp" data-t="34:14:00">[34:14:00]</a>. While clever prompting can push their output beyond the average, it generally does not reach the level of great human creativity <a class="yt-timestamp" data-t="34:31:00">[34:31:00]</a>. LLMs can produce first drafts of movie scripts or decent blues guitar solos <a class="yt-timestamp" data-t="35:00:00">[35:00:00]</a>, but they are not close to generating truly original artistic works or inventing new musical styles like Thelonious Monk or Jimi Hendrix <a class="yt-timestamp" data-t="29:13:00">[29:13:00]</a>.

### Inability for Complex Multi-Step Reasoning and Original Science
LLMs struggle with complex multi-step reasoning required for writing original scientific papers or inventing new theories like quantum gravity <a class="yt-timestamp" data-t="30:04:00">[30:04:00]</a>. While they can "turn the crank" on advanced mathematical concepts if given an initial idea, they lack the deep judgment and aesthetic sense of mathematics to discern truly interesting definitions or theorems <a class="yt-timestamp" data-t="38:48:00">[38:48:00]</a>. Fundamentally, LLMs recognize primarily surface-level patterns in data and do not seem to learn abstractions in the way humans do <a class="yt-timestamp" data-t="32:33:00">[32:33:00]</a>. Their character is "fundamentally derivative and imitative," which limits their capacity for fundamental surprise or radical leaps beyond known information <a class="yt-timestamp" data-t="33:18:00">[33:18:00]</a>.

## Defining [[artificial_general_intelligence_agi | AGI]] and Its Benchmarks

There is no universally agreed-upon definition for [[artificial_general_intelligence_agi | AGI]] <a class="yt-timestamp" data-t="21:37:00">[21:37:00]</a>. One mathematical approach, formalized by Marcus Hutter and DeepMind co-founder Shane Legg, defines [[artificial_general_intelligence_agi | AGI]] as the ability to achieve a huge variety of computable goals across diverse computable environments <a class="yt-timestamp" data-t="21:49:00">[21:49:00]</a>. However, this definition suggests humans are "complete retards" at optimizing arbitrary reward functions <a class="yt-timestamp" data-t="23:22:00">[23:22:00]</a>.

Other philosophical views, like Warren Weaver's theory of open-ended intelligence, suggest intelligence is about complex self-organizing systems maintaining existence, individuating, and self-transforming <a class="yt-timestamp" data-t="24:15:00">[24:15:00]</a>.

For human-level [[artificial_general_intelligence_agi | AGI]], the focus shifts to capabilities people are good at. While IQ tests are imperfect, more multifactorial views like Gardner's theory of multiple intelligences (musical, literary, logical, etc.) offer a closer approximation <a class="yt-timestamp" data-t="25:49:00">[25:49:00]</a>.

The Turing Test, which assesses an AI's ability to imitate human conversation, was never a robust measure of general intelligence, as fooling people can be "disturbingly easy" <a class="yt-timestamp" data-t="26:31:00">[26:31:00]</a>. Ben Goertzel proposed the "MIT student test" (a robot passing MIT classes with good grades) and the "Berklee School of Music test" (becoming a jazz guitar player and getting laid at the bar) as benchmarks <a class="yt-timestamp" data-t="27:48:00">[27:48:00]</a>. However, even these have limitations, as they don't necessarily require frontier-pushing creativity or original composition <a class="yt-timestamp" data-t="29:06:00">[29:06:00]</a>.

Humans' ability to abstract is guided by their "agentic nature," which involves survival, reproduction, and self-transformation within an environment <a class="yt-timestamp" data-t="43:18:00">[43:18:00]</a>. This leads to the development of heuristics â€“ compact summaries of tactics that generate new solutions <a class="yt-timestamp" data-t="44:08:00">[44:08:00]</a>. This interplay between abstraction and heuristic development is crucial for human intelligence.

## [[Future Directions and Challenges for AI and AGI | Future Directions for AGI Development]]

To overcome the limitations of LLMs and achieve [[artificial_general_intelligence_agi | AGI]], several [[approaches_to_evolving_ai_architectures | architectural and training approaches]] are being explored:

### Neural Network Innovations
One promising path involves introducing more recurrence into Transformer networks, similar to LSTMs, which were largely stripped out for scalability <a class="yt-timestamp" data-t="46:43:00">[46:43:00]</a>. Recurrence is key for generating interesting abstractions <a class="yt-timestamp" data-t="47:04:00">[47:04:00]</a>. Alternatives to backpropagation for training, such as predictive coding-based methods, could also be explored, especially for richly recurrent networks <a class="yt-timestamp" data-t="47:36:00">[47:36:00]</a>.

### Hybrid Architectures
Integrating different deep neural network architectures is another avenue. An example is a "Gemini-type architecture" that combines something like AlphaZero (for planning and strategic thinking) with a neural knowledge graph (like in differential neural computing) and a Transformer, potentially with added recurrence <a class="yt-timestamp" data-t="48:14:00">[48:14:00]</a>. Google's DeepMind is ideally suited for this due to their expertise in DNC, AlphaZero, and evolutionary learning <a class="yt-timestamp" data-t="48:42:00">[48:42:00]</a>. Yoshua Bengio's group also explores combining Transformers with neural nets that perform minimum description length learning, explicitly seeking abstractions <a class="yt-timestamp" data-t="49:31:00">[49:31:00]</a>.

### [[Cognitive Synergy in AGI development | OpenCog Hyperon's Approach]]
Goertzel's [[opencog_hyperon | OpenCog Hyperon]] project is a framework for [[artificial_general_intelligence_agi | AGI]] that aims to achieve human-level intelligence and beyond <a class="yt-timestamp" data-t="54:11:00">[54:11:00]</a>. Its core component is a "weighted labeled metagraph" (AtomSpace) <a class="yt-timestamp" data-t="54:38:00">[54:38:00]</a>. This metagraph is:
*   **Hypergraph**: Links can span multiple nodes <a class="yt-timestamp" data-t="54:41:00">[54:41:00]</a>.
*   **Metagraph**: Links can point to other links or subgraphs <a class="yt-timestamp" data-t="54:46:00">[54:46:00]</a>.
*   **Typed and Weighted**: Each link has a type (represented as a sub-metagraph) and numerical weights <a class="yt-timestamp" data-t="54:51:00">[54:51:00]</a>.

This framework represents various types of knowledge (declarative, procedural, attentional, sensory) and cognitive operations (reinforcement learning, logical reasoning, pattern recognition) as "little learning programs" within the hypergraph itself <a class="yt-timestamp" data-t="55:02:00">[55:02:00]</a>. A new programming language called MeTTa (Meta-Type Talk) is used, where programs are sub-metagraphs that act on, transform, and rewrite chunks of the same metagraph in which they exist <a class="yt-timestamp" data-t="55:33:00">[55:33:00]</a>.

The core philosophy is that a mind is a system for recognizing patterns in the world and itself, including patterns in its own processes and execution traces <a class="yt-timestamp" data-t="56:33:00">[56:33:00]</a>. Unlike LLMs, which are not ideally suited for recognizing patterns within themselves, [[opencog_hyperon | OpenCog Hyperon]] is reflection-oriented due to its self-referential metagraph structure <a class="yt-timestamp" data-t="57:11:00">[57:11:00]</a>.

[[opencog_hyperon | Hyperon]] lends itself well to:
*   [[approaches_to_evolving_ai_architectures | Evolutionary program learning]] (e.g., genetic programming) <a class="yt-timestamp" data-t="57:36:00">[57:36:00]</a>.
*   Logical inference <a class="yt-timestamp" data-t="57:43:00">[57:43:00]</a>.
*   New [[artificial_general_intelligence_agi | AI]] paradigms like "self-organizing mutually rewriting sets of rewrite rules" <a class="yt-timestamp" data-t="58:09:00">[58:09:00]</a>.

In this architecture, LLMs can exist at the periphery, supporting the central self-rewriting metagraph <a class="yt-timestamp" data-t="58:37:00">[58:37:00]</a>. This approach is distinct from LLM-centric systems (like OpenAI's) or constellations of deep neural nets (like DeepMind's) <a class="yt-timestamp" data-t="58:44:00">[58:44:00]</a>. Goertzel believes it offers a shorter path from human-level [[artificial_general_intelligence_agi | AGI]] to superhuman [[artificial_general_intelligence_agi | ASI]] because the system is designed to rewrite its own code <a class="yt-timestamp" data-t="59:17:00">[59:17:00]</a>. It is also well-suited for science due to its capacity for logical reasoning and precise description of repeatable procedures <a class="yt-timestamp" data-t="59:48:00">[59:48:00]</a>.

The main challenge for [[opencog_hyperon | OpenCog Hyperon]] is scalability of infrastructure <a class="yt-timestamp" data-t="01:00:40">[01:00:40]</a>. The project involves building a new version from the ground up to address usability and scalability issues <a class="yt-timestamp" data-t="01:01:31">[01:01:31]</a>. This includes a compiler from MeTTa to a language called Rholang (developed by Greg Meredith) for efficient use of CPU cores, which can then translate into hypervector math for specialized hardware like associative processors <a class="yt-timestamp" data-t="01:02:05">[01:02:05]</a>. This pipeline aims to provide the scalable plumbing needed to validate if [[opencog_hyperon | OpenCog Hyperon]] can leverage logical reasoning and [[approaches_to_evolving_ai_architectures | evolutionary programming]] at scale <a class="yt-timestamp" data-t="01:02:51">[01:02:51]</a>.

The "[[artificial_general_intelligence_agi | AGI]] race" is genuinely underway, with major companies investing significant resources <a class="yt-timestamp" data-t="01:05:56">[01:05:56]</a>. However, Goertzel argues that even with substantial funding, the "weird little lore" of tuning complex [[artificial_general_intelligence_agi | AI]] systems makes it difficult to replicate specialized architectural successes quickly <a class="yt-timestamp" data-t="01:09:12">[01:09:12]</a>. The [[opencog_hyperon | Hyperon]] project is progressing well on technical milestones, benefiting from increased funding and improved tooling <a class="yt-timestamp" data-t="01:05:54">[01:05:54]</a>. The distributed AtomSpace, built by Andre Senna and based on MongoDB and Redis, is designed to scale effectively for this project <a class="yt-timestamp" data-t="01:06:03">[01:06:03]</a>.