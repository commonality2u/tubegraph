---
title: Comparison of human and AI understanding
videoId: S5npIx_yonY
---

From: [[jimruttshow8596]] <br/> 

Melanie Mitchell, a professor at the Santa Fe Institute, whose research focuses on conceptual abstraction, analogy making, and visual recognition in artificial intelligence systems, discusses the nuances of [[artificial_general_intelligence_agi_vs_narrow_ai | AI]] understanding compared to human cognition <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>. Her latest book, "Artificial Intelligence: A Guide for Thinking Humans," delves into these topics <a class="yt-timestamp" data-t="01:11:00">[01:11:00]</a>.

## Limitations of AI on Standardized Tests

Mitchell highlights the limitations of current AI models, such as GPT-3.5 and GPT-4, when assessed with standardized tests <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>. While GPT-4 has shown significantly better performance on various standardized exams than its predecessors <a class="yt-timestamp" data-t="02:24:00">[02:24:00]</a>, Melanie Mitchell's initial concerns regarding GPT-3.5's performance remain relevant <a class="yt-timestamp" data-t="02:55:00">[02:55:00]</a>.

Key issues with using these tests for AI include:
*   **Training Data Influence**: It's difficult to ascertain if the AI is genuinely understanding concepts or merely "memorizing or compressing" similar questions encountered in its vast training data <a class="yt-timestamp" data-t="04:00:00">[04:00:00]</a> <a class="yt-timestamp" data-t="04:32:00">[04:32:00]</a>. Humans are not expected to have memorized all of Wikipedia or GitHub code, unlike AI <a class="yt-timestamp" data-t="03:31:00">[03:31:00]</a> <a class="yt-timestamp" data-t="03:39:00">[03:39:00]</a>.
*   **Prompt Sensitivity**: AI models are highly sensitive to the way prompts are phrased <a class="yt-timestamp" data-t="05:32:00">[05:32:00]</a>. Mitchell conducted an experiment where a slightly reworded version of a question that GPT-3.5 initially answered with an A+ resulted in a poor response <a class="yt-timestamp" data-t="05:15:00">[05:15:00]</a>. This raises questions about the AI's "understanding of the underlying concepts" <a class="yt-timestamp" data-t="05:47:00">[05:47:00]</a>.
*   **Lack of Transparency**: OpenAI's lack of transparency regarding the exact material used for GPT-4's tests and restricted access to the model hinders independent scientific probing and verification <a class="yt-timestamp" data-t="06:21:00">[06:21:00]</a> <a class="yt-timestamp" data-t="06:30:00">[06:30:00]</a>.
*   **Extrapolation Challenges**: Assumptions about human cognition, such as the ability to extrapolate test performance to real-world understanding, may not apply to large language models <a class="yt-timestamp" data-t="03:13:00">[03:13:00]</a> <a class="yt-timestamp" data-t="03:50:00">[03:50:00]</a>.

Despite these concerns, GPT-4 demonstrated a significant improvement over GPT-3.5, with 9 out of 10 answers being correct when asked about prominent guests on the Jim Rutt Show, whereas GPT-3.5 only got 2 out of 10 correct <a class="yt-timestamp" data-t="13:17:00">[13:17:00]</a>.

### Measuring Intelligence
When given a vocabulary IQ test (VIQT), GPT-3.5 achieved an IQ of 119 <a class="yt-timestamp" data-t="02:17:00">[02:17:00]</a>. While this seems impressive, it's a task ideally suited for a language model trained on vast amounts of text <a class="yt-timestamp" data-t="02:30:00">[02:30:00]</a>. The correlation between vocabulary knowledge and general intelligence, which is assumed in human IQ tests, may not hold true for AI systems <a class="yt-timestamp" data-t="02:51:00">[02:51:00]</a>.

## The [[debate_on_ai_understanding_and_consciousness | Debate on AI Understanding and Consciousness]]

Melanie Mitchell, along with David Krakauer, co-authored a paper titled "The Debate Over Understanding and AI's Large Language Models" <a class="yt-timestamp" data-t="02:07:00">[02:07:00]</a>. This paper summarizes the two main sides of the [[mind_and_artificial_intelligence | AI]] understanding debate:
*   **AI Understands**: Proponents argue that large language models understand human language and potentially the world in a similar way to humans, with some even suggesting they may be [[consciousness_and_sentience_in_ai | conscious]] <a class="yt-timestamp" data-t="02:44:00">[02:44:00]</a> <a class="yt-timestamp" data-t="02:51:00">[02:51:00]</a>.
*   **Stochastic Parrots**: Opponents contend that these systems merely parrot language and compute the probability of the next word without true understanding <a class="yt-timestamp" data-t="03:17:00">[03:17:17]</a>.

The core issue is that the term "understanding" itself is not well-understood in the context of [[mind_and_artificial_intelligence | AI]] <a class="yt-timestamp" data-t="03:18:00">[03:18:00]</a>. This ambiguity is forcing researchers to "refine and clarify our understanding of what these mental terms mean" <a class="yt-timestamp" data-t="03:49:00">[03:49:00]</a>.

## Distinctions Between Human and AI Cognition

### Compression vs. Vast Memory
Humans possess an innate desire to "compress" information, forming "lower dimensional representations" or models of the world <a class="yt-timestamp" data-t="03:09:00">[03:09:00]</a> <a class="yt-timestamp" data-t="03:14:00">[03:14:00]</a>. This is partly due to the constraint of a small working memory <a class="yt-timestamp" data-t="03:53:00">[03:53:00]</a>. AI models, with context windows of up to 32,000 tokens (GPT-4), do not face the same evolutionary pressure to build these compressed models <a class="yt-timestamp" data-t="03:59:00">[03:59:00]</a> <a class="yt-timestamp" data-t="03:49:00">[03:49:00]</a>. This difference may lead to human understanding being "more generalizable" <a class="yt-timestamp" data-t="03:29:00">[03:29:00]</a>.

### [[role_of_emotions_and_longterm_memory_in_ai_and_human_cognition | Emotions, Long-Term Memory, and Caring]]
AI models lack a human-like "long-term memory" or episodic memory <a class="yt-timestamp" data-t="03:21:00">[03:21:00]</a>. While they store information in billions of weights, they do not possess a memory of past interactions or experiences that form a sense of self <a class="yt-timestamp" data-t="03:33:00">[03:33:00]</a>.

Humans are social species, and [[role_of_emotions_and_longterm_memory_in_ai_and_human_cognition | emotions]] play a crucial role in social interactions and decision-making <a class="yt-timestamp" data-t="04:35:00">[04:35:00]</a>. Antonio Damasio's work highlights that individuals with damaged emotional machinery struggle with even simple decisions, suggesting that emotions or intuition serve as a "hack to get around the combinatoric explosion of inference" <a class="yt-timestamp" data-t="03:57:00">[03:57:00]</a> <a class="yt-timestamp" data-t="04:00:00">[04:00:00]</a> <a class="yt-timestamp" data-t="04:22:00">[04:22:00]</a>.

Philosopher Margaret Boden suggested that "AI won't take over the world because it doesn't care" <a class="yt-timestamp" data-t="04:07:00">[04:07:00]</a>. While AlphaGo can win games of Go better than any human, it does not "care" in an emotional sense, which is a key differentiator from human motivation <a class="yt-timestamp" data-t="04:24:00">[04:24:00]</a> <a class="yt-timestamp" data-t="04:28:00">[04:28:00]</a>.

### Hallucinations and Truth
AI models, unlike humans who know when they are lying, do not have a model of what is true or untrue <a class="yt-timestamp" data-t="04:50:00">[04:50:00]</a>. Their "hallucinations" are linguistically indistinguishable from truths because they rely purely on statistics, making it difficult to detect falsehoods without external verification <a class="yt-timestamp" data-t="04:41:00">[04:41:00]</a> <a class="yt-timestamp" data-t="04:56:00">[04:56:00]</a>.

## The Future of AI and Human Understanding

The development of LLMs is forcing a re-evaluation of what intelligence, [[mind_and_artificial_intelligence | mind and artificial intelligence | cognition]], and understanding truly mean <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>. There is a need for "a new, better science of intelligence" to make sense of these systems <a class="yt-timestamp" data-t="04:49:00">[04:49:00]</a>.

Key areas for future research and development include:
*   **Improved Assessments**: Developing better assessments that can truly predict AI abilities in real-world tasks, beyond traditional standardized tests <a class="yt-timestamp" data-t="04:55:00">[04:55:00]</a>. Efforts like the Stanford "Holistic Evaluation of Language Models" (HELM) aim to address this <a class="yt-timestamp" data-t="05:08:00">[05:08:00]</a>.
*   **Open Source Models**: Projects like the joint venture between Stability AI and EleutherAI promise to provide open-source models, data sets, and software, enabling more rigorous and transparent scientific research into [[possibilities_for_achieving_humanlevel_agi | AI capabilities]] <a class="yt-timestamp" data-t="07:33:00">[07:33:00]</a> <a class="yt-timestamp" data-t="08:13:00">[08:13:00]</a>.
*   **Integrating Memory and Intentional Mechanisms**: Exploring ways to build hierarchies of memory and intentional mechanisms external to LLMs to make them act more like the unconscious processes in human language production <a class="yt-timestamp" data-t="03:52:00">[03:52:00]</a> <a class="yt-timestamp" data-t="03:57:00">[03:57:00]</a>.
*   **Multimodality**: The integration of various data types (text, images, video) in AI models could allow them to develop more intuitive physics models, similar to how humans learn from physical experience <a class="yt-timestamp" data-t="04:38:00">[04:38:00]</a> <a class="yt-timestamp" data-t="04:59:00">[04:59:00]</a>.
*   **Understanding Emergence**: Investigating "phase changes" or emergent properties that occur in LLMs at certain scales, where new capabilities appear that were not present in smaller models <a class="yt-timestamp" data-t="05:17:00">[05:17:00]</a>.

Despite the rapid advancements, there's significant disagreement among experts regarding how these systems work and their true capabilities <a class="yt-timestamp" data-t="05:35:00">[05:35:00]</a>. This highlights how little we still understand about the [[ai_and_humanitys_relationship | AI we have created]] <a class="yt-timestamp" data-t="05:48:00">[05:48:00]</a>.