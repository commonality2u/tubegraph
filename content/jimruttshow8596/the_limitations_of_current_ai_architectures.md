---
title: The limitations of current AI architectures
videoId: isIrLmYTdvU
---

From: [[jimruttshow8596]] <br/> 

Current artificial intelligence (AI) architectures, particularly deep neural networks (DNNs) and other machine learning (ML) algorithms, are considered by some leading authorities to be fundamentally unsuited for the creation of [[future_directions_and_challenges_for_ai_and_agi | human-level Artificial General Intelligence (AGI)]] <a class="yt-timestamp" data-t="01:10:07">[01:10:07]</a>. While these approaches have achieved significant practical success in narrow AI applications <a class="yt-timestamp" data-t="00:02:35">[00:02:35]</a>, they exhibit specific [[current_limitations_of_ai_in_multistep_reasoning_and_creativity | limitations]] that prevent them from achieving true generality <a class="yt-timestamp" data-t="01:16:17">[01:16:17]</a>.

## Defining AGI vs. Narrow AI

[[Future Directions and Challenges for AI and AGI | AGI]] is an imprecise and informal term referring to computer systems that can perform tasks considered intelligent when done by people, including those they weren't specifically programmed or trained for <a class="yt-timestamp" data-t="00:01:52">[00:01:52]</a>. In contrast, narrow AI excels at highly particular tasks based on programming or data-driven training <a class="yt-timestamp" data-t="00:02:40">[00:02:40]</a>. Humans, for example, can make leaps into domains only loosely connected with prior experience <a class="yt-timestamp" data-t="00:02:55">[00:02:55]</a>, a capability largely absent in current narrow AI.

### Examples of Narrow AI Limitations
*   **AlphaFold**: An impressive example of narrow AI that predicts protein folding based on training data <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>. However, it struggles with "floppy proteins" or new molecular classes from, for instance, an alien planet <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>. To deal with these, it requires manual feeding of more training data or algorithm changes; it cannot make the generalization leap on its own <a class="yt-timestamp" data-t="00:04:26">[00:04:26]</a>.
*   **Self-Driving Cars**: While perhaps not "AGI-hard," self-driving cars demonstrate the [[comparison_of_human_and_ai_understanding | generalization problem]] because of the endless variety of "weird left turn situations" or other unexpected road events <a class="yt-timestamp" data-t="00:07:38">[00:07:38]</a>. The training data sets don't allow them to leap to deal with all such scenarios <a class="yt-timestamp" data-t="00:08:00">[00:08:00]</a>.
*   **The "Coffee Test"**: A simple-minded example of AGI involves a robot placed in a random kitchen tasked with making coffee <a class="yt-timestamp" data-t="00:06:28">[00:06:28]</a>. An average human could do this, but no current robot or AI can even begin to solve it <a class="yt-timestamp" data-t="00:06:38">[00:06:38]</a>.

## The Shallow Pattern Problem of Deep Neural Networks

A core limitation of current DNNs is that they behave largely like "very clever lookup tables" <a class="yt-timestamp" data-t="01:16:53">[01:16:53]</a>. They record and store every detailed pattern they see, accounting for overlap, usefulness, and weightings in different contexts <a class="yt-timestamp" data-t="01:17:01">[01:17:01]</a>. However, despite being called "deep," these networks primarily look at "shallow patterns" in datasets <a class="yt-timestamp" data-t="01:17:47">[01:17:47]</a>.

*   **Lack of World Model**: In natural language processing, DNNs focus on sequences of words rather than trying to build a model of the conceived world underlying those words <a class="yt-timestamp" data-t="01:18:00">[01:18:00]</a>.
    *   **The Table Saw Example**: When asked how to fit a large table through a small door, a transformer neural network suggested using a "table saw" <a class="yt-timestamp" data-t="01:18:23">[01:18:23]</a>. It mistakenly assumed a "table saw" was for sawing tables in half, failing to understand its physical function despite having read manuals explaining it in its training data <a class="yt-timestamp" data-t="01:19:00">[01:19:00]</a>. This illustrates a failure to build a model of reality underlying the text <a class="yt-timestamp" data-t="01:20:00">[01:20:00]</a>.
*   **Knowledge Representation Issue**: Current systems leverage vast data and processing power to recognize highly particular patterns and extrapolate from them <a class="yt-timestamp" data-t="01:20:59">[01:20:59]</a>. This approach struggles to generalize to domains of reality that do not exhibit those specific patterns <a class="yt-timestamp" data-t="01:21:17">[01:21:17]</a>. The knowledge is represented as a large catalog of weighted particulars, with "no attempt to abstract" <a class="yt-timestamp" data-t="01:21:47">[01:21:47]</a>.

### The Crux: Lack of Abstraction and Generalization
The ability to find concise abstractions of experience is equivalent to the raw ability to generalize to different domains <a class="yt-timestamp" data-t="01:21:55">[01:21:55]</a>. This is the crucial missing element in current DNNs <a class="yt-timestamp" data-t="01:22:09">[01:22:09]</a>. Humans, even with small datasets (e.g., a few thousand war game sessions), can pull out broad generalizations and apply them to new, distinct scenarios <a class="yt-timestamp" data-t="01:23:08">[01:23:08]</a>. This capability, often referred to as "one-shot learning" or "few-shot learning," remains a challenge for current architectures <a class="yt-timestamp" data-t="01:25:55">[01:25:55]</a>.

## Limitations in Creativity and Imagination

Current AI architectures tend to bypass the aspects of human intelligence that allow for "creative imaginative leaps" <a class="yt-timestamp" data-t="01:27:12">[01:27:12]</a>. While AI can re-permute elements from existing images (like DALL-E) <a class="yt-timestamp" data-t="01:29:09">[01:29:09]</a>, they do not innovate like artists such as Matisse or Picasso, who fundamentally rethought art <a class="yt-timestamp" data-t="01:29:14">[01:29:14]</a>. This limitation stems from the economic and commercial motivations driving AI development.

### Commercial Biases
The AI industry has largely organized itself to deploy AI in ways that extremely leverage DNNs' strengths <a class="yt-timestamp" data-t="01:28:45">[01:28:45]</a>. To be a good employee of a company with a well-defined business model, an AI needs to "repeat some well understood operations in a predictable way to maximize well-defined metrics" <a class="yt-timestamp" data-t="01:27:58">[01:27:58]</a>. This includes tasks like predicting ad clicks <a class="yt-timestamp" data-t="01:28:20">[01:28:20]</a> or generating graphics that combine recognizable visual tropes with known measurable impact <a class="yt-timestamp" data-t="01:29:36">[01:29:36]</a>. In these contexts, improvising and imagining are often "beside the point" <a class="yt-timestamp" data-t="01:28:36">[01:28:36]</a>. As a result, AGI research, which seeks unpredictable and creative intelligence, often remains on the margins of the AI field <a class="yt-timestamp" data-t="01:31:20">[01:31:20]</a>.

## Historical Context and Future Integration

The term "good old-fashioned AI" (GOFAI) often refers to earlier approaches that relied on explicitly typing knowledge into systems or using crisp logic <a class="yt-timestamp" data-t="01:41:20">[01:41:20]</a>. While the idea of hand-coding all knowledge is now considered ridiculous <a class="yt-timestamp" data-t="01:43:17">[01:43:17]</a>, certain aspects of GOFAI, such as logic-based knowledge representation (with uncertainty incorporated), can be combined with learning algorithms and low-level perception <a class="yt-timestamp" data-t="01:43:55">[01:43:55]</a>.

Interestingly, neural networks themselves are "most good old-fashioned AI there is," with concepts dating back to the 1940s and 50s <a class="yt-timestamp" data-t="01:45:38">[01:45:38]</a>. Their recent success is attributed to the availability of "enough data and big enough computers" <a class="yt-timestamp" data-t="01:46:00">[01:46:00]</a>. It is hypothesized that almost every idea from the [[innovative_approaches_in_ai_research | history of AI]] could eventually contribute to AGI systems when deployed with the right hardware, data, and integration <a class="yt-timestamp" data-t="01:46:09">[01:46:09]</a>. This suggests that current DNNs may be just the first type of "good old-fashioned AI" to achieve prominence with the advent of copious processing and data <a class="yt-timestamp" data-t="01:46:36">[01:46:36]</a>. Future AGI might involve integrating various approaches, including logic, evolutionary learning, and agent-based systems <a class="yt-timestamp" data-t="01:46:43">[01:46:43]</a>.