---
title: Issues surrounding Googles machine learning fairness project
videoId: O22A1-Lb0KM
---

From: [[jimruttshow8596]] <br/> 

Zachary Vorhies, a former Google software engineer, has raised concerns about Google's "machine learning fairness" project, alleging it is part of a broader strategy to manipulate information and [[instances_of_alleged_interference_by_google_in_political_and_electoral_matters | interfere in elections]] <a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>. He describes this as a "new system" Google is building <a class="yt-timestamp" data-t="00:12:14">[00:12:14]</a>.

## Project Overview and Aims
The "machine learning fairness" project is described as revising Google's search results, biasing YouTube results, and revising news content <a class="yt-timestamp" data-t="00:12:41">[00:12:41]</a>. Its main targets are Google Search, YouTube, and News <a class="yt-timestamp" data-t="00:12:56">[00:12:56]</a>. The system takes training data as input and generates rules that are applied to comments, videos, and documents to rank content based on how "fair" it is <a class="yt-timestamp" data-t="00:13:02">[00:13:02]</a>.

## Allegations of Reality Distortion
Vorhies claims that Google is using the term "fairness" to justify distorting reality <a class="yt-timestamp" data-t="00:14:02">[00:14:02]</a>. He cites an internal document that defined "algorithmic unfairness" with an example: if a search for CEOs predominantly returned male results, even if this represented objective reality, it could still be classified as algorithmically unfair, requiring "product intervention" <a class="yt-timestamp" data-t="00:13:23">[00:13:23]</a>. This suggests Google aims to "change the nature of reality to make a better person" <a class="yt-timestamp" data-t="00:14:10">[00:14:10]</a>.

## "Programmable Units" and User Manipulation
A disturbing aspect of this project, according to Vorhies, is Google's perceived view of its users. Internal documents allegedly describe users as being "programmed" by the content they interact with <a class="yt-timestamp" data-t="00:14:27">[00:14:27]</a>. This perception leads Google to believe it has a moral or business obligation to "program" people to be "better" in ways Google deems appropriate <a class="yt-timestamp" data-t="00:16:39">[00:16:39]</a>. Vorhies states that this idea of users as "programmable units" intended to be influenced by Google's control mechanisms is "out of a sci-fi novel" <a class="yt-timestamp" data-t="00:15:13">[00:15:13]</a>.

## Context of Implementation
Vorhies observed the ramping up of this "crazy" agenda after the 2016 US Presidential election, which Google executives attributed to "fake news" and societal issues like racism <a class="yt-timestamp" data-t="00:10:09">[00:10:09]</a>, <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>. This led to the company defining "fake news" and actively censoring what they deemed to be such, even if the content related to factual events <a class="yt-timestamp" data-t="00:10:20">[00:10:20]</a>. This alleged behavior directly contradicts Google's long-held claim of being objective and unbiased in its search results <a class="yt-timestamp" data-t="00:16:51">[00:16:51]</a>.

The broader [[impact_of_algorithms_and_ai_on_society | impact of algorithms and AI on society]] is a significant concern. Vorhies highlights that Google's pervasive presence through services like Chrome, Gmail, and Android phones gives it the "scale necessary to be able to sculpt that information landscape" <a class="yt-timestamp" data-t="00:15:48">[00:15:48]</a>. The potential for Google to "turn evil" and control user information is presented as a frightening future <a class="yt-timestamp" data-t="00:15:56">[00:15:56]</a>.

## Related Topics
This topic ties into broader discussions about the [[potential_implications_of_googles_control_over_information_and_user_behavior | potential implications of Google's control over information and user behavior]] and [[claims_of_googles_search_manipulation_and_internal_blacklists | claims of Google's search manipulation and internal blacklists]]. It also touches on [[challenges_in_ai_measurement_and_transparency | challenges in AI measurement and transparency]], and the wider [[ethics_and_aesthetics_in_artificial_intelligence | ethics and aesthetics in artificial intelligence]] as well as [[regulation_and_impact_of_ai_on_society | regulation and impact of AI on society]] and [[economic_and_social_implications_of_ai | economic and social implications of AI]].

Zachary Vorhies's allegations and collected documents, available publicly <a class="yt-timestamp" data-t="00:17:26">[00:17:26]</a>, serve as a primary source for these claims, encouraging individuals to "decide for yourself" <a class="yt-timestamp" data-t="00:01:19">[00:01:19]</a>.