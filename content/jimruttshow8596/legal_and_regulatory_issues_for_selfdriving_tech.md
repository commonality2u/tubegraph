---
title: Legal and regulatory issues for selfdriving tech
videoId: 2WmczROXzco
---

From: [[jimruttshow8596]] <br/> 

The evolution of self-driving technology brings forth significant [[legal_and_ethical_challenges_with_tech_regulation | legal and ethical challenges with tech regulation]], particularly concerning liability and regulatory frameworks. The six levels of self-driving automation, from Level Zero to Level Five, are primarily defined by liability, not capability <a class="yt-timestamp" data-t="07:20:20">[07:20:20]</a>.

## Levels of Automation and Liability
*   **Level Two**: The human driver remains fully liable for the decisions the car makes <a class="yt-timestamp" data-t="07:27:28">[07:27:28]</a>. The system acts as supervision of the car <a class="yt-timestamp" data-t="07:30:32">[07:30:32]</a>.
*   **Level Three**: The human is liable in certain scenarios <a class="yt-timestamp" data-t="07:39:39">[07:39:39]</a>.
*   **Level Four**: The human is not liable in specific cities or defined areas <a class="yt-timestamp" data-t="07:43:43">[07:43:43]</a>.
*   **Level Five**: The human is never liable <a class="yt-timestamp" data-t="07:47:47">[07:47:47]</a>. Early predictions of full automation, such as Google's initial prototypes without steering wheels, envisioned this level of capability <a class="yt-timestamp" data-t="08:10:10">[08:10:10]</a>.

## Regulatory Environment
In the United States, automotive regulation operates on a self-certification model, where manufacturers certify their compliance with safety standards <a class="yt-timestamp" data-t="42:41:43">[42:41:43]</a>. Comma.ai, for example, self-certifies its compliance with standards like ISO 26262 <a class="yt-timestamp" data-t="42:50:53">[42:50:53]</a>. The European Union has taken a lead in regulating specific aspects like maximum steering wheel torque, braking force, and acceleration <a class="yt-timestamp" data-t="42:57:00">[42:57:00]</a>.

There is skepticism about the feasibility of extensive government infrastructure investment (e.g., smart telemetry in roads) for self-driving cars, given that even basic road maintenance like fixing stop signs is often neglected <a class="yt-timestamp" data-t="29:13:10">[29:13:10]</a>.

## Liability for Level 2 Systems (Comma.ai's Stance)
Comma.ai maintains that its product is a Level 2 system, meaning the human driver remains in control and is ultimately liable for any incidents <a class="yt-timestamp" data-t="43:14:00">[43:14:00]</a>. The system is designed to always allow human override:
*   The car can never become uncontrollable <a class="yt-timestamp" data-t="43:21:22">[43:21:22]</a>.
*   The brake pedal will always function <a class="yt-timestamp" data-t="43:26:28">[43:26:28]</a>.
*   The steering wheel can be overpowered with minimal effort <a class="yt-timestamp" data-t="43:30:32">[43:30:32]</a>.
*   Emergency braking is not disabled by default <a class="yt-timestamp" data-t="44:19:21">[44:19:21]</a>.

The company's philosophy is that a computer cannot be held accountable, so the human is always responsible <a class="yt-timestamp" data-t="50:16:20">[50:16:20]</a>. They view their system as an advanced form of driver assistance, akin to power steering or cruise control, where the driver still bears responsibility <a class="yt-timestamp" data-t="50:32:32">[50:32:32]</a>.

Users are explicitly required to keep their eyes on the road at all times, and a camera monitors this <a class="yt-timestamp" data-t="44:01:03">[44:01:03]</a>. The driver monitoring system is designed to provide timely alerts without inducing fatigue, helping to keep drivers attentive <a class="yt-timestamp" data-t="45:00:01">[45:00:01]</a>.

### Legal Challenges and Product Liability
Comma.ai's terms of service clearly state that users indemnify the company for liability when using the system <a class="yt-timestamp" data-t="52:31:33">[52:31:33]</a>. While the company has successfully defended against patent trolls <a class="yt-timestamp" data-t="50:57:58">[50:57:58]</a>, they anticipate future lawsuits and intend to maintain the stance that the human is always in control <a class="yt-timestamp" data-t="51:49:50">[51:49:50]</a>.

There is a distinction in product liability:
*   **Functional Safety**: If the product malfunctions and directly causes a loss of control (e.g., brakes stop working), the manufacturer could be liable <a class="yt-timestamp" data-t="53:22:24">[53:22:24]</a>.
*   **Judgment Calls**: If the human makes a decision or fails to intervene, that responsibility rests with the driver <a class="yt-timestamp" data-t="53:33:33">[53:33:33]</a>.

Comma.ai develops its system to operate within the manufacturer's intended specifications for driver assistance messages, using reverse-engineered specifications. They have even discovered bugs in manufacturer software due to their full-loop system analysis <a class="yt-timestamp" data-t="54:26:26">[54:26:26]</a>.

## Remote Operation and Fragility
Some self-driving companies, such as Cruise and Waymo, have been criticized for their reliance on remote operators and high-definition maps. These systems are described as "fancy remote control cars" <a class="yt-timestamp" data-t="06:26:29">[06:26:29]</a> or "trackless monorails" <a class="yt-timestamp" data-t="28:48:00">[28:48:00]</a>. Cruise has admitted to using multiple remote operators for each car, with decisions fundamentally still being made by a human <a class="yt-timestamp" data-t="29:36:00">[29:36:00]</a>. These systems often stop if the cell phone network goes down, highlighting their fragility and dependence on external infrastructure <a class="yt-timestamp" data-t="30:11:11">[30:11:11]</a>.

This contrasts with systems like Comma.ai's, which operate locally on the device without needing an internet connection <a class="yt-timestamp" data-t="30:27:29">[30:27:29]</a>. The reliance on expensive, meticulously mapped environments (Level 4 approaches) is viewed as an unsustainable business model, as Level 5 (full autonomy everywhere) is expected to follow too quickly to recoup the investment <a class="yt-timestamp" data-t="49:21:23">[49:21:23]</a>.