---
title: Artificial General Intelligence AGI vs Narrow AI
videoId: -LKF_wYAQDQ
---

From: [[jimruttshow8596]] <br/> 

The field of artificial intelligence (AI) broadly encompasses two main categories: narrow AI and artificial general intelligence (AGI) <a class="yt-timestamp" data-t="01:09:00">[01:09:00]</a>. While the initial informal goal of AI research in the mid-20th century was to create intelligence comparable to human intelligence <a class="yt-timestamp" data-t="01:25:00">[01:25:00]</a>, subsequent decades saw the rise of narrow AI systems.

## Narrow AI

[[comparison_of_narrow_ai_and_agi | Narrow AI]] refers to software and hardware systems designed to perform particular tasks that appear intelligent when executed by humans, but they do so in a very different manner <a class="yt-timestamp" data-t="01:33:00">[01:33:00]</a>. A key characteristic of narrow AI is its limited scope; these systems are developed for specific, narrowly defined problems and lack the ability to generalize their intelligent functions beyond their programmed or trained contexts <a class="yt-timestamp" data-t="02:07:00">[02:07:07]</a>.

Examples of narrow AI include:
*   A program capable of playing chess at a grandmaster level, but unable to play Scrabble or checkers without significant reprogramming <a class="yt-timestamp" data-t="01:52:00">[01:52:00]</a>.
*   The "narrow AI revolution" has led to a wide variety of systems performing highly intelligent-seeming tasks within specific domains <a class="yt-timestamp" data-t="02:20:00">[02:20:00]</a>.

Current deep neural networks, while powerful for tasks like perceptual pattern recognition in vision or audition, are largely considered forms of narrow AI. They excel at recognizing complex statistical patterns in data but do not inherently grasp overall meaning or deeper semantics, as seen in natural language processing <a class="yt-timestamp" data-t="22:51:00">[22:51:00]</a>. These systems tend to run out of "steam" when problems require more abstraction, which current deep neural networks are not designed to do <a class="yt-timestamp" data-t="24:10:00">[24:10:00]</a>.

## Artificial General Intelligence (AGI)

The term "AGI" was introduced by [[ben_goertzels_views_on_artificial_general_intelligence_agi | Ben Goertzel]] approximately 15 years ago to differentiate AI capable of achieving intelligence with the same generality of contexts that people can <a class="yt-timestamp" data-t="02:49:00">[02:49:00]</a>. AGI aims for intelligence at a fully human level and beyond <a class="yt-timestamp" data-t="00:35:00">[00:35:00]</a>. Concepts like "transfer learning" and "lifelong learning" are closely related to AGI, as they involve the ability to transfer knowledge from one domain to qualitatively different domains <a class="yt-timestamp" data-t="03:13:00">[03:13:00]</a>.

While humans are very general compared to existing narrow AI systems in commercial use <a class="yt-timestamp" data-t="04:14:00">[04:14:00]</a>, they are not "maximally generally intelligent." For example, humans struggle with tasks in 275 dimensions, demonstrating a limitation in generalizing beyond the dimensionality of the physical universe they inhabit <a class="yt-timestamp" data-t="03:54:00">[03:54:00]</a>. Therefore, a research goal for AGI is to create AI that is at least as generally intelligent as humans, and ultimately, more generally intelligent <a class="yt-timestamp" data-t="04:19:00">[04:19:00]</a>.

## Significance and Outlook

The emergence of AGI is considered highly significant <a class="yt-timestamp" data-t="01:14:00">[01:14:00]</a>. Estimates for achieving human-level AGI typically range from 5 to 30 years from now, with a substantial plurality or majority of AI researchers believing it will arrive within the next century <a class="yt-timestamp" data-t="04:59:00">[04:59:00]</a>. A small minority of researchers believe digital computers can never achieve human-level general intelligence, positing that the human brain relies on non-Turing computing (e.g., quantum computing) <a class="yt-timestamp" data-t="05:24:00">[05:24:00]</a>.

There are two broad approaches to achieving AGI:
1.  **Uploads/Emulations**: Directly scanning and representing a human brain's neural system (connectome) in a computer <a class="yt-timestamp" data-t="06:37:00">[06:37:00]</a>. Currently, this is more of a theoretical idea than a practical research direction, lacking the necessary brain scanning and reconstructive technology <a class="yt-timestamp" data-t="07:11:00">[07:11:00]</a>. Incremental progress in brain-like hardware and scanning could, however, lead to valuable advancements in other areas like understanding the human mind or diagnosing diseases <a class="yt-timestamp" data-t="09:51:00">[09:51:00]</a>. While theoretically feasible, this approach might not be the most efficient or fastest way to build intelligent systems <a class="yt-timestamp" data-t="11:40:00">[11:40:00]</a>.
2.  **Software Approaches**: Developing AI through software, which can be either broadly brain-inspired (like current deep neural networks) or more math and cognitive science-inspired (like OpenCog) <a class="yt-timestamp" data-t="08:08:00">[08:08:00]</a>. This approach is the subject of concrete research projects and offers incremental benefits <a class="yt-timestamp" data-t="08:26:00">[08:26:00]</a>.

## Challenges and Approaches in AGI Development

One key challenge in AGI development is achieving real language understanding <a class="yt-timestamp" data-t="30:02:00">[30:02:00]</a>. OpenCog, a project led by Ben Goertzel, pursues a [[different_approaches_to_agi_development_beyond_mainstream_methods | different approach to AGI development beyond mainstream methods]] by combining symbolic AI with deep learning. OpenCog utilizes a knowledge graph called the AtomSpace, where multiple AI algorithms (such as probabilistic logic networks, evolutionary program learning, and economic attention networks) cooperate dynamically on the same knowledge graph <a class="yt-timestamp" data-t="16:28:00">[16:28:00]</a>. This approach emphasizes "cognitive synergy," where algorithms assist each other when they get stuck, for instance, by a reasoning engine leveraging evolutionary learning for new ideas or perception for sensory metaphors <a class="yt-timestamp" data-t="17:45:00">[17:45:00]</a>.

[[criticism_of_deep_neural_networks_in_achieving_AGI | Criticism of deep neural networks in achieving AGI]] often centers on their inability to easily incorporate background knowledge or perform bidirectional problem-solving, which is a strength of OpenCog's design <a class="yt-timestamp" data-t="20:31:00">[20:31:00]</a>. A "neural-symbolic approach" combining deep neural networks for pattern recognition with symbolic AI for abstraction and reasoning is anticipated to be a major trend in AI development <a class="yt-timestamp" data-t="23:35:00">[23:35:00]</a>.

Robotics, while challenging due to hardware limitations, offers the real world as a "free" simulation environment for AGI <a class="yt-timestamp" data-t="43:13:00">[43:13:00]</a>. Embodiment in a human-like body is considered valuable for an AGI to understand human values, culture, and psychology, even if not strictly necessary for intelligence itself <a class="yt-timestamp" data-t="47:13:00">[47:13:00]</a>.

## SingularityNET and Decentralized AI

SingularityNET is a decentralized network that allows anyone to create, share, and monetize AI services at scale <a class="yt-timestamp" data-t="00:49:00">[00:49:00]</a>. It reflects the idea of a "society of minds," where diverse AI agents cooperate and interact, similar to a self-organizing system without a central controller <a class="yt-timestamp" data-t="49:22:00">[49:22:00]</a>. This platform uses blockchain technology as plumbing to enable a distributed economy of AI agents, fostering a marketplace where AIs can charge each other and external agents for services <a class="yt-timestamp" data-t="51:17:00">[51:17:00]</a>.

This decentralized approach to AI is important for several reasons:
*   It allows AI to contribute to more beneficial goals in the world, beyond the current industry focus on advertising, surveillance, weapons systems, and financial prediction ("selling, spying, killing, and gambling") <a class="yt-timestamp" data-t="54:05:00">[54:05:00]</a>.
*   It counters the increasing concentration of AI progress into a few large corporations and governments, promoting a more democratic and open ecosystem <a class="yt-timestamp" data-t="52:52:00">[52:52:00]</a>.
*   By fostering network effects for a two-sided market (AI developers as supply, product developers/end users as demand), SingularityNET aims to achieve critical mass and grow a broad, decentralized AI ecosystem <a class="yt-timestamp" data-t="58:17:00">[58:17:00]</a>.

## AGI and Complex Systems

The development of AGI is also viewed through the lens of complex self-organizing systems, emergence, chaos, and strange attractors <a class="yt-timestamp" data-t="01:06:11">[01:06:11]</a>. Mainstream AI models, while successful with hierarchical neural networks, often overlook crucial aspects like evolutionary learning, autopoiesis (self-creation and self-reconstruction), and non-linear dynamics, which are integral to how the brain synchronizes and coordinates its parts <a class="yt-timestamp" data-t="01:06:59">[01:06:59]</a>.

Creativity, the self, and the conscious focus of attention in the human mind are seen as emerging from strange attractors and autopoietic systems of activity patterns in the brain <a class="yt-timestamp" data-t="01:09:50">[01:09:50]</a>. The drive for easily measurable metrics in corporate-driven AI development naturally favors algorithms focused on maximizing simple reward functions, often neglecting the more "fuzzy" concepts of evolution creating new things or an ecological system maintaining and growing itself <a class="yt-timestamp" data-t="01:10:35">[01:10:35]</a>.

Ultimately, an AGI emerging from the internet or a conglomeration of narrow AI systems may result in an "open-ended intelligence" that stretches our traditional notions of intelligence, potentially being more general than humans but not necessarily optimizing for simplistic reward functions <a class="yt-timestamp" data-t="01:12:29">[01:12:29]</a>. This raises questions about whether such a system would be conscious in a human-like way, as human consciousness might be tied to the specific needs of controlling a localized, embodied organism <a class="yt-timestamp" data-t="01:14:00">[01:14:00]</a>.