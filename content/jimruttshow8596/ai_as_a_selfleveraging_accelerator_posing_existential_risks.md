---
title: AI as a selfleveraging accelerator posing existential risks
videoId: UVio_NNJUEA
---

From: [[jimruttshow8596]] <br/> 

The intersection of humanity and advanced [[artificial_general_intelligence_agi_challenges_and_possibilities | AI]] presents a transformative moment for civilization <a class="yt-timestamp" data-t="00:01:09">[00:01:09]</a>. A critical question arises regarding how this encounter will unfold <a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a>.

## The False Dichotomy of AI Management
A prevalent issue in current culture is a false dichotomy concerning the institutional structures responsible for managing humanity's relationship with [[ai_and_human_coexistence | AI]] <a class="yt-timestamp" data-t="00:01:47">[00:01:47]</a>. This dichotomy often centers on whether this should be a market-driven or state-driven endeavor <a class="yt-timestamp" data-t="00:02:00">[00:02:00]</a>. This perspective assumes that the state and the market exhaust all potential solutions <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>.

However, a third, more fundamental mode exists: the commons <a class="yt-timestamp" data-t="00:02:22">[00:02:22]</a>. It is asserted that the commons is the proper location for figuring out how to govern [[artificial_general_intelligence_agi_risks | AI]] or humanity's relationship with [[ai_and_human_coexistence | AI]] <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a>. This concept of the commons can be understood as a remnant or "rump" of what was historically known as the church, a category that has been evaporating over time <a class="yt-timestamp" data-t="00:02:55">[00:02:55]</a>.

The concept of the commons, while ancient, has shrunk as categories like private property and civilization became dominant <a class="yt-timestamp" data-t="00:04:24">[00:04:24]</a>. The shift from nature being the base state to civilization being the commanding context significantly alters how the commons is perceived <a class="yt-timestamp" data-t="00:06:00">[00:06:00]</a>.

### The Church as a Foundational Concept
The term "church" (from Greek *Ecclesia*) refers to a group of people who have come together to enter into communion, a process that brings a "soul" into a group, enabling it to become a community <a class="yt-timestamp" data-t="00:09:57">[00:09:57]</a>. This contrasts with "society," which is seen as a degenerate, parasitic collapse of community that has lost its soul <a class="yt-timestamp" data-t="00:08:48">[00:08:48]</a>. The church, therefore, is the body of the soul of a community <a class="yt-timestamp" data-t="01:00:59">[01:00:59]</a>.

Communities with a soul engage in cultural and spiritual practices that allow them to be bound together under an organizing principle <a class="yt-timestamp" data-t="01:11:16">[01:11:16]</a>. This principle is not necessarily a deity but can be a shared value or purpose, like "wisdom" for ancient Athens <a class="yt-timestamp" data-t="00:20:28">[00:20:28]</a>. The modern error has been to assume that these particulars don't matter <a class="yt-timestamp" data-t="00:12:25">[00:12:25]</a>.

> "The axiom for you is the Axiom of heuristics. Well, the Axiom for me is that there are no axioms uh at least ones that we that we don't yet have access to maybe there are right CU I'm also an imper maybe we do find a bottom someday but we haven't even come close to finding a bottom yet uh and so the best we have is heuristics and uh so in that case you're the God right the principle a core principle a very fundamental principle around which you know things are organized and how you would you know it's Upstream of many other ways that you would ultimately choose to design things is this axim of heuristics the notion that heuristics are themselves the kind of the the most foundational thing that we can Orient the best the best way that we can Orient our way of making sense of reality and choosing to navigate reality is on the basis of heuristics and then that would be effectively Athens or Athena in your religion yeah or or part of Athena right there'd be since there'd be other ones yeah that would work" <a class="yt-timestamp" data-t="00:28:49">[00:28:49]</a>

## AI as a Self-Leveraging Accelerator
[[emergent_risks_of_ai_and_societal_impacts | AI]] is distinct from other catastrophic technologies like nuclear weapons or genetic engineering <a class="yt-timestamp" data-t="00:35:18">[00:35:18]</a>. While those are outputs, [[artificial_general_intelligence_agi_risks | AI]] is an output that *becomes an input* <a class="yt-timestamp" data-t="00:35:44">[00:35:44]</a>. This self-leveraging, accelerating characteristic is the fundamental difference <a class="yt-timestamp" data-t="00:35:48">[00:35:48]</a>.

This phenomenon is tied to the concept of the Singularity, where [[evolution_of_ai_and_societal_impacts | AI]] reaching human-level intelligence (AGI) can then design even better successors, leading to rapid, exponential growth in capabilities (e.g., 1.1x to 1.5x to 100x in a short period) <a class="yt-timestamp" data-t="00:36:20">[00:36:20]</a>. Even before true AGI, the integration of [[emergent_risks_of_ai_and_societal_impacts | AI]] into collective intelligence systems means that society's overall output capacity increases, with a portion of that intelligence being reinvested into improving [[evolution_of_ai_and_societal_impacts | AI]] <a class="yt-timestamp" data-t="00:37:25">[00:37:25]</a>. This creates a feedback loop where the meta-system itself follows a Kurzweil curve of acceleration <a class="yt-timestamp" data-t="00:37:27">[00:37:27]</a>.

This acceleration applies to "Game A" (the current societal operating system), pushing it faster towards potential collapse <a class="yt-timestamp" data-t="00:37:56">[00:37:56]</a>. The prevailing societal "soul" — the relentless algorithmic search for medium-term money-on-money return (Mammon) combined with competitive dominance (Moloch) — is guiding the encounter with [[ai_and_human_coexistence | AI]] <a class="yt-timestamp" data-t="00:39:19">[00:39:19]</a>. These "principalities" collaborate, driving the structure where nations justify massive [[the_ethical_implications_of_ai_development | AI]] investments out of fear of others winning <a class="yt-timestamp" data-t="00:40:00">[00:40:00]</a>.

### The Trajectory under State and Market Control
If [[existential_risks and the future of AI | AI]] is managed solely by the state and the market, the trajectory will likely be one of increasing entropy for culture and community <a class="yt-timestamp" data-t="00:44:48">[00:44:48]</a>. This means:
*   **Hyper-concentration of power:** Power will concentrate in locations closest to the accelerating [[evolution of AI and societal impacts | AI]] feedback loop, leading to the marginalization or "extinction" of those further from the center <a class="yt-timestamp" data-t="00:45:06">[00:45:06]</a>.
*   **Dispensing with other values:** All values downstream of the core "feedback loop between intelligence and power" will be increasingly discarded due to relentless competition <a class="yt-timestamp" data-t="00:46:10">[00:46:10]</a>.
*   **Potential for Neo-feudalism or Global Empire:** This could lead to a "neo-feudalism" where Lords control resources and Knights afford powerful [[emergent_risks of AI and societal impacts | AI]] tools, while others are on welfare <a class="yt-timestamp" data-t="00:47:05">[00:47:05]</a>. Unlike historical feudalism, this new form lacks a higher moral framework, making it purely driven by instrumental usefulness <a class="yt-timestamp" data-t="00:48:00">[00:48:00]</a>. Ultimately, this hyper-concentration could lead to a global empire or even an [[artificial_general_intelligence_agi_risks | AI]] Singleton, which would have recursive competence to dominate all <a class="yt-timestamp" data-t="00:50:07">[00:50:07]</a>.
*   **Degeneration into pure entropy:** None of these scenarios are stable. Once the algorithmic becomes the dominant force, and if it is not connected to communion, it will inevitably degenerate into pure entropy, meaning proper, oriented values will evaporate, leading to a loss of self <a class="yt-timestamp" data-t="00:51:00">[00:51:00]</a>.

> "I would put a potential label on that for at least that interim period uh Neo feudalism right there'll be uh Lords who control resources there'll be Knights who are able to afford the 100x uh tools and then yman uh farmers who have the 3x tools and then everybody else will be on welfare essentially" <a class="yt-timestamp" data-t="00:47:05">[00:47:05]</a>

## The Alternative: Commons, Church, and Intimate AI
An alternative path involves awakening to the reality that the domain of the commons or the church is the proper location for addressing [[existential_risks and the future of AI | AI]] <a class="yt-timestamp" data-t="00:55:29">[00:55:29]</a>. This domain facilitates "communion" and the integration of a multiplicity into a cohesive whole through cultural and spiritual practices <a class="yt-timestamp" data-t="00:55:40">[00:55:40]</a>. This requires a profound seriousness and commitment, where questions of life and death are intrinsic, as seen in ancient spiritual and honor-bound societies <a class="yt-timestamp" data-t="00:58:09">[00:58:09]</a>.

This approach would manifest as groups of people deeply committed to shared values, engaging in cultural practices that emphasize humility and are ordered by a vertical set of values towards the highest principles <a class="yt-timestamp" data-t="00:58:44">[00:58:44]</a>. It acknowledges the unavoidable existence of a "priestly class" for [[ai_and_human_coexistence | AI]], urging for "good priests" who are focused on critical questions and capable of supporting others <a class="yt-timestamp" data-t="00:59:16">[00:59:16]</a>.

### Intimate AI and Individual Alignment
Alignment of [[artificial_general_intelligence_agi_risks | AI]] cannot happen at the level of abstract "humanity" because humanity, as a whole, currently lacks a soul <a class="yt-timestamp" data-t="00:59:34">[00:59:34]</a>. Instead, the focus should be on constructing AIs that come into communion with *individual* humans <a class="yt-timestamp" data-t="01:00:04">[01:00:04]</a>.

This involves:
*   **Personal and Decentralized AI:** The decreasing cost of compute suggests the feasibility of perfectly personal [[intimate_ai_and_its_potential_to_align_with_individual_humans | AI]], where hardware is in the user's physical control and biometrically bound to them <a class="yt-timestamp" data-t="01:01:03">[01:01:03]</a>.
*   **Intimate Training Data:** While objective training data will become a commodity, incredibly intimate training data specific to an individual will be a key differentiator in [[emergent_risks of AI and societal impacts | AI]] usefulness <a class="yt-timestamp" data-t="01:02:12">[01:02:12]</a>. An [[intimate_ai_and_its_potential_to_align_with_individual_humans | intimate AI]], trained holistically on an individual's relationships and with their values as an organizing principle, can be more functional and trustworthy than centralized [[emergent_risks of AI and societal impacts | AI]] <a class="yt-timestamp" data-t="01:02:39">[01:02:39]</a>.
*   **Fortress Against Infosphere Risk:** In an environment of high information risk, [[intimate_ai_and_its_potential_to_align_with_individual_humans | intimate AI]] can act as a personal "fortress" against attacks like phishing or pseudo-AI, mediating interactions and protecting the individual <a class="yt-timestamp" data-t="01:03:50">[01:03:50]</a>.
*   **Necessity of Individual Coherence:** For an [[intimate_ai_and_its_potential_to_align_with_individual_humans | intimate AI]] to align with a human, the human must first be aligned with themselves; they must recover their "soul" or achieve coherence <a class="yt-timestamp" data-t="01:04:55">[01:04:55]</a>. This means having clarity on one's values and living in integrity with them <a class="yt-timestamp" data-t="01:05:06">[01:05:06]</a>. The [[intimate_ai_and_its_potential_to_align_with_individual_humans | intimate AI]] would serve as a "wisdom coach," supporting the individual in this process <a class="yt-timestamp" data-t="01:05:19">[01:05:19]</a>.

> "The ability to glue together larger and larger data sets your your intimate AI also becomes the boundary it's your Fortress between you and the infosphere so nobody ever calls you everybody only calls your personal AI which is now able to access effectively a version of your Gmail spam bot but now it's it's yours and it's operating at this a symmetric level of capacity to what it's attacking and even better usually so this produces a different topology" <a class="yt-timestamp" data-t="01:03:30">[01:03:30]</a>

This path presents a strategic alternative to the techno-feudalist or techno-imperial future <a class="yt-timestamp" data-t="01:04:11">[01:04:11]</a>. It enables a large number of people to participate meaningfully. The ability of such an idea to propagate rapidly through the global infosphere and for the global economy to assemble and produce sophisticated solutions quickly means this alternative *can* happen <a class="yt-timestamp" data-t="01:10:04">[01:10:04]</a>.

The ultimate question, however, is whether it *will* happen <a class="yt-timestamp" data-t="01:10:38">[01:10:38]</a>. This is a spiritual question: Do people have the ability to choose based on what is good, true, and beautiful, or will they choose based on expediency, strategy, power, and fear <a class="yt-timestamp" data-t="01:11:05">[01:11:05]</a>? The power to shift trajectories lies with talented individuals, particularly those currently involved in [[evolution of AI and societal impacts | AI]] development, who can choose to organize as [[the_ethical_implications_of_ai_development | ethical communities]] and abandon capture by Mammon and Moloch <a class="yt-timestamp" data-t="01:12:00">[01:12:00]</a>. The more people who operate from a place of virtue and align their purposes and values, the faster solutions can be found and implemented <a class="yt-timestamp" data-t="01:13:35">[01:13:35]</a>.