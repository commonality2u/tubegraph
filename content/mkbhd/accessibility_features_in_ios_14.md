---
title: Accessibility Features in iOS 14
videoId: ZLyDvABxGF0
---

From: [[mkbhd]] <br/> 

iOS 14 introduces several new accessibility features, alongside other general improvements to the operating system. These features aim to enhance usability for a wider range of users.

## Back Tap
One of the unique accessibility settings in iOS 14 is "Back Tap" <a class="yt-timestamp" data-t="00:08:24">[00:08:24]</a>.
Found under Settings > Accessibility > Touch > Back Tap <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>, this feature allows users to map a double-tap or triple-tap on the back of the iPhone to a specific shortcut <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>.

Examples of mapped actions include:
*   Double-tapping to open Siri <a class="yt-timestamp" data-t="00:08:38">[00:08:38]</a>.
*   Triple-tapping to take a screenshot <a class="yt-timestamp" data-t="00:08:49">[00:08:49]</a>.

While there is a slight delay, the feature functions effectively, providing an additional way to interact with the device <a class="yt-timestamp" data-t="00:08:52">[00:08:52]</a>.

> [!TIP] Siri Shortcut Integration
> An update note from the editor highlights that a Siri shortcut can be set to run on a double-tap of the phone's back <a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a>. This allows the shortcut to trigger various actions, such as opening Google Assistant or the camera <a class="yt-timestamp" data-t="00:09:14">[00:09:14]</a>.

## Sound Recognition
Another notable accessibility feature is Sound Recognition, located in Settings > Accessibility > Sound Recognition <a class="yt-timestamp" data-t="00:09:31">[00:09:31]</a>. This feature allows users to enable notifications when the iPhone's microphones recognize important sounds <a class="yt-timestamp" data-t="00:09:36">[00:09:36]</a>. Primarily designed for individuals who are hard of hearing <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>, it can also be useful for anyone, alerting them to sounds like a doorbell, a fire alarm, or a running faucet <a class="yt-timestamp" data-t="00:09:46">[00:09:46]</a>.

## Sign Language Detection in FaceTime
In group FaceTime calls, iOS 14's AI can detect if someone is using sign language <a class="yt-timestamp" data-t="00:10:26">[00:10:26]</a>. When detected, the system will automatically move that person to the most prominent, biggest spot in the call view, ensuring everyone can clearly see the sign language <a class="yt-timestamp" data-t="00:10:30">[00:10:30]</a>.

For more details on other enhancements in iOS 14, refer to [[Privacy Features in iOS 14 | Privacy Features in iOS 14]] and [[New Home Screen Features in iOS 14 | New Home Screen Features in iOS 14]].