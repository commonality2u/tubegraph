---
title: Advancements in AI generated videos
videoId: NXpdyAWLDas
---

From: [[mkbhd]] <br/> 

The field of AI-generated video has seen rapid and "insanely fast" advancements, moving from rudimentary outputs to highly realistic and complex scenes in a remarkably short period, particularly within a single year <a class="yt-timestamp" data-t="00:00:40">[00:00:40]</a>, <a class="yt-timestamp" data-t="00:04:03">[00:04:03]</a>. This progression is compared to the significant leaps seen with ChatGPT and DALL.E <a class="yt-timestamp" data-t="00:00:43">[00:00:43]</a>.

## OpenAI's Sora Model

OpenAI, led by Sam Altman, announced a new model called Sora, which can generate full video clips up to one minute in length from simple text input <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>, <a class="yt-timestamp" data-t="00:01:06">[00:01:06]</a>, <a class="yt-timestamp" data-t="00:01:08">[00:01:08]</a>. Similar to how DALL.E translates text into photorealistic or stylized images, Sora extends this capability to video <a class="yt-timestamp" data-t="00:01:13">[00:01:13]</a>, <a class="yt-timestamp" data-t="00:01:22">[00:01:22]</a>. A key aspect of Sora's [[software_and_ai_capabilities | capabilities and limitations of Sora AI model]] is its ability to understand how elements like reflections, textures, materials, and physics interact over time to create a "reasonable looking video" <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>.

### Examples of Sora's Output

Initial examples showcased on OpenAI's website demonstrate the model's impressive range <a class="yt-timestamp" data-t="00:01:37">[00:01:37]</a>. These videos feature:
*   A stylish woman walking a Tokyo street with neon lights, accurate lighting, materials, skin tones, movement, and reflections <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>, <a class="yt-timestamp" data-t="00:02:30">[00:02:30]</a>.
*   A vintage SUV speeding up a dirt road, resembling "rock solid drone footage" <a class="yt-timestamp" data-t="00:03:08">[00:03:08]</a>, <a class="yt-timestamp" data-t="00:03:20">[00:03:20]</a>.
*   Golden retriever puppies playing in the snow, exhibiting realistic physics for fur, ears, and snow movement <a class="yt-timestamp" data-t="00:03:28">[00:03:28]</a>, <a class="yt-timestamp" data-t="00:03:35">[00:03:35]</a>.
*   A young man sitting on a cloud reading a book, showcasing impressive lighting, shadows, skin tones, and realistic textures on clothing and hair <a class="yt-timestamp" data-t="00:04:31">[00:04:31]</a>, <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a>.
*   A movie trailer featuring a spaceman, notable for close-ups of the face, fabric textures, film grain, and cinematic style <a class="yt-timestamp" data-t="00:05:12">[00:05:12]</a>, <a class="yt-timestamp" data-t="00:05:28">[00:05:28]</a>.
*   A drone shot of waves at Big Sur, which could easily be mistaken for real footage <a class="yt-timestamp" data-t="00:06:40">[00:06:40]</a>.
*   A wall of old TVs, an expensive and difficult shot to capture traditionally, generated with convincing reflections and environment <a class="yt-timestamp" data-t="00:07:16">[00:07:16]</a>.
*   Historical footage, such as California during the Gold Rush, capable of passing as an opening scene in a Western film <a class="yt-timestamp" data-t="00:07:33">[00:07:33]</a>.

### Identified Imperfections and Limitations

Despite their quality, Sora's outputs still contain imperfections, especially upon close inspection <a class="yt-timestamp" data-t="00:01:53">[00:01:53]</a>, <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>:
*   Figures in the background might appear to glide unnaturally <a class="yt-timestamp" data-t="00:02:43">[00:02:43]</a>.
*   Inconsistent camera movement <a class="yt-timestamp" data-t="00:02:52">[00:02:52]</a>.
*   Lower frame rates in reflections compared to the main video <a class="yt-timestamp" data-t="00:02:48">[00:02:48]</a>.
*   Subtle "off" feelings in overall motion <a class="yt-timestamp" data-t="00:02:54">[00:02:54]</a>.
*   Difficulties with human features like eyes and the motion of book pages <a class="yt-timestamp" data-t="00:04:54">[00:04:54]</a>.
*   Physics inconsistencies, such as wolf pups appearing out of nowhere and walking through each other <a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a>.
*   Challenges with rendering human hands accurately, as seen in a birthday celebration clip <a class="yt-timestamp" data-t="00:09:27">[00:09:27]</a>.
*   Inconsistencies with elements like wind direction on candles <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>.

These [[capabilities_and_limitations_of_sora_ai_model | capabilities and limitations of Sora AI model]] are openly acknowledged by OpenAI, which displays some of the model's "downfalls" <a class="yt-timestamp" data-t="00:10:11">[00:10:11]</a>.

## [[implications_of_ai_technology_on_video_creation | Implications of AI Technology on Video Creation]]

The current state of AI-generated videos means they "can and will pass as real videos to people who are not looking for AI generated videos" <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a>.

### [[impact_of_ai_on_video_licensing_and_stock_footage | Impact of AI on Video Licensing and Stock Footage]]

A significant [[implications_of_ai_technology_on_video_creation | implication of AI technology on video creation]] is its potential to disrupt the stock video market. AI-generated videos are already sufficient for advertisements, presentations, and PowerPoints that require "oddly specific stock videos" <a class="yt-timestamp" data-t="00:06:22">[00:06:22]</a>, <a class="yt-timestamp" data-t="00:06:33">[00:06:33]</a>. This advancement is expected to significantly reduce demand for licensed footage from drone pilots, photographers, and videographers, as businesses can generate custom content for free or a small subscription <a class="yt-timestamp" data-t="00:07:01">[00:07:01]</a>, <a class="yt-timestamp" data-t="00:10:56">[00:10:56]</a>.

### [[ethical_and_societal_concerns_of_ai_generated_content | Ethical and Societal Concerns of AI Generated Content]]

The realism of these videos raises "insanely sketchy" [[ethical_and_societal_concerns_of_ai_generated_content | ethical and societal concerns of AI generated content]], especially during an election year <a class="yt-timestamp" data-t="00:06:09">[00:06:09]</a>. OpenAI recognizes the need for caution, implementing measures like a watermark in the bottom corner of every generated video to indicate its AI origin <a class="yt-timestamp" data-t="00:10:18">[00:10:18]</a>. Furthermore, there will likely be strict safety protocols, even more stringent than DALL.E's, to prevent the generation of people's likenesses or depicting politicians in compromising situations <a class="yt-timestamp" data-t="00:10:29">[00:10:29]</a>.

### Future Outlook

The rapid improvement of AI models suggests that current "flaws clearly" and the lack of sound in videos will be addressed <a class="yt-timestamp" data-t="00:07:56">[00:07:56]</a>. The progression from basic AI-generated images (like "Will Smith eating spaghetti" <a class="yt-timestamp" data-t="00:00:12">[00:00:12]</a>) to complex video scenes in just a year highlights the exponential growth of this technology <a class="yt-timestamp" data-t="00:08:04">[00:08:04]</a>. The future raises "pretty existential" questions, particularly whether AI, trained on human-made videos, can achieve true innovation or creativity beyond existing human endeavors <a class="yt-timestamp" data-t="00:11:15">[00:11:15]</a>. It is expected that the current state of this technology is the "worst that this technology is going to be from here on out" <a class="yt-timestamp" data-t="00:02:06">[00:02:06]</a>, <a class="yt-timestamp" data-t="00:11:48">[00:11:48]</a>.