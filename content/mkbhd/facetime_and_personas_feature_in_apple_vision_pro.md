---
title: FaceTime and Personas feature in Apple Vision Pro
videoId: dtp6b76pMak
---

From: [[mkbhd]] <br/> 

The Apple Vision Pro introduces "Personas" as a beta feature, enabling unique communication experiences, particularly with FaceTime <a class="yt-timestamp" data-t="02:11:00">[02:11:00]</a>. This feature is both impressive and "slightly unsettling" due to its human-like but not quite perfect representation <a class="yt-timestamp" data-t="02:31:23">[02:31:23]</a>.

## Personas: Digital Representation

Personas are digital representations of a user's face, created by scanning the user's facial features <a class="yt-timestamp" data-t="02:16:50">[02:16:50]</a>. These are displayed on the headset's outward-facing OLED screen, which sits behind a lenticular film to give the appearance of depth <a class="yt-timestamp" data-t="02:47:00">[02:47:00]</a>. This design aims to make the eyes appear sunken into the display, rather than simply glued to the front <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>.

The purpose of the eyes on the outside of the headset is to indicate to others whether the wearer can see them <a class="yt-timestamp" data-t="02:25:24">[02:25:24]</a>.
*   When the user is in passthrough mode, their eyes "shine through" <a class="yt-timestamp" data-t="02:34:00">[02:34:00]</a>.
*   When the user is in an immersive environment, their eyes are covered by a blue/purple glow <a class="yt-timestamp" data-t="02:45:00">[02:45:00]</a>.
*   If someone outside the headset looks at the wearer and begins speaking while the wearer is immersed, the person's image can appear through the "fog" of the environment, and the wearer's eyes will "show through" the glow on the outside <a class="yt-timestamp" data-t="02:04:00">[02:04:00]</a>. This feature generally only shows one person at a time <a class="yt-timestamp" data-t="02:26:24">[02:26:24]</a>.

Despite advertising, the external eye display is often subtle and can appear dim, especially for users with darker skin tones <a class="yt-timestamp" data-t="02:42:00">[02:42:00]</a>. The eyes can also appear "a little too far apart sometimes" <a class="yt-timestamp" data-t="02:55:00">[02:55:00]</a>.

### Creating a Persona

The process of registering a Persona involves:
1.  **Hand Scan**: The headset captures details from the front of the device of the user's hands <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>.
2.  **Head Movements**: The user removes the headset and holds it at eye level, slowly turning their head right and left, and tilting it up and down <a class="yt-timestamp" data-t="02:28:10">[02:28:10]</a>.
3.  **Facial Expressions**: The user performs specific expressions, including smiling with a closed mouth, a big smile with teeth showing, raising eyebrows, and closing eyes for a moment <a class="yt-timestamp" data-t="02:46:00">[02:46:00]</a>.
4.  **Adjustments**: Users can refine their Persona by adjusting lighting, skin tone color temperature, and brightness <a class="yt-timestamp" data-t="02:35:00">[02:35:00]</a>. There's also an option to add virtual glasses for a consistent appearance in video calls <a class="yt-timestamp" data-t="02:02:00">[02:02:00]</a>.

Once created, the Persona can track micro-expressions and movements of the eyes, cheeks, and mouth <a class="yt-timestamp" data-t="02:33:00">[02:33:00]</a>. However, a "number one weakness" for Personas is the hair, which often appears as a "frozen lump" instead of flowing realistically <a class="yt-timestamp" data-t="02:54:00">[02:54:00]</a>. Similarly, any accessories like necklaces are also frozen in their scanned position <a class="yt-timestamp" data-t="02:06:00">[02:06:00]</a>.

## FaceTime Experience

FaceTime is described as the "most well thought out" and "most futuristic" [[apple_vision_pro_features_and_design | Vision Pro experience]] <a class="yt-timestamp" data-t="02:28:00">[02:28:00]</a>. When making a FaceTime call, the Persona is used as the camera feed <a class="yt-timestamp" data-t="02:58:00">[02:58:00]</a>.

Key aspects of the FaceTime experience:
*   **Window Placement**: FaceTime windows appear as glassy panels floating in 3D space <a class="yt-timestamp" data-t="02:36:00">[02:36:00]</a>. Users can pick up and move these windows around the virtual room <a class="yt-timestamp" data-t="02:54:00">[02:54:00]</a>.
*   **Gaze Matching**: The angle at which a user looks into a window will match the angle that other callers see them looking <a class="yt-timestamp" data-t="02:46:00">[02:46:00]</a>. For example, if a user looks at a person on the right, a person on the left will see the side of their head <a class="yt-timestamp" data-t="02:09:00">[02:09:00]</a>. This leverages the [[user_experience_and_eye_tracking_with_apple_vision_pro | eye tracking]] capabilities.
*   **Hand Gestures**: Hand gestures made within the headset's tracking bubble appear at the correct angle towards the specific person being gestured at, not to everyone else on the call <a class="yt-timestamp" data-t="02:19:00">[02:19:00]</a>. This is enabled by the sophisticated [[control_methods_and_sensors_in_apple_vision_pro | sensors]] of the Vision Pro.
*   **Spatial Audio**: The [[apple_vision_pro_features_and_design | spatial audio]] is "incredibly well developed" <a class="yt-timestamp" data-t="02:45:00">[02:45:00]</a>. Voices of participants come from their respective virtual positions in the room <a class="yt-timestamp" data-t="02:50:00">[02:50:00]</a>. Moving a window around will also shift the sound's perceived origin <a class="yt-timestamp" data-t="02:54:00">[02:54:00]</a>. If an immersive environment is engaged, the audio adjusts to sound as if in a larger space with less echo <a class="yt-timestamp" data-t="02:16:00">[02:16:00]</a>.

Overall, the FaceTime experience with Personas is described as "technically incredible" <a class="yt-timestamp" data-t="02:15:00">[02:15:00]</a>, providing a highly immersive and well-considered interaction, despite the uncanny valley effect of the digital avatars <a class="yt-timestamp" data-t="02:22:00">[02:22:00]</a>.