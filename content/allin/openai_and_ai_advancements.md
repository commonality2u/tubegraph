---
title: OpenAI and AI advancements
videoId: nSM0xd8xHUM
---

From: [[allin]] <br/> 

[[OpenAI and AI advancements | OpenAI]], co-founded by Sam Altman in 2016, set out with the goal of ensuring that artificial general intelligence (AGI) benefits all of humanity <a class="yt-timestamp" data-t="00:01:03">[00:01:03]</a>. Sam Altman, who previously served as president of Y Combinator from 2014 to 2019, joined [[OpenAI and AI advancements | OpenAI]] full-time as CEO in 2019 <a class="yt-timestamp" data-t="00:01:09">[00:01:09]</a>.

## Key Milestones and Products

A significant turning point for [[OpenAI and AI advancements | OpenAI]] occurred on November 30, 2022, with the launch of Chat [[OpenAI and GPT4o Innovations | GPT]] <a class="yt-timestamp" data-t="00:01:14">[00:01:14]</a>. This product became reportedly the fastest to reach 100 million users in history, achieving this milestone in just two months <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>. In January 2023, [[Microsofts investment in OpenAI and generative AI technologies | Microsoft]] invested $10 billion in [[OpenAI and AI advancements | OpenAI]] <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. [[OpenAI and AI advancements | OpenAI]] also reportedly hit $2 billion in annual recurring revenue (ARR) last year <a class="yt-timestamp" data-t="00:02:18">[00:02:18]</a>.

Other notable [[developments_in_technology_and_ai_for_2024 | developments]] from [[OpenAI and AI advancements | OpenAI]] include:
*   **GPT-4**: This model has seen significant improvements, particularly in recent months <a class="yt-timestamp" data-t="00:03:06">[00:03:06]</a>. [[OpenAI and AI advancements | OpenAI]] is working to make GPT-4 level technology available to free users, though it remains very expensive <a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a>.
*   **Sora**: This video model generates "amazing moving images" <a class="yt-timestamp" data-t="00:31:15">[00:31:15]</a>. Sora does not start with a language model, but is customized for video <a class="yt-timestamp" data-t="00:32:11">[00:32:11]</a>.

## Sam Altman's Brief Departure and Return

In November 2023, Sam Altman was briefly fired from [[OpenAI and AI advancements | OpenAI]] over a "crazy 5-day span" <a class="yt-timestamp" data-t="00:01:25">[00:01:25]</a>. This event led to widespread speculation, including theories that the team had reached AGI and that "the world was going to end" <a class="yt-timestamp" data-t="00:01:36">[00:01:36]</a>. Within a few days, he was reinstated as CEO <a class="yt-timestamp" data-t="00:01:42">[00:01:42]</a>. Altman confirmed he was fired and considered his options, but ultimately returned due to his love for [[OpenAI and AI advancements | OpenAI]] and its people <a class="yt-timestamp" data-t="00:53:02">[00:53:02]</a>. He respects the former board's commitment to [[OpenAI and AI advancements | AI]] safety, despite disagreeing with their decision-making <a class="yt-timestamp" data-t="00:56:43">[00:56:43]</a>.

The board's composition, with a majority of disinterested directors, played a role in the structure that led to Altman not having equity in [[OpenAI and AI advancements | OpenAI]] <a class="yt-timestamp" data-t="00:59:45">[00:59:45]</a>. This lack of equity sometimes leads to "weird questions" about his motivations <a class="yt-timestamp" data-t="00:59:59">[00:59:59]</a>. He also clarified that projects like device companies or chip fabrication companies, which he is reportedly involved in, would be under [[OpenAI and AI advancements | OpenAI]]'s equity, not his personal ventures <a class="yt-timestamp" data-t="01:01:27">[01:01:27]</a>.

## Future of [[OpenAI and AI advancements | AI]] Development

### GPT-5 and Model Evolution
[[OpenAI and AI advancements | OpenAI]] takes its time with major model releases <a class="yt-timestamp" data-t="00:02:44">[00:02:44]</a>. While there are reports of GPT-5 launching in the summer, Sam Altman notes that it might not even be called GPT-5 <a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a>. He suggests a future where [[OpenAI and AI advancements | AI]] systems continuously improve rather than through discrete version numbers (1, 2, 3, 4, 5) <a class="yt-timestamp" data-t="00:03:17">[00:03:17]</a>. This continuous improvement is seen as technologically better and easier for society to adapt to <a class="yt-timestamp" data-t="00:03:32">[00:03:32]</a>.

### Open vs. Closed Source
Altman believes there are "great roles for both" open and closed source models <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>. [[OpenAI and AI advancements | OpenAI]]'s primary mission is to build towards AGI and broadly distribute its benefits <a class="yt-timestamp" data-t="00:07:17">[00:07:17]</a>. He is particularly interested in an open-source model that can run effectively on a phone <a class="yt-timestamp" data-t="00:07:41">[00:07:41]</a>.

The initial rationale for [[OpenAI and AI advancements | OpenAI]] being open was the belief that [[regulating_ai_and_its_implications | AI]] was "too important for any one company to own" <a class="yt-timestamp" data-t="00:09:34">[00:09:34]</a>. Later, the perception shifted to it being "too dangerous for anybody to be able to see it," leading to a more closed approach <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>. However, Altman argues that releasing Chat [[OpenAI and GPT4o Innovations | GPT]] was a way to make the world "see this" and understand [[regulating_ai_and_its_implications | AI]]'s importance <a class="yt-timestamp" data-t="00:10:12">[00:10:12]</a>.

### Cost and Latency
Reducing the cost and dramatically cutting the latency of [[OpenAI and AI advancements | AI]] models are "hugely important" to [[OpenAI and AI advancements | OpenAI]] <a class="yt-timestamp" data-t="00:06:16">[00:06:16]</a>. Altman is confident this will happen due to the early stage of the science and "engineering Tailwinds" <a class="yt-timestamp" data-t="00:06:27">[00:06:27]</a>. He envisions a future where "intelligence [is] too cheap to meter and so fast that it feels instantaneous" <a class="yt-timestamp" data-t="00:06:50">[00:06:50]</a>.

### AI Infrastructure
To achieve cheaper and faster compute, significant algorithmic gains are expected <a class="yt-timestamp" data-t="00:14:22">[00:14:22]</a>. The entire supply chain for [[OpenAI and AI advancements | AI]], including logic fab capacity, HBM manufacturing, data center construction, and energy, is complex and presents bottlenecks <a class="yt-timestamp" data-t="00:14:47">[00:14:47]</a>.

### The Role of Reasoning
A key missing element for many [[impact_of_ai_on_different_industries_and_technical_fields | AI applications]] is models that can perform reasoning <a class="yt-timestamp" data-t="00:27:25">[00:27:25]</a>. Altman believes that if core generalized reasoning can be figured out, connecting it to new problem domains will be "doable" and a "fast unlock" <a class="yt-timestamp" data-t="00:31:49">[00:31:49]</a>.

## [[Impact of AI on different industries and technical fields | Impact of AI on Industries and Society]]

### New Device Form Factors
Sam Altman is highly interested in "great new form factors of computing" enabled by technological advancements <a class="yt-timestamp" data-t="00:15:47">[00:15:47]</a>. While the iPhone is considered "the greatest piece of technology Humanity has ever made," he anticipates a shift beyond current devices <a class="yt-timestamp" data-t="00:16:07">[00:16:07]</a>. Voice interaction, despite current latency issues, is seen as a hint to the "next thing" in computing <a class="yt-timestamp" data-t="00:17:34">[00:17:34]</a>. Computer vision, combined with voice, allowing [[OpenAI and AI advancements | AI]] to understand its surroundings, is another powerful multimodal direction <a class="yt-timestamp" data-t="00:18:13">[00:18:13]</a>.

Altman envisions an "always on, super low friction" [[OpenAI and AI advancements | AI]] assistant that "just kind of knows what I want" and has context to help throughout the day <a class="yt-timestamp" data-t="00:19:21">[00:19:21]</a>. He prefers the model of [[OpenAI and AI advancements | AI]] as a "great senior employee" rather than an "extension of myself" or an "alter ego" <a class="yt-timestamp" data-t="00:20:25">[00:20:25]</a>. This assistant would be an "always available, always great, super capable assistant executive agent" that can reason and even push back <a class="yt-timestamp" data-t="00:20:48">[00:20:48]</a>.

### App Interaction and User Interfaces
Altman is interested in designing a world that is "equally usable by humans and by [[OpenAI and AI advancements | AIs]]" <a class="yt-timestamp" data-t="00:23:23">[00:23:23]</a>. This could involve apps exposing APIs to [[OpenAI and AI advancements | AI]] assistants or users watching the [[OpenAI and AI advancements | AI]] interact with an app and providing feedback <a class="yt-timestamp" data-t="00:22:55">[00:22:55]</a>. While voice interaction is powerful, he believes visual user interfaces will remain important for many tasks <a class="yt-timestamp" data-t="00:24:02">[00:24:02]</a>.

### Exciting Applications
Sam Altman is particularly excited about:
*   **AI Tutors**: The potential for [[OpenAI and AI advancements | AI]] to fundamentally reinvent how people learn <a class="yt-timestamp" data-t="00:25:48">[00:25:48]</a>.
*   **Coding Tools**: Tools like Devin are seen as a "super cool vision of the future" <a class="yt-timestamp" data-t="00:26:20">[00:26:20]</a>.
*   **Healthcare**: Believes healthcare should be "pretty transformed" by [[OpenAI and AI advancements | AI]] <a class="yt-timestamp" data-t="00:26:26">[00:26:26]</a>.
*   **Scientific Discovery**: Most excited about [[OpenAI and AI advancements | AI]] enabling "faster and better scientific discovery" <a class="yt-timestamp" data-t="00:26:34">[00:26:34]</a>.

### Intellectual Property and Fair Use
The conversation around [[OpenAI and AI advancements | AI]] and content creation is complex <a class="yt-timestamp" data-t="00:33:10">[00:33:10]</a>. [[OpenAI and AI advancements | OpenAI]] has been engaging in licensing deals with entities like the Financial Times (FT) <a class="yt-timestamp" data-t="00:33:06">[00:33:06]</a>. Altman distinguishes between generalized human knowledge (like math theorems) and art, especially when a system generates art in the style or likeness of another artist <a class="yt-timestamp" data-t="00:34:50">[00:34:50]</a>. He believes the debate will increasingly shift from training data to "what happens at inference time" as training data becomes less valuable <a class="yt-timestamp" data-t="00:35:36">[00:35:36]</a>. For instance, if a model generates a song in the style of Taylor Swift, even without being trained on her songs, questions arise about whether this should be allowed and how the artist should be compensated <a class="yt-timestamp" data-t="00:36:08">[00:36:08]</a>. [[OpenAI and AI advancements | OpenAI]] has currently chosen not to develop music models due to the complexities of these questions <a class="yt-timestamp" data-t="00:38:27">[00:38:27]</a>, and their DALL-E model prevents users from generating images of specific copyrighted characters like Darth Vader <a class="yt-timestamp" data-t="00:40:24">[00:40:24]</a>.

## [[Regulating AI and its implications | Regulating AI]]

Sam Altman expresses concern about "regulatory overreach" and the idea of states creating their own [[regulating_ai_and_its_implications | AI]] regulations <a class="yt-timestamp" data-t="00:42:17">[00:42:17]</a>. He advocates for an international agency that would oversee the most powerful [[OpenAI and AI advancements | AI]] systems, similar to global oversight for nuclear weapons or synthetic biology <a class="yt-timestamp" data-t="00:43:06">[00:43:06]</a>. The purpose of this would be to ensure "reasonable safety testing" for systems capable of causing "significant global harm," such as those that could recursively self-improve or autonomously design bioweapons <a class="yt-timestamp" data-t="00:42:58">[00:42:58]</a>. He suggests that regulation could apply to models trained on computers costing more than $10 billion or $100 billion, to avoid burdening startups <a class="yt-timestamp" data-t="00:44:00">[00:44:00]</a>.

Altman believes that current proposed legislation, particularly in California, is problematic because it would require government agencies to audit proprietary code and model weights <a class="yt-timestamp" data-t="00:45:31">[00:45:31]</a>. He argues that such laws would quickly become outdated due to the rapid pace of [[OpenAI and AI advancements | AI]] development <a class="yt-timestamp" data-t="00:46:18">[00:46:18]</a>. Instead, he favors safety testing on the *outputs* of models, akin to how airplanes are certified, rather than scrutinizing their internal workings <a class="yt-timestamp" data-t="00:47:03">[00:47:03]</a>. He emphasizes that current models like GPT-4 do not pose a "material threat" regarding catastrophic risks <a class="yt-timestamp" data-t="00:49:29">[00:49:29]</a>.

## [[Challenges and opportunities in AI development and deployment | Challenges and Opportunities]]

### Jobs and Universal Basic Income (UBI)
Sam Altman began considering universal basic income (UBI) around 2016, concurrently with taking [[OpenAI and AI advancements | AI]] seriously <a class="yt-timestamp" data-t="00:50:22">[00:50:22]</a>. The theory was that the magnitude of change [[OpenAI and AI advancements | AI]] might bring to jobs and the economy warranted exploring new societal arrangements <a class="yt-timestamp" data-t="00:50:31">[00:50:31]</a>. He believes direct financial aid to people can be a more effective way to eliminate poverty than traditional government policies <a class="yt-timestamp" data-t="00:51:01">[00:51:01]</a>.

However, given the current [[developments_in_technology_and_ai_for_2024 | developments in AI]], Altman wonders if a "Universal Basic Compute" model might be more fitting for the future than UBI <a class="yt-timestamp" data-t="00:52:03">[00:52:03]</a>. In this model, everyone would receive a "slice of GPT-7 compute" that they could use, resell, or donate for purposes like cancer research, effectively owning a "productivity slice" <a class="yt-timestamp" data-t="00:52:09">[00:52:09]</a>.

### Organizational Approach
[[OpenAI and AI advancements | OpenAI]] operates with a highly organized effort, not primarily to prevent edge cases, but because its systems are complex and "concentrating bets are so important" <a class="yt-timestamp" data-t="01:03:00">[01:03:00]</a>. This approach contrasts with the "move fast, break things" ethos of some startups or the distributed teams of other research labs <a class="yt-timestamp" data-t="01:03:01">[01:03:01]</a>. For [[OpenAI and AI advancements | OpenAI]], putting the "whole company" to work on projects like GPT-4 proved effective, even if initially "unimaginable" for an [[OpenAI and AI advancements | AI]] research lab <a class="yt-timestamp" data-t="01:03:19">[01:03:19]</a>.