---
title: Groqs LPU technology and potential
videoId: z6vrKA_L5pk
---

From: [[allin]] <br/> 

Groq, a company in which Chamath Palihapitiya invested early, has recently gained significant attention for its Language Processing Unit (LPU) technology <a class="yt-timestamp" data-t="06:26:00">[06:26:00]</a>. Chamath was the seed investor in Groq, which began its journey in 2016, extracting the core concept and team from Google <a class="yt-timestamp" data-t="27:39:00">[27:39:00]</a>.

## The "Overnight Success" Story
After eight years of development, Groq experienced a "super viral moment" that led to a massive influx of interest <a class="yt-timestamp" data-t="07:34:00">[07:34:00]</a>, <a class="yt-timestamp" data-t="27:52:00">[27:52:00]</a>. Just two months prior, the company had virtually no customers, but within days, it attracted 3,000 unique customers, ranging from [[Fortune 500 | Fortune 500]] companies to individual developers <a class="yt-timestamp" data-t="28:31:00">[28:31:00]</a>, <a class="yt-timestamp" data-t="28:41:00">[28:41:00]</a>, <a class="yt-timestamp" data-t="28:48:00">[28:48:00]</a>. This rapid adoption highlights the "deep tech" nature of Groq's business, which involves a long development cycle with many difficult, interconnected components that must "click together" <a class="yt-timestamp" data-t="32:01:00">[32:01:00]</a>, <a class="yt-timestamp" data-t="32:20:00">[32:20:00]</a>.

## LPU Technology: Training vs. Inference
At a high level, [[AI Benchmarks and Progress with LLMs | AI]] problems are divided into two distinct categories: training and inference <a class="yt-timestamp" data-t="29:09:00">[29:09:00]</a>.
*   **Training** is about brute force and power, requiring vast numbers of machines, high-quality networking, and enormous energy to run for months to learn from data <a class="yt-timestamp" data-t="29:45:00">[29:45:00]</a>.
*   **Inference** is about speed and cost <a class="yt-timestamp" data-t="30:11:00">[30:11:00]</a>. This is the part that consumers experience when asking [[ChatGPT and AIs impact on various industries | chatbots]] like [[OpenAI and GPT4o Innovations | ChatGPT]] or [[Googles Quantum Chip | Gemini]] a question and receiving a useful answer <a class="yt-timestamp" data-t="29:30:00">[29:30:00]</a>.

Groq's LPU chips are specifically designed for the inference challenge, proving to be "extremely fast and extremely cheap" <a class="yt-timestamp" data-t="30:28:00">[30:28:00]</a>. They are "meaningfully faster and cheaper than any [[Nvidia | Nvidia]] solution" for this purpose <a class="yt-timestamp" data-t="30:46:00">[30:46:00]</a>.

## LPU vs. CPU and GPU: A Historical Evolution
The evolution of processing units illustrates the unique contribution of the LPU:
*   **CPU (Central Processing Unit)**: The "Workhorse of all computing," designed for serial computation. A CPU is efficient at processing one instruction, acting on it, and producing one answer <a class="yt-timestamp" data-t="46:45:00">[46:45:00]</a>, <a class="yt-timestamp" data-t="47:09:00">[47:09:00]</a>.
*   **GPU (Graphics Processing Unit)**: Jensen Huang, the founder of [[Nvidia | Nvidia]], realized that CPUs "failed quite brilliantly" at certain tasks, such as graphics and video games <a class="yt-timestamp" data-t="47:00:00">[47:00:00]</a>, <a class="yt-timestamp" data-t="47:29:00">[47:29:00]</a>. GPUs excel at parallel computation, processing many things simultaneously <a class="yt-timestamp" data-t="47:47:00">[47:47:00]</a>. Around ten years ago, it became clear that the mathematical processes required for [[AI Benchmarks and Progress with LLMs | AI models]] were similar to those used in processing game imagery, making GPUs highly effective for AI <a class="yt-timestamp" data-t="48:01:00">[48:01:00]</a>.
*   **LPU (Language Processing Unit)**: Groq's insight was that the fundamental design of GPUs had not substantially changed since 1999 <a class="yt-timestamp" data-t="48:41:00">[48:41:00]</a>. They decided to discard expensive memory and other components, instead creating "small little brains" (chips) and connecting many of them together with clever software for scheduling and optimization <a class="yt-timestamp" data-t="48:58:00">[48:58:00]</a>. This design, making the chip "much much smaller and cheaper," turns out to be "hyper optimized" for [[AI Benchmarks and Progress with LLMs | large language models]] <a class="yt-timestamp" data-t="49:09:00">[49:09:00]</a>, <a class="yt-timestamp" data-t="49:17:00">[49:17:00]</a>.

## Potential and Market Impact
Groq is currently valued as a "meager unicorn" with a valuation of around $1 billion, compared to [[Nvidia | Nvidia]]'s $2 trillion market capitalization <a class="yt-timestamp" data-t="31:00:00">[31:00:00]</a>, <a class="yt-timestamp" data-t="31:03:00">[31:03:00]</a>. However, there is "a lot of market cap for Groq to gain" by scaling its production <a class="yt-timestamp" data-t="31:07:00">[31:07:00]</a>.

The company's technology has the potential to "enable that monetization leap forward" for [[AI Benchmarks and Progress with LLMs | AI applications]] <a class="yt-timestamp" data-t="37:28:00">[37:28:00]</a>. Current [[AI Benchmarks and Progress with LLMs | AI applications]] are often seen as "toy apps" for proofs of concept or demos, not yet production-ready <a class="yt-timestamp" data-t="15:11:00">[15:11:00]</a>, <a class="yt-timestamp" data-t="36:46:00">[36:46:00]</a>. This is because they are too slow, require too much infrastructure, and are too costly <a class="yt-timestamp" data-t="37:22:00">[37:22:00]</a>. Groq aims to address these limitations by offering a significantly faster and cheaper inference solution <a class="yt-timestamp" data-t="37:24:00">[37:24:00]</a>.

The success of deep tech companies like Groq, [[SpaceX | SpaceX]], and [[Tesla | Tesla]] demonstrates that while they take a long time and significant investment, they can build "extraordinary moats" and achieve "hundreds of billions and sometimes trillions of dollars of market value" when they work out <a class="yt-timestamp" data-t="33:05:00">[33:05:00]</a>, <a class="yt-timestamp" data-t="33:39:00">[33:39:00]</a>. This is in contrast to software businesses that can achieve [[Impact of ChatGPT and AI on various industries | product-market fit]] and profitability more quickly <a class="yt-timestamp" data-t="32:09:00">[32:09:00]</a>. Groq represents a "good risk" in the investment landscape because it does not aim to "debate the laws of physics" but rather solve a "well-defined bounded problem" through technical innovation in chip design and compilers <a class="yt-timestamp" data-t="38:27:00">[38:27:00]</a>, <a class="yt-timestamp" data-t="39:35:00">[39:35:00]</a>.