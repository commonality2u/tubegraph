---
title: AI and intellectual property issues
videoId: AI5qI6ej-yM
---

From: [[allin]] <br/> 

The emergence of [[AI and its potential disruption | AI]] has brought significant challenges to established intellectual property laws, particularly concerning copyright and fair use. A key point of contention revolves around how AI models are trained on vast datasets, often scraped from the internet, and the resulting output.

## Legal Precedents and Arguments

### Thompson Reuters vs. Ross
In the first major U.S. [[Role of AI in content generation and copyrights | AI copyright]] case, Thompson Reuters, owner of the legal database Westlaw, sued its competitor, Ross, for copyright infringement <a class="yt-timestamp" data-t="01:21:18">[01:21:18]</a>. Ross had developed an [[AI as a computing platform and its potential disruption | AI]]-powered legal search engine and had sought a license from Westlaw to train its models, which Westlaw denied <a class="yt-timestamp" data-t="01:22:00">[01:22:00]</a>. Ross then partnered with Legal Ease, whose database was found to be copied from Westlaw answers, leading to Ross being held vicariously liable for direct infringement <a class="yt-timestamp" data-t="01:22:20">[01:22:20]</a>. Initially, the judge favored Ross under fair use, but this ruling was later reversed, with the judge concluding that fair use did not apply <a class="yt-timestamp" data-t="01:22:37">[01:22:37]</a>.

This case highlights the "fourth factor test" of the fair use doctrine: the effect of the use on the potential market and the value of the original work <a class="yt-timestamp" data-t="01:23:03">[01:23:03]</a>. It raises questions about whether companies like Getty Images have the right to create derivative products from their images, and whether crawling the open web without a license constitutes copyright infringement <a class="yt-timestamp" data-t="01:23:10">[01:23:10]</a>. Just because content is technically accessible doesn't mean it can be used without permission <a class="yt-timestamp" data-t="01:23:25">[01:23:25]</a>.

### The "Napster/Spotify" Scenario
It is predicted that the current [[AI and job displacement | AI]] copyright disputes, such as OpenAI's lawsuit with The New York Times, may conclude similarly to the Napster and Spotify cases <a class="yt-timestamp" data-t="01:24:43">[01:24:43]</a>. This could result in large language models (LLMs), especially closed-source ones, being required to pay a percentage of their revenue to content holders in a negotiated settlement <a class="yt-timestamp" data-t="01:25:12">[01:25:12]</a>. Such an outcome could lead to a significant resurgence and uplift for the content industry <a class="yt-timestamp" data-t="01:25:29">[01:25:29]</a>.

### Challenges in Legal Interpretation
The legal community faces challenges in understanding how [[AI as a computing platform and its potential disruption | AI]] models function <a class="yt-timestamp" data-t="01:26:10">[01:26:10]</a>. LLMs are often described as "extreme compressors" that summarize and repackage information, rather than truly learning or creating new knowledge <a class="yt-timestamp" data-t="01:26:50">[01:26:50]</a>. Unlike Google, which links back to original sources and sends traffic, LLMs often provide direct substitutions, keeping users within the model <a class="yt-timestamp" data-t="01:27:07">[01:27:07]</a>. The key question in fair use is how much content is changed or remixed by the [[AI and its impact on Googles business model | AI]] model <a class="yt-timestamp" data-t="01:30:00">[01:30:00]</a>.

## Open Source vs. Closed Source Models

A proposed solution is that if an [[AI investment and technology | AI]] model is trained on the open web, its resulting model should also be open source, contributing back to the public domain <a class="yt-timestamp" data-t="01:24:37">[01:24:37]</a>. Alternatively, if content is crawled, it should be made open source, or copyright holders must go to significant lengths to protect their data <a class="yt-timestamp" data-t="01:31:37">[01:31:37]</a>.

Some [[AI and M&A in tech industry | AI]] companies, like Microsoft, are proactively licensing content for their models, such as paying authors for indexing their books <a class="yt-timestamp" data-t="01:32:00">[01:32:00]</a>. This establishes a precedent for content creators to have their work respected and compensated.

### Open AI's Approach
The transition of OpenAI from a nonprofit to a for-profit entity, allowing it to raise significant capital and incentivize employees, has drawn criticism for its handling of [[Regulating AI and its implications | AI]] control <a class="yt-timestamp" data-t="01:32:20">[01:32:20]</a>. While incentivizing the team and raising money are necessary, some argue that the nonprofit portion could have been maintained to retain control for humanity, rather than completely privatizing the venture <a class="yt-timestamp" data-t="01:33:05">[01:33:05]</a>. This concern stems from the idea that if [[AI as a computing platform and its potential disruption | AI]] is truly as powerful as some predict (capturing future value), then its control should not be consolidated in a single private company <a class="yt-timestamp" data-t="01:32:20">[01:32:20]</a>.

The historical precedent of the internet, an open technology based on open source, shows that U.S. companies were able to dominate because they were in the lead <a class="yt-timestamp" data-t="01:38:34">[01:38:34]</a>. Similarly, an open and distributed approach to [[AI and technologys role in economic and geopolitical shifts | AI]] could lead to faster innovation and benefit humanity, even if it means some leakage of technology to other countries <a class="yt-timestamp" data-t="01:08:08">[01:08:08]</a>. The argument for openness is that if a country doesn't embrace and lead in [[AI and job displacement | AI]], others will, as demonstrated by companies like DeepMind <a class="yt-timestamp" data-t="01:06:06">[01:06:06]</a>.