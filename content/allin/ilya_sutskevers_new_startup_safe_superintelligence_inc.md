---
title: Ilya Sutskevers New Startup Safe Superintelligence Inc
videoId: aEYcZtaZRXQ
---

From: [[allin]] <br/> 

Ilya Sutskever, a co-founder and former Chief Scientist at [[OpenAI and AI advancements | OpenAI]], has launched a new startup named Safe Superintelligence Inc (SSI) <a class="yt-timestamp" data-t="01:14:14">[01:14:14]</a>.

## Formation and Background
Sutskever resigned from [[OpenAI and AI advancements | OpenAI]] in May 2024, after a decade with the company where he also served as co-head of super alignment <a class="yt-timestamp" data-t="01:14:25">[01:14:25]</a>. His departure followed a period of internal turmoil at [[OpenAI and AI advancements | OpenAI]], where he was part of the board that attempted to oust CEO Sam Altman in November 2023, only to reverse course days later and express regret <a class="yt-timestamp" data-t="01:14:31">[01:14:31]</a>.

The co-founders of SSI include Daniel Gross, a YC partner and Pioneer Labs co-founder, and Daniel Levy, an [[OpenAI and AI advancements | OpenAI]] engineer <a class="yt-timestamp" data-t="01:14:44">[01:14:44]</a>.

## Mission and Strategy
The company's primary goal is stated within its name: to develop a safe superintelligence <a class="yt-timestamp" data-t="01:14:52">[01:14:52]</a>. Sutskever explicitly stated that SSI's "first product will be the safe super intelligence and it will not do anything else until then" <a class="yt-timestamp" data-t="01:14:57">[01:14:57]</a>.

## Industry Reaction and Challenges
Commentators have expressed mixed reactions and identified several challenges for SSI's unique approach:

*   **"Throttle" or "Governor" on Development**: The focus on "safety" is seen by some as a potential hindrance, akin to a "throttle" or "governor" on a startup that needs to move quickly to compete <a class="yt-timestamp" data-t="01:55:58">[01:55:58]</a>. This focus on safety concerns acts as a "brake pedal" and can slow down development <a class="yt-timestamp" data-t="01:56:19">[01:56:19]</a>.
*   **Competitive Disadvantage**: It has been suggested that [[OpenAI and AI advancements | OpenAI]] CEO Sam Altman may have intentionally limited resources for safety-focused groups within [[OpenAI and AI advancements | OpenAI]] to prioritize speed in [[AI investment and technology | AI advancements]] <a class="yt-timestamp" data-t="01:56:30">[01:56:30]</a>. This competitive landscape suggests that "companies that care about safety more than others are going to lose" in the race to achieve Artificial General Intelligence (AGI) <a class="yt-timestamp" data-t="01:57:42">[01:57:42]</a>.
*   **[[AI investment and technology | Investment]] Requirements**: The cost of developing functional [[AI investment and technology | AI models]] is rapidly increasing, from billions of dollars today to potentially hundreds of billions by 2027 <a class="yt-timestamp" data-t="01:00:01">[01:00:01]</a>. This creates an "arms race on cost and compute" <a class="yt-timestamp" data-t="01:01:06">[01:01:06]</a>. Securing such massive funding could be a significant challenge for a new startup, as major tech companies like Google, Microsoft, Facebook, and Amazon have deeper pockets to invest in this area <a class="yt-timestamp" data-t="01:00:14">[01:00:14]</a>.
*   **Market Dynamics**: Foundational models are quickly becoming a "consumer surplus," with models approaching asymptotic returns <a class="yt-timestamp" data-t="00:59:20">[00:59:20]</a>. This implies that differentiation might require increasingly expensive and refined data processing, leading to market conditions where "one startup can probably win but there will be a bunch of open source alternatives" that are "asymptotically similar" <a class="yt-timestamp" data-t="01:01:00">[01:01:00]</a>.