---
title: Future of humancomputer interaction and Googles role
videoId: ReGC2GtWFp4
---

From: [[allin]] <br/> 

Sundar Pichai, CEO of Alphabet, believes that the future of human-computer interaction will involve a shift where computing does more of the "hard work" and "adaptation" for the user, rather than the user adapting to the computing system. This is seen as the "holy grail" of progress <a class="yt-timestamp" data-t="02:55:54">[02:55:54]</a>.

## Evolving Interaction Paradigms
Current interactions involve asking [[Googles AI investment and strategy | AI]] questions through chat interfaces and receiving complete answers <a class="yt-timestamp" data-t="03:28:29">[03:28:29]</a>. The use of voice [[future_of_ai_in_technology_and_society | AI]] tools is becoming more prevalent, enabling conversations and deeper dives into topics <a class="yt-timestamp" data-t="02:59:00">[02:59:00]</a>.

Looking ahead 5 to 10 years, Pichai anticipates a future with:
*   Less reliance on screens or typing into chat interfaces <a class="yt-timestamp" data-t="02:50:50">[02:50:50]</a>.
*   Increased use of audio-only interactions (e.g., via AirPods) or a combination of audio and screen <a class="yt-timestamp" data-t="02:50:50">[02:50:50]</a>.
*   Personalized interfaces, potentially eliminating the traditional concept of the web <a class="yt-timestamp" data-t="02:50:50">[02:50:50]</a>.

### Ambient Computing and AR Glasses
A significant leap is expected with [[future_of_ai_in_technology_and_society | AR glasses]], which are seen as the next frontier for seamless, ambient computing <a class="yt-timestamp" data-t="02:50:50">[02:50:50]</a>, <a class="yt-timestamp" data-t="02:56:56">[02:56:56]</a>. While not yet as comfortable as regular glasses, their progression suggests a future where technology is "ambiently there and doing stuff for you" <a class="yt-timestamp" data-t="02:56:56">[02:56:56]</a>. Pichai views this paradigm as "very interesting" and a "magical moment" within a couple of cycles away, similar to the impact of smartphones in 2006-2007 <a class="yt-timestamp" data-t="02:50:50">[02:50:50]</a>, <a class="yt-timestamp" data-t="02:56:56">[02:56:56]</a>, <a class="yt-timestamp" data-t="02:00:27">[02:00:27]</a>, <a class="yt-timestamp" data-t="02:00:33">[02:00:33]</a>.

Longer-term possibilities include direct neural interfaces, like Neuralink, though this is considered a distant possibility <a class="yt-timestamp" data-t="02:38:39">[02:38:39]</a>.

### Multimodal AI and Robotics
The future will heavily feature natively multimodal models capable of processing audio, vision, and language, being present in the user's line of view <a class="yt-timestamp" data-t="02:56:56">[02:56:56]</a>.

[[Googles AI investment and strategy | Google]] is also actively involved in robotics, seeing it as another significant area of focus <a class="yt-timestamp" data-t="02:58:01">[02:58:01]</a>. While past efforts at the application layer were premature, the current combination of [[Googles AI investment and strategy | AI]] and robotics offers a "next sweet spot" <a class="yt-timestamp" data-t="02:58:01">[02:58:01]</a>, <a class="yt-timestamp" data-t="02:46:26">[02:46:26]</a>. The company is developing advanced frontier R&D teams and "world class" Gemini robotics efforts focused on vision, language, and action models <a class="yt-timestamp" data-t="02:46:01">[02:46:01]</a>. Humanoid robots, once easily identifiable as "janky," now require close inspection to determine if they are real or simulated <a class="yt-timestamp" data-t="02:46:46">[02:46:46]</a>, <a class="yt-timestamp" data-t="02:52:52">[02:52:52]</a>. Google is exploring partnerships and direct product launches in this area, potentially developing an "Android for robotics" by supporting manufacturers with Gemini models <a class="yt-timestamp" data-t="02:58:01">[02:58:01]</a>, <a class="yt-timestamp" data-t="02:00:27">[02:00:27]</a>.

## Google's Foundational Approach
[[Googles infrastructure and technological innovations | Google's]] long-term commitment to foundational technologies and deep R&D positions it to drive these future interactions. Key aspects of its strategy include:
*   **[[googles_ai_advancements_and_search_redesign | AI Search Redesign]]**: [[Googles AI Advancements and Search Redesign | AI Overviews]] are already used by over 1.5 billion users in 150+ countries, expanding query types and leading to query growth <a class="yt-timestamp" data-t="05:16:00">[05:16:00]</a>. A dedicated [[googles_ai_advancements_and_search_redesign | AI mode]] is being tested in labs for search, offering a full AI experience with conversational follow-up queries <a class="yt-timestamp" data-t="05:51:00">[05:51:00]</a>.
*   **Hardware Investment**: Google invests heavily in hardware, including Pixel phones, and vast data centers, as well as ventures like Waymo (self-driving cars) which are essentially "big robots" <a class="yt-timestamp" data-t="02:58:01">[02:58:01]</a>, <a class="yt-timestamp" data-t="02:00:27">[02:00:27]</a>, <a class="yt-timestamp" data-t="02:00:33">[02:00:33]</a>.
*   **Infrastructure Advantage**: Google's investments in its own [[googles_infrastructure_and_technological_innovations | infrastructure]], including its custom-built Tensor Processing Units (TPUs), allow it to deliver high-performance [[Googles AI investment and strategy | AI]] models at cost-effective price points <a class="yt-timestamp" data-t="01:15:00">[01:15:00]</a>. This full-stack approach, from subsea cables to large-scale data centers, supports its ability to innovate and serve [[Googles AI Advancements and Search Redesign | AI]]-driven queries efficiently <a class="yt-timestamp" data-t="01:16:00">[01:16:00]</a>.
*   **Long-term Bets**: Google's history of patient investment in technologies like TPUs and DeepMind, even when initially underestimated, demonstrates its strategy to pursue conviction-driven long-term trends <a class="yt-timestamp" data-t="01:18:00">[01:18:00]</a>, <a class="yt-timestamp" data-t="01:21:00">[01:21:00]</a>. This includes significant efforts in quantum computing, which Pichai anticipates will demonstrate useful, practical computations superior to classical computers within a 5-year timeframe <a class="yt-timestamp" data-t="01:42:00">[01:42:00]</a>.

Google aims to leverage its broad user base across products like Gmail, Calendar, Docs, YouTube, and Search to integrate personal context (with user permission) and deliver significantly improved [[Googles AI investment and strategy | AI]] experiences <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>. This differentiated innovation opportunity is being thoughtfully pursued <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>.

> [!info] Addressing the Innovator's Dilemma
> Sundar Pichai dismisses the notion of an "innovator's dilemma" for Google, stating that it "only exists if you treat it as a dilemma" <a class="yt-timestamp" data-t="00:07:02">[00:07:02]</a>. He emphasizes the company's long-standing principle: "Follow the user, all else will follow" <a class="yt-timestamp" data-t="00:08:06">[00:08:06]</a>. By constantly innovating and leaning into major technological shifts like [[future_of_ai_in_technology_and_society | AI]], Google aims to stay ahead, rather than being disrupted <a class="yt-timestamp" data-t="00:07:09">[00:07:09]</a>. This approach mirrors successful transitions in the past, such as the shift to mobile, where initially monetizing challenges were overcome by focusing on user experience <a class="yt-timestamp" data-t="00:07:27">[00:07:27]</a>, <a class="yt-timestamp" data-t="00:07:46">[00:07:46]</a>. This proactive stance reflects Google's belief that [[ai_and_its_impact_on_googles_business_model | AI will drive significant progress]] for search and other services <a class="yt-timestamp" data-t="00:04:32">[00:04:32]</a>.