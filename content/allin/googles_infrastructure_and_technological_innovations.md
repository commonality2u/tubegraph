---
title: Googles infrastructure and technological innovations
videoId: ReGC2GtWFp4
---

From: [[allin]] <br/> 

Google, now Alphabet, is positioned as a deep computer science company that applies fundamental research to build products impacting daily life <a class="yt-timestamp" data-t="02:21:55">[02:21:55]</a>. This approach has driven significant financial growth, with revenue growing from $20 billion to nearly $100 billion per quarter, and the stock increasing 4.5 times to a $2 trillion market cap under CEO Sundar Pichai's tenure <a class="yt-timestamp" data-t="01:53:05">[01:53:05]</a>.

## AI-First Philosophy and Core Research

Google adopted an "AI-first" approach almost a decade ago <a class="yt-timestamp" data-t="04:11:00">[04:11:00]</a>. Key foundational investments include:
*   Establishing Google Brain in 2012 <a class="yt-timestamp" data-t="04:18:00">[04:18:00]</a>.
*   Acquiring DeepMind in 2014 <a class="yt-timestamp" data-t="04:20:00">[04:20:00]</a>.
*   Pichai declared Google "AI first" upon becoming CEO in 2015, believing AI would drive the biggest progress in search and beyond <a class="yt-timestamp" data-t="04:23:00">[04:23:00]</a>.

## Evolution of Search with AI

Despite concerns about [[googles_challenges_and_the_impact_of_ai_on_its_business_model | AI's potential disruption to its core search business]], Google views AI as an "extraordinary opportunity" for search <a class="yt-timestamp" data-t="04:42:00">[04:42:00]</a>. The company aims to make information more accessible to everyone <a class="yt-timestamp" data-t="04:50:00">[04:50:00]</a>.

Key [[googles_ai_advancements_and_search_redesign | AI advancements in search]] include:
*   **Transformers (BERT and MUM)**: These models significantly improved search quality over the last couple of years <a class="yt-timestamp" data-t="05:09:00">[05:09:00]</a>.
*   **AI Overviews**: Launched about a year ago, these overviews are used by over 1.5 billion users in more than 150 countries <a class="yt-timestamp" data-t="05:16:00">[05:16:00]</a>. They expand the types of queries people can use and have led to empirical query growth <a class="yt-timestamp" data-t="05:28:00">[05:28:00]</a>.
*   **AI Mode**: A new dedicated AI experience coming to search, announced at Google I/O <a class="yt-timestamp" data-t="05:51:00">[05:51:00]</a>. This mode allows for full-on AI experiences, including follow-on conversational queries, using Google's cutting-edge models <a class="yt-timestamp" data-t="05:59:00">[05:59:00]</a>. Users are typing much longer, paragraph-length queries, two to three times the average length from two years ago <a class="yt-timestamp" data-t="06:18:00">[06:18:00]</a>.

Google's strategy is to "follow the user" <a class="yt-timestamp" data-t="08:06:00">[08:06:00]</a>, adapting to new formats and user experiences even if monetization follows later. This approach was evident with YouTube Shorts, which initially didn't monetize as well as long-form content but was prioritized for user experience <a class="yt-timestamp" data-t="07:43:00">[07:43:00]</a>.

## Infrastructure as a Core Advantage

Google's long-standing investment in infrastructure is a significant competitive advantage <a class="yt-timestamp" data-t="15:56:00">[15:56:00]</a>. This includes shipping container data centers from 20 years ago and continued investments <a class="yt-timestamp" data-t="15:37:00">[15:37:00]</a>.

### TPUs and Custom Chips
Google literally operates on the "Pareto frontier" of performance and cost, delivering the best models at the most cost-effective price points <a class="yt-timestamp" data-t="16:40:00">[16:40:00]</a>. This is partly due to training and serving models on its own infrastructure, including Tensor Processing Units (TPUs) <a class="yt-timestamp" data-t="17:05:00">[17:05:05]</a>.
*   Google is in its seventh generation of TPUs, with the first version built in 2017 <a class="yt-timestamp" data-t="17:10:00">[17:10:00]</a>.
*   The latest TPU in the series, Ironwood, boasts a single part exceeding 40 exaflops <a class="yt-timestamp" data-t="17:43:00">[17:43:00]</a>.
*   TPUs are especially good at inference, helping manage the cost per query in search at scale <a class="yt-timestamp" data-t="17:39:00">[17:39:00]</a>.

Google continues to work with NVIDIA, using both TPUs and GPUs for Gemini traffic, providing customer choice and leveraging NVIDIA's world-class R&D and software stack <a class="yt-timestamp" data-t="20:12:00">[20:12:00]</a>.

### Cost and Latency Considerations
While there were concerns about the cost of serving AI-driven queries, Google has seen the cost per query fall dramatically in an 18-month timeframe <a class="yt-timestamp" data-t="11:27:00">[11:27:00]</a>. The primary constraint is latency, as search has historically been near-instantaneous <a class="yt-timestamp" data-t="11:33:00">[11:33:00]</a>. Ad revenue per AI query with AI Overviews is already at baseline compared to non-AI search, with potential for improvement <a class="yt-timestamp" data-t="12:05:00">[12:05:00]</a>.

### Investment Strategy
In 2025, Google plans to invest $70 billion in capital expenditure <a class="yt-timestamp" data-t="18:37:00">[18:37:00]</a>. The majority goes into servers and data centers <a class="yt-timestamp" data-t="18:48:00">[18:48:00]</a>. Half of the compute spend in 2025 is directed towards its Google Cloud business <a class="yt-timestamp" data-t="19:04:00">[19:04:00]</a>. This investment also powers innovations from Google DeepMind, pushing the frontier across various AI dimensions, including large language models, text, images, video, and world models <a class="yt-timestamp" data-t="19:17:00">[19:17:00]</a>.

## Broader AI and "Other Bets" Innovations

Google's [[googles_ai_investment_and_strategy | AI investment and strategy]] extends beyond search, with AI horizontally impacting all aspects of its business, including YouTube and Cloud <a class="yt-timestamp" data-t="15:06:00">[15:06:00]</a>.

### Gemini Ecosystem
Google is actively developing the Gemini app, which has seen an "uptick in engagement and usage growth" with the introduction of Gemini 2.5 Pro <a class="yt-timestamp" data-t="09:20:00">[09:20:00]</a>. Recent features include deep research, updated canvas audio overviews, V2 video generation, and Gemini Live for screen sharing and interaction on Android phones <a class="yt-timestamp" data-t="09:32:00">[09:32:00]</a>.

### Quantum Computing
Google has been making a patient investment in quantum computing for some time, working on it "out of conviction on the long-term trends" <a class="yt-timestamp" data-t="41:52:00">[41:52:00]</a>. Quantum computing is seen as fundamental to conducting large-scale simulations that truly represent nature <a class="yt-timestamp" data-t="42:10:00">[42:10:00]</a>. Pichai believes that within a five-year timeframe, a "really useful practical computation" will be performed quantum-style, far superior to classical computers, marking an "aha moment" for the industry <a class="yt-timestamp" data-t="42:27:00">[42:27:00]</a>. Google aims to provide access to quantum computing through its cloud services <a class="yt-timestamp" data-t="44:59:00">[44:59:00]</a>.

### Robotics
Google has one of the most advanced frontier R&D teams in robotics, with Gemini robotics efforts in vision, language, and action models being "world-class" <a class="yt-timestamp" data-t="45:53:00">[45:53:00]</a>. While past attempts to enter the application layer were too early (e.g., selling Boston Dynamics), the current combination of AI plus robotics presents a new "sweet spot" <a class="yt-timestamp" data-t="46:15:00">[46:15:00]</a>. Pichai predicts a "magical moment in robotics" within two to three years <a class="yt-timestamp" data-t="47:18:00">[47:18:00]</a>. Google's intrinsic team is developing models like "Android for robotics" to support robotics manufacturers <a class="yt-timestamp" data-t="47:27:00">[47:27:00]</a>.

### Waymo
Waymo, Google's self-driving car project, is highlighted as an example of "mindblowing persistence and patience" <a class="yt-timestamp" data-t="41:18:00">[41:18:00]</a>. It is now on track to be a hundred-billion-dollar business, demonstrating the success of Google's long-term, conviction-based approach to innovation <a class="yt-timestamp" data-t="41:12:00">[41:12:00]</a>.

## Culture of Innovation

Google's culture emphasizes investing in and empowering employees to foster a "positive, optimistic, innovation mindset" <a class="yt-timestamp" data-t="48:48:00">[48:48:00]</a>. Perks like free food were intended to encourage cross-pollination of ideas <a class="yt-timestamp" data-t="49:06:00">[49:06:00]</a>. Google believes this culture attracts higher-caliber talent who feel they have the agency to innovate <a class="yt-timestamp" data-t="49:43:00">[49:43:00]</a>.

Pichai notes that the intense and exciting nature of the current AI moment reminds him of early Google, with engineers working with passion and intensity <a class="yt-timestamp" data-t="51:47:00">[51:47:00]</a>. The company has also reintroduced "labs" to foster innovation from small, 10-person teams <a class="yt-timestamp" data-t="52:39:00">[52:39:00]</a>.

## Future Outlook

Google sees [[future_of_humancomputer_interaction_and_googles_role | AI as a much bigger opportunity landscape]] than all previous technologies combined <a class="yt-timestamp" data-t="33:15:00">[33:15:00]</a>. The future of human-computer interaction, in 5 to 10 years, will involve less human adaptation and more computing that "works for you" <a class="yt-timestamp" data-t="25:50:00">[25:50:00]</a>. This seamless interaction could be driven by advancements like AR glasses, which Pichai believes will "wow people" and represent the "next leap" in user experience <a class="yt-timestamp" data-t="26:11:00">[26:11:00]</a>.