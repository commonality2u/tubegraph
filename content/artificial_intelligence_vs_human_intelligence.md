---
title: Artificial Intelligence vs Human Intelligence
videoId: EVwjofV5TgU
---

From: [[dwarkesh | The Dwarkesh Podcast]]

Here is the article with added backlinks:

David Deutsch, in a podcast discussion, outlined his anticipation that Artificial General Intelligences (AGIs) will possess a fundamentally equivalent range of intelligence to humans <a class="yt-timestamp" data-t="00:00:10">[00:00:10]</a>. This article summarizes his perspective on the capabilities and limitations of AGIs in comparison to human intelligence, based solely on the provided podcast transcript.

## Fundamental Equivalence of AGIs and Humans

Deutsch defines "fundamentally intelligent" as being capable of the same types of cognition as humans in principle. This includes activities like engaging in science and art, and potentially experiencing emotions such as falling in love, or embodying concepts like good and evil <a class="yt-timestamp" data-t="00:00:25">[00:00:25]</a>. His reasoning for this equivalence is twofold, involving considerations of both hardware and software <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>.

### Hardware Considerations
Human brains are considered Turing-complete hardware, capable of running any computable program or function, within certain practical limits <a class="yt-timestamp" data-t="00:01:14">[00:01:14]</a>. Deutsch clarifies that "any" program doesn't mean literally any, as humans are limited by factors like lifespan (limiting the number of conversations) <a class="yt-timestamp" data-t="00:01:39">[00:01:39]</a> and computational speed (e.g., solving complex traveling salesman problems within the age of the universe) <a class="yt-timestamp" data-t="00:02:02">[00:02:02]</a>.
Essentially, all hardware limitations on humans boil down to speed and memory capacity <a class="yt-timestamp" data-t="00:02:26">[00:02:26]</a>. Deutsch argues that these can be augmented to match any other entity in the universe; if a faster computer is built, humans could theoretically use that technology to enhance their own thinking speed <a class="yt-timestamp" data-t="00:02:42">[00:02:42]</a>.

### Software and Conceptual Capabilities
Regarding explanations and concepts, Deutsch addresses the idea that AGIs or extraterrestrial intelligences might possess concepts humans are inherently incapable of comprehending (a view he attributes to Martin Rees, e.g., apes can't grasp quantum mechanics, perhaps humans can't grasp something beyond it) [[theories_of_intelligence_and_cognition]] <a class="yt-timestamp" data-t="00:03:51">[00:03:51]</a>.
He argues that even if specialized hardware is posited for certain concepts or qualia (like love), this hardware itself must be a form of computer <a class="yt-timestamp" data-t="00:04:50">[00:04:50]</a>. If someone were born without such "love hardware," an artificial device computing the necessary neural signals and chemical adjustments could, in principle, replicate the function, making the experience indistinguishable and allowing an augmented individual to feel love [[human_enhancement_and_intelligence_augmentation]] <a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a> - <a class="yt-timestamp" data-t="00:05:47">[00:05:47]</a>.
Therefore, Deutsch concludes that AGIs and humans share the same "range" of potential capabilities in the sense defined <a class="yt-timestamp" data-t="00:06:08">[00:06:08]</a>.

## Addressing Variations in Human Intelligence

The discussion explored whether all humans are capable of explaining everything that the "smartest" humans can, using the example of a "village idiot" being asked to create the theory of quantum computing <a class="yt-timestamp" data-t="00:06:30">[00:06:30]</a>. The interviewer also cited US literacy statistics, where 21-24% of adults struggle with basic tasks like identifying an expiry date on a driver's license <a class="yt-timestamp" data-t="00:06:48">[00:06:48]</a>.

### Hardware vs. Software in Human Differences
Deutsch posits that tasks like reading a driver's license are beyond any ape's capability <a class="yt-timestamp" data-t="00:07:20">[00:07:20]</a>. While some humans may have brain damage (a hardware issue) preventing them from performing even ape-level tasks <a class="yt-timestamp" data-t="00:07:26">[00:07:26]</a>, he believes that for the 24% with low literacy, the limitation is "definitely not hardware" but rather software <a class="yt-timestamp" data-t="00:07:58">[00:07:58]</a>.
If it were a hardware issue, repair would be needed <a class="yt-timestamp" data-t="00:08:13">[00:08:13]</a>. If it's software, it's not merely a matter of "wanting to" but whether their existing software (their conceptual framework and motivations) is "conceptually ready" to acquire the new program/skill <a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a>. He uses the analogy of Brett Hall wanting to speak Mandarin but not wanting it enough to go through the arduous learning process <a class="yt-timestamp" data-t="00:08:48">[00:08:48]</a>, contrasting this with his ancestors who were forced to learn new languages quickly due to migration <a class="yt-timestamp" data-t="00:09:47">[00:09:47]</a>.
Deutsch suggests that those who cannot perform basic literacy tasks are in a "different culture" and would need to learn that culture, alongside the specific skills, to function at a higher intellectual level within the dominant civilization <a class="yt-timestamp" data-t="00:19:43">[00:19:43]</a>. He believes they could learn if they "wanted to" in the profound sense his ancestors did <a class="yt-timestamp" data-t="00:10:16">[00:10:16]</a>.

### Choice, Culture, and IQ Correlations
When challenged that these same individuals often choose lower-paying, less "cognitively demanding" jobs, Deutsch argues that labeling jobs as "cognitively demanding" begs the question and that this is a "software choice" influenced by culture [[impact_of_culture_and_environment_on_intelligence]] <a class="yt-timestamp" data-t="00:14:06">[00:14:06]</a>. He states that culture assigns a hardware interpretation to the difficulty of tasks <a class="yt-timestamp" data-t="00:14:58">[00:14:58]</a>.
Regarding the high correlation of IQ in identical twins reared apart (0.8) <a class="yt-timestamp" data-t="00:20:09">[00:20:09]</a>, which the interviewer presents as evidence for hardware influence, Deutsch responds that while a hardware theory *might* be true <a class="yt-timestamp" data-t="00:20:53">[00:20:53]</a>, correlations are ubiquitous <a class="yt-timestamp" data-t="00:23:24">[00:23:24]</a>. He suggests there could be unmeasured, uncontrolled variables (e.g., how a child is treated between ages 3.5 and 4.5) that are the true determinants of IQ and also happen to correlate with being an identical twin <a class="yt-timestamp" data-t="00:24:31">[00:24:31]</a>. Parents, he notes, unconsciously process vast amounts of information about their children, which could influence such factors <a class="yt-timestamp" data-t="00:26:41">[00:26:41]</a>.
Software can be genetic, meaning it's present at birth but not necessarily immutable <a class="yt-timestamp" data-t="00:13:05">[00:13:05]</a>.

## Distinguishing Human/AGI Creativity from Animal Problem-Solving

The conversation touched upon animal intelligence, using the example of a cat learning to open a door by jumping on the handle, a behavior it likely hasn't observed <a class="yt-timestamp" data-t="00:27:15">[00:27:15]</a>. The interviewer suggested this resembles a cycle of conjecture and refutation, implying bounded creativity.

Deutsch argues this is perfectly compatible with the cat not being creative in the human/AGI sense <a class="yt-timestamp" data-t="00:27:56">[00:27:56]</a>. He describes animal instinctive knowledge as vast and encoded in their genes, enabling them to thrive in novel situations (e.g., a wolf navigating a forest it has never seen before) <a class="yt-timestamp" data-t="00:28:06">[00:28:06]</a>. This, he claims, is a result of incredibly sophisticated genetic programming that generates relevant behavior based on external input, far beyond current human robotics, but does not involve creativity [[biological_and_cultural_evolution]] <a class="yt-timestamp" data-t="00:29:31">[00:29:31]</a>. The next wolf, under similar circumstances, would do the same thing <a class="yt-timestamp" data-t="00:30:16">[00:30:16]</a>.
Humans, by contrast, can perform tasks like telling a scary story around a campfireâ€”a creative activity involving explanation, which animals do not do, even if they can enact complex narratives in their behavior <a class="yt-timestamp" data-t="00:30:38">[00:30:38]</a>, <a class="yt-timestamp" data-t="00:31:13">[00:31:13]</a>. The cat's ability to jump on a handle is likely part of the same sophisticated program that allows it to, for example, jump on a branch in undergrowth <a class="yt-timestamp" data-t="00:31:30">[00:31:30]</a>, <a class="yt-timestamp" data-t="00:32:36">[00:32:36]</a>.

## Narrow AI vs. Artificial General Intelligence (AGI)

The discussion differentiated between narrow AI and AGI, particularly in the context of AI performing powerful but specific tasks, such as an AI designed to make a trillion dollars on the stock market <a class="yt-timestamp" data-t="00:33:30">[00:33:30]</a>.

Deutsch's view is that even if a non-AGI system (like a "dumb arbitrage machine") achieved such a feat, the true value or ingenuity would lie in the human *idea* for how to search for those arbitrage opportunities or the idea for the system itself, similar to how the idea for a paperclip created value <a class="yt-timestamp" data-t="00:34:12">[00:34:12]</a> - <a class="yt-timestamp" data-t="00:34:57">[00:34:57]</a>.
When asked if a blank neural network (like AlphaZero) fed financial history could be said to have "figured out" the trades, Deutsch conceded this might be possible in a closed system like chess but not in the broader economy [[alphazero_and_efficient_search_techniques]] <a class="yt-timestamp" data-t="00:35:52">[00:35:52]</a>. He argues that most value in the economy is created by the *creation of knowledge* (e.g., the idea for a smartphone), which involves creativity and cannot be anticipated by anything less than an AGI <a class="yt-timestamp" data-t="00:36:22">[00:36:22]</a>.

## Creating AGI Through Simulated Evolution and Ethical Concerns

A potential method for creating AGI through simulated evolution was discussed, along with its ethical implications [[ethical_considerations_and_deployment_of_ai]] <a class="yt-timestamp" data-t="01:14:13">[01:14:13]</a>. Deutsch considers simulating the actual evolution of humans from pre-human, non-people (likened to NPCs) as potentially "the greatest crime in history" <a class="yt-timestamp" data-t="01:14:46">[01:14:46]</a>.
He theorizes that personhood and explanatory creativity might have evolved when the necessary hardware, initially developed for another purpose like transmitting memes, reached a certain threshold <a class="yt-timestamp" data-t="01:15:33">[01:15:33]</a>. As memes became more complex, their transmission would have required creativity from the recipient [[cultural_transmission_knowledge_accumulation_and_social_learning]] <a class="yt-timestamp" data-t="01:16:12">[01:16:12]</a>.
There may have been a period where genuine creativity was used for meme transmission but with very limited resources, creating an "unpleasant" existence for these evolving beings <a class="yt-timestamp" data-t="01:16:26">[01:16:26]</a>, <a class="yt-timestamp" data-t="01:17:14">[01:17:14]</a>. He suggests that suffering could have occurred even when these beings were "blindly" (but creatively) transmitting memes, as they were using genuine creativity but not yet to any good effect for themselves <a class="yt-timestamp" data-t="01:17:39">[01:17:39]</a>. The suffering arises during the evolutionary process before full AGI is achieved and the simulation could be stopped <a class="yt-timestamp" data-t="01:14:27">[01:14:27]</a>.