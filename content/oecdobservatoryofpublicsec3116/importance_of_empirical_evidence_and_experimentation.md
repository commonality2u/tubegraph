---
title: Importance of empirical evidence and experimentation
videoId: AVRS-x9mS7E
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

Empirical evidence and [[experimentation_and_policy_prototyping | experimentation]] are considered foundational in [[behavioral_insights_in_innovation | behavioral science]], providing a means to test what works and ensure evidence-based policymaking <a class="yt-timestamp" data-t="00:17:00">[00:17:00]</a>.

## Challenges and Adaptations During Crisis

During a crisis, such as the COVID-19 pandemic, generating empirical evidence can be challenging due to time and resource constraints <a class="yt-timestamp" data-t="00:37:10">[00:37:10]</a>. The rapid response required means there isn't always the luxury to conduct extensive [[experimentation_in_government_innovation | experimentation]], like Randomized Control Trials (RCTs) that might take 18 months <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>, <a class="yt-timestamp" data-t="00:37:59">[00:37:59]</a>.

In such dynamic environments, behavioral science teams have had to adapt:
*   **Smaller Pilots** Rather than large-scale RCTs, smaller pilots are conducted to learn and re-adapt quickly to fast-changing environments <a class="yt-timestamp" data-t="00:38:10">[00:38:10]</a>, <a class="yt-timestamp" data-t="01:01:12">[01:01:12]</a>.
*   **Rapid Assessment** The focus shifts to rapid assessment, sometimes using quasi-experimental methods <a class="yt-timestamp" data-t="00:38:35">[00:38:35]</a>.
*   **Experimental Surveys** Surveys, such as Knowledge, Attitudes, and Perception (CAP) surveys, are regularly conducted and enhanced with an experimental angle to test interventions without affecting the survey's validity <a class="yt-timestamp" data-t="00:38:40">[00:38:40]</a>, <a class="yt-timestamp" data-t="00:39:10">[00:39:10]</a>. This allows for quick insights, for instance, on what makes people tick to comply with measures <a class="yt-timestamp" data-t="00:41:12">[00:41:12]</a>.
*   **Timely Answers** Policymakers need evidence-based answers quickly, not in several months <a class="yt-timestamp" data-t="00:43:53">[00:43:53]</a>. The challenge lies in balancing academic rigor with timely, relevant answers <a class="yt-timestamp" data-t="00:43:56">[00:43:56]</a>.

### Limitations of Surveys Alone
While surveys are useful, they are not sufficient for empirical evidence as they do not provide a counterfactual <a class="yt-timestamp" data-t="00:41:51">[00:41:51]</a>. Building and conducting actual experiments remain crucial for understanding what truly works <a class="yt-timestamp" data-t="00:42:06">[00:42:06]</a>.

## Future of Empirical Evidence in Government

Going forward, there is a strong desire to continue leveraging [[experimental_approaches | experimental approaches]] <a class="yt-timestamp" data-t="00:19:13">[00:19:13]</a>.
Key areas for the future of empirical evidence in government include:
*   **Dedicated Resources for Experimentation** Allocating a portion of resources specifically for anticipating long-term problems and working on [[experimentation_and_policy_prototyping | experimentation]] <a class="yt-timestamp" data-t="00:23:50">[00:23:50]</a>.
*   **Mainstreaming Behavioral Science** Integrating [[behavioral_insights_in_innovation | behavioral science]] and its [[utilizing_data_for_policymaking_and_evidencebased_solutions | evidence-based approach]] into how governments tackle policy problems, ensuring a behavioral lens is applied to government work <a class="yt-timestamp" data-t="00:34:45">[00:34:45]</a>, <a class="yt-timestamp" data-t="00:35:47">[00:35:47]</a>.
*   **Collaborative Learning** Learning from other countries and contexts to avoid reinventing the wheel and adapting insights from global experiences <a class="yt-timestamp" data-t="00:45:51">[00:45:51]</a>.
*   **"What Works" Centers** Establishing a central resource or "what works" center for best practices in compliance, communication, and other areas during crises <a class="yt-timestamp" data-t="00:49:25">[00:49:25]</a>.
*   **Standardizing Evidence Quality** Creating labels or indicators for the type of evidence supporting recommendations (e.g., based on surveys, interviews, or RCTs) to set clear expectations for policymakers and ensure shared standards for quality <a class="yt-timestamp" data-t="00:50:28">[00:50:28]</a>.
*   **Pre-registration of Trials** Encouraging pre-registration of trials within the behavioral insights community to track predictions and assess the accuracy of expected outcomes <a class="yt-timestamp" data-t="00:52:10">[00:52:10]</a>.
*   **Ethical Considerations** As the field grows, ensuring robust ethical standards, especially with the integration of AI and big data <a class="yt-timestamp" data-t="00:56:25">[00:56:25]</a>.

The field of [[behavioral_science_and_misinformation | behavioral science]] is still young, and continuous testing, learning, and adaptation are essential to its growth and effective application to major policy challenges <a class="yt-timestamp" data-t="00:53:44">[00:53:44]</a>, <a class="yt-timestamp" data-t="00:54:06">[00:54:06]</a>.