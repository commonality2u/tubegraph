---
title: Behavioral science applications in combating misinformation
videoId: IUItMNuR23s
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

This article summarizes a meet-up focused on [[Behavioral science and misinformation | behavioral science]] and misinformation, co-organized by the OECD and UNDP. The event aimed to share insights from speakers and discuss how attendees are using or would like to use [[Behavioral science and misinformation | behavioral science]] to tackle misinformation <a class="yt-timestamp" data-t="00:00:39">[00:00:39]</a>.

## The Growing Threat of Misinformation

The spread of misinformation is a serious and escalating concern, posing a potential threat to the future of democracy <a class="yt-timestamp" data-t="00:01:05">[00:01:05]</a>. The current information ecosystem is characterized by limited regulation, increasing algorithmic determinism, and a media business constantly competing for limited attention <a class="yt-timestamp" data-t="00:01:16">[00:01:16]</a>.

While academic literature on misinformation and [[Behavioral science and misinformation | behavioral science]] is prolific, governments often still rely on traditional tools like education or regulation, with limited consideration for evidence-based solutions from [[Behavioral science and misinformation | behavioral science]] <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>. These solutions could proactively change attitudes and behaviors contributing to the spread of misinformation <a class="yt-timestamp" data-t="00:02:24">[00:02:24]</a>.

## Canadian Experience: Applying Behavioral Science to COVID-19 Misinformation

Lauren Conway, Lead Behavioral Scientist at the Impact and Innovation Unit within the Canadian federal government, shared insights from their work <a class="yt-timestamp" data-t="00:03:55">[00:03:55]</a>. Her team applies [[Behavioral science and misinformation | behavioral science]] to various policy areas, including the COVID-19 response <a class="yt-timestamp" data-t="00:04:07">[00:04:07]</a>.

### Data Collection and Key Findings
The Canadian team rapidly developed a research architecture to support responsive research and analysis for COVID-19 <a class="yt-timestamp" data-t="00:07:10">[00:07:10]</a>. They have been collecting data from Canadians since April 2020, primarily through three channels <a class="yt-timestamp" data-t="00:07:21">[00:07:21]</a>:
*   **COSMO Canada:** A nationwide longitudinal tracking study adopted from the WHO's behavioral insights tool, following a cohort of 2,000 Canadians to monitor their knowledge, risk perceptions, and self-reported behaviors as the pandemic evolves <a class="yt-timestamp" data-t="00:07:33">[00:07:33]</a>.
*   Deeper dives on public health behaviors like mask-wearing and vaccination through online survey experiments and in-field work <a class="yt-timestamp" data-t="00:08:26">[00:08:26]</a>.

A consistent finding is that the ability to discern the accuracy of misinformation has emerged as an important factor in understanding [[the_impact_of_misinformation_on_public_health_behaviors | public health behaviors]] <a class="yt-timestamp" data-t="00:08:52">[00:08:52]</a>. For example, presenting false statements related to COVID-19 (e.g., exaggerated death rates, vaccines altering DNA) revealed that 20-30% of the sample either believed them true or were unsure of their accuracy <a class="yt-timestamp" data-t="00:09:11">[00:09:11]</a>.

Furthermore, the ability to correctly identify misinformation statements about COVID-19 was strongly and uniquely associated with Canadians' intentions to vaccinate <a class="yt-timestamp" data-t="00:10:53">[00:10:53]</a>. Those better at identifying misinformation were more likely to get vaccinated <a class="yt-timestamp" data-t="00:11:09">[00:11:09]</a>. This pattern consistently appeared as one of the strongest predictors, particularly in later waves of the pandemic <a class="yt-timestamp" data-t="00:11:17">[00:11:17]</a>.

### Research Program Objectives
In response to these findings, Canada launched a [[Behavioral science and misinformation | behavioral science]] research program with two main objectives <a class="yt-timestamp" data-t="00:12:28">[00:12:28]</a>:
1.  **Understanding the Landscape:** Better comprehend the COVID-19 misinformation landscape in Canada, including individual and environmental factors underlying susceptibility to misinformation and propensity to share it online <a class="yt-timestamp" data-t="00:12:41">[00:12:41]</a>.
2.  **Designing Interventions:** Using this knowledge to design and test [[Interventions and strategies to reduce misinformation | interventions]] effective in reducing or slowing the spread of misinformation online <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>.

### Insights from Literature and Experts
Initial scoping work, including ongoing reviews of academic literature and key informant interviews with academic experts across disciplines, yielded several insights <a class="yt-timestamp" data-t="00:13:30">[00:13:30]</a>:
*   **Susceptibility:** Socio-demographic factors like gender and age show mixed evidence, but cognitive and motivational factors like trust in public institutions and science, reasoning skills, and numeracy have stronger associations with susceptibility <a class="yt-timestamp" data-t="00:15:16">[00:15:16]</a>. The structure of online environments and social network effects can amplify cognitive biases (e.g., echo chambers, false consensus, confirmation bias) <a class="yt-timestamp" data-t="00:15:46">[00:15:46]</a>.
*   **Sharing Behavior:** Factors related to susceptibility may differ from those associated with the propensity to share misinformation <a class="yt-timestamp" data-t="00:16:17">[00:16:17]</a>. One prominent theory suggests people share due to **inattention** to accuracy, as [[the_role_of_social_media_platforms_in_spreading_misinformation | social media platforms]] often focus attention on other factors like the desire to attract followers <a class="yt-timestamp" data-t="00:16:42">[00:16:42]</a>. Research suggests attention-based [[Interventions and strategies to reduce misinformation | interventions]] that prompt users to think about accuracy might be scalable <a class="yt-timestamp" data-t="00:17:10">[00:17:10]</a>.
*   **Interventions:** More research is needed using a [[Behavioral science and misinformation | behavioral]] and cognitive lens to understand which strategies are most effective, for whom, and if they can be realistically implemented and scaled <a class="yt-timestamp" data-t="00:17:44">[00:17:44]</a>.

### [[challenges_in_addressing_misinformation_in_different_contexts | Challenges]] and Next Steps
A key takeaway from interviews is that collective knowledge gaps about misinformation stem from a lack of research and empirical evidence in real-world contexts, particularly on [[the_role_of_social_media_platforms_in_spreading_misinformation | social media platforms]] <a class="yt-timestamp" data-t="00:18:16">[00:18:16]</a>. There is frustration in the academic community regarding limited access to social media platform data <a class="yt-timestamp" data-t="00:18:52">[00:18:52]</a>.

Specific [[challenges_in_addressing_misinformation_in_different_contexts | challenges]] identified include <a class="yt-timestamp" data-t="00:19:12">[00:19:12]</a>:
*   **Measuring Spread:** Difficulty in understanding and measuring the spread of misinformation <a class="yt-timestamp" data-t="00:19:18">[00:19:18]</a>. Most knowledge on spread comes from platforms like Twitter (due to open APIs), while less is known about platforms where misinformation may be more rampant (e.g., Facebook, TikTok, WhatsApp) <a class="yt-timestamp" data-t="00:19:26">[00:19:26]</a>.
*   **Measuring Impact:** Difficulty measuring the impact of exposure to misinformation. Researchers often have access to "expression data" (likes, shares) but lack "impression data" (who actually read or was exposed to content), hindering a true understanding of misinformation's impact <a class="yt-timestamp" data-t="00:19:53">[00:19:53]</a>.
*   **Intervention Testing:** Minimal opportunities for researchers to collaborate with platforms mean that tested [[Interventions and strategies to reduce misinformation | interventions]] often lack ecological and external validity, making it hard to know if they would work in real-world contexts <a class="yt-timestamp" data-t="00:20:25">[00:20:25]</a>. The current evidence also heavily relies on self-report data, which has limitations <a class="yt-timestamp" data-t="00:20:53">[00:20:53]</a>.

The Canadian team plans to synthesize findings, narrow the scope of their work, and identify opportunities for research and testing, with a focus on understanding the propensity to share information <a class="yt-timestamp" data-t="00:21:21">[00:21:21]</a>. They also plan a first-step trial in partnership with the OECD to test ideas in the Canadian context <a class="yt-timestamp" data-t="00:21:41">[00:21:41]</a>.

## Lebanese Experience: Context-Specific Solutions

Rory Jibanian, Head of Experimentation at the UNDP Lebanon Accelerator Lab, presented on their work <a class="yt-timestamp" data-t="00:23:19">[00:23:19]</a>. He emphasized that behaviorally informed [[Interventions and strategies to reduce misinformation | interventions]] must operate within an ecosystem of different factors and forces, requiring regular understanding of how behaviors are situated in a constantly changing environment <a class="yt-timestamp" data-t="00:24:23">[00:24:23]</a>.

### Lebanon's Compounded Crises and Information Landscape
Lebanon is experiencing compounded crises, including political deadlock, an economic collapse leading to widespread poverty and hyperinflation, and the devastating Beirut port explosion in August 2020 <a class="yt-timestamp" data-t="00:25:58">[00:25:58]</a>. These crises have led to declining public faith in the government and rising fatigue and anxiety <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>.

The media landscape in Lebanon is further muddied by misinformation. Traditional media outlets are often affiliated with the country's political parties, fragmenting information access and resulting in further distrust in formal or legacy media platforms <a class="yt-timestamp" data-t="00:27:42">[00:27:42]</a>. [[The_role_of_social_media_platforms_in_spreading_misinformation | Social media platforms]] also contribute to information pollution <a class="yt-timestamp" data-t="00:28:15">[00:28:15]</a>.

### Lack of Bandwidth and Tailored Interventions
The majority of Lebanese people have little to no bandwidth to verify information or critically engage with it, instead relying on common sense or self-constructed judgment of information or sources <a class="yt-timestamp" data-t="00:29:13">[00:29:13]</a>. Fact-checking is not common, with the top reason being a lack of interest <a class="yt-timestamp" data-t="00:29:29">[00:29:29]</a>.

UNDP Lebanon's COVID-19 chatbot, designed to provide reliable health information via WhatsApp, unexpectedly became an outlet for people to seek information and resources about the country's other various crises, indicating that COVID-19 was not a priority for many <a class="yt-timestamp" data-t="00:30:20">[00:30:20]</a>.

Understanding this lack of bandwidth necessitates designing [[Interventions and strategies to reduce misinformation | interventions]] accordingly <a class="yt-timestamp" data-t="00:31:02">[00:31:02]</a>.
*   **Lightweight Interactions:** Collaboration with TED's Healthy Internet Project encourages lightweight interactions, asking Lebanese youth to flag potential misinformation rather than bearing the burden of fact-checking <a class="yt-timestamp" data-t="00:31:09">[00:31:09]</a>. This crowdsourcing approach shifts responsibility, allowing many people to contribute in a tiny way to address misinformation at a structural level <a class="yt-timestamp" data-t="00:31:45">[00:31:45]</a>.
*   **Beyond the Digital:** Misinformation has a long history outside the digital sphere in Lebanon, dating back to the civil war when rumors were used by political parties and militias to maintain fear <a class="yt-timestamp" data-t="00:32:15">[00:32:15]</a>. Traditional media, particularly TV, remains a significant source of news, despite being often affiliated with political parties and thus distrusted <a class="yt-timestamp" data-t="00:32:51">[00:32:51]</a>. UNDP Lebanon is launching a new research project to understand common misinformation topics and their relation to behaviors, informing a future behaviorally informed campaign that will be both digital and analog <a class="yt-timestamp" data-t="00:33:43">[00:33:43]</a>.
*   **Context is Key:** Research showed that a one-size-fits-all approach will not work for interventions in Lebanon, highlighting the importance of considering generational divides and urban-rural specificities even in a small country <a class="yt-timestamp" data-t="00:34:38">[00:34:38]</a>.

### [[policy_implications_for_tackling_misinformation | The Role of Government]]
In Lebanon, due to a lack of a functioning government and resulting public distrust, governments cannot be the main player in fighting misinformation <a class="yt-timestamp" data-t="00:35:10">[00:35:10]</a>. Approaches that foreground the government's role in fact-checking quickly lose traction <a class="yt-timestamp" data-t="00:37:57">[00:37:57]</a>. For example, a successful Facebook ad campaign encouraging survey participation used a message highlighting a conspiracy theory about COVID-19 as a government control mechanism, demonstrating people's greater interest in engaging with such narratives than in trusting official sources <a class="yt-timestamp" data-t="00:36:08">[00:36:08]</a>. Campaigns in Lebanon avoid government logos, as they often hurt rather than help <a class="yt-timestamp" data-t="00:37:17">[00:37:17]</a>, instead including logos of trusted agencies like WHO and UNICEF <a class="yt-timestamp" data-t="00:37:36">[00:37:36]</a>.

### Conclusion on [[Behavioral science and misinformation | Behavioral Science Applications]]
*   Architects of disinformation often have a deep understanding of human behavior, surpassing that of organizations trying to combat it <a class="yt-timestamp" data-t="00:38:11">[00:38:11]</a>.
*   It is crucial to rigorously research factors shaping people's perceptions and behaviors, rather than relying on assumptions or general behavioral trends <a class="yt-timestamp" data-t="00:38:21">[00:38:21]</a>. This research must be grounded in specific contexts <a class="yt-timestamp" data-t="00:38:33">[00:38:33]</a>.
*   Research results should be made accessible to other organizations and, importantly, to the communities served <a class="yt-timestamp" data-t="00:38:40">[00:38:40]</a>.

## Debunking vs. Inoculation and [[The role of social media platforms in spreading misinformation | Social Media Platforms]]

A core question is whether fundamental redesign of [[the_role_of_social_media_platforms in spreading misinformation | social media platforms]] is necessary to fight misinformation <a class="yt-timestamp" data-t="00:48:51">[00:48:51]</a>. Speakers noted that influencing change will require redesigning online environments and gaining access to platform data to understand the problem and test [[Interventions and strategies to reduce misinformation | interventions]] <a class="yt-timestamp" data-t="00:50:37">[00:50:37]</a>. The solution to this remains largely unclear <a class="yt-timestamp" data-t="00:51:06">[00:51:06]</a>.

There is a discussion on whether **inoculation** (pre-bunking) is a sufficient long-term solution <a class="yt-timestamp" data-t="00:55:02">[00:55:02]</a>.
*   **Complex Problem, Multiple Solutions:** Given the complexity, heterogeneous populations, and multiple drivers of misinformation, no single solution will fit all <a class="yt-timestamp" data-t="00:55:21">[00:55:21]</a>. A range of solutions that vary in terms of user engagement is required <a class="yt-timestamp" data-t="00:55:47">[00:55:47]</a>.
*   **Inoculation's Promise and Limitations:** Inoculation approaches show promise, but more evidence is needed to understand how their effects decay over time, which is a broader limitation in the literature <a class="yt-timestamp" data-t="00:56:00">[00:56:00]</a>.
*   **Debunking Nuances:** While some literature suggests debunking is not an ideal or effective strategy and may have backfire effects, other academics argue these effects are overblown and debunking can have a place in certain contexts <a class="yt-timestamp" data-t="00:56:22">[00:56:22]</a>.
*   **Evolving Nature of Misinformation:** Misinformation is not a static phenomenon; its "architects" constantly evolve their methods <a class="yt-timestamp" data-t="00:57:15">[00:57:15]</a>. Therefore, a "family of solutions" based on different target groups, areas, and personas is needed, requiring ongoing segmentation and adaptation <a class="yt-timestamp" data-t="00:57:46">[00:57:46]</a>. The focus must be on continuously monitoring new forms of misinformation and designing new [[Interventions and strategies to reduce misinformation | interventions]] to tackle them <a class="yt-timestamp" data-t="00:58:18">[00:58:18]</a>.