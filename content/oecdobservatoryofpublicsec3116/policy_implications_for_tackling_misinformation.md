---
title: Policy implications for tackling misinformation
videoId: soQN97fWlxQ
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

Addressing misinformation and disinformation is an undoubtedly important topic <a class="yt-timestamp" data-t="00:00:07">[00:00:07]</a>. The Organisation for Economic Co-operation and Development (OECD)'s Behavioral Insights Network is actively applying [[behavioral_science_and_misinformation | Behavioral Science]] to these issues <a class="yt-timestamp" data-t="00:00:28">[00:00:28]</a>. The Office of Evaluation Sciences (OES) in the U.S. federal government also applies behavioral insights across federal agencies, emphasizing interdisciplinary perspectives, rigorous evaluation, and evidence-based policy advice <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>.

## The Global Nature of Misinformation

The spread of inaccurate information has trickled into all aspects of public life, including health, education, financial markets, and political affairs <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>. This was particularly evident during the COVID-19 pandemic <a class="yt-timestamp" data-t="00:05:11">[00:05:11]</a>. The global challenge of misinformation heavily depends on individual behaviors, as its spread relies on people's choices in how they consume and share information <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>.

Effective responses to tackle misinformation should be designed and tested across borders, ideally through [[international_collaboration_on_misinformation | collaboration across governments]] <a class="yt-timestamp" data-t="00:06:26">[00:06:26]</a>. This is because "fake news knows no borders" <a class="yt-timestamp" data-t="00:06:20">[00:06:20]</a>. Such [[international_collaboration_on_misinformation | partnerships]] foster inclusivity and diversity in approaching complex policy challenges at local, regional, or global levels <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>. Coordinating efforts across diverse teams, despite potential [[challenges_in_addressing_misinformation_in_different_contexts | challenges]], demonstrates the value of cross-border experimentation and coordination, particularly when dealing with [[challenges_in_addressing_misinformation_in_different_contexts | challenges that know no boundaries]] and where solutions benefit global public welfare <a class="yt-timestamp" data-t="00:01:32">[00:01:32]</a>.

The success of most policy issues, whether climate emergencies, socioeconomic inequalities, or the rising influence of [[the_role_of_social_media_platforms_in_spreading_misinformation | digital technologies]] on public life, can be partially attributed to individual behaviors and preferences <a class="yt-timestamp" data-t="00:01:56">[00:01:56]</a>. Therefore, [[behavioral_science_applications_in_combating_misinformation | behavioral experimentation]] is increasingly used by policymakers to test what works and doesn't, guided by empirical evidence and aiming to put real people at the center of policy design, implementation, and evaluation <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>. Knowledge and experience sharing are critical for the responsible and sustained use of [[behavioral_science_and_misinformation | Behavioral Science]] in policy design and implementation <a class="yt-timestamp" data-t="00:02:35">[00:02:35]</a>.

## Findings from a Cross-Border Collaboration

A first-of-its-kind partnership between the OECD, the Canadian Privy Council Office's Impact and Innovation Unit, and the French Behavioral Insights Unit aimed to apply [[behavioral_science_and_misinformation | Behavioral Science]] to misinformation <a class="yt-timestamp" data-t="00:02:21">[00:02:21]</a>, <a class="yt-timestamp" data-t="00:06:49">[00:06:49]</a>, <a class="yt-timestamp" data-t="00:07:08">[00:07:08]</a>. The objectives were to:
*   Understand the complexities of why people share misinformation on [[the_role_of_social_media_platforms_in_spreading_misinformation | social media]] <a class="yt-timestamp" data-t="00:07:16">[00:07:16]</a>.
*   Evaluate the impact of [[behavioral_science_applications_in_combating_misinformation | behavioral interventions]] on choices to share fake news <a class="yt-timestamp" data-t="00:07:23">[00:07:23]</a>.
*   Co-develop best practices to inform policy responses <a class="yt-timestamp" data-t="00:07:31">[00:07:31]</a>.

### Understanding Why Misinformation is Shared

A key hypothesis replicated and extended in the Canadian context is that people share misinformation not only on purpose, but also partially due to inattention to accuracy when engaging with news online <a class="yt-timestamp" data-t="00:08:00">[00:08:00]</a>, <a class="yt-timestamp" data-t="00:08:13">[00:08:13]</a>.

The study found a disconnect between sharing intentions and knowledge of what is true and false <a class="yt-timestamp" data-t="00:11:48">[00:11:48]</a>. Individuals may share fake news even when they do not believe it to be true <a class="yt-timestamp" data-t="00:11:58">[00:11:58]</a>. While people were more likely to rate true news as accurate and had higher intentions to share true headlines compared to false news, the difference in sharing intentions for true versus false headlines was almost four times smaller than the difference in accuracy judgments <a class="yt-timestamp" data-t="00:11:10">[00:11:10]</a>.

Individual differences in trust and information consumption patterns significantly shape beliefs and sharing of misinformation <a class="yt-timestamp" data-t="00:16:20">[00:16:20]</a>. Three clusters of participants were identified based on trust, information consumption, cognitive factors (conspiracy mentality, openness to evidence), and psychological reactance <a class="yt-timestamp" data-t="00:13:27">[00:13:27]</a>:
*   **Non-trusting**: Low trust in all information sources, low openness to evidence, high conspiratorial thinking, high psychological reactance (approx. 20% of sample) <a class="yt-timestamp" data-t="00:13:59">[00:13:59]</a>.
*   **High-trusting**: High trust in all information sources, especially [[the_role_of_social_media_platforms_in_spreading_misinformation | social media]], low openness to evidence, medium-high conspiratorial thinking, high psychological reactance <a class="yt-timestamp" data-t="00:14:21">[00:14:21]</a>.
*   **Institution-trusting**: High trust in institutional sources, low trust in [[the_role_of_social_media_platforms_in_spreading_misinformation | social media]], high openness to evidence, low conspiratorial thinking, low psychological reactance <a class="yt-timestamp" data-t="00:14:44">[00:14:44]</a>.

The non-trusting and high-trusting (social media trusting) clusters exhibited significantly greater belief in and sharing of fake news compared to the institution-trusting cluster <a class="yt-timestamp" data-t="00:15:33">[00:15:33]</a>.

### Effective Interventions

Two scalable [[interventions_and_strategies_to_reduce_misinformation | interventions]] aimed at boosting attention before people engage with news online were tested in Canada with almost 2,000 Canadians <a class="yt-timestamp" data-t="00:09:29">[00:09:29]</a>, <a class="yt-timestamp" data-t="00:09:50">[00:09:50]</a>:
1.  **Accuracy Evaluation**: Respondents rated the accuracy of a random news headline <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>.
2.  **[[digital_media_literacy_tips | Digital Media Literacy Tips]]**: Respondents viewed a brief list of media literacy tips before seeing news headlines, such as "investigate the source" or "look at other reports" <a class="yt-timestamp" data-t="00:09:16">[00:09:16]</a>.

Both [[interventions_and_strategies_to_reduce_misinformation | interventions]] were effective <a class="yt-timestamp" data-t="00:12:26">[00:12:26]</a>. The [[digital_media_literacy_tips | digital media literacy tips]] had the greatest impact, reducing intentions to share fake news by 21% <a class="yt-timestamp" data-t="00:12:31">[00:12:31]</a>. This intervention was found to be similarly effective across all identified clusters (non-trusting, high-trusting, institution-trusting) <a class="yt-timestamp" data-t="00:32:08">[00:32:08]</a>, suggesting that these types of [[interventions_and_strategies_to_reduce_misinformation | interventions]] are broadly useful regardless of demographic variables or political ideology <a class="yt-timestamp" data-t="00:33:08">[00:33:08]</a>. The tips worked most effectively on information rated as most inaccurate, pointing to the accuracy mechanism of the intervention <a class="yt-timestamp" data-t="00:38:53">[00:38:53]</a>.

## Key Policy Messages

The research highlights three main policy messages:

1.  **Don't Ignore the Human Factor**: A comprehensive policy response to both disinformation and misinformation must include an expanded understanding of human behavior <a class="yt-timestamp" data-t="00:16:43">[00:16:43]</a>. Everything governments do—legislative, regulatory, program, communications—has a human behavioral component, and understanding this is crucial for the success of any efforts <a class="yt-timestamp" data-t="00:46:53">[00:46:53]</a>. [[behavioral_science_and_misinformation | Behavioral Science]] is key for all governments as a policy tool <a class="yt-timestamp" data-t="00:47:22">[00:47:22]</a>.

2.  **Empower People**: The collaboration focused on empowering users and changing their behaviors rather than regulating content <a class="yt-timestamp" data-t="00:17:17">[00:17:17]</a>. Empowering users offers effective and scalable [[interventions_and_strategies_to_reduce_misinformation | solutions]] that can complement holistic policy strategies and potentially offset the threat of fake news without direct content regulation <a class="yt-timestamp" data-t="00:17:23">[00:17:23]</a>. This approach aims to preserve individual autonomy while fostering better digital competencies <a class="yt-timestamp" data-t="00:36:28">[00:36:28]</a>. These types of interventions are seen as less complex to operationalize than systemic changes <a class="yt-timestamp" data-t="00:43:09">[00:43:09]</a>.

3.  **Find What Works Across Borders**: Governments should conduct rigorous policy experiments in [[international_collaboration_on_misinformation | collaboration with other countries]] to generate sustainable responses to the spread of misinformation <a class="yt-timestamp" data-t="00:17:43">[00:17:43]</a>. This cross-border approach, as demonstrated by the collaboration, offers a Brain Trust for navigating the complex landscape of misinformation <a class="yt-timestamp" data-t="00:23:45">[00:23:45]</a>. It allows for learning from diverse perspectives, sense-checking assumptions, and gaining technical expertise <a class="yt-timestamp" data-t="00:24:37">[00:24:37]</a>. This fosters knowledge transfer and helps overcome silos in policy work <a class="yt-timestamp" data-t="00:30:07">[00:30:07]</a>.

While these findings are an important step, they are not a "silver bullet" to solve all problems <a class="yt-timestamp" data-t="00:47:31">[00:47:31]</a>. Misinformation is often a symptom of larger issues in democracies, particularly an erosion of trust in governments and institutions <a class="yt-timestamp" data-t="00:48:12">[00:48:12]</a>. Therefore, addressing the core component of trust is crucial, alongside tackling misinformation itself <a class="yt-timestamp" data-t="00:48:51">[00:48:51]</a>.

The OECD's broader "Building Trust and Reinforcing Democracy" initiative looks at key governance challenges to democracy, including misinformation, participation and representation, dealing with global challenges and undue foreign influence, delivering on climate goals, and transitioning institutions from an analog to a digital world <a class="yt-timestamp" data-t="00:51:51">[00:51:51]</a>. The work on misinformation is split into three areas, aiming for a whole-of-government and whole-of-society approach, incorporating [[digital_media_literacy_tips | media literacy]], regulatory transparency (not content regulation), and competition angles regarding platforms <a class="yt-timestamp" data-t="00:53:26">[00:53:26]</a>. Building societal resilience to misinformation, including understanding human behavior, is a primary focus <a class="yt-timestamp" data-t="00:54:07">[00:54:07]</a>.