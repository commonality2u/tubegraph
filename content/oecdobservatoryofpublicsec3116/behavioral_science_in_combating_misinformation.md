---
title: Behavioral science in combating misinformation
videoId: IUItMNuR23s
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

The spread of [[Misinformation and disinformation|misinformation]] is recognized as an increasingly serious problem, posing a potential threat to the future of democracy <a class="yt-timestamp" data-t="01:03:03">[01:03:03]</a>. The contemporary information ecosystem is characterized by limited regulation and increasing algorithmic determinism, where the media business constantly competes for limited human attention <a class="yt-timestamp" data-t="01:13:59">[01:13:59]</a>. While academic literature on [[Misinformation and disinformation|misinformation]] and [[Behavioral science in policy making|behavioral science]] is prolific, governments often still rely on traditional tools like education or regulation, with limited consideration for evidence-based solutions from [[Behavioral science in policy making|behavioral science]] <a class="yt-timestamp" data-t="02:05:05">[02:05:05]</a>.

## OECD's Approach to Misinformation

The OECD has a stream of work focused on [[Misinformation and disinformation|misinformation]], leading to several open-source publications available on their website <a class="yt-timestamp" data-t="01:31:31">[01:31:31]</a>. Current efforts are concentrated on developing principles for good public communications to counter [[Misinformation and disinformation|misinformation]] and [[Misinformation and disinformation|disinformation]] <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a>.

## Canadian Government's Behavioral Science Initiative

The Canadian federal government's Impact and Innovation Unit, specifically its behavioral science team, pivoted entirely to supporting the government's COVID-19 response <a class="yt-timestamp" data-t="06:49:00">[06:49:00]</a>. This shift necessitated the rapid establishment of a new research architecture to support quick, responsive analysis <a class="yt-timestamp" data-t="07:10:10">[07:10:10]</a>.

### Data Collection and Key Findings
The team has been collecting data from Canadians since April 2020 using three main channels <a class="yt-timestamp" data-t="07:24:00">[07:24:00]</a>:
1.  **COSMO Canada**: A nationwide longitudinal tracking study, adapted from the WHO's behavioral insights tool, following a cohort of about 2,000 Canadians <a class="yt-timestamp" data-t="07:33:00">[07:33:00]</a>. This study monitors knowledge, risk perceptions, and self-reported behaviors as the pandemic evolves, identifying early warning signs <a class="yt-timestamp" data-t="07:50:00">[07:50:00]</a>.
2.  **Online Survey Experiments**: Deeper dives into key public health behaviors like mask-wearing and vaccination <a class="yt-timestamp" data-t="08:26:00">[08:26:00]</a>.
3.  **In-field Work** <a class="yt-timestamp" data-t="08:34:00">[08:34:00]</a>.

The ability to discern the accuracy of [[Misinformation and disinformation|misinformation]] has emerged as a significant factor in their analyses <a class="yt-timestamp" data-t="08:52:00">[08:52:00]</a>. For instance, in COSMO, respondents were presented with true and false COVID-19 statements drawn from fact-checking websites <a class="yt-timestamp" data-t="09:13:00">[09:13:00]</a>. Between 20-30% of the sample either classified false statements as true or were unsure about their accuracy <a class="yt-timestamp" data-t="09:50:00">[09:50:00]</a>.

Advanced models showed that the ability to correctly identify [[Misinformation and disinformation|misinformation]] statements about COVID-19 was strongly associated with Canadians' intentions to get vaccinated <a class="yt-timestamp" data-t="10:56:00">[10:56:00]</a>. The better someone was at identifying [[Misinformation and disinformation|misinformation]], the more likely they were to get vaccinated, making it one of the strongest predictors, particularly in later waves of the pandemic <a class="yt-timestamp" data-t="11:11:00">[11:11:00]</a>. For example, 90% of individuals who would get a vaccine as soon as available identified all [[Misinformation and disinformation|misinformation]] statements as false <a class="yt-timestamp" data-t="11:39:00">[11:39:00]</a>.

### Research Program and Insights
In response to these findings, a [[Behavioral science in policy making|behavioral science]]-grounded research program was launched with two main objectives <a class="yt-timestamp" data-t="12:28:00">[12:28:00]</a>:
1.  **Understand the Landscape**: Better understand the COVID-19 [[Misinformation and disinformation|misinformation]] and [[Misinformation and disinformation|disinformation]] landscape in Canada, including individual and environmental factors underlying susceptibility to [[Misinformation and disinformation|misinformation]] and the propensity to share it online <a class="yt-timestamp" data-t="12:41:00">[12:41:00]</a>.
2.  **Design and Test Interventions**: Use this knowledge to design and test effective interventions to reduce or slow the spread of [[Misinformation and disinformation|misinformation]] online, in collaboration with the Canadian federal government and OECD <a class="yt-timestamp" data-t="13:01:00">[13:01:00]</a>.

Early insights from ongoing literature reviews and expert interviews indicate:
*   **Susceptibility**: Socio-demographic factors like gender and age show mixed evidence regarding susceptibility, but cognitive and motivational factors like trust in public institutions and science, reasoning, and numeracy skills have stronger associations <a class="yt-timestamp" data-t="15:19:00">[15:19:00]</a>. The structure of online environments, such as echo chambers, can amplify existing cognitive biases like false consensus effects and confirmation biases <a class="yt-timestamp" data-t="15:45:00">[15:45:00]</a>.
*   **Sharing**: Factors related to susceptibility may differ from those associated with the propensity to share [[Misinformation and disinformation|misinformation]] <a class="yt-timestamp" data-t="16:17:00">[16:17:00]</a>. A prominent theory suggests people share due to inattention to accuracy, with social media focusing their attention on other factors like attracting followers <a class="yt-timestamp" data-t="16:42:00">[16:42:00]</a>. Research by Pennycook and Rand suggests attention-based interventions can nudge users to think about accuracy <a class="yt-timestamp" data-t="17:05:00">[17:05:00]</a>.
*   **Challenges**: A major gap is the lack of research and empirical evidence in real-world contexts, particularly on social media platforms <a class="yt-timestamp" data-t="18:16:00">[18:16:00]</a>. There's frustration in the academic community regarding limited access to social media platform data, which hinders understanding the nature and spread of [[Misinformation and disinformation|misinformation]] <a class="yt-timestamp" data-t="18:52:00">[18:52:00]</a>. It's difficult to measure the impact of exposure to [[Misinformation and disinformation|misinformation]], as researchers often have expression data (likes, shares) but not impression data (who actually read content) <a class="yt-timestamp" data-t="19:43:00">[19:43:00]</a>. Interventions often lack ecological and external validity because rigorous testing on social media platforms is challenging <a class="yt-timestamp" data-t="20:25:00">[20:25:00]</a>.

## UNDP Lebanon's Contextual Approach

UNDP Lebanon's work highlights that behaviorally informed interventions must consider the broader ecosystem of factors and forces <a class="yt-timestamp" data-t="24:23:00">[24:23:00]</a>. In Lebanon, the country faces compounded crises including political deadlock, economic collapse, hyperinflation, capital control, and the Beirut port explosion <a class="yt-timestamp" data-t="25:56:00">[25:56:00]</a>. This has led to declining trust in [[Government and media trust in misinformation contexts|government and media trust]] and rising fatigue <a class="yt-timestamp" data-t="27:01:00">[27:01:00]</a>.

### Information Landscape and Behavior
The media landscape in Lebanon is fragmented, with traditional outlets largely affiliated with political parties, leading to further distrust in formal or legacy media <a class="yt-timestamp" data-t="27:42:00">[27:42:00]</a>. Social media also contributes to "information pollution" <a class="yt-timestamp" data-t="28:15:00">[28:15:00]</a>.

A key finding is that the majority of people in Lebanon have little to no bandwidth to verify information or critically engage with it <a class="yt-timestamp" data-t="28:50:00">[28:50:00]</a>. They rely on common sense or self-constructed judgment of information or its source, and fact-checking is not common due to lack of interest <a class="yt-timestamp" data-t="29:21:00">[29:21:00]</a>. A chatbot designed to provide COVID-19 information found that people primarily used it to seek assistance and resources for other ongoing crises, indicating that COVID-19 was not their top priority <a class="yt-timestamp" data-t="30:20:00">[30:20:00]</a>.

### Intervention Strategies
Given people's limited bandwidth, interventions need to be designed accordingly <a class="yt-timestamp" data-t="31:02:00">[31:02:00]</a>.
*   **Lightweight Interactions**: Collaboration with TED's Healthy Internet Project encourages Lebanese youth to flag potential [[Misinformation and disinformation|misinformation]] rather than carry the burden of fact-checking themselves <a class="yt-timestamp" data-t="31:09:00">[31:09:00]</a>. This crowdsourced moderation aims to address [[Misinformation and disinformation|misinformation]] at a structural level <a class="yt-timestamp" data-t="31:51:00">[31:51:00]</a>.
*   **Beyond Digital**: While social media is a focus, [[Misinformation and disinformation|misinformation]] has a long history and exists outside the digital sphere <a class="yt-timestamp" data-t="32:05:00">[32:05:00]</a>. For example, during the Lebanese civil war, rumors were used to maintain fear <a class="yt-timestamp" data-t="32:20:00">[32:20:00]</a>. Traditional media (like TV, which 84% of Lebanese respondents used for news in 2019) remains significant, despite being tied to political parties and fostering distrust <a class="yt-timestamp" data-t="32:51:00">[32:51:00]</a>. UNDP Lebanon is launching a new research project to understand common [[Misinformation and disinformation|misinformation]]/[[Misinformation and disinformation|disinformation]] topics and their relation to behaviors, informing a new campaign that will be both digital and analog <a class="yt-timestamp" data-t="33:43:00">[33:43:00]</a>.
*   **Context is Key**: A "one-size-fits-all" approach will not work <a class="yt-timestamp" data-t="34:38:00">[34:38:00]</a>. Even in a small country like Lebanon, perceptions and behaviors vastly differ between areas, necessitating segmentation (e.g., urban vs. rural, generational divides) <a class="yt-timestamp" data-t="34:40:00">[34:40:00]</a>.
*   **Addressing Trust Deficits**: In Lebanon, due to a lack of [[Government and media trust in misinformation contexts|government trust]], using government logos can hurt campaigns more than help <a class="yt-timestamp" data-t="37:17:00">[37:17:00]</a>. A successful strategy was to include logos of trusted agencies like WHO and UNICEF <a class="yt-timestamp" data-t="37:36:00">[37:36:00]</a>. Messages that engage with existing skepticism, such as "57% of Lebanese believe COVID-19 is a conspiracy intended to control people. What do you think? Let your opinions be heard," were highly successful in eliciting engagement <a class="yt-timestamp" data-t="36:08:00">[36:08:00]</a>.

### Overarching Learnings from UNDP
*   Architects of [[Misinformation and disinformation|disinformation]] often have a deeper understanding of human behavior than organizations combating it <a class="yt-timestamp" data-t="38:11:00">[38:11:00]</a>.
*   Interventions should not rely on assumptions or general behavioral trends but rigorously research contextual factors shaping perceptions and behaviors <a class="yt-timestamp" data-t="38:21:00">[38:21:00]</a>.
*   Research results should be made accessible to other organizations and the communities they serve <a class="yt-timestamp" data-t="38:40:00">[38:40:00]</a>.

## Reflections on Combating Misinformation

### Debunking and Inoculation
A key reflection is that myths and conspiracy theories should generally not be actively debunked in public information campaigns or behavioral interventions, as this can have a reinforcing effect in the online space <a class="yt-timestamp" data-t="45:10:00">[45:10:00]</a>. While fine in on-site workshops where conversation can occur, repetition online is problematic <a class="yt-timestamp" data-t="45:21:00">[45:21:00]</a>.

The effectiveness of "inoculation" or "pre-bunking" as a long-term solution is debated <a class="yt-timestamp" data-t="55:00:00">[55:00:00]</a>. While showing promise, more research is needed to understand how long these effects last <a class="yt-timestamp" data-t="56:00:00">[56:00:00]</a>. Overall, there is no single solution due to the complex and heterogeneous nature of populations and drivers of [[Misinformation and disinformation|misinformation]] <a class="yt-timestamp" data-t="55:28:00">[55:28:00]</a>. A range of varied, context-specific solutions, adapting to evolving forms of [[Misinformation and disinformation|misinformation]], is necessary <a class="yt-timestamp" data-t="57:46:00">[57:46:00]</a>.

### The Role of Social Media Platforms
The [[Role of social media algorithms in misinformation|role of social media algorithms in misinformation]] spread is fundamental <a class="yt-timestamp" data-t="47:41:00">[47:41:00]</a>. To influence change, redesigning online environments and gaining access to platforms where people "live and work" is necessary to understand the problem and test interventions <a class="yt-timestamp" data-t="50:37:00">[50:37:00]</a>. It is a critical concern that highly skilled behavioral scientists at social media platforms may be using their knowledge to increase content virality rather than combat [[Misinformation and disinformation|misinformation]] <a class="yt-timestamp" data-t="51:24:00">[51:24:00]</a>. The fact that content can be taken down by platforms if it doesn't fit a specific agenda also raises questions about the realistic possibility of fighting [[Misinformation and disinformation|misinformation]] when platforms themselves act against that goal <a class="yt-timestamp" data-t="53:50:00">[53:50:00]</a>.

### Importance of Context and Human Perspective
[[International collaborations to combat misinformation|International collaborations to combat misinformation]] highlight that "context is key," meaning there is no one-size-fits-all or "silver bullet" solution <a class="yt-timestamp" data-t="42:07:00">[42:07:00]</a>. Combining social monitoring and online research with "human perspectives" (audience/user research, key informant interviews, focus group discussions) provides a more nuanced and localized understanding of [[Misinformation and disinformation|disinformation]] trends and how people interact with it <a class="yt-timestamp" data-t="43:22:00">[43:22:00]</a>. Continually understanding how the public interacts with the information ecosystem and how it changes over time is crucial for effective [[Addressing misinformation and improving communication between citizens and governments|communication between citizens and governments]] and adaptable responses <a class="yt-timestamp" data-t="44:01:00">[44:01:00]</a>.