---
title: Digital media literacy and misinformation
videoId: soQN97fWlxQ
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

## The Growing Challenge of Misinformation

The spread of [[misinformation_and_disinformation | misinformation and disinformation]] has fundamentally reshaped how information is consumed and shared online and offline over the last decade <a class="yt-timestamp" data-t="00:04:51">[00:04:51]</a>. This issue impacts nearly all aspects of public life, including health, education, financial markets, and political affairs <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>. The global nature of this challenge means that effective responses require global and cross-border solutions, as "fake news knows no borders" <a class="yt-timestamp" data-t="00:06:17">[00:06:17]</a>.

## A Behavioral Science Approach

Addressing [[misinformation_and_disinformation | misinformation]] depends heavily on individual behaviors, as its spread relies on people's choices in how they consume and share information <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>. Ignoring the human factor is a significant risk to the success of any solutions <a class="yt-timestamp" data-t="00:05:40">[00:05:40]</a>. Therefore, applying [[behavioral_science_in_combating_misinformation | Behavioral Science]] is crucial for understanding how cognitive and social factors influence engagement with information ecosystems, and how these ecosystems, in turn, influence behavior <a class="yt-timestamp" data-t="00:05:53">[00:05:53]</a>. This understanding helps in designing and delivering effective policies, programs, and communications <a class="yt-timestamp" data-t="00:06:06">[00:06:06]</a>.

The OECD, as a member of the Behavioral Insights Network, has engaged in an [[international_collaborations_to_combat_misinformation | international collaboration]] with the Canadian and French governments to apply behavioral science to address [[misinformation_and_disinformation | misinformation]] <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a>. This first-of-its-kind partnership aims to develop and disseminate solutions to guide government responses <a class="yt-timestamp" data-t="00:06:34">[00:06:34]</a>.

### Understanding Sharing Behaviors

Research indicates that people often share [[misinformation_and_disinformation | misinformation]] not solely due to malicious intent, but partly because of inattention to accuracy when engaging with news online <a class="yt-timestamp" data-t="00:08:02">[00:08:02]</a>. There is often a disconnect between an individual's intention to share news and their knowledge of its truthfulness <a class="yt-timestamp" data-t="00:11:48">[00:11:48]</a>. This means some individuals may share fake news even if they don't believe it to be true <a class="yt-timestamp" data-t="00:11:58">[00:11:58]</a>.

### Experimental Interventions and Findings

A study involving nearly 2,000 Canadians tested two scalable interventions to boost attention to accuracy before online news engagement <a class="yt-timestamp" data-t="00:09:50">[00:09:50]</a>:
*   **Accuracy Evaluation** <a class="yt-timestamp" data-t="00:09:41">[00:09:41]</a>: Respondents were shown a random news headline and asked to rate its accuracy <a class="yt-timestamp" data-t="00:08:44">[00:08:44]</a>.
*   **Digital Media Literacy Tips** <a class="yt-timestamp" data-t="00:09:16">[00:09:16]</a>: Respondents saw a brief list of media literacy tips (e.g., "investigate the source," "look at other reports," "watch for unusual formatting") before seeing news headlines <a class="yt-timestamp" data-t="00:09:23">[00:09:23]</a>.

Both interventions were effective, but the **digital media literacy tips had the greatest impact**, reducing intentions to share fake news by 21% <a class="yt-timestamp" data-t="00:12:26">[00:12:26]</a>. This effect was found to be consistent across different population clusters, suggesting these interventions can be broadly useful <a class="yt-timestamp" data-t="00:32:11">[00:32:11]</a>.

### Identifying Susceptible Groups

Individual differences in [[government_and_media_trust_in_misinformation_contexts | trust in information consumption]] and cognitive factors (like conspiracy mentality and openness to evidence) shape beliefs and sharing of [[misinformation_and_disinformation | misinformation]] <a class="yt-timestamp" data-t="00:13:29">[00:13:29]</a>. Three main clusters of participants were identified <a class="yt-timestamp" data-t="00:13:54">[00:13:54]</a>:
*   **Non-trusting**: Low trust in all information sources, low openness to evidence, high conspiratorial thinking, high psychological reactance (~20% of sample) <a class="yt-timestamp" data-t="00:13:59">[00:13:59]</a>.
*   **High-trusting**: High trust in all information sources (especially social media), low openness to evidence, medium-high conspiratorial thinking, high psychological reactance <a class="yt-timestamp" data-t="00:14:21">[00:14:21]</a>.
*   **Institution-trusting**: High trust in institutional sources, low trust in social media, high openness to evidence, low conspiratorial thinking, low psychological reactance <a class="yt-timestamp" data-t="00:14:44">[00:14:44]</a>.

The "non-trusting" and "social media trusting" clusters showed significantly greater belief and sharing of fake news compared to the "institution-trusting" cluster <a class="yt-timestamp" data-t="00:15:33">[00:15:33]</a>.

## Key Policy Implications

### The Human Factor
A comprehensive policy response to [[misinformation_and_disinformation | misinformation and disinformation]] must incorporate an expanded understanding of human behavior <a class="yt-timestamp" data-t="00:16:53">[00:16:53]</a>. [[behavioral_science_in_combating_misinformation | Behavioral Science]] is a crucial policy tool for all governments, as understanding how people operate in real-world contexts is essential for effective policy <a class="yt-timestamp" data-t="00:47:04">[00:47:04]</a>.

### Empowering Citizens
Rather than solely regulating content, policy should focus on empowering users to change their behaviors <a class="yt-timestamp" data-t="00:17:15">[00:17:15]</a>. Solutions that empower users can offer effective and scalable ways to complement holistic policy strategies and mitigate the threat of fake news without direct content regulation <a class="yt-timestamp" data-t="00:17:23">[00:17:23]</a>.

### The Value of Cross-Border Collaboration
Governments should conduct rigorous policy experiments in collaboration with other countries to generate sustainable responses to the spread of [[misinformation_and_disinformation | misinformation]] <a class="yt-timestamp" data-t="00:17:47">[00:17:47]</a>. [[international_collaborations_to_combat_misinformation | International partnerships]], like the one between OECD, Canada, and France, foster inclusivity and diversity in framing policy issues and developing responses <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>. Coordinating efforts across diverse countries working towards a common goal makes navigating complex policy landscapes easier <a class="yt-timestamp" data-t="00:01:27">[00:01:27]</a>. This approach is particularly valuable for challenges that know no boundaries, like [[misinformation_and_disinformation | misinformation]], where solutions benefit the global public welfare <a class="yt-timestamp" data-t="00:01:46">[00:01:46]</a>. Such collaborations facilitate knowledge transfer and allow teams to learn from each other's operational methods <a class="yt-timestamp" data-t="00:30:07">[00:30:07]</a>.

## Context and Future Directions

### Lessons from the COVID-19 Pandemic
The Canadian team's work during the COVID-19 pandemic highlighted the emergence of [[misinformation_and_disinformation | misinformation]] as a significant challenge <a class="yt-timestamp" data-t="00:22:06">[00:22:06]</a>. Belief in false claims about COVID-19 was found to impact crucial behaviors like vaccination decisions and staying home when sick <a class="yt-timestamp" data-t="00:22:15">[00:22:15]</a>. This direct link underscores the [[impact_of_misinformation_on_public_health_behaviors | impact of misinformation on public health behaviors]] <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>. The collaboration allowed governments to address this timely need, providing a "Brain Trust" to navigate the complex space and leverage a global network of academic experts <a class="yt-timestamp" data-t="00:23:45">[00:23:45]</a>.

### Broader Implications for Trust and Democracy
[[misinformation_and_disinformation | Misinformation]] is often seen as a symptom of a larger problem: the erosion of [[government_and_media_trust_in_misinformation_contexts | trust in government and government institutions]] in Western democracies <a class="yt-timestamp" data-t="00:48:12">[00:48:12]</a>. Addressing this underlying issue of trust is critical for strengthening fragile democracies <a class="yt-timestamp" data-t="00:48:41">[00:48:41]</a>.

The OECD's broader initiative on "Building Trust and Reinforcing Democracy" identifies [[misinformation_and_disinformation | miss and disinformation]] as a key governance challenge <a class="yt-timestamp" data-t="00:51:51">[00:51:51]</a>. This initiative promotes a "whole of government and a whole of society approach" to [[addressing_misinformation_and_improving_communication_between_citizens_and_governments | addressing misinformation]] <a class="yt-timestamp" data-t="00:53:29">[00:53:29]</a>. It emphasizes looking at the issue from multiple angles, including media literacy, regulatory perspectives (transparency over content regulation), and the position of digital platforms <a class="yt-timestamp" data-t="00:53:39">[00:53:39]</a>. The goal is to build societal resilience to [[misinformation_and_disinformation | miss and disinformation]] by understanding why people engage with it and by fostering better digital competencies <a class="yt-timestamp" data-t="00:54:07">[00:54:07]</a>.