---
title: Empirical evidence in behavioral science
videoId: AVRS-x9mS7E
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

The application of [[behavioral_science_in_policy_making | behavioral science in public policy]] emphasizes a strong reliance on empirical evidence to inform and validate interventions <a class="yt-timestamp" data-t="00:37:04">[00:37:04]</a>. This focus on testing what works and what does not is a core aspect of the field <a class="yt-timestamp" data-t="00:37:07">[00:37:07]</a>.

## The Importance of Empirical Evidence
Empirical evidence, particularly through experimentation, is considered the "cornerstone" and "golden standard" for [[behavioral_science_in_policy_making | behavioral science]] <a class="yt-timestamp" data-t="00:37:48">[00:37:48]</a>. It has been at the vanguard of evidence-based policy and testing what works, a case that was just as important before the COVID-19 crisis <a class="yt-timestamp" data-t="00:16:57">[00:16:57]</a>.

## Challenges in Generating Evidence During Crises
During times of crisis, such as the COVID-19 pandemic, generating robust empirical evidence presents significant challenges <a class="yt-timestamp" data-t="00:37:14">[00:37:14]</a>.
These challenges include:
*   **Lack of Luxury for Extensive Experimentation** Resources and time constraints make it difficult to conduct expanded experimentation like Randomized Control Trials (RCTs) <a class="yt-timestamp" data-t="00:38:02">[00:38:02]</a>.
*   **Rapidly Changing Environment** Behaviors are constantly changing, making it extremely difficult to track and evaluate interventions over time <a class="yt-timestamp" data-t="01:00:57">[01:00:57]</a>.
*   **Need for Rapid Turnaround** Policymakers require quick answers, often within hours, which conflicts with the typical lengthy timelines for rigorous academic studies <a class="yt-timestamp" data-t="00:43:29">[00:43:29]</a>, <a class="yt-timestamp" data-t="00:48:58">[00:48:58]</a>.
*   **Maintaining Relevance** The need to be timely and provide relevant answers is paramount for behavioral scientists working in government <a class="yt-timestamp" data-t="00:43:47">[00:43:47]</a>.

## Adaptations and New Approaches
In response to these challenges, [[application_of_behavioral_science | behavioral science]] practitioners have adapted their methods:
*   **Smaller Pilots** Settling for smaller pilots allows for rapid learning and re-adaptation in fast-changing environments <a class="yt-timestamp" data-t="00:38:10">[00:38:10]</a>.
*   **Quasi-Experimental Methods** Adopting quasi-experimental evaluation methods is crucial for rapid assessment when full RCTs are not feasible <a class="yt-timestamp" data-t="00:38:35">[00:38:35]</a>.
*   **Experimental Angle in Surveys** Surveys, while not providing a counterfactual, can be enhanced by adding an experimental angle to test specific hypotheses, such as the effectiveness of dynamic social norms on trust <a class="yt-timestamp" data-t="00:38:47">[00:38:47]</a>, <a class="yt-timestamp" data-t="00:40:22">[00:40:22]</a>. These "knowledge, attitudes, and perception" (KAP) surveys are run regularly by countries to track changing behaviors <a class="yt-timestamp" data-t="00:39:10">[00:39:10]</a>.
*   **Flexibility and Pivoting** [[behavioral_insights in public policy | Behavioral insights]] teams have demonstrated flexibility, shifting from preferred methodological approaches to different ones quickly, such as providing advice in one hour instead of conducting an 18-month RCT <a class="yt-timestamp" data-t="00:25:47">[00:25:47]</a>.

## Future Directions for Empirical Evidence
For the future, the [[application_of_behavioral_science | behavioral science]] community aims to:
*   **Standardize Evidence Quality** The OECD could help by creating a "what works" center for best practices during crises and developing a labeling system for the quality of evidence supporting recommendations (e.g., based on surveys, interviews, or RCTs) <a class="yt-timestamp" data-t="00:49:25">[00:49:25]</a>, <a class="yt-timestamp" data-t="00:50:50">[00:50:50]</a>. This would set clear expectations for policymakers regarding the rigor and robustness of advice <a class="yt-timestamp" data-t="00:51:18">[00:51:18]</a>.
*   **Promote Pre-registration of Trials** Encouraging pre-registration of trials within the [[collaborations_in_behavioral_science | behavioral insights community]] can help assess the accuracy of intuitions and predictions about intervention outcomes <a class="yt-timestamp" data-t="00:52:10">[00:52:10]</a>.
*   **Embrace International Cooperation** There is a need to share findings across countries to avoid reinventing the wheel and to learn from contextualized experiences <a class="yt-timestamp" data-t="00:45:32">[00:45:32]</a>, <a class="yt-timestamp" data-t="01:12:18">[01:12:18]</a>.
*   **Integrate New Technologies** The integration of Artificial Intelligence and big data is expected to take the field to a new level <a class="yt-timestamp" data-t="00:56:04">[00:56:04]</a>.
*   **Address [[ethics_in_behavioral_insights | Ethics in Behavioral Insights]]** As the field grows, ensuring adherence to ethical standards and pre-registration of activities is crucial to maintain trust and prevent misuse <a class="yt-timestamp" data-t="00:56:25">[00:56:25]</a>.
*   **Mainstreaming Behavioral Science** The goal is for a "behavioral lens" to be applied to all government work, even for complex policy problems, rather than just focusing on specific behaviors <a class="yt-timestamp" data-t="00:35:50">[00:35:50]</a>, <a class="yt-timestamp" data-t="00:36:44">[00:36:44]</a>.