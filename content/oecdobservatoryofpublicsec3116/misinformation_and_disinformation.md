---
title: Misinformation and disinformation
videoId: soQN97fWlxQ
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

Misinformation and disinformation are undoubtedly important and complex challenges impacting public life globally <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a><a class="yt-timestamp" data-t="00:01:16">[00:01:16]</a>. New digital technologies and information ecosystems have fundamentally reshaped how individuals consume and share information online and offline over the last decade <a class="yt-timestamp" data-t="00:04:51">[00:04:51]</a>. The spread of inaccurate information has trickled into all aspects of public life, including health (as seen during the COVID-19 pandemic), education, financial markets, and political affairs <a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>. The global challenge of misinformation depends heavily on individual behaviors, as its spread relies on people's choices in how they consume and share information with their networks <a class="yt-timestamp" data-t="00:05:21">[00:05:21]</a>. Ignoring the human factor poses a significant risk to the success of any solutions tackling misinformation <a class="yt-timestamp" data-t="00:05:40">[00:05:40]</a>.

## Applying Behavioral Science

The OECD's Behavioral Insights Network aims to apply [[behavioral_science_in_combating_misinformation | behavioral science]] to address misinformation and disinformation <a class="yt-timestamp" data-t="00:00:09">[00:00:09]</a><a class="yt-timestamp" data-t="00:00:28">[00:00:28]</a>. The Office of Evaluation Sciences (OES) in the U.S. federal government applies behavioral insights across federal agencies, emphasizing interdisciplinary perspectives, rigorous evaluation methods, and evidence-based policy advice <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>.

The collaboration highlights the importance of interdisciplinary perspectives and rigorous evaluation methods, translating into a meaningful partnership <a class="yt-timestamp" data-t="00:00:48">[00:00:48]</a>. This approach fosters inclusivity and diversity in framing policy issues and responding to complex challenges at local, regional, or global levels <a class="yt-timestamp" data-t="00:01:02">[00:01:02]</a>. Navigating the complex policy landscape becomes easier with diverse perspectives from several countries working towards a common goal <a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. Coordinating efforts across teams, while challenging, demonstrates the value of cross-border experimentation and coordination, especially for challenges that know no boundaries and benefit the global public welfare <a class="yt-timestamp" data-t="00:01:32">[00:01:32]</a>.

Many policy issues, such as the [[addressing_climate_misinformation | climate emergency]], socioeconomic inequalities, or the influence of [[role_of_social_media_algorithms_in_misinformation | digital technologies]] on public life, are partially attributed to individual behaviors and preferences <a class="yt-timestamp" data-t="00:01:56">[00:01:56]</a>. Therefore, behavioral experimentation is increasingly used by policymakers to test what works and doesn't work, guided by empirical evidence and a desire to center real people in policy design <a class="yt-timestamp" data-t="00:02:15">[00:02:15]</a>. Knowledge and experience sharing is critical for responsible and sustained use of behavioral science in policy <a class="yt-timestamp" data-t="00:02:35">[00:02:35]</a>.

## International Collaboration

The OECD initiated an [[international_collaborations_to_combat_misinformation | international partnership]] with the Canadian and French governments to develop and disseminate solutions to guide government responses to tackle misinformation <a class="yt-timestamp" data-t="00:06:34">[00:06:34]</a>. This partnership involved the OECD, Duke City, the Impact Innovation Unit in the Canadian Privy Council Office, and the French Behavioral Insights Unit in the Ministry of Public Transformation <a class="yt-timestamp" data-t="00:06:52">[00:06:52]</a>. This was a first-of-its-kind cross-border collaboration <a class="yt-timestamp" data-t="00:07:08">[00:07:08]</a>.

### Collaboration Objectives
The collaboration had three main objectives:
1.  To better understand why people share misinformation on social media <a class="yt-timestamp" data-t="00:07:16">[00:07:16]</a>.
2.  To evaluate the impact of behavioral interventions on choices to share fake news <a class="yt-timestamp" data-t="00:07:23">[00:07:23]</a>.
3.  To co-develop best practices to inform policy responses to misinformation <a class="yt-timestamp" data-t="00:07:31">[00:07:31]</a>.

### Practical Aspects of the Partnership
The Canadian team, the Impact Innovation Unit, pivoted to support the government's COVID-19 response in March 2020 <a class="yt-timestamp" data-t="00:21:02">[00:21:02]</a>. They set up a large-scale longitudinal tracking study called COSMO, which followed approximately 2,000 Canadians over time, collecting data on their knowledge, risk perceptions, and behaviors related to COVID-19 <a class="yt-timestamp" data-t="00:21:16">[00:21:16]</a>. Through monthly data analysis from COSMO, the challenge of misinformation naturally emerged, with belief in false COVID-19 claims impacting downstream behaviors like vaccination decisions or staying home when sick <a class="yt-timestamp" data-t="00:22:01">[00:22:01]</a>.

Recognizing that misinformation was not unique to Canada, the team sought to partner with academic experts and other governments grappling with the issue <a class="yt-timestamp" data-t="00:22:45">[00:22:45]</a>. The partnership between Canada, the OECD, and France came together in response to this timely need, forming a "Brain Trust" <a class="yt-timestamp" data-t="00:23:25">[00:23:25]</a>. Despite time zone differences, they met regularly to discuss data, literature reviews, and conversations with academics, parsing out evidence gaps and their practical implications for governments <a class="yt-timestamp" data-t="00:23:51">[00:23:51]</a>. This real-time dialogue during the COVID-19 response was highly beneficial, allowing access to diverse perspectives and a global network of academic experts <a class="yt-timestamp" data-t="00:24:28">[00:24:28]</a>.

The French Behavioral Science team also found the collaboration inspiring, especially during the high-pressure, uncertain times of the COVID-19 crisis <a class="yt-timestamp" data-t="00:26:30">[00:26:30]</a>. The OECD facilitated an "extremely easy and straightforward" experience for cross-country collaboration <a class="yt-timestamp" data-t="00:28:20">[00:28:20]</a>. This type of collaboration is seen as extremely beneficial for knowledge transfer, helping to overcome "silos" where different teams work on the same topics without proper knowledge sharing <a class="yt-timestamp" data-t="00:30:07">[00:30:07]</a>.

## Understanding Sharing Behavior and Interventions

A key question addressed was: why do people share fake news on social media <a class="yt-timestamp" data-t="00:07:41">[00:07:41]</a>? One influential hypothesis suggests that people share misinformation partly due to inattention to accuracy when engaging with news online, rather than solely intentionally sharing fake news <a class="yt-timestamp" data-t="00:08:05">[00:08:05]</a>. This intuitive idea reflects how often people scroll and share without much thought <a class="yt-timestamp" data-t="00:08:18">[00:08:18]</a>.

### Interventions Tested
Two scalable interventions were tested to boost attention before people engage with news online:
1.  **Accuracy Evaluation**: A direct replication of a 2021 Nature study <a class="yt-timestamp" data-t="00:08:41">[00:08:41]</a>. Respondents saw a random news headline (e.g., about a neutron star) and were asked to rate its accuracy <a class="yt-timestamp" data-t="00:08:44">[00:08:44]</a>.
2.  **[[digital_media_literacy_and_misinformation | Digital Media Literacy]] Tips**: Respondents saw a brief list of media literacy tips before viewing news <a class="yt-timestamp" data-t="00:09:16">[00:09:16]</a>. These tips included advice like investigating the source, looking for other reports, and watching for unusual formatting <a class="yt-timestamp" data-t="00:09:30">[00:09:30]</a>.

### Experimental Design and Outcomes
The experiment was led by the Canadian team as part of their longitudinal COSMO survey <a class="yt-timestamp" data-t="00:09:50">[00:09:50]</a>. The sample included almost 2,000 Canadians, quota-matched to the national distribution on age, gender, and geographic region <a class="yt-timestamp" data-t="00:09:57">[00:09:57]</a>. It was a randomized controlled trial, testing the two treatments against a control group <a class="yt-timestamp" data-t="00:10:10">[00:10:10]</a>. All participants saw the same 14 headlines (7 true, 7 false) <a class="yt-timestamp" data-t="00:10:22">[00:10:22]</a>. Outcome variables measured were participants' belief in true vs. false news and their likelihood of sharing news on social media <a class="yt-timestamp" data-t="00:10:33">[00:10:33]</a>.

## Key Findings

### Disconnect Between Belief and Sharing
Initially, people were more likely to rate true news as accurate and had higher intentions to share true headlines compared to false news <a class="yt-timestamp" data-t="00:11:10">[00:11:10]</a>. However, the difference in sharing intentions for true versus false headlines was almost four times smaller in effect size than the difference in accuracy judgments <a class="yt-timestamp" data-t="00:11:28">[00:11:28]</a>. This indicates a "disconnect" between sharing intentions and knowledge of what is true and false <a class="yt-timestamp" data-t="00:11:48">[00:11:48]</a>. In practice, some individuals may share fake news even when they don't believe it to be true <a class="yt-timestamp" data-t="00:11:57">[00:11:57]</a>.

### Effectiveness of Interventions
Both interventions were found to be effective in reducing intentions to share fake news <a class="yt-timestamp" data-t="00:12:24">[00:12:24]</a>. The [[digital_media_literacy_and_misinformation | digital media literacy]] tips had the greatest impact, reducing intentions to share fake news by 21% <a class="yt-timestamp" data-t="00:12:31">[00:12:31]</a>.

### Identifying Subgroups and Susceptibility
To understand who spreads misinformation and why, a cluster analysis leveraged COSMO Canada survey data <a class="yt-timestamp" data-t="00:13:08">[00:13:08]</a>. The hypothesis was that individual differences in belief and sharing of misinformation would be related to differences in trust, information consumption, and cognitive factors like conspiracy mentality and openness to evidence <a class="yt-timestamp" data-t="00:13:27">[00:13:27]</a>.

Three clusters of participants were identified:
1.  **Non-trusting**: About 20% of the sample <a class="yt-timestamp" data-t="00:14:15">[00:14:15]</a>. These individuals showed low trust in all information sources, low openness to evidence, high conspiratorial thinking, and high psychological reactance <a class="yt-timestamp" data-t="00:14:04">[00:14:04]</a>.
2.  **High-trusting (Social Media Trusting)**: These individuals had high trust in all information sources, especially social media <a class="yt-timestamp" data-t="00:14:28">[00:14:28]</a>. They also showed low openness to evidence, medium-high conspiratorial thinking, and high psychological reactance <a class="yt-timestamp" data-t="00:14:34">[00:14:34]</a>.
3.  **Institution-trusting**: This cluster had high trust in institutional sources of information but low trust in social media <a class="yt-timestamp" data-t="00:14:44">[00:14:44]</a>. They also showed high openness to evidence, low conspiratorial thinking, and low psychological reactance <a class="yt-timestamp" data-t="00:14:56">[00:14:56]</a>.

As predicted, the non-trusting and social media trusting clusters exhibited significantly greater belief and sharing of fake news compared to the institution-trusting cluster <a class="yt-timestamp" data-t="00:15:33">[00:15:33]</a>. Importantly, the interventions had a similarly affecting impact across all three clusters, suggesting they are "globally useful" on average <a class="yt-timestamp" data-t="00:32:15">[00:32:15]</a><a class="yt-timestamp" data-t="00:33:03">[00:33:03]</a>. This aligns with academic literature suggesting that interventions boosting attention to accuracy tend to show similar effects regardless of demographic variables, partisanship, or political ideology <a class="yt-timestamp" data-t="00:33:15">[00:33:15]</a>.

## Policy Implications

The study provides three main policy messages <a class="yt-timestamp" data-t="00:16:30">[00:16:30]</a>:

1.  **Don't Ignore the Human Factor**: A comprehensive policy response to both disinformation and misinformation should include an expanded understanding of human behavior <a class="yt-timestamp" data-t="00:16:43">[00:16:43]</a>. All government actions (legislative, regulatory, program, communications) have a human component, and understanding real-world human operation is key to policy success <a class="yt-timestamp" data-t="00:47:00">[00:47:00]</a>.
2.  **Empowering People**: The collaboration focused on empowering users and changing behaviors, rather than regulating content <a class="yt-timestamp" data-t="00:17:17">[00:17:17]</a>. These results offer effective and scalable solutions to complement holistic policy strategies and offset the threat of fake news without direct content regulation <a class="yt-timestamp" data-t="00:17:23">[00:17:23]</a>. Such interventions can preserve user autonomy while fostering better [[digital_media_literacy_and_misinformation | digital competencies]] <a class="yt-timestamp" data-t="00:36:28">[00:36:28]</a>. The study aligns with existing French policy efforts that focus on [[digital_media_literacy_and_misinformation | media literacy]] and critical thinking <a class="yt-timestamp" data-t="00:42:18">[00:42:18]</a>.
3.  **Find What Works Across Borders**: Governments should conduct rigorous policy experiments in [[international_collaborations_to_combat_misinformation | collaboration with other countries]] to generate sustainable responses to the spread of misinformation <a class="yt-timestamp" data-t="00:17:43">[00:17:43]</a>. This collaboration is hoped to be just the beginning of further work to determine which mitigation strategies work for whom and in what context <a class="yt-timestamp" data-t="00:17:58">[00:17:58]</a>.

## Broader Context and Future Directions

The OECD's Public Governance Directorate places this work within its wider initiative on Building Trust and Reinforcing Democracy <a class="yt-timestamp" data-t="00:50:49">[00:50:49]</a>. This initiative acknowledges the fragility of democracies worldwide, evidenced by events like those in the US, France, and Canada <a class="yt-timestamp" data-t="00:51:20">[00:51:20]</a>. Misinformation is seen as a symptom of a larger problem: the erosion of trust, particularly [[government_and_media_trust_in_misinformation_contexts | trust in government]] and government institutions <a class="yt-timestamp" data-t="00:48:13">[00:48:13]</a>. Addressing this core component of trust is crucial <a class="yt-timestamp" data-t="00:48:51">[00:48:51]</a>.

The work on misinformation and disinformation within this initiative employs a "whole of government and a whole of society" approach, recognizing there is no single "silver bullet" solution <a class="yt-timestamp" data-t="00:53:29">[00:53:29]</a><a class="yt-timestamp" data-t="00:35:37">[00:35:37]</a>. It examines multiple angles, including [[digital_media_literacy_and_misinformation | media literacy]], regulatory perspectives (e.g., transparency over content regulation), and the position of platforms <a class="yt-timestamp" data-t="00:53:42">[00:53:42]</a>. A prime focus is building societal resilience to misinformation and disinformation, which involves media literacy and understanding people's motivations <a class="yt-timestamp" data-t="00:54:07">[00:54:07]</a>.

A health misinformation toolkit developed by OES with the Office of the Surgeon General in the U.S. aims to explain motivations for sharing misinformation and help slow its spread <a class="yt-timestamp" data-t="00:03:04">[00:03:04]</a>. The toolkit provides information and exercises to help people recognize false health information and talk effectively with others prone to spreading it <a class="yt-timestamp" data-t="00:03:18">[00:03:18]</a>.

Future work will continue to explore different types of misinformation (e.g., scientific, political, cultural) and how interventions might operate differently for specific subtypes of information <a class="yt-timestamp" data-t="00:37:34">[00:37:34]</a><a class="yt-timestamp" data-t="00:38:49">[00:38:49]</a>. The aim is to conduct further research to understand where these types of interventions might have the greatest effect <a class="yt-timestamp" data-t="00:39:16">[00:39:16]</a>. Continued engagement with the OECD behavioral insights network and the broader initiative on reinforcing democracy is encouraged <a class="yt-timestamp" data-t="00:55:00">[00:55:00]</a>.