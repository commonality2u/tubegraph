---
title: Evaluation and metrics in missionoriented policy
videoId: -KQokCATILo
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

Effective evaluation and appropriate metrics are crucial for the success of [[mission_oriented_innovation | mission-oriented innovation]] and policies. This section explores the challenges with traditional evaluation methods and outlines the requirements for new approaches suitable for complex, goal-oriented initiatives.

## Current Challenges in Evaluation and Metrics

Traditional approaches to economic policy often frame the role of the state as merely "fixing markets" [01:16:11]. This limited perspective is reflected in evaluation methods that focus on patching problems rather than assessing proactive value creation [02:00:19].

Key challenges include:
*   **Problematic Narratives** Traditional storytelling often portrays the public sector as solely responsible for de-risking, facilitating, or enabling the private sector, rather than being a value-creating partner [02:00:50]. This narrative, reinforced by media, suggests government intervention is "boring" compared to dynamic business innovation [02:10:00].
*   **Inadequate Justification for Public Investment** Justifying public investment in innovation as merely "fixing market failures" (e.g., addressing positive externalities in basic research or asymmetric information in SME financing) is insufficient [02:00:19]. It positions the public sector as filling gaps rather than driving creation [02:01:11].
*   **Limitations of Traditional Tools** Current evaluation tools, such as cost-benefit analysis and net present value, are often too static to capture the dynamic and systemic impacts of [[mission_oriented_innovation | mission-oriented innovation]] [02:15:23].
*   **Difficulty in Capturing Spillovers** There is a lack of understanding and measures for the dynamic spillovers that occur throughout a mission's journey, similar to how software benefited from the moon landing mission [02:15:30].
*   **Absence of Partnership Metrics** While concepts like ESG (Environmental, Social, and Governance) focus on purpose within companies, there are no equivalent metrics to assess whether public-private partnerships are symbiotic, mutualistic, or parasitic [02:44:50].
*   **Fear of Risk-Taking** Public agents and decision-makers often feel pressured by evaluation systems, which tend to punish failure rather than encourage necessary risk-taking for innovation [02:46:56]. This stifles experimentation and learning [02:49:02].
*   **Limited Reflectivity in Pilot Experiments** Many [[mission_oriented_innovation | mission-oriented policies]] are still pilots, and there is limited learning and reflection from these experiments, hindering their scale-up and diffusion [01:06:02].
*   **Dilution of Missions** In overarching strategic frameworks, there is a risk of diluting missions or creating too many, making clear target setting and evaluation difficult [01:00:40].
*   **Focus on Technological Solutions** Many [[mission_oriented_innovation | mission-oriented policies]] currently focus primarily on scientific and technological solutions, often neglecting the need for social solutions that require changes in consumption or production behavior [01:02:45]. This is partly due to these policies often falling under the authority of science, technology, and innovation bodies [01:03:20].

## Requirements for New Evaluation Approaches

A new approach to evaluation is needed to align with the principles of [[mission_oriented_innovation | mission-oriented innovation]]. This involves moving from a "market-fixing" to a "market-shaping" or "market co-creation" framework [01:16:18].

Key requirements include:
*   **Dynamic and Systemic Metrics** Evaluation needs to capture the dynamic spillovers and broader impact across the entire innovation chain, not just direct outcomes [02:15:25]. This includes assessing whether the process itself fosters public interest and beneficial spillovers [02:19:00].
*   **Embracing Uncertainty and Sharing Risks/Rewards** Evaluation should acknowledge and welcome uncertainty, focusing on how risks are shared and how rewards are distributed in the public interest [02:14:12]. This includes mechanisms like equity retention, intellectual property rights (IPR) governance, and conditionality on reinvestment [02:15:06].
*   **Focus on Learning and Adaptability** Organizations need to become "learning organizations" that invest in the capability to learn from both successes and failures [02:49:25]. This involves continuous engagement and adapting strategies based on evidence gathered from prototyping and experimentation [02:22:40].
*   **Tilted Direction of Growth** Instead of simply "leveling the playing field," evaluation should assess how policies "tilt" the direction of growth towards specific societal goals, rather than putting all resources in one basket [02:16:15].
*   **Internal Public Sector Capabilities** Robust evaluation requires strengthening the internal capabilities and capacities of the public sector, which have often been outsourced [02:16:27].
*   **Contextual and Multi-Level Approach** Missions must be nested within local contexts, co-created by diverse participants, including citizens [02:28:00]. Evaluation should reflect this multi-level perspective, connecting local initiatives with national goals [01:43:30].
*   **Inclusive Engagement** Evaluation design and implementation should be inclusive, listening to underrepresented voices to mitigate unintended consequences and ensure broad buy-in [02:53:29].
*   **Beyond Silos** Evaluation must transcend traditional ministerial or sectoral silos, assessing cross-disciplinary and cross-actor collaboration (public, private, third sector) [02:57:00].

## Practical Application and Learnings

Organizations actively implementing [[mission_oriented_innovation | mission-oriented innovation]] are evolving their evaluation practices:
*   **Vinnova (Sweden):** Started with open co-creation processes in pilot areas like mobility and food [01:13:11]. Their "system in the room" workshops involved diverse stakeholders, including school kids as urban designers for streets [01:16:09]. Evaluation focuses on feedback from residents and users, with high positive responses for initiatives like re-purposing parking spaces [01:19:37]. The goal is to design prototypes that can be rapidly scaled and invested in [02:11:37].
*   **Enisa (Spain):** Focuses on leveraging the experience of 6,000 innovative SMEs and startups [01:25:08]. Their approach emphasizes industrial and business perspectives over basic R&D, and uses a "bottom-up discovery process" [01:28:00]. The implementation phase, supported by European recovery funds, will include defining impact metrics and addressing bureaucratic challenges [01:33:11].
*   **Health Holland (Netherlands):** Coordinates missions in health and care with 97 partners, focusing on increasing quality of life and decreasing health inequalities [01:40:26]. They employ a "quadruple helix" model, involving citizens as a core part of the co-creation process [01:41:40]. Evaluation involves monitoring based on a vision of a world where missions are already accomplished, designed with experts from local to national levels [01:46:26].
*   **Engineering X (Royal Academy of Engineering, UK):** Undertakes global missions like "safer end of engineered life" [01:53:35]. They use a framework to navigate uncertainty and encourage experimentation [01:55:51]. Their process involves global workshops to "put the system in a room" [01:58:19], gather collective intelligence, and build a network map [01:59:17]. Project funding includes a two-stage review process and annual reviews that plug in new stakeholders and allow for adaptation of projects [02:01:46]. They emphasize that collaboration is primarily about trusted personal relationships and mutual understanding, rather than just funding or IPR [02:05:37]. The evaluation framework itself should be viewed as an entry point for diverse stakeholders, allowing them to engage without needing to grasp the entire mission's terminology upfront [02:06:40].

## OECD Insights on Evaluation Challenges

The OECD's work on [[impact_and_scaling_of_mission_oriented_policies | mission-oriented policies]] identifies several challenges in evaluation:
*   **Strategic Orientation:** Missions often lack clear targets and timelines, sometimes appearing as "mission washing" where industry targeting is relabeled [01:03:36]. The "mission creation moment" is not a one-off stage; true mission definition often emerges sequentially from bottom-up projects [01:04:06].
*   **Policy Coordination:** While multi-level and cross-ministerial governance structures are established, internal tensions and power conflicts within committees are common, requiring deeper analysis [01:05:02].
*   **Policy Implementation:** Systemic evaluation for systemic policies is not yet the norm; current evaluation tools remain traditional. This limits learning from pilot experiments and hinders scale-up [01:05:40].

The collective experience indicates that successful evaluation in [[mission_oriented_innovation | mission-oriented policy]] requires a fundamental shift in mindset, moving beyond conventional metrics to embrace complexity, learning, and genuine co-creation across all stages of the innovation cycle.