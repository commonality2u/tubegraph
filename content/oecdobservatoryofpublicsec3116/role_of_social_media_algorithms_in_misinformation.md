---
title: Role of social media algorithms in misinformation
videoId: IUItMNuR23s
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

The spread of [[Misinformation and disinformation | misinformation]] has become an increasingly serious threat, particularly influenced by the digital information ecosystem [00:01:03]. A key aspect of this challenge is the role of algorithms in social media platforms [00:48:05].

## The Problem Defined

The contemporary information ecosystem is characterized by limited regulation and increasing algorithmic determinism [00:01:16]. This environment, where media constantly competes for limited attention, contributes to the spread of [[Misinformation and disinformation | misinformation]] [00:01:27]. Social media platforms significantly contribute to an ecosystem of information pollution, where misleading information, voice notes, and pictures circulate easily [00:28:15]. The fundamental question arises: is it realistic to combat [[Misinformation and disinformation | misinformation]] without a fundamental redesign of how social media platforms promote content and the criteria they use [00:48:51]?

## Algorithmic Determinism and its Effects

Social media algorithms reach a problematic level in spreading [[Misinformation and disinformation | misinformation]] [00:48:05]. The structure of online environments and social network effects can amplify and exacerbate existing cognitive biases [00:15:46]. For example, echo chambers in online ecosystems can create an illusion of support, amplifying biases like false consensus effects and confirmation biases [00:15:57].

One theory suggests that people share information online due to inattention, as social media contexts focus their attention on other factors, such as the desire to attract and please followers, rather than the accuracy of content [00:16:45]. There is evidence that scalable attention-based interventions can nudge users to think about accuracy when engaging on social media platforms [00:17:10].

## Challenges for Researchers

A significant gap in knowledge about [[Misinformation and disinformation | misinformation]] stems from a lack of real-world research and empirical evidence in natural use settings, especially on social media platforms [00:18:16]. Researchers face challenges in accessing social media platform data to advance understanding [00:18:44], leading to frustration in the academic community due to this lack of access and collaboration between researchers and platforms [00:19:01].

It is difficult to understand and measure the spread of [[Misinformation and disinformation | misinformation]] [00:19:16]. Much of the current research on spread and sharing originates from Twitter, which has an open API, meaning less is known about platforms where [[Misinformation and disinformation | misinformation]] might be more prevalent, such as Facebook, TikTok, or WhatsApp [00:19:29]. Furthermore, measuring the true impact of exposure to [[Misinformation and disinformation | misinformation]] is difficult because researchers typically have access to "expression data" (likes, shares) but not "impression data" (who actually read or was exposed to content) [00:19:53].

Interventions tested to date often lack ecological and external validity because opportunities to rigorously test them on social media platforms are minimal [00:20:34]. This makes it challenging to know if interventions would work in real-world contexts, their effect sizes, or how they might be optimized for different populations [00:20:45]. The current body of evidence heavily relies on self-report data, which has inherent challenges [00:20:57].

## User Behavior and Engagement

In contexts like Lebanon, where people face multiple crises, the majority have little bandwidth to verify information or critically engage with it [00:28:50]. They tend to rely on common sense or self-constructed judgments of information sources [00:29:21]. Fact-checking is uncommon, primarily due to a lack of interest [00:29:31]. Interventions, therefore, should consider lightweight interactions rather than extensive fact-checking [00:31:09].

For instance, a project in Lebanon encourages youth to flag potential [[Misinformation and disinformation | misinformation]] instead of bearing the burden of fact-checking themselves [00:31:22]. This approach shifts responsibility, allowing many individuals to contribute in small ways to address [[Misinformation and disinformation | misinformation]] at a structural level [00:31:45].

## Proposed Solutions and Future Directions

Given the complexities, a single "silver bullet" solution is unlikely [00:55:40]. A range of solutions that vary in user engagement levels will be required [00:55:47]. The architects of [[Misinformation and disinformation | misinformation]] already possess a deep understanding of human behavior, often surpassing that of organizations trying to combat it [00:38:11]. This highlights the need for rigorous research into the various factors shaping people's perceptions and behaviors [00:38:24].

Research should be grounded in particular contexts, acknowledging that a one-size-fits-all approach is ineffective [00:34:37]. For example, in Lebanon, despite being a small country, significant differences in perception and behavior exist between areas [00:34:43]. Combining social monitoring (e.g., online research) with human perspectives (e.g., audience research, interviews, focus groups) can provide a more nuanced and localized understanding of [[Misinformation and disinformation | disinformation]] trends and how people interact with information [00:43:22]. This ongoing understanding of public interaction with the information ecosystem is crucial for adapting responses effectively [00:44:01].

The effectiveness of strategies like "inoculation" or "pre-bunking" shows promise, but more evidence is needed on their long-term effects and how those effects decay over time [00:56:00]. Similarly, the strategy of "debunking" is debated; while some literature suggests it may not be ideal and could have backfire effects, other academics argue these effects are overblown and debunking has a place in certain contexts [00:56:22]. Ultimately, a complex and varied set of solutions is needed, as no single approach will solve the problem [00:56:46].