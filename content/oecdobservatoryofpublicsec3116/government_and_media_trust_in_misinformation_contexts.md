---
title: Government and media trust in misinformation contexts
videoId: IUItMNuR23s
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

The spread of [[misinformation_and_disinformation | misinformation]] is a growing threat, particularly to the future of democracy, in a world characterized by an unregulated information ecosystem and increasing algorithmic determinism on social media platforms <a class="yt-timestamp" data-t="00:01:06">[00:01:06]</a>. Effective strategies for [[addressing_misinformation_and_improving_communication_between_citizens_and_governments | addressing misinformation]] must consider the crucial role of [[public_trust_and_governance | public trust]] in government and media.

## The Role of Trust in Susceptibility to Misinformation

Research indicates that the degree of trust individuals place in public institutions and science is a significant factor in their susceptibility to [[misinformation_and_disinformation | misinformation]] <a class="yt-timestamp" data-t="00:15:34">[00:15:34]</a>. The OECD's behavioral science team is developing good practice principles for public communications to counter [[misinformation_and_disinformation | misinformation]] <a class="yt-timestamp" data-t="00:01:53">[00:01:53]</a>.

In Canada, data from the COSMO study, which monitors Canadians' knowledge, risk perceptions, and self-reported behaviors during the COVID-19 pandemic, has shown a strong association between the ability to discern the accuracy of misinformation statements and vaccine intentions <a class="yt-timestamp" data-t="00:10:56">[00:10:56]</a>. Specifically, those better at identifying misinformation were more likely to intend to get vaccinated <a class="yt-timestamp" data-t="00:11:14">[00:11:14]</a>.

It was observed that factors like trust in government and scientists were more predictive of susceptibility to misinformation than socio-economic factors <a class="yt-timestamp" data-t="00:22:31">[00:22:31]</a>. For instance, 90% of individuals who intended to get a vaccine as soon as it was available correctly identified all misinformation statements as false. This percentage significantly decreased as vaccine acceptance declined <a class="yt-timestamp" data-t="00:11:37">[00:11:37]</a>. This highlights the [[impact_of_misinformation_on_public_health_behaviors | impact of misinformation on public health behaviors]].

## Case Study: Lebanon's Unique Challenges

Lebanon presents a complex context for combating [[misinformation_and_disinformation | misinformation]] due to compounded crises, including political deadlock, economic collapse, and the Beirut explosion <a class="yt-timestamp" data-t="00:25:58">[00:25:58]</a>. These crises have led to declining public faith in the government and rising fatigue <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a>.

### Limited Public Bandwidth and Media Landscape
In such an environment, the majority of people have little to no bandwidth to verify information or critically engage with it <a class="yt-timestamp" data-t="00:28:55">[00:28:55]</a>. Instead, they rely on common sense or self-constructed judgments of information sources <a class="yt-timestamp" data-t="00:29:21">[00:29:21]</a>. Fact-checking is uncommon, primarily due to a lack of interest <a class="yt-timestamp" data-t="00:29:31">[00:29:31]</a>.

The media landscape in Lebanon is further complicated by traditional media outlets being largely affiliated with the country's political parties <a class="yt-timestamp" data-t="00:27:57">[00:27:57]</a>. This historical fragmentation of information access has resulted in further distrust in formal or legacy media platforms <a class="yt-timestamp" data-t="00:28:07">[00:28:07]</a>. While social media contributes to information pollution, legacy media, particularly TV, remains a primary news source for a large portion of the population <a class="yt-timestamp" data-t="00:32:51">[00:32:51]</a>.

### Absence of Government Trust
The prolonged absence of a functioning government in Lebanon has eroded [[public_trust_and_governance | public trust]] <a class="yt-timestamp" data-t="00:35:10">[00:35:10]</a>. As a result, approaches that foreground the government as a primary fact-checker or a trustworthy source of information are unlikely to gain traction <a class="yt-timestamp" data-t="00:37:54">[00:37:54]</a>.

Experiments in Lebanon have shown that messaging appealing to common skepticism about government motives, such as "57% of Lebanese believe COVID-19 is a conspiracy intended to control people. What do you think?", garnered significant engagement, demonstrating a greater interest in discussing conspiracies about the government than in taking the government seriously <a class="yt-timestamp" data-t="00:36:08">[00:36:08]</a>. This led to strategies where government logos were excluded or balanced with logos from trusted international agencies like WHO and UNICEF in public health campaigns <a class="yt-timestamp" data-t="00:37:18">[00:37:18]</a>.

## Challenges and Future Directions

The context-specificity of misinformation interventions is paramount; a one-size-fits-all approach will not work <a class="yt-timestamp" data-t="00:42:07">[00:42:07]</a>. Even within a small country like Lebanon, significant differences in perception and behavior exist between areas <a class="yt-timestamp" data-t="00:34:40">[00:34:40]</a>.

### Data Access and Collaboration
A key challenge for researchers is the lack of access to social media platform data, particularly "impression data" (who was actually exposed to content), which limits the ability to understand the true impact of misinformation <a class="yt-timestamp" data-t="00:19:56">[00:19:56]</a>. This lack of collaboration between researchers and platforms hinders the development and rigorous testing of effective interventions in real-world contexts <a class="yt-timestamp" data-t="00:20:25">[00:20:25]</a>.

### Behavioral Science and Intervention Design
Governments often rely on traditional tools like education and regulation, with limited consideration for solutions based on [[behavioral_science_in_combating_misinformation | behavioral science]] <a class="yt-timestamp" data-t="00:02:11">[00:02:11]</a>. However, the architects of [[misinformation_and_disinformation | disinformation]] often possess a deep understanding of human behavior <a class="yt-timestamp" data-t="00:38:11">[00:38:11]</a>.

Future interventions need to:
*   **Acknowledge bandwidth limitations**: Design lightweight interactions rather than extensive fact-checking requirements <a class="yt-timestamp" data-t="00:31:12">[00:31:12]</a>.
*   **Go beyond digital**: Recognize that misinformation exists outside the digital sphere and consider analog campaign components <a class="yt-timestamp" data-t="00:33:39">[00:33:39]</a>.
*   **Rigorously research contexts**: Interventions must be grounded in specific contexts and cater to diverse populations (e.g., generational divides, urban-rural specificities) <a class="yt-timestamp" data-t="00:34:33">[00:34:33]</a>.
*   **Consider [[role_of_social_media_algorithms_in_misinformation | algorithmic redesign]]**: Some argue that fundamental redesign of how social media platforms promote content is necessary to combat the spread of misinformation <a class="yt-timestamp" data-t="00:48:51">[00:48:51]</a>.

Ultimately, there is no single "silver bullet" solution to [[misinformation_and_disinformation | misinformation]] <a class="yt-timestamp" data-t="00:55:43">[00:55:43]</a>. A varied set of solutions, continually evolving to address new forms of fake news and [[misinformation_and_disinformation | disinformation]], is required <a class="yt-timestamp" data-t="00:57:49">[00:57:49]</a>. This necessitates ongoing research that is made accessible to other organizations and the communities they serve <a class="yt-timestamp" data-t="00:38:40">[00:38:40]</a>.