---
title: The role of social media platforms in spreading misinformation
videoId: IUItMNuR23s
---

From: [[oecdobservatoryofpublicsec3116]] <br/> 

Social media platforms play a significant role in the spread of misinformation, presenting unique challenges due to their structure, algorithms, and user behavior <a class="yt-timestamp" data-t="00:01:16">[00:01:16]</a>. The information ecosystem on these platforms suffers from limited regulation and increasing algorithmic determinism <a class="yt-timestamp" data-t="00:01:16">[00:01:16]</a>.

## How Social Media Contributes to Misinformation

The structure of online environments and social network effects can amplify and exacerbate existing cognitive biases <a class="yt-timestamp" data-t="00:15:46">[00:15:46]</a>. Specifically:
*   **Echo Chambers** Online ecosystems can create an illusion of support and amplify biases such as false consensus effects and confirmation biases <a class="yt-timestamp" data-t="00:15:57">[00:15:57]</a>.
*   **Inattention and Virality** People often share misinformation not because they believe it, but because they are not paying attention to the accuracy of content <a class="yt-timestamp" data-t="00:16:48">[00:16:48]</a>. The social media context often shifts user attention to other factors, like the desire to attract and please followers <a class="yt-timestamp" data-t="00:16:53">[00:16:53]</a>.
*   **Algorithmic Promotion** Algorithms govern how information is spread and which articles are shared more than others <a class="yt-timestamp" data-t="00:48:22">[00:48:22]</a>. These algorithms can problematic because they tend to have an unintended effect of spreading misinformation <a class="yt-timestamp" data-t="00:48:40">[00:48:40]</a>.
*   **Information Pollution** Platforms contribute to an ecosystem of "information pollution," where misleading information, voice notes, and pictures circulate easily and readily <a class="yt-timestamp" data-t="00:28:15">[00:28:15]</a>.

## Challenges for Research and Interventions

Understanding and combating misinformation on social media is complex, largely due to challenges in research and collaboration with platforms:
*   **Lack of Real-World Data** There is a significant lack of research and empirical evidence in real-world contexts and natural use settings where people interact with information daily, particularly on social media platforms <a class="yt-timestamp" data-t="00:18:27">[00:18:27]</a>.
*   **Data Access Issues** Misinformation researchers need better access to social media platform data to further their knowledge base <a class="yt-timestamp" data-t="00:18:41">[00:18:41]</a>. There is frustration in the academic community regarding this lack of data access and collaboration between researchers and platforms <a class="yt-timestamp" data-t="00:18:53">[00:18:53]</a>.
*   **Limited Measurement of Impact** While researchers can access "expression data" (who liked and shared content), they currently lack "impression data" (who actually read or was exposed to the content) <a class="yt-timestamp" data-t="00:19:53">[00:19:53]</a>. This limitation makes it difficult to understand the true impact of misinformation <a class="yt-timestamp" data-t="00:20:09">[00:20:09]</a>.
*   **Ecological Validity of Interventions** Interventions tested to date often lack ecological and external validity because there are few opportunities to rigorously test them on social media platforms <a class="yt-timestamp" data-t="00:20:25">[00:20:25]</a>. This makes it hard to determine if they would work in real-world contexts, what effect sizes they might have, or how they could be optimized for different populations <a class="yt-timestamp" data-t="00:20:45">[00:20:45]</a>.
*   **Reliance on Self-Report Data** The current body of evidence relies heavily on self-report data, which has inherent challenges <a class="yt-timestamp" data-t="00:20:57">[00:20:57]</a>.

## Potential [[Interventions and strategies to reduce misinformation]]

Despite the challenges, efforts are being made to develop effective interventions:
*   **Attention-Based Interventions** Research suggests that scalable attention-based interventions could nudge or prompt users to think about accuracy as they engage on social media platforms <a class="yt-timestamp" data-t="00:17:01">[00:17:01]</a>.
*   **Crowdsourced Moderation** Projects like Ted's Healthy Internet Project encourage lightweight interactions, such as asking youth to flag potential misinformation rather than bearing the full burden of fact-checking themselves <a class="yt-timestamp" data-t="03:10:09">[03:10:09]</a>. This approach shifts the responsibility from individuals to a collective, with many people contributing in a tiny way to address misinformation at a structural level <a class="yt-timestamp" data-t="03:11:54">[03:11:54]</a>.

### Broader Considerations for Addressing Misinformation

The issue of misinformation on social media is part of a larger problem that requires a multifaceted approach:
*   **Beyond Digital** Misinformation has a long history and exists outside the digital sphere, with traditional media outlets also contributing to fragmented information landscapes and distrust <a class="yt-timestamp" data-t="03:16:50">[03:16:50]</a>.
*   **Context is Key** There is no one-size-fits-all solution for combating misinformation <a class="yt-timestamp" data-t="03:40:51">[03:40:51]</a>. Strategies need to be adapted to specific contexts, considering political, social, and economic landscapes, as well as generational and urban-rural divides <a class="yt-timestamp" data-t="03:42:07">[03:42:07]</a>.
*   **Trust in Institutions** The effectiveness of interventions can be heavily influenced by public trust in government and other institutions <a class="yt-timestamp" data-t="03:54:05">[03:54:05]</a>. In contexts where government trust is low, relying on government logos or direct debunking can be counterproductive <a class="yt-timestamp" data-t="03:57:18">[03:57:18]</a>. Leveraging credible non-governmental organizations or international bodies can be more effective <a class="yt-timestamp" data-t="03:57:36">[03:57:36]</a>.
*   **Behavioral Science Application** [[Behavioral science applications in combating misinformation]] are crucial across all aspects of response to information pollution, including building public trust and resilience, improving media capacity, and supporting evidence-based policy <a class="yt-timestamp" data-t="04:10:07">[04:10:07]</a>.
*   **Ongoing Research** Continuous research is needed to understand how the public interacts with the information ecosystem and how it changes over time, allowing for adaptable responses <a class="yt-timestamp" data-t="04:40:01">[04:40:01]</a>. This includes combining social listening with human-centric research methods like audience interviews and focus groups for nuanced understanding <a class="yt-timestamp" data-t="04:30:30">[04:30:30]</a>.