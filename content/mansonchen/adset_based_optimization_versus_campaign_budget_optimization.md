---
title: Adset based optimization versus campaign budget optimization
videoId: 4xoC_A-3Ed8
---

From: [[mansonchen]] <br/> 

To maximize creative learnings and scale potential in advertising, properly setting up creative testing campaigns is crucial. Without the correct setup, advertisers risk wasting money on inefficient tests, plateauing, and burning through resources on ineffective ads <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>.

## The Need for Diverse Creatives

Key statistics highlight the importance of a high volume of diverse creatives in ad campaigns:
*   Only 2% of ad variations account for 68% of ad spend, according to Appsfly research <a class="yt-timestamp" data-t="00:38:00">[00:38:00]</a>.
*   Facebook research indicates a 60% drop in conversions after just four repeated ad exposures <a class="yt-timestamp" data-t="00:45:00">[00:45:00]</a>.
*   Half of all ads don't last more than two days <a class="yt-timestamp" data-t="00:53:00">[00:53:00]</a>.

For monthly ad spends between $10,000 and $100,000, Veros analysis found an average of 103 creatives live, emphasizing the need for a high volume of new creative concepts <a class="yt-timestamp" data-t="01:07:00">[01:07:00]</a>.

## Optimizing for Purchase or Trial Start

The first principle for effective creative testing is to [[optimizing_meta_ad_campaigns_for_purchases | optimize for the purchase or trial start]] (or an event highly correlated to revenue growth) <a class="yt-timestamp" data-t="01:55:00">[01:55:00]</a>. While there's a trade-off between signal impact and signal volume, it's generally not recommended to optimize for installs or registrations unless there's a clear understanding of the implications <a class="yt-timestamp" data-t="02:05:00">[02:05:00]</a>.

> [!NOTE] Higher-funnel optimization can reach new audiences, but it requires robust measurement to ensure accuracy <a class="yt-timestamp" data-t="02:19:00">[02:19:00]</a>. It's usually best to start by optimizing for purchase or trial start <a class="yt-timestamp" data-t="02:34:00">[02:34:00]</a>. If optimizing for trial starts, ensure they are high-quality and pass relevant signals to Facebook <a class="yt-timestamp" data-t="02:46:00">[02:46:00]</a>.

## Adset-Based Optimization for Creative Testing

For creative testing campaigns, an [[adset_budget_optimization_vs_advantage_shopping_campaigns | adset-based optimization]] approach is preferred over Campaign Budget Optimization (CBO) <a class="yt-timestamp" data-t="03:05:00">[03:05:00]</a>.

> [!INFO] **Adset Tests**
> It's recommended to have around four to six ad variations of an ad concept within each adset <a class="yt-timestamp" data-t="05:17:00">[05:17:00]</a>. These variations can include different hooks, script bodies (e.g., problem/solution statements), or music variations <a class="yt-timestamp" data-t="05:25:00">[05:25:00]</a>. Remember to test one variable at a time <a class="yt-timestamp" data-t="05:53:00">[05:53:00]</a>.

### Why Adset-Based Optimization for Testing?

Adset-based optimization is crucial for creative testing because it forces spend to individual ad concepts and variations, allowing advertisers to understand how they perform relative to each other <a class="yt-timestamp" data-t="03:12:00">[03:12:00]</a>. This approach maximizes learnings <a class="yt-timestamp" data-t="04:41:00">[04:41:00]</a>.

### Drawbacks of Campaign Budget Optimization (CBO) for Creative Testing

Running CBO campaigns as creative testing campaigns can be a misunderstanding of their purpose <a class="yt-timestamp" data-t="03:38:00">[03:38:00]</a>. While CBO optimizes for short-term performance, it has significant drawbacks for creative testing:
*   **Underspending on Concepts**: CBO doesn't force spend evenly across ad concepts, preventing an understanding of how different concepts or ad variations stack rank against each other <a class="yt-timestamp" data-t="03:18:00">[03:18:00]</a>.
*   **Missed Insights**: CBO can lead to a lack of insights into what creative dimensions truly work, such as visual hooks, text hooks, angles, or creators <a class="yt-timestamp" data-t="04:08:00">[04:08:00]</a>.
*   **Budget Concentration**: Facebook's CBO typically allocates most of its budget to only one or two ads within an adset, meaning the vast majority of ad variations may receive little to no spend <a class="yt-timestamp" data-t="04:19:00">[04:19:00]</a>.

While CBO with [[adset_budget_optimization_vs_advantage_shopping_campaigns | Advantage Shopping Plus]] campaigns can work for overall performance, it hinders the long-term understanding of creative effectiveness <a class="yt-timestamp" data-t="05:00:00">[05:00:00]</a>.

## Automated Stop-Losses to Eliminate Waste

Implementing automated stop-losses helps eliminate waste and allows for testing a high volume of creatives without overspending on underperforming ads <a class="yt-timestamp" data-t="06:12:00">[06:12:00]</a>. These triggers can be adjusted based on the funnel's conversion rates, install-to-trial, and trial-to-paid metrics <a class="yt-timestamp" data-t="06:37:00">[06:37:00]</a>.

Recommended triggers:
*   **Trigger 1 (3x CPA)**: If an ad has spent 3 times the target Cost Per Acquisition (CPA) with zero conversions, kill it <a class="yt-timestamp" data-t="06:46:00">[06:46:00]</a>. For example, if CPA is $50, kill the ad if it spends $150 with no trial starts <a class="yt-timestamp" data-t="06:56:00">[06:56:00]</a>.
*   **Trigger 2 (5x CPA)**: If an ad spends 5 times the CPA (e.g., $250) and its current CPA is 25% above the goal, kill it <a class="yt-timestamp" data-t="07:08:00">[07:08:00]</a>.
*   **Trigger 3 (10x CPA)**: If an ad spends 10 times the CPA (e.g., $500) and its current CPA is above the goal, kill it <a class="yt-timestamp" data-t="07:20:00">[07:20:00]</a>.

## Disabling Enhancements

It is advisable to disable automatic enhancements in ad settings <a class="yt-timestamp" data-t="07:55:00">[07:55:00]</a>. These enhancements can negatively affect ad performance and introduce too many variables, making it harder to understand what specific creative elements are working <a class="yt-timestamp" data-t="07:58:00">[07:58:00]</a>.

## Scaling Winning Ads

For ads that haven't been killed by the automated stop-losses, there are two primary [[strategies_for_scaling_successful_ads | scaling strategies]]:
1.  **Gradually increase daily budgets** within the adset of the creative testing campaign <a class="yt-timestamp" data-t="08:25:00">[08:25:00]</a>.
2.  **Move the ad to an evergreen campaign** using the post ID method <a class="yt-timestamp" data-t="08:34:00">[08:34:00]</a>. This consolidates social proof and allows the working ad to continue running <a class="yt-timestamp" data-t="08:39:00">[08:39:00]</a>. To get the post ID, preview the ad in Ads Manager, click "See Facebook post with comments," and copy the numbers after the page ID <a class="yt-timestamp" data-t="08:47:00">[08:47:00]</a>.

## Creative Testing Framework: Iterate and Optimize

A top-down framework for creative testing involves a dedicated creative testing campaign feeding into an evergreen or scaling campaign <a class="yt-timestamp" data-t="09:06:00">[09:06:00]</a>. Ads are categorized based on their performance in the testing campaign:
*   **Red (High CPA)**: Ads with a CPA that is too high should not be iterated upon <a class="yt-timestamp" data-t="09:42:00">[09:42:00]</a>.
*   **Green (Meets CPA Goal)**: Ads that meet the CPA goal after sufficient spend (e.g., 10x CPA) can be moved into the evergreen campaign <a class="yt-timestamp" data-t="09:53:00">[09:53:00]</a>.
*   **Yellow (Close to CPA Goal)**: These ad variations show promise, being somewhat close to the CPA goal <a class="yt-timestamp" data-t="10:01:00">[10:01:00]</a>. They should be iterated upon by [[testing_and_optimizing_ad_variations | adjusting hooks, script frameworks, editing, pacing, or trying different creators]] <a class="yt-timestamp" data-t="10:08:00">[10:08:00]</a>.

It can take two to three rounds of iteration for a new ad concept to become a winner <a class="yt-timestamp" data-t="10:21:00">[10:21:00]</a>. If an ad concept doesn't work after four rounds of iteration, it may be dropped <a class="yt-timestamp" data-t="10:36:00">[10:36:00]</a>.

## Final Thoughts on Creative Testing

*   **Be Wary of Copying Ads**: Copying competitor ads is risky as 90% of ads are duds, and it's impossible to know how well those ads are truly performing for competitors <a class="yt-timestamp" data-t="10:54:00">[10:54:00]</a>. Instead, derive high-level insights such as creator types, angles, script frameworks, and concepts they repeatedly iterate on <a class="yt-timestamp" data-t="11:10:00">[11:10:00]</a>.
*   **Ensure Sufficient Spend on Tests**: Conclusions cannot be drawn on ad variation performance with less than $10 of spend <a class="yt-timestamp" data-t="11:35:00">[11:35:00]</a>. Many advertisers test many ads but fail to allocate enough spend to gather meaningful learnings <a class="yt-timestamp" data-t="11:43:00">[11:43:00]</a>.
*   **Have Fun**: Finding winning ads can be challenging when company growth depends on it, but maintaining creativity by having fun is essential for generating new ad ideas <a class="yt-timestamp" data-t="11:58:00">[11:58:00]</a>.