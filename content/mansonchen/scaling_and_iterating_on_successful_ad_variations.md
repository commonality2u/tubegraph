---
title: Scaling and iterating on successful ad variations
videoId: 4xoC_A-3Ed8
---

From: [[mansonchen]] <br/> 

Optimizing ad campaigns is crucial to maximizing creative learnings and scaling potential <a class="yt-timestamp" data-t="00:00:04">[00:00:04]</a>. Without proper setup, testing can lead to wasted money on inefficient tests, performance plateaus, and spending on ineffective ads <a class="yt-timestamp" data-t="00:00:08">[00:00:08]</a>. This article, informed by insights from multi-7-figure monthly Facebook ad spends <a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a>, outlines principles for effective [[Testing and Iteration for Successful Ads | testing and iteration]].

## Key Ad Campaign Statistics

Several statistics highlight the dynamic nature of ad performance and the importance of continuous [[Testing and Iteration for Successful Ads | testing and iteration]]:
*   **Ad Variation Concentration** Only 2% of ad variations capture 68% of ad spend, according to Appsfly research <a class="yt-timestamp" data-t="00:00:38">[00:00:38]</a>.
*   **Conversion Decline** Facebook research indicates a 60% drop in conversions after an ad is exposed four times <a class="yt-timestamp" data-t="00:00:45">[00:00:45]</a>.
*   **Ad Lifespan** 50% of ads do not last more than two days <a class="yt-timestamp" data-t="00:00:53">[00:00:53]</a>.

These figures underscore the need for a high volume of diverse and strategic creatives <a class="yt-timestamp" data-t="00:00:59">[00:00:59]</a>. For example, a Veros analysis of 5,000 ad accounts in May 2024 showed that accounts with $10,000 to $100,000 in monthly spend typically had around 103 live creatives with over 20 impressions <a class="yt-timestamp" data-t="00:01:07">[00:01:07]</a>.

## Principles of Creative Testing Campaigns

### 1. Optimize for Revenue-Correlating Events
The primary objective should be to optimize for events directly correlated with revenue growth, such as purchases or trial starts <a class="yt-timestamp" data-t="00:01:55">[00:01:55]</a>. While there is a trade-off between signal impact and signal volume, optimizing for higher-funnel objectives like installs or registrations without proper measurement can be challenging <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>. It's recommended to start by optimizing for purchases or trial starts <a class="yt-timestamp" data-t="00:02:34">[00:02:34]</a>. Ensure that trial starts are high-quality and signal this to Facebook <a class="yt-timestamp" data-t="00:02:46">[00:02:46]</a>.

### 2. Adset-Based Optimization
For [[Testing and Iteration for Successful Ads | creative testing campaigns]], adset-based optimization is preferred over Campaign Budget Optimization (CBO) <a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a>. CBO tends to underspend on ad concepts, making it difficult to understand how different concepts or their variations perform relative to each other <a class="yt-timestamp" data-t="00:03:15">[00:03:15]</a>.

While CBO can be used for short-term performance optimization (e.g., throwing everything into an Advantage Shopping Plus campaign) <a class="yt-timestamp" data-t="00:03:59">[00:03:59]</a>, it misses critical insights into which creative dimensions (e.g., visual hooks, text hooks, angles, creators) are effective in the long term <a class="yt-timestamp" data-t="00:04:08">[00:04:08]</a>. CBO typically allocates most of its budget to only one or two ads within an ad set, limiting spend on other variations and hindering learning <a class="yt-timestamp" data-t="00:04:24">[00:04:24]</a>. To maximize learnings, it's essential to force spend to various ads and ad sets <a class="yt-timestamp" data-t="00:04:41">[00:04:41]</a>.

Each adset should contain around four to six ad variations of a single ad concept <a class="yt-timestamp" data-t="00:05:20">[00:05:20]</a>. These variations can include changes to hooks, script bodies (problem/solution statements), or music <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>. Remember to test only one variable at a time <a class="yt-timestamp" data-t="00:05:53">[00:05:53]</a> and maintain consistent naming conventions <a class="yt-timestamp" data-t="00:05:56">[00:05:56]</a>.

### 3. Automated Stop-Losses
Implementing automated stop-losses helps eliminate waste by killing ads with a low likelihood of working, allowing for [[Testing and optimizing ad variations | testing a high volume of creatives]] without excessive spending <a class="yt-timestamp" data-t="00:06:12">[00:06:12]</a>. Triggers can be adjusted over time based on funnel conversion rates, but a good starting point is <a class="yt-timestamp" data-t="00:06:34">[00:06:34]</a>:
*   **Trigger 1** If an ad spends 3x your Cost Per Action (CPA) goal (e.g., $150 for a $50 CPA) with zero conversions, kill it <a class="yt-timestamp" data-t="00:06:46">[00:06:46]</a>.
*   **Trigger 2** If an ad spends 5x your CPA goal (e.g., $250 for a $50 CPA) and is 25% above your CPA goal, kill it <a class="yt-timestamp" data-t="00:07:08">[00:07:08]</a>.
*   **Trigger 3** If an ad spends 10x your CPA goal (e.g., $500 for a $50 CPA) and is above your CPA goal, kill it <a class="yt-timestamp" data-t="00:07:20">[00:07:20]</a>.
These triggers can be refined based on payback period goals and historical funnel performance <a class="yt-timestamp" data-t="00:07:32">[00:07:32]</a>.

### 4. Disable Enhancements
Disabling automatic ad enhancements is recommended because they can negatively affect performance and introduce too many variables, reducing understanding of what works <a class="yt-timestamp" data-t="00:07:55">[00:07:55]</a>.

### 5. Scaling Successful Ads
[[Strategies for scaling successful ads | Scaling successful ads]] involves gradually increasing daily budgets for ads that haven't been killed by stop-losses <a class="yt-timestamp" data-t="00:08:17">[00:08:17]</a>. Winning ads should be moved into an evergreen campaign using the post ID method to consolidate social proof and maintain ad set performance <a class="yt-timestamp" data-t="00:08:31">[00:08:31]</a>.

To obtain the post ID:
1.  In Ads Manager, click "Preview ad" <a class="yt-timestamp" data-t="00:08:50">[00:08:50]</a>.
2.  Select "See Facebook post with comments" <a class="yt-timestamp" data-t="00:08:53">[00:08:53]</a>.
3.  Copy the numbers after the page ID in the URL <a class="yt-timestamp" data-t="00:08:56">[00:08:56]</a>.
4.  In the evergreen campaign, create a new ad and paste the post ID <a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a>.

## Creative Testing Framework

The creative testing framework involves a **creative testing campaign** and an **evergreen campaign** (or multiple scaling campaigns) <a class="yt-timestamp" data-t="00:09:10">[00:09:10]</a>.

Based on an ad's performance in the creative testing campaign, categorize it:
*   **Red Ads** Those significantly above the CPA goal should not be iterated on <a class="yt-timestamp" data-t="00:09:42">[00:09:42]</a>.
*   **Green Ads** Ads that meet the CPA goal after 10x CPA spend should be moved into the evergreen campaign <a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a>.
*   **Yellow Ads** Ad variations that are somewhat close to the CPA goal and show promise should be [[Iterating and improving Meta ads | iterated on]] <a class="yt-timestamp" data-t="00:10:04">[00:10:04]</a>. This involves switching hooks, adjusting script frameworks, changing editing/pacing, or trying different creators <a class="yt-timestamp" data-t="00:10:08">[00:10:08]</a>.

It can take two to three rounds of [[Iterative testing process to find winning ads | iteration]] for a new concept to become a winner and meet the CPA goal <a class="yt-timestamp" data-t="00:10:21">[00:10:21]</a>. If an ad concept is tested for four rounds of iteration and still doesn't perform, it should be dropped <a class="yt-timestamp" data-t="00:10:36">[00:10:36]</a>.

## Final Considerations

*   **Avoid Blind Copying** Be cautious when copying competitors' ads, as you don't know if they are actually working for them <a class="yt-timestamp" data-t="00:10:54">[00:10:54]</a>. 90% of ads are duds <a class="yt-timestamp" data-t="00:11:02">[00:11:02]</a>. Instead, derive high-level insights, such as creators used, angles, script frameworks, and concepts they continually iterate on <a class="yt-timestamp" data-t="00:11:14">[00:11:14]</a>.
*   **Adequate Spend on Tests** Conclusions on ad variation performance cannot be drawn with less than $10 of spend <a class="yt-timestamp" data-t="00:11:35">[00:11:35]</a>. Many advertisers make the mistake of creating many ads but not spending enough to gain sufficient learnings <a class="yt-timestamp" data-t="00:11:46">[00:11:46]</a>.
*   **Have Fun** Maintaining a positive attitude fosters creativity, which leads to more effective ad ideas <a class="yt-timestamp" data-t="00:11:58">[00:11:58]</a>.