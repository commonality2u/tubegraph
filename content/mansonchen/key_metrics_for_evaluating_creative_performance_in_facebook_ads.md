---
title: Key Metrics for Evaluating Creative Performance in Facebook Ads
videoId: 9mGvU3flyLE
---

From: [[mansonchen]] <br/> 

To effectively [[creative_testing_for_facebook_ads|test creative]] at scale, a dashboard is essential for visualizing and understanding which creative elements, ads, and concepts are performing well <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a>. This article outlines a method for monitoring [[creative_testing_in_facebook_ads|creative tests]] using [[understanding_facebook_ads_reporting_for_creative_testing|Facebook's ad reporting]], which is powerful, flexible, and free <a class="yt-timestamp" data-t="00:00:19">[00:00:19]</a>.

## Dashboard Setup and Core Metrics

The dashboard columns are structured to provide a clear view of performance:

*   **Adset Name**: Groups concepts together, with each ad set containing four to six video or ad variations <a class="yt-timestamp" data-t="00:00:37">[00:00:37]</a>. Variables are isolated within each variance to identify effective hooks, visuals, and scripts <a class="yt-timestamp" data-t="00:00:48">[00:00:48]</a>.
*   **Ad Name**: Identifies individual ad variations within an ad set <a class="yt-timestamp" data-t="00:01:05">[00:01:05]</a>.
*   **Delivery**: Indicates if the ad is active <a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a>.
*   **Amount Spent**: Tracks the total expenditure on an ad <a class="yt-timestamp" data-t="00:01:14">[00:01:14]</a>.
*   **Results (Purchases)**: Shows the number of conversions or purchases achieved <a class="yt-timestamp" data-t="00:01:17">[00:01:17]</a>.
*   **Cost Per Purchase (Cost Per Result)**: A crucial metric, often enhanced with conditional formatting (similar to Excel or Google Sheets) to easily visualize performance <a class="yt-timestamp" data-t="00:01:20">[00:01:20]</a>.

### Additional Metrics for Monitoring Performance

Less critical but still monitored metrics include:

*   **Impression CPM** <a class="yt-timestamp" data-t="00:01:38">[00:01:38]</a>
*   **Reach** <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a>
*   **Frequency** <a class="yt-timestamp" data-t="00:01:42">[00:01:42]</a>

## [[custom_metrics_in_facebook_ads|Custom Metrics]] for Video Ad Effectiveness

For video ads, specific "soft metrics" provide insights into engagement:

*   **Hook Rate**: Calculated as 3-second video views divided by impressions <a class="yt-timestamp" data-t="00:01:43">[00:01:43]</a>.
*   **Hold Rate**: Represents through plays (or 15-second video views) divided by impressions <a class="yt-timestamp" data-t="00:01:50">[00:01:50]</a>.
*   **Cost Per 3-Second Video Play** <a class="yt-timestamp" data-t="00:01:58">[00:01:58]</a>
*   **Average View Duration** <a class="yt-timestamp" data-t="00:02:01">[00:02:01]</a>

Other key metrics include:

*   **Link Click CTR (Click-Through Rate)** <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>
*   **Result Rate** <a class="yt-timestamp" data-t="00:02:04">[00:02:04]</a>

## [[effective_creative_testing_strategies_on_facebook|Creative Testing Campaign Structure]]

It is highly recommended to set up a separate [[creative_testing_campaign_facebook_ads|creative testing campaign]], especially for ad accounts spending over $50,000 per month <a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>. This is because Facebook often allocates most of an ad set's budget to one ad, which may not always be the best performer <a class="yt-timestamp" data-t="00:02:27">[00:02:27]</a>. Isolating tests allows for more controlled evaluation <a class="yt-timestamp" data-t="00:02:51">[00:02:51]</a>.

## Automated Triggers for Pausing Underperforming Ads

To maintain efficiency and keep costs low during [[high_volume_of_creative_for_scaling_facebook_ads|high-volume creative testing]], automated rules should be implemented to pause ads that do not meet KPI goals <a class="yt-timestamp" data-t="00:02:56">[00:02:56]</a>. These "gates" are based on spend and Cost Per Acquisition (CPA):

*   **Gate 1**: Pause an ad after $150 in spend if it has generated zero purchases <a class="yt-timestamp" data-t="00:03:03">[00:03:03]</a>. This threshold is determined by observing ad performance and typical scaling patterns <a class="yt-timestamp" data-t="00:03:19">[00:03:19]</a>.
*   **Gate 2**: Pause an ad after $300 in spend if its CPA is higher than $75 or $80 <a class="yt-timestamp" data-t="00:03:43">[00:03:43]</a>.
*   **Gate 3**: Pause an ad if spend exceeds $500 and CPA is over $65 <a class="yt-timestamp" data-t="00:03:54">[00:03:54]</a>.

## Identifying and Scaling Winning Ads

A winning ad is generally identified when its cost per purchase is less than $65 after spending $150 <a class="yt-timestamp" data-t="00:04:23">[00:04:23]</a>. Once identified, these winning ads are duplicated into broader "winning ad campaigns," which might run worldwide, separate from the US-based testing campaign <a class="yt-timestamp" data-t="00:04:42">[00:04:42]</a>.

## Creative Win Rate

The [[creative_win_rate_facebook_ads|creative win rate]] is an important metric to monitor, calculated as the number of ads that meet the performance criteria (e.g., CPA goal) divided by the total number of ad variations tested <a class="yt-timestamp" data-t="00:05:36">[00:05:36]</a>. For example, testing 47 ad variations and having six meet the CPA goal results in a 12-13% win rate <a class="yt-timestamp" data-t="00:05:40">[00:05:40]</a>. A typical win rate observed is around 10%, though it can vary significantly, sometimes as low as 2%, depending on the scale of testing and whether an account is just starting out <a class="yt-timestamp" data-t="00:05:48">[00:05:48]</a>.

By diligently monitoring these metrics and implementing automated rules, [[creative_team_strategies_for_facebook_ads|teams]] can efficiently identify and scale high-performing [[creative_team_strategies_for_facebook_ads|creative]].