---
title: Creative testing in marketing campaigns
videoId: _48xHTUsHuo
---

From: [[mansonchen]] <br/> 

Welcome to a webinar focusing on [[creative_testing_for_facebook_ads | creative testing]], a crucial process for growth in both web funnels and apps, where "creatives is the king" <a class="yt-timestamp" data-t="00:02:41">[00:02:41]</a>. The session provides useful and interesting content, followed by a Q&A segment <a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a>.

The guest speaker, Manson, has a background in growth at companies like Calm and Cash App, and previously worked at Smartly and FMP, running direct response campaigns for companies such as Uber and DoorDash <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a>. He has managed monthly Facebook ad spends ranging from 7 to 8 figures and now helps subscription brands scale video creative production and [[creative_testing_in_facebook_ads | testing]] <a class="yt-timestamp" data-t="00:03:37">[00:03:37]</a>.

## Agenda
The webinar covers:
1.  The current landscape and latest trends in [[creative_testing_in_facebook_ads | creative testing]] <a class="yt-timestamp" data-t="00:03:51">[00:03:51]</a>.
2.  The foundations of a successful [[principles_of_creative_testing_campaigns | creative testing program]] <a class="yt-timestamp" data-t="00:03:58">[00:03:58]</a>.
3.  Audience research methods <a class="yt-timestamp" data-t="00:04:06">[00:04:06]</a>.
4.  Understanding creative diversity <a class="yt-timestamp" data-t="00:04:10">[00:04:10]</a>.
5.  Setting up a cost-effective and objective [[creative_testing_structure_for_meta_ads | creative testing system]] in Facebook <a class="yt-timestamp" data-t="00:04:16">[00:04:16]</a>.
6.  Scaling ads in Evergreen campaigns <a class="yt-timestamp" data-t="00:04:24">[00:04:24]</a>.
7.  Q&A <a class="yt-timestamp" data-t="00:04:27">[00:04:27]</a>.

## The Current Landscape of Creative Testing
Finding "unicorn ads" that perform exceptionally well is challenging <a class="yt-timestamp" data-t="00:04:37">[00:04:37]</a>. A study by AppsFlyer found that only 2% of ad variations capture 68% of ad spend, and 90% of spend goes to just 10% of ads (excluding ads with less than $50 spend) <a class="yt-timestamp" data-t="00:04:40">[00:04:40]</a>. This means a very small fraction of ads actually make a significant impact <a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a>.

Data from Facebook, dating back about 8 years, revealed that the fastest-growing advertisers tested 11 times more ads per month (45 versus 4) <a class="yt-timestamp" data-t="00:05:31">[00:05:31]</a>. They also found an 11x average variance in Return On Ad Spend (ROAS) between top and bottom-performing creatives <a class="yt-timestamp" data-t="00:05:48">[00:05:48]</a>. This principle of iterative [[testing_and_iterating_ad_concepts | testing and iterating]] remains true, and likely even more so today <a class="yt-timestamp" data-t="00:06:00">[00:06:00]</a>.

A Veros analysis of 5,000 Meta accounts showed a correlation between ad spend and the number of active ads:
*   Advertisers spending $100K-$500K/month had an average of 335 ads with over 20 impressions <a class="yt-timestamp" data-t="00:06:49">[00:06:49]</a>.
*   Those spending $500K-$1M/month had 422 active ads <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>.
*   Smaller advertisers ($10K-$100K/month) had 103 active ads <a class="yt-timestamp" data-t="00:07:05">[00:07:05]</a>.
While there's a "chicken and egg" situation where growth requires extensive [[creative_testing_in_facebook_ads | testing]], budget is also a factor <a class="yt-timestamp" data-t="00:07:15">[00:07:15]</a>.

## Creative Trends Noticed Heading into 2025
*   **Loi Ads ("Looks like it, not an ad")**: These ads are unpolished, don't appear as traditional advertisements, and often perform well due to their authentic feel <a class="yt-timestamp" data-t="00:07:50">[00:07:50]</a>. Examples include Post-its, whiteboard writing, iMessage, Slack messages, and Google Hangouts <a class="yt-timestamp" data-t="00:08:30">[00:08:30]</a>.
*   **AI UGC (User-Generated Content)**: Software like Arc Ads, Puldai, Cify, Captions AI, TikTok Creative Symphony, HeyGen, and CapCut significantly reduce the production cost of these ads <a class="yt-timestamp" data-t="00:09:43">[00:09:43]</a>. They look natural and contribute to [[creative_testing_for_facebook_ads | creative diversity]] <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a>.
*   **AI Statics**: Tools like Midjourney and Flux (an open-source text-to-image model) enable rapid [[testing_and_iterating_ad_concepts | testing and iteration]] of ad concepts <a class="yt-timestamp" data-t="00:11:40">[00:11:40]</a>. A pro tip is using Replicate.com's API to generate hundreds of images at once and then adding text overlays with tools like Canva <a class="yt-timestamp" data-t="00:11:55">[00:11:55]</a>.
*   **AI Video**: Runway's Gen-3 is a leader in AI video <a class="yt-timestamp" data-t="00:12:41">[00:12:41]</a>. A common strategy involves testing different AI visual hooks that lead to the same body video, as seen with BetterMe <a class="yt-timestamp" data-t="00:12:48">[00:12:48]</a>. This represents a modular approach to [[creative_testing_in_facebook_ads | testing]] <a class="yt-timestamp" data-t="00:13:13">[00:13:13]</a>. The overall [[effective_creative_testing_strategies_on_facebook | creative strategy]] for app and web campaigns is similar, with the main difference being optimization events and user-level data availability (web has an advantage here) <a class="yt-timestamp" data-t="00:13:37">[00:13:37]</a>.
*   **Podcast-style Ads**: These ads, exemplified by Obvy and Headway (which uses an AI voice), leverage the authenticity and trust associated with podcasts, especially in the US <a class="yt-timestamp" data-t="00:14:46">[00:14:46]</a>. They don't immediately appear as ads, drawing attention and engagement <a class="yt-timestamp" data-t="00:15:17">[00:15:17]</a>.

## Foundations of a Successful Creative Testing Program
Building a successful Facebook ad account structure for performance requires several key elements:
1.  **Conversion API (CAPI)**: Using CAPI in addition to the pixel provides Facebook with more signal, leading to better algorithmic decisions for ad delivery <a class="yt-timestamp" data-t="00:16:31">[00:16:31]</a>. Without it, you could lose around 15% of your conversion data <a class="yt-timestamp" data-t="00:16:37">[00:16:37]</a>.
2.  **High Volume of Ad Variations**: Allow the audience to "vote" on the best ad by testing a large number of variations <a class="yt-timestamp" data-t="00:17:24">[00:17:24]</a>. Top-performing ads will naturally get more spend, while bottom performers will get none <a class="yt-timestamp" data-t="00:17:37">[00:17:37]</a>.
3.  **Low Cost per Creative**: This is critical for [[principles_of_creative_testing_campaigns | performance testing]] because most ads won't meet benchmarks <a class="yt-timestamp" data-t="00:17:46">[00:17:46]</a>. Keeping costs low enables [[creative_testing_in_facebook_ads | testing]] more ideas <a class="yt-timestamp" data-t="00:18:01">[00:18:01]</a>.
4.  **Never Stop Testing**: Brands often make the mistake of ceasing [[creative_testing_in_facebook_ads | testing]] after finding a winning ad <a class="yt-timestamp" data-t="00:18:08">[00:18:08]</a>. As spend increases, ads fatigue, so a continuous "army of new ads" is needed to sustain scale <a class="yt-timestamp" data-t="00:18:24">[00:18:24]</a>.

A recommended budget allocation for [[creative_testing_in_facebook_ads | creative testing]] is 10-20% of your total marketing budget, dedicated to always-on [[creative_testing_for_facebook_ads | creative testing]] <a class="yt-timestamp" data-t="00:19:03">[00:19:03]</a>. Automated triggers can ensure each ad receives minimum spend, preventing under-spending on ad tests <a class="yt-timestamp" data-t="00:19:16">[00:19:16]</a>.

## Research Phase for Creative Concepts
*   **Leverage Chat GPT for Reviews**: Upload your reviews to Chat GPT and ask it to find 20 concise five-star reviews for Facebook ads <a class="yt-timestamp" data-t="00:19:38">[00:19:38]</a>. These testimonials can be used as Loi static ads or incorporated into video ads <a class="yt-timestamp" data-t="00:19:51">[00:19:51]</a>. Calm, for example, tested 50 different testimonials to identify the top 3-5 performers to use across all video ads <a class="yt-timestamp" data-t="00:19:58">[00:19:58]</a>.
*   **Use "Gigabrain"**: A tool like "gigabrain" can be used to search for online discussions (e.g., Reddit threads) about your brand, category, or niche to understand the language people use <a class="yt-timestamp" data-t="00:20:43">[00:20:43]</a>. Using this authentic language in ads resonates better with the audience <a class="yt-timestamp" data-t="00:21:04">[00:21:04]</a>.
*   **Analyze Post/Ad Comments**: Similar to Reddit threads, comments on posts and ads reveal the language and pain points of your target audience <a class="yt-timestamp" data-t="00:21:30">[00:21:30]</a>.
*   **Monitor Ad Libraries**: Tools like Motion Creative Analytics (free ad library tracking tool) allow you to track brands doing high-volume, diverse [[creative_testing_in_facebook_ads | creative testing]] for inspiration <a class="yt-timestamp" data-t="00:22:00">[00:22:00]</a>. Examples include Headway, Loop Earplugs, Rise Superfoods, BetterMe, Rise Science, and Calm <a class="yt-timestamp" data-t="00:22:10">[00:22:10]</a>.

## Understanding Creative Diversity
[[Creative testing for Facebook ads | Creative diversity]] involves [[testing_and_iterating_ad_concepts | testing combinations]] of concepts and messages to find what works and then doubling down on those <a class="yt-timestamp" data-t="00:23:45">[00:23:45]</a>. A mind map approach can be used to brainstorm diverse creatives:
*   **Universal Human Motivators**: Start with these (e.g., from copywriting books) to determine angles <a class="yt-timestamp" data-t="00:23:59">[00:23:59]</a>.
*   **Stages of Awareness**: Consider the audience's awareness level (unaware, problem aware, solution aware, product aware, most aware) <a class="yt-timestamp" data-t="00:24:21">[00:24:21]</a>. For example, static ads with testimonials work well for lower-funnel audiences, while video ads with problem-solution scripts suit top-of-funnel <a class="yt-timestamp" data-t="00:24:30">[00:24:30]</a>.
*   **Messaging Frameworks**: Test different styles like listicles ("3 reasons why"), common myths, or problem-solution <a class="yt-timestamp" data-t="00:24:45">[00:24:45]</a>.
*   **Formats**: Once the message and angle are clear, explore various formats such as static ads (Post-it notes, Reddit post screenshots, iMessage conversations) or video formats (AI UGC, talking head UGC) <a class="yt-timestamp" data-t="00:25:06">[00:25:06]</a>.

## Creative Testing Setup (Nitty-Gritty)
A common and effective [[creative_testing_structure_for_meta_ads | creative testing structure]] involves:
*   **Separate Testing Campaign**: Dedicate a distinct campaign for [[creative_testing_for_facebook_ads | testing]] <a class="yt-timestamp" data-t="00:26:29">[00:26:29]</a>.
*   **Adset Concepts/Tests**: Within the testing campaign, create adsets for different concepts or tests <a class="yt-timestamp" data-t="00:26:35">[00:26:35]</a>.
*   **Ad Variations per Adset**: Aim for around 4-6 ad variations per adset <a class="yt-timestamp" data-t="00:26:41">[00:26:41]</a>. When [[testing_and_iterating_ad_concepts | testing]] specific elements like hooks, keep everything else consistent to accurately measure the variable being tested <a class="yt-timestamp" data-t="00:26:48">[00:26:48]</a>.
*   **Iteration and Greenlighting**: Ads that meet KPI goals (green ads) are sent to an Evergreen ad set <a class="yt-timestamp" data-t="00:27:08">[00:27:08]</a>. Iterate on "green" and "yellow" performing ads, while stopping iteration on "red" (non-performing) ones <a class="yt-timestamp" data-t="00:27:19">[00:27:19]</a>.
*   **Targeting and Budget**: Use broad country-level targeting for highest volume delivery <a class="yt-timestamp" data-t="00:27:26">[00:27:26]</a>. Start adsets with $100-$200/day <a class="yt-timestamp" data-t="00:27:30">[00:27:30]</a>. As mentioned, dedicate 10-20% of your Facebook budget to always-on [[creative_testing_in_facebook_ads | creative testing]] <a class="yt-timestamp" data-t="00:27:38">[00:27:38]</a>.
*   **Stop-Loss Triggers**: To ensure objective and cost-effective [[creative_testing_for_facebook_ads | testing]], set automated stop-loss triggers for ads in the testing campaign <a class="yt-timestamp" data-t="00:27:49">[00:27:49]</a>.
    *   **Gate 1**: Pause ad if spend reaches 3x CPA goal with zero conversions (e.g., $150 spend for a $50 CPA goal) <a class="yt-timestamp" data-t="00:28:01">[00:28:01]</a>.
    *   **Gate 2**: Pause ad if spend reaches 6x CPA goal with CPA still above a threshold (e.g., $300 spend for a $50 CPA goal, but CPA is over $75) <a class="yt-timestamp" data-t="00:28:36">[00:28:36]</a>.
    *   **Gate 3**: Pause ad if spend reaches a higher threshold with CPA still too high (e.g., $500 spend, CPA still $65) <a class="yt-timestamp" data-t="00:28:52">[00:28:52]</a>. These gates ensure each ad gets a minimum impression/reach level before a decision is made <a class="yt-timestamp" data-t="00:47:09">[00:47:09]</a>.

## Scaling Winning Ads (Evergreen Setup)
*   **Use Post IDs**: When moving winning ads from the testing campaign to Evergreen, use their Post IDs instead of duplicating them <a class="yt-timestamp" data-t="00:28:31">[00:28:31]</a>. Duplicating creates a new post and fragments social proof, whereas using Post IDs preserves engagement data <a class="yt-timestamp" data-t="00:28:40">[00:28:40]</a>.
*   **Bid Caps/Cost Caps**: Set bid caps or cost caps on Evergreen campaign adsets with a very high daily budget <a class="yt-timestamp" data-t="00:29:32">[00:29:32]</a>. This caps delivery by your cost goal, which is more effective for scaling than lowest cost setting or auto-bid <a class="yt-timestamp" data-t="00:29:47">[00:29:47]</a>.
*   **Broad Targeting**: Maintain broad targeting and exclude current subscribers <a class="yt-timestamp" data-t="00:30:05">[00:30:05]</a>.
*   **Fresh Creative**: Continuously pump the Evergreen ad sets with fresh creative <a class="yt-timestamp" data-t="00:30:08">[00:30:08]</a>.
*   **New Winner Adsets**: If new ads don't take off in an ad set with an existing winner (because Facebook focuses on the working ad), create a separate ad set specifically for new winners <a class="yt-timestamp" data-t="00:30:14">[00:30:14]</a>.
*   **Ads per Adset**: Aim for six ads per adset in Evergreen campaigns, as this has been found to be the sweet spot by Facebook and Smartly's data science team <a class="yt-timestamp" data-t="00:30:29">[00:30:29]</a>.
*   **Bid Multipliers API**: If you have a Facebook representative, get your account weightlisted for the bid multipliers API <a class="yt-timestamp" data-t="00:30:51">[00:30:51]</a>. This allows you to bid higher on high LTV (Lifetime Value) demographics (e.g., females over 40) and lower on low LTV demographics (e.g., 18-24), skewing algorithmic delivery towards valuable audiences <a class="yt-timestamp" data-t="00:31:01">[00:31:01]</a>.

## Measurement and Benchmarks
*   **Facebook's Free Ad Reporting Tool**: Utilize this tool for easy setup and monitoring <a class="yt-timestamp" data-t="00:31:38">[00:31:38]</a>.
*   **Color Codes**: Use color codes based on Cost Per Result (CPA) to quickly identify performance <a class="yt-timestamp" data-t="00:31:46">[00:31:46]</a>.
*   **Monitor Creative Hit Rate**: This is the number of creatives that meet your KPI/CPA goal divided by the number of creatives tested <a class="yt-timestamp" data-t="00:32:04">[00:32:04]</a>. A 10% creative hit rate is considered very good <a class="yt-timestamp" data-t="00:32:13">[00:32:13]</a>.
*   **Video Metrics Benchmarks**:
    *   **Hook Rate**: 3-second video view / impressions; aim for above 30% <a class="yt-timestamp" data-t="00:32:25">[00:32:25]</a>.
    *   **Hold Rate**: Through-play (15-second video view) / impressions; aim for around 10% <a class="yt-timestamp" data-t="00:32:33">[00:32:33]</a>.
    *   **Link Clickthrough Rate (CTR)**: Above 1% <a class="yt-timestamp" data-t="00:32:43">[00:32:43]</a>.
*   **Standardized Naming Convention**: Implement a standardized naming convention at the ad level to easily slice and dice data (e.g., in Excel with pivot tables) to identify working concepts (text hooks, visual hooks, etc.) <a class="yt-timestamp" data-t="00:32:48">[00:32:48]</a>.

**Key Principle**: Always keep an open mind and never stop [[creative_testing_in_facebook_ads | testing]] because you never know which creative will work <a class="yt-timestamp" data-t="00:33:14">[00:33:14]</a>.

---

## Q&A Highlights
*   **[[frequency_of_creative_testing_in_ads | Frequency of creative testing]]**: Have an "always-on" [[creative_testing_in_facebook_ads | creative testing]] campaign to continuously feed fresh creative into Evergreen adsets <a class="yt-timestamp" data-t="00:34:01">[00:34:01]</a>. When winning ads show signs of fatigue (e.g., CTR drop, CPA increase), pause them, leveraging pre-tested ads <a class="yt-timestamp" data-t="00:34:11">[00:34:11]</a>. Monitor rolling averages (7-14 days) before making decisions <a class="yt-timestamp" data-t="00:34:24">[00:34:24]</a>.
*   **CBO vs. Adset Budget**: The choice between CBO (Campaign Budget Optimization) and adset budget is less critical <a class="yt-timestamp" data-t="00:35:03">[00:35:03]</a>. The recommendation is to use bid caps or cost caps on Evergreen adsets with very high daily budgets to cap delivery by your cost goal <a class="yt-timestamp" data-t="00:35:20">[00:35:20]</a>.
*   **Ratio of New Concepts to Variations**: Start with a 50/50 mix of new concepts and iterations <a class="yt-timestamp" data-t="00:35:56">[00:35:56]</a>. If performance is struggling, consider a 70/30 split favoring brand new concepts to find new "local maximums" <a class="yt-timestamp" data-t="00:36:10">[00:36:10]</a>.
*   **[[creative_testing_for_facebook_ads | Testing]] with iOS 14**: One drawback of running Scan attribution for iOS campaigns is slower feedback <a class="yt-timestamp" data-t="00:36:43">[00:36:43]</a>. It's recommended to use Facebook's Aggregated Event Management (AEM) for iOS [[creative_testing_in_facebook_ads | testing]] as it provides a faster feedback loop and immediate data in ad-level reporting <a class="yt-timestamp" data-t="00:37:19">[00:37:19]</a>. Web campaigns still offer the advantage of user-level data <a class="yt-timestamp" data-t="00:37:03">[00:37:03]</a>.
*   **[[creative_testing_in_facebook_ads | Testing]] in AA+ Campaigns**: Some brands successfully test by uploading up to 50 ads into one Automated Shopping Campaign (ASC), a "Battle Royale" style <a class="yt-timestamp" data-t="00:38:13">[00:38:13]</a>. However, be mindful of "trial to purchase" rates, as ad concepts can have very different rates, and it can be less clear what exactly is working and why <a class="yt-timestamp" data-t="00:38:52">[00:38:52]</a>.
*   **Minimum Budget for App Developers**: A recommended starting budget for app developers to realistically see results is around $20K-$30K per month <a class="yt-timestamp" data-t="00:39:44">[00:39:44]</a>. Expectations should be managed for the first few weeks as new concepts, funnels, and landing pages are being tested <a class="yt-timestamp" data-t="00:40:14">[00:40:14]</a>.
*   **Flexible/Dynamic Creative Ads**: This method involves uploading multiple videos or images, text variations, and headlines into the same ad unit <a class="yt-timestamp" data-t="00:40:49">[00:40:49]</a>. While effective for [[creative_testing_in_facebook_ads | testing]] and scaling, a drawback is the inability to get the post ID from individual ad variations <a class="yt-timestamp" data-t="00:41:17">[00:41:17]</a>.
*   **Success Rate for [[creative_testing_for_facebook_ads | Creative Testing]]**: A good benchmark is a 10% creative win rate (1 out of every 10 ads tested hits CPA goal) <a class="yt-timestamp" data-t="00:42:02">[00:42:02]</a>. The speaker cautions against underspending on ad tests, which leads to insufficient data per variation <a class="yt-timestamp" data-t="00:42:48">[00:42:48]</a>.
*   **Launching Campaigns with Bid/Cost Caps**: Both bid caps and cost caps can work <a class="yt-timestamp" data-t="00:43:07">[00:43:07]</a>. With cost caps, start 25-30% above your CPA goal <a class="yt-timestamp" data-t="00:43:31">[00:43:31]</a>. With bid caps, start high and then decrease if daily budget is maxed out <a class="yt-timestamp" data-t="00:43:45">[00:43:45]</a>. When changing bid caps, a general rule of thumb is to adjust by about 20% per day <a class="yt-timestamp" data-t="00:44:08">[00:44:08]</a>. Monitor hourly delivery to avoid underbidding <a class="yt-timestamp" data-t="00:44:27">[00:44:27]</a>.
*   **Most Impactful Creative Elements**: Messaging is considered the most important piece, followed by visuals <a class="yt-timestamp" data-t="00:45:04">[00:45:04]</a>. A 60% message / 40% visual split of importance is suggested <a class="yt-timestamp" data-t="00:45:12">[00:45:12]</a>. Agencies often A/B test visual hooks with text hooks to pinpoint what works <a class="yt-timestamp" data-t="00:45:26">[00:45:26]</a>.
*   **Conversions for Creative Parts Tested**: Refer to the stop-loss triggers detailed above <a class="yt-timestamp" data-t="00:46:06">[00:46:06]</a>. This method provides a balance between testing volume and confidence in the data, as requiring 20 conversions per ad would severely limit the number of ads that could be tested <a class="yt-timestamp" data-t="00:47:20">[00:47:20]</a>.