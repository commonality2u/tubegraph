---
title: Steps and processes involved in creating automated research reports
videoId: aEOu9P4_2cU
---

From: [[amiteshanand]] <br/> 

The "Open Deep Think Researcher" is an open-source tool designed to automate the process of generating research reports, similar to OpenAI's Deep Research but without the associated high cost <a class="yt-timestamp" data-t="00:04:00">[00:04:00]</a>, <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a>, <a class="yt-timestamp" data-t="10:25:00">[10:25:00]</a>. It leverages [[using_thirdparty_tools_in_ai_development | various third-party tools]] and large language models (LLMs) to conduct automated research and compile comprehensive reports on any given query <a class="yt-timestamp" data-t="01:17:00">[01:17:00]</a>.

## Core Process of Automated Research

The system follows a sequential, iterative workflow to generate research reports <a class="yt-timestamp" data-t="00:51:00">[00:51:00]</a>, <a class="yt-timestamp" data-t="00:56:00">[00:56:00]</a>:

1.  **Query Generation** <a class="yt-timestamp" data-t="01:23:00">[01:23:00]</a>: The AI first generates specific search queries based on the user's input topic.
2.  **Iterative Refinement** <a class="yt-timestamp" data-t="01:25:00">[01:25:00]</a>: It then runs multiple iterations to refine and improve the quality of the search results.
3.  **Information Extraction** <a class="yt-timestamp" data-t="01:30:00">[01:30:00]</a>: Relevant information is identified and extracted from the search results.
4.  **Final Report Generation** <a class="yt-timestamp" data-t="01:34:00">[01:34:00]</a>: A final report is generated by the AI, synthesizing all collected context and data <a class="yt-timestamp" data-t="01:38:00">[01:38:00]</a>.

## Key Components and Technologies

The "Open Deep Think Researcher" integrates several APIs and models to achieve its functionality <a class="yt-timestamp" data-t="00:57:00">[00:57:00]</a>:

*   **Deep Seek R1 (via NVS AI Studio)** <a class="yt-timestamp" data-t="00:58:00">[00:58:00]</a>, <a class="yt-timestamp" data-t="01:07:00">[01:07:00]</a>: Used for LLM processing, inference, and iterative thinking <a class="yt-timestamp" data-t="02:27:00">[02:27:00]</a>. NVS AI Studio provides an inference provider service with multiple LLM models <a class="yt-timestamp" data-t="02:16:00">[02:16:00]</a>.
*   **XA Search API** <a class="yt-timestamp" data-t="01:09:00">[01:09:00]</a>: Performs web searches, crawls pages, and retrieves the latest information for the LLM to process <a class="yt-timestamp" data-t="02:41:00">[02:41:00]</a>.
*   **Gradio UI** <a class="yt-timestamp" data-t="01:42:00">[01:42:00]</a>: Provides the user interface for inputting queries and displaying results, typically run in a Colab notebook but deployable as a Python app <a class="yt-timestamp" data-t="01:44:00">[01:44:00]</a>, <a class="yt-timestamp" data-t="01:49:00">[01:49:00]</a>.

To run the project, users need API keys for NVS AI Studio and XA Search <a class="yt-timestamp" data-t="01:57:00">[01:57:00]</a>.

## Detailed Workflow Steps

The operation of the research tool involves several distinct steps, each contributing to the final report:

1.  **User Input** <a class="yt-timestamp" data-t="02:54:00">[02:54:00]</a>: The user provides a research query and sets the number of iterations (maximum of 10 to manage processing time) <a class="yt-timestamp" data-t="02:57:00">[02:57:00]</a>.
2.  **Initial Search Query Generation** <a class="yt-timestamp" data-t="05:51:00">[05:51:00]</a>: The system, acting as an expert research assistant, generates four distinct search queries to gather comprehensive information on the topic <a class="yt-timestamp" data-t="05:53:00">[05:53:00]</a>.
3.  **Content Retrieval and Evaluation** <a class="yt-timestamp" data-t="03:05:00">[03:05:00]</a>:
    *   XA Search retrieves content from the web <a class="yt-timestamp" data-t="03:05:00">[03:05:00]</a>.
    *   The LLM (Deep Seek R1 via NVS AI Studio) evaluates the relevance of web pages to the initial query <a class="yt-timestamp" data-t="03:08:00">[03:08:00]</a>, responding with a "yes" or "no" to indicate usefulness <a class="yt-timestamp" data-t="06:14:00">[06:14:00]</a>.
    *   Useful information is extracted from relevant pages <a class="yt-timestamp" data-t="03:10:00">[03:10:00]</a>.
4.  **Iterative Processing** <a class="yt-timestamp" data-t="02:55:00">[02:55:00]</a>: This cycle of searching, evaluating, and extracting is repeated for the specified number of iterations, aggregating unique links and processing content <a class="yt-timestamp" data-t="06:44:00">[06:44:00]</a>, <a class="yt-timestamp" data-t="07:18:00">[07:18:00]</a>.
5.  **Final Report Compilation** <a class="yt-timestamp" data-t="03:13:00">[03:13:00]</a>: All collected and processed information is compiled into a final search report by the LLM <a class="yt-timestamp" data-t="08:40:00">[08:40:00]</a>. The report includes details and a conclusion <a class="yt-timestamp" data-t="08:00:00">[08:00:00]</a>.

### Example Report Generation Flow

For a query like "what happened around the world yesterday" (February 18, 2025), the process includes <a class="yt-timestamp" data-t="04:34:00">[04:34:00]</a>, <a class="yt-timestamp" data-t="04:48:00">[04:48:00]</a>:

*   **Generating initial search queries**: e.g., "Global events on February 18th 2025" <a class="yt-timestamp" data-t="06:38:00">[06:38:00]</a>.
*   **Iteration 1**: Aggregates unique links (e.g., 29 links), processing content from various sources like Wikipedia and Reuters, and evaluating their usefulness <a class="yt-timestamp" data-t="06:44:00">[06:44:00]</a>.
*   **Iteration 2**: Aggregates more unique links (e.g., 36 links) and continues evaluating usefulness of pages <a class="yt-timestamp" data-t="07:18:00">[07:18:00]</a>.
*   **Final Report**: Presents a "Global Events Report" including details like "Middle Tension and Conflict," "AI Incident Delta Airline Crash," and "Geopolitical US Talks in Saudi Arabia," with a conclusion <a class="yt-timestamp" data-t="07:40:00">[07:40:00]</a>.

## Optimizations and Future Improvements

The current implementation is optimized for speed by instructing the LLM to process only the first 200 characters of web page content for relevance evaluation <a class="yt-timestamp" data-t="09:01:00">[09:01:00]</a>, <a class="yt-timestamp" data-t="09:10:00">[09:10:00]</a>. While this speeds up the process (e.g., 45 seconds for a report), it can reduce the depth of analysis compared to processing 2,000 or 20,000 characters <a class="yt-timestamp" data-t="09:14:00">[09:14:00]</a>, <a class="yt-timestamp" data-t="09:19:00">[09:19:00]</a>.

Potential improvements for the project include [[professional_workflow_improvements | professional workflow improvements]] <a class="yt-timestamp" data-t="09:48:00">[09:48:00]</a>:

*   **LLM Model Selection** <a class="yt-timestamp" data-t="09:51:00">[09:51:00]</a>: Allowing users to choose different LLM models available via NVS AI Studio, instead of just Deep Seek R1 <a class="yt-timestamp" data-t="09:54:00">[09:54:00]</a>.
*   **Full-Stack Deployment** <a class="yt-timestamp" data-t="01:50:00">[01:50:00]</a>, <a class="yt-timestamp" data-t="10:05:00">[10:05:00]</a>: Deploying the application as a full-stack Python application using frameworks like Reflex or Streamlit <a class="yt-timestamp" data-t="10:07:00">[10:07:00]</a>.
*   **Adjustable Character Limits** <a class="yt-timestamp" data-t="10:10:00">[10:10:00]</a>: Providing options in the UI to increase the character limit for page content processing (e.g., 2,000, 5,000, or 20,000 words) for more detailed analysis, though this would impact API usage and pricing <a class="yt-timestamp" data-t="10:13:00">[10:13:00]</a>.

The project emphasizes that its open-source nature allows for continuous iteration and optimization to make it more useful, optimized, and faster <a class="yt-timestamp" data-t="10:31:00">[10:31:00]</a>.