---
title: Leveraging AI for Star Wars Data Retrieval and Image Generation
videoId: H-3VJ7usA58
---

From: [[amiteshanand]] <br/> 

The Model Context Protocol (MCP) is an open-source framework launched by Anthropic, the company behind the large model [[aibased_language_and_voice_generation | Claude]], which has seen significant adoption since its launch three months prior to this discussion <a class="yt-timestamp" data-t="00:00:00">[00:00:00]</a><a class="yt-timestamp" data-t="00:00:05">[00:00:05]</a><a class="yt-timestamp" data-t="00:00:06">[00:00:06]</a><a class="yt-timestamp" data-t="00:00:08">[00:00:08]</a><a class="yt-timestamp" data-t="00:00:11">[00:00:11]</a>. MCP addresses a fundamental shift in how users interact with AI systems, moving beyond simple text generation towards [[using_deep_learning_models_for_content_generation | agentic AI]] <a class="yt-timestamp" data-t="00:00:25">[00:00:25]</a><a class="yt-timestamp" data-t="00:00:27">[00:00:27]</a><a class="yt-timestamp" data-t="00:00:28">[00:00:28]</a>.

## Agentic AI and Tool Calling

Traditionally, large language models (LLMs) like [[aibased_language_and_voice_generation | Claude]] or ChatGPT primarily generate text responses to user queries <a class="yt-timestamp" data-t="00:00:16">[00:00:16]</a><a class="yt-timestamp" data-t="00:00:18">[00:00:18]</a><a class="yt-timestamp" data-t="00:00:19">[00:00:19]</a>. However, [[using_deep_learning_models_for_content_generation | agentic AI]] systems allow these models to access external tools, enabling them to carry out tasks beyond just text generation <a class="yt-timestamp" data-t="00:00:31">[00:00:31]</a><a class="yt-timestamp" data-t="00:00:33">[00:00:33]</a><a class="yt-timestamp" data-t="00:00:36">[00:00:36]</a><a class="yt-timestamp" data-t="00:00:38">[00:00:38]</a>.

### What is Tool Calling?
Tool calling is a core concept where LLMs are given access to external databases, APIs, and other tools <a class="yt-timestamp" data-t="00:00:41">[00:00:41]</a><a class="yt-timestamp" data-t="00:00:43">[00:00:43]</a><a class="yt-timestamp" data-t="00:00:57">[00:00:57]</a><a class="yt-timestamp" data-t="00:00:58">[00:00:58]</a>. This means LLMs can retrieve real-time API data or information from a database, which wouldn't be possible otherwise <a class="yt-timestamp" data-t="00:00:49">[00:00:49]</a><a class="yt-timestamp" data-t="00:00:50">[00:00:50]</a><a class="yt-timestamp" data-t="00:00:54">[00:00:54]</a><a class="yt-timestamp" data-t="00:00:57">[00:00:57]</a>.

Based on a user's input query, the LLM analyzes it to determine whether to provide a text-based response or to use an available tool to augment its response, provide real-time updates, or access proprietary data <a class="yt-timestamp" data-t="00:01:05">[00:01:05]</a><a class="yt-timestamp" data-t="00:01:07">[00:01:07]</a><a class="yt-timestamp" data-t="00:01:09">[00:01:09]</a><a class="yt-timestamp" data-t="00:01:11">[00:01:11]</a><a class="yt-timestamp" data-t="00:01:13">[00:01:13]</a><a class="yt-timestamp" data-t="00:01:15">[00:01:15]</a><a class="yt-timestamp" data-t="00:01:17">[00:01:17]</a><a class="yt-timestamp" data-t="00:01:19">[00:01:19]</a><a class="yt-timestamp" data-t="00:01:21">[00:01:21]</a>. This capability expands the potential use cases for LLMs significantly <a class="yt-timestamp" data-t="00:01:35">[00:01:35]</a>.

## Building a Model Context Protocol (MCP) Server

MCP servers can be built using TypeScript SDK or Python SDK to define the tools an LLM like [[aibased_language_and_voice_generation | Claude]] can leverage <a class="yt-timestamp" data-t="00:01:40">[00:01:40]</a><a class="yt-timestamp" data-t="00:01:42">[00:01:42]</a><a class="yt-timestamp" data-t="00:01:45">[00:01:45]</a><a class="yt-timestamp" data-t="00:01:47">[00:01:47]</a>. When these tools are defined, [[aibased_language_and_voice_generation | Claude]] (e.g., in its desktop application) can automatically identify them <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a><a class="yt-timestamp" data-t="00:03:01">[00:03:01]</a><a class="yt-timestamp" data-t="00:03:02">[00:03:02]</a>. Based on the user's prompt, [[aibased_language_and_voice_generation | Claude]] intelligently decides whether to use a tool and then executes its functionality <a class="yt-timestamp" data-t="00:03:03">[00:03:03]</a><a class="yt-timestamp" data-t="00:03:05">[00:03:05]</a><a class="yt-timestamp" data-t="00:03:06">[00:03:06]</a><a class="yt-timestamp" data-t="00:03:08">[00:03:08]</a><a class="yt-timestamp" data-t="00:03:09">[00:03:09]</a>.

### Schema and Tool Definition
MCP requires a JSON input schema for tools to understand how to process user prompts <a class="yt-timestamp" data-t="00:03:30">[00:03:30]</a><a class="yt-timestamp" data-t="00:03:31">[00:03:31]</a><a class="yt-timestamp" data-t="00:03:33">[00:03:33]</a>. For TypeScript, Zod is used for type safety and to define types, which are then converted to JSON schema <a class="yt-timestamp" data-t="00:03:22">[00:03:22]</a><a class="yt-timestamp" data-t="00:03:24">[00:03:24]</a><a class="yt-timestamp" data-t="00:03:26">[00:03:26]</a><a class="yt-timestamp" data-t="00:03:52">[00:03:52]</a><a class="yt-timestamp" data-t="00:03:53">[00:03:53]</a><a class="yt-timestamp" data-t="00:03:55">[00:03:55]</a><a class="yt-timestamp" data-t="00:03:56">[00:03:56]</a><a class="yt-timestamp" data-t="00:03:58">[00:03:58]</a>. The model then generates responses based on JSON, which is sent back to the LLM for augmentation <a class="yt-timestamp" data-t="00:03:44">[00:03:44]</a><a class="yt-timestamp" data-t="00:03:45">[00:03:45]</a><a class="yt-timestamp" data-t="00:03:46">[00:03:46]</a><a class="yt-timestamp" data-t="00:03:48">[00:03:48]</a>. The `server.setRequestHandler` method is used to define the list of available tools <a class="yt-timestamp" data-t="00:04:47">[00:04:47]</a><a class="yt-timestamp" data-t="00:04:50">[00:04:50]</a><a class="yt-timestamp" data-t="00:05:51">[00:05:51]</a><a class="yt-timestamp" data-t="00:05:53">[00:05:53]</a>. The tool's name and description are crucial for the LLM to identify the most relevant tool for a given input prompt <a class="yt-timestamp" data-t="00:05:13">[00:05:13]</a><a class="yt-timestamp" data-t="00:05:16">[00:05:16]</a><a class="yt-timestamp" data-t="00:05:17">[00:05:17]</a><a class="yt-timestamp" data-t="00:05:19">[00:05:19]</a>.

## Star Wars Data Retrieval and Image Generation Example

An MCP server can be built to retrieve Star Wars planet data and generate images of planets <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a><a class="yt-timestamp" data-t="00:02:05">[00:02:05]</a><a class="yt-timestamp" data-t="00:02:08">[00:02:08]</a>.

### Defined Tools:
The example server defines four key tools for [[aibased_language_and_voice_generation | Claude]] <a class="yt-timestamp" data-t="00:13:32">[00:13:32]</a><a class="yt-timestamp" data-t="00:13:34">[00:13:34]</a>:

*   **`fetchPlanetName`**: Retrieves details about a specific Star Wars planet from a Couchbase database <a class="yt-timestamp" data-t="00:04:55">[00:04:55]</a><a class="yt-timestamp" data-t="00:04:57">[00:04:57]</a><a class="yt-timestamp" data-t="00:06:26">[00:06:26]</a><a class="yt-timestamp" data-t="00:06:28">[00:06:28]</a>.
*   **`findSimilarPlanets`**: Uses vector search to identify planets with similar characteristics from the Couchbase database <a class="yt-timestamp" data-t="00:06:32">[00:06:32]</a><a class="yt-timestamp" data-t="00:06:34">[00:06:34]</a><a class="yt-timestamp" data-t="00:06:37">[00:06:37]</a><a class="yt-timestamp" data-t="00:06:39">[00:06:39]</a><a class="yt-timestamp" data-t="00:06:41">[00:06:41]</a><a class="yt-timestamp" data-t="00:06:43">[00:06:43]</a><a class="yt-timestamp" data-t="00:06:45">[00:06:45]</a>.
*   **`generatePlanetImage`**: Creates a realistic image of a planet using [[text_and_image_generation_using_nebius_ai_models | Nebius AI Studio]] <a class="yt-timestamp" data-t="00:06:48">[00:06:48]</a><a class="yt-timestamp" data-t="00:06:50">[00:06:50]</a><a class="yt-timestamp" data-t="00:06:51">[00:06:51]</a><a class="yt-timestamp" data-t="00:06:53">[00:06:53]</a><a class="yt-timestamp" data-t="00:06:57">[00:06:57]</a><a class="yt-timestamp" data-t="00:06:59">[00:06:59]</a>.

When a user provides a prompt, [[aibased_language_and_voice_generation | Claude]] identifies the appropriate tool (or tools) to use <a class="yt-timestamp" data-t="00:05:01">[00:05:01]</a><a class="yt-timestamp" data-t="00:05:02">[00:05:02]</a><a class="yt-timestamp" data-t="00:05:04">[00:05:04]</a><a class="yt-timestamp" data-t="00:05:05">[00:05:05]</a><a class="yt-timestamp" data-t="00:05:06">[00:05:06]</a>. A `switch` case handles function calling based on the identified tool, executing the corresponding request handler <a class="yt-timestamp" data-t="00:06:05">[00:06:05]</a><a class="yt-timestamp" data-t="00:06:07">[00:06:07]</a><a class="yt-timestamp" data-t="00:06:08">[00:06:08]</a><a class="yt-timestamp" data-t="00:06:09">[00:06:09]</a><a class="yt-timestamp" data-t="00:06:10">[00:06:10]</a>.

### Data Retrieval with Couchbase
The `getCharacter` function retrieves planet details from a Couchbase database by matching the planet name from the input query <a class="yt-timestamp" data-t="00:07:33">[00:07:33]</a><a class="yt-timestamp" data-t="00:07:35">[00:07:35]</a><a class="yt-timestamp" data-t="00:07:37">[00:07:37]</a><a class="yt-timestamp" data-t="00:07:39">[00:07:39]</a><a class="yt-timestamp" data-t="00:07:41">[00:07:41]</a>. To find similar planets, the system retrieves the embedding for the input planet and performs a vector search within Couchbase <a class="yt-timestamp" data-t="00:07:52">[00:07:52]</a><a class="yt-timestamp" data-t="00:07:53">[00:07:53]</a><a class="yt-timestamp" data-t="00:07:54">[00:07:54]</a><a class="yt-timestamp" data-t="00:07:55">[00:07:55]</a><a class="yt-timestamp" data-t="00:07:57">[00:07:57]</a><a class="yt-timestamp" data-t="00:08:00">[00:08:00]</a><a class="yt-timestamp" data-t="00:08:02">[00:08:02]</a>. This identifies the most closely matching vectors/embeddings, representing planets with similar features, and returns their details along with a match score <a class="yt-timestamp" data-t="00:08:20">[00:08:20]</a><a class="yt-timestamp" data-t="00:08:23">[00:08:23]</a><a class="yt-timestamp" data-t="00:08:25">[00:08:25]</a><a class="yt-timestamp" data-t="00:08:27">[00:08:27]</a><a class="yt-timestamp" data-t="00:08:28">[00:08:28]</a><a class="yt-timestamp" data-t="00:08:30">[00:08:30]</a><a class="yt-timestamp" data-t="00:08:32">[00:08:32]</a><a class="yt-timestamp" data-t="00:08:33">[00:08:33]</a><a class="yt-timestamp" data-t="00:08:34">[00:08:34]</a>.

### Image Generation with [[text_and_image_generation_using_nebius_ai_models | Nebius AI Studio]]
For image generation, [[text_and_image_generation_using_nebius_ai_models | Nebius AI Studio]] is utilized <a class="yt-timestamp" data-t="00:08:52">[00:08:52]</a><a class="yt-timestamp" data-t="00:08:54">[00:08:54]</a><a class="yt-timestamp" data-t="00:08:57">[00:08:57]</a>. [[text_and_image_generation_using_nebius_ai_models | Nebius AI Studio]] offers various open-source large language models for tasks like text-to-text generation (e.g., Lama 3, DeepSeek R1, DeepSeek V3) and embedding generation <a class="yt-timestamp" data-t="00:08:58">[00:08:58]</a><a class="yt-timestamp" data-t="00:08:59">[00:08:59]</a><a class="yt-timestamp" data-t="00:09:01">[00:09:01]</a><a class="yt-timestamp" data-t="00:09:03">[00:09:03]</a><a class="yt-timestamp" data-t="00:09:05">[00:09:05]</a><a class="yt-timestamp" data-t="00:09:06">[00:09:06]</a><a class="yt-timestamp" data-t="00:09:09">[00:09:09]</a><a class="yt-timestamp" data-t="00:09:10">[00:09:10]</a><a class="yt-timestamp" data-t="00:09:12">[00:09:12]</a><a class="yt-timestamp" data-t="00:09:13">[00:09:13]</a><a class="yt-timestamp" data-t="00:09:15">[00:09:15]</a>. Specifically, the text-to-image model, Flux, is used <a class="yt-timestamp" data-t="00:09:17">[00:09:17]</a><a class="yt-timestamp" data-t="00:09:19">[00:09:19]</a><a class="yt-timestamp" data-t="00:09:23">[00:09:23]</a><a class="yt-timestamp" data-t="00:09:25">[00:09:25]</a>. The [[api_integration_with_nvs_ai_studio_for_model_usage | OpenAI client]] is initialized with the [[api_integration_with_nvs_ai_studio_for_model_usage | Nebius AI Studio]] URL and an API key <a class="yt-timestamp" data-t="00:09:25">[00:09:25]</a><a class="yt-timestamp" data-t="00:09:27">[00:09:27]</a><a class="yt-timestamp" data-t="00:09:28">[00:09:28]</a><a class="yt-timestamp" data-t="00:09:31">[00:09:31]</a>. The `clients.images.generate` function is called with a prompt (e.g., "realistic astronomical image of a Star Wars planet with the given name"), specifying the Flux model and requesting a base64 response, which is the type accepted by MCP <a class="yt-timestamp" data-t="00:09:34">[00:09:34]</a><a class="yt-timestamp" data-t="00:09:37">[00:09:37]</a><a class="yt-timestamp" data-t="00:09:38">[00:09:38]</a><a class="yt-timestamp" data-t="00:09:40">[00:09:40]</a><a class="yt-timestamp" data-t="00:09:42">[00:09:42]</a><a class="yt-timestamp" data-t="00:09:44">[00:09:44]</a><a class="yt-timestamp" data-t="00:09:46">[00:09:46]</a><a class="yt-timestamp" data-t="00:09:47">[00:09:47]</a><a class="yt-timestamp" data-t="00:09:49">[00:09:49]</a><a class="yt-timestamp" data-t="00:09:51">[00:09:51]</a><a class="yt-timestamp" data-t="00:09:53">[00:09:53]</a><a class="yt-timestamp" data-t="00:09:56">[00:09:56]</a>.

### Demonstration Workflow
When a user asks [[aibased_language_and_voice_generation | Claude]], "Show me planets that are probably similar to the planet Alderaan and include an image of Alderaan," the MCP workflow unfolds as follows <a class="yt-timestamp" data-t="00:10:31">[00:10:31]</a><a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a><a class="yt-timestamp" data-t="00:10:34">[00:10:34]</a><a class="yt-timestamp" data-t="00:10:36">[00:10:36]</a>:

1.  [[aibased_language_and_voice_generation | Claude]] identifies the need to use the "find similar planets" tool <a class="yt-timestamp" data-t="00:11:14">[00:11:14]</a>.
2.  It fetches Alderaan's data from the Couchbase database <a class="yt-timestamp" data-t="00:11:41">[00:11:41]</a><a class="yt-timestamp" data-t="00:11:43">[00:11:43]</a>.
3.  It then uses vector search to find the top similar planets to Alderaan, providing a match score <a class="yt-timestamp" data-t="00:11:45">[00:11:45]</a><a class="yt-timestamp" data-t="00:11:47">[00:11:47]</a><a class="yt-timestamp" data-t="00:11:50">[00:11:50]</a><a class="yt-timestamp" data-t="00:11:52">[00:11:52]</a><a class="yt-timestamp" data-t="00:11:54">[00:11:54]</a>.
4.  Concurrently, [[aibased_language_and_voice_generation | Claude]] calls the "generate planet image" tool <a class="yt-timestamp" data-t="00:11:21">[00:11:21]</a><a class="yt-timestamp" data-t="00:11:24">[00:11:24]</a><a class="yt-timestamp" data-t="00:11:25">[00:11:25]</a>.
5.  Based on Alderaan's description, [[text_and_image_generation_using_nebius_ai_models | Nebius AI Studio]] (using the Flux model) generates a realistic image of the planet <a class="yt-timestamp" data-t="00:12:06">[00:12:06]</a><a class="yt-timestamp" data-t="00:12:07">[00:12:07]</a><a class="yt-timestamp" data-t="00:12:09">[00:12:09]</a><a class="yt-timestamp" data-t="00:12:11">[00:12:11]</a><a class="yt-timestamp" data-t="00:12:14">[00:12:14]</a>.
6.  Finally, [[aibased_language_and_voice_generation | Claude]] uses the JSON output from the tool calls to render an enriched response, including the generated image and details about similar planets (climate, terrain, etc.) <a class="yt-timestamp" data-t="00:12:18">[00:12:18]</a><a class="yt-timestamp" data-t="00:12:20">[00:12:20]</a><a class="yt-timestamp" data-t="00:12:21">[00:12:21]</a><a class="yt-timestamp" data-t="00:12:24">[00:12:24]</a><a class="yt-timestamp" data-t="00:12:26">[00:12:26]</a><a class="yt-timestamp" data-t="00:12:29">[00:12:29]</a><a class="yt-timestamp" data-t="00:12:30">[00:12:30]</a><a class="yt-timestamp" data-t="00:12:32">[00:12:32]</a><a class="yt-timestamp" data-t="00:12:33">[00:12:33]</a><a class="yt-timestamp" data-t="00:12:36">[00:12:36]</a>.

## Expanding AI Capabilities with MCP

MCP allows LLMs like [[aibased_language_and_voice_generation | Claude]] to transcend their inherent text-generation limitations by accessing external databases and making API calls <a class="yt-timestamp" data-t="00:12:50">[00:12:50]</a><a class="yt-timestamp" data-t="00:12:52">[00:12:52]</a><a class="yt-timestamp" data-t="00:12:53">[00:12:53]</a><a class="yt-timestamp" data-t="00:12:55">[00:12:55]</a><a class="yt-timestamp" data-t="00:12:58">[00:12:58]</a><a class="yt-timestamp" data-t="00:13:00">[00:13:00]</a><a class="yt-timestamp" data-t="00:13:02">[00:13:02]</a>. This opens up vast possibilities for [[integrating_ai_tools_for_blogging_efficiency | AI tools for video creation]] and content generation <a class="yt-timestamp" data-t="00:13:05">[00:13:05]</a>. For instance, an LLM could check current weather, use an external API to order clothes based on conditions, and arrange delivery by accessing payment and address information <a class="yt-timestamp" data-t="00:13:06">[00:13:06]</a><a class="yt-timestamp" data-t="00:13:08">[00:13:08]</a><a class="yt-timestamp" data-t="00:13:10">[00:13:10]</a><a class="yt-timestamp" data-t="00:13:11">[00:13:11]</a><a class="yt-timestamp" data-t="00:13:13">[00:13:13]</a><a class="yt-timestamp" data-t="00:13:14">[00:13:14]</a><a class="yt-timestamp" data-t="00:13:16">[00:13:16]</a><a class="yt-timestamp" data-t="00:13:18">[00:13:18]</a><a class="yt-timestamp" data-t="00:13:20">[00:13:20]</a>. The ability to integrate with any API makes the applications limitless <a class="yt-timestamp" data-t="00:13:22">[00:13:22]</a><a class="yt-timestamp" data-t="00:13:23">[00:13:23]</a><a class="yt-timestamp" data-t="00:13:25">[00:13:25]</a>. MCP allows for the easy construction of [[using_deep_learning_models_for_content_generation | agentic workflows]], where LLMs can not only generate text but also access external data and tools to enhance their responses and capabilities <a class="yt-timestamp" data-t="00:14:09">[00:14:09]</a><a class="yt-timestamp" data-t="00:14:12">[00:14:12]</a><a class="yt-timestamp" data-t="00:14:13">[00:14:13]</a><a class="yt-timestamp" data-t="00:14:14">[00:14:14]</a><a class="yt-timestamp" data-t="00:14:16">[00:14:16]</a><a class="yt-timestamp" data-t="00:14:18">[00:14:18]</a>.